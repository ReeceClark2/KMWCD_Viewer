 1/1: ls
 1/2: f = file('CCOMCasterSourceTable.txt')
 1/3: a = f.open()
 1/4: a = f.read?
 1/5: a = f.read()
 1/6: print a
 1/7: a
 1/8: ls
 1/9: b = file("Euref-IPCasterTable.txt")
1/10: c = b.read()
1/11: c
1/12: print c
1/13: Server: NTRIP BKG Caster 2.0.24/2.0
1/14: Date: Wed, 17 Jun 2015 15:09:31 GMT
1/15: Connection: close
1/16: Content-Type: text/plain
 2/1: import glob
 2/2: glob?
 2/3: cd /Volumes/assets/Gavia_Dora/adminscripts/
 2/4: dirs = glob.glob('../dataproducts/[0-9]*/*')
 2/5: print dirs
 2/6: dirs = glob.glob('../dataproducts/[0-9]*/*')
 2/7: print dirs
 2/8: dirs = glob.glob('../dataproducts/[0-9]..../*')
 2/9: print dirs
2/10: dirs = glob.glob('../dataproducts/[0-9]/*')
2/11: print dirs
2/12: dirs = glob.glob('../dataproducts/[0-9]*/*')
2/13: print dirs
2/14: from shutil import copytree
2/15: pwd
2/16: ls
2/17: copytree('templates/','../dataproducts/2014/20140914/')
2/18: copytree('templates/directorytree/','../dataproducts/2014/20140914_IM/')
2/19: copytree('templates/directorytree/','../dataproducts/2014/20140914_IM/')
2/20: print dirs
2/21: from distutils.dir_util import copy_tree
2/22: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/')
2/23: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/')
2/24: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/')
2/25: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/')
2/26: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/',verbose=1)
2/27: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/',verbose=1)
2/28: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/',verbose=1)
2/29: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/')
2/30: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/')
2/31: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/',verbose=1)
2/32: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/',verbose=1)
2/33: ls
2/34: from distutils.dir_util import copy_tree
2/35: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/',verbose=1)
2/36: cd ~
2/37: cd /Volumes/assets/Gavia_Dora/adminscripts/
2/38: copy_tree('templates/directorytree/','../dataproducts/2014/20140914_IM/',verbose=1)
2/39: ls ../dataproducts/2014/20140914_IM/
2/40: ls templates/directorytree/
 4/1: import numpy as np
 4/2: import matplotlib.pyplot as plt
 4/3: import res_dev2 as rd2
 4/4: dmax = 100 # meters on a side
 4/5: dres = 0.1 # meters resolution
 4/6: print 'Build surface'
 4/7: r = np.arange(0,dmax,dres)
 4/8: x,y = np.meshgrid(r,r)
 4/9: sx = int(dmax/dres)
4/10: ## build the z layer
4/11: #define a red spectral content
4/12: fn = np.fft.fftfreq(sx, d = dres)
4/13: c = -20
4/14: whos fn
4/15: fn
4/16: size(fn)
4/17: fn.size()
4/18: who
4/19: whos
4/20: plt.plot(fn,'.')
4/21: plt.plot(fn,'.')
4/22: fn(1:4)
4/23: fn[1:5]
4/24: fn = np.fft.fftfreq(sx, d = dres)
4/25: c = -20
4/26: A = np.zeros(np.size(fn))
4/27: A[fn!=0] = (sx/dres)*(3**(c/10))/fn[fn!=0]**1
4/28: FX, FY = np.meshgrid(fn, fn)
4/29: # calculate the radial wavenumber for each pixel
4/30: FR = np.sqrt(FX**2+FY**2)
4/31: #then for each pixel, choose the closest frequency value to the radial frequency
4/32: aa = np.zeros((np.size(A), np.size(A)))
4/33: idx1 = 0
4/34: idx2 = 0
4/35:
for row in aa:
        for col in row:
                aa[idx1, idx2] = A[np.abs(fn - FR[idx1, idx2]).argmin()]    #need to reintroduce phase
                idx1 = idx1 + 1
            idx1 = 0
            idx2 = idx2 + 1
4/36:
for row in aa:
        for col in row:
                aa[idx1, idx2] = A[np.abs(fn - FR[idx1, idx2]).argmin()]    #need to reintroduce phase
                idx1 = idx1 + 1
                idx1 = 0
                idx2 = idx2 + 1
4/37: aa.size()
4/38: np.size(aa)
4/39: dmax = 100 # meters on a side
4/40: dres = 0.1 # meters resolution
4/41: print 'Build surface'
4/42: r = np.arange(0,dmax,dres)
4/43: x,y = np.meshgrid(r,r)
4/44: sx = int(dmax/dres)
4/45: ## build the z layer
4/46: #define a red spectral content
4/47: fn = np.fft.fftfreq(sx, d = dres)
4/48: c = -20
4/49: A = np.zeros(np.size(fn))
4/50: A[fn!=0] = (sx/dres)*(3**(c/10))/fn[fn!=0]**1
4/51: FX, FY = np.meshgrid(fn, fn)
4/52: # calculate the radial wavenumber for each pixel
4/53: FR = np.sqrt(FX**2+FY**2)
4/54: #then for each pixel, choose the closest frequency value to the radial frequency
4/55: aa = np.zeros((np.size(A), np.size(A)))
4/56: idx1 = 0
4/57: idx2 = 0
4/58:
for row in aa:
        for col in row:
                aa[idx1, idx2] = A[np.abs(fn - FR[idx1, idx2]).argmin()]    #need to reintroduce phase
                idx1 = idx1 + 1
            idx1 = 0
                idx1 = 0
                idx2 = idx2 + 1
4/59: %paste
4/60: import scipy.io as sio
4/61: sio.savemat('surf.mat',aa)
4/62: data['z'] = aa;
4/63: data = {}
4/64: data['z'] = aa;
4/65: sio.savemat('surf.mat',aa)
4/66: data = {}
4/67: surface = {}
4/68: data['surface'] = surface
4/69: surface['z'] = aa;
4/70: sio.savemat('surf.mat',aa)
4/71: sio.savemat('surf.mat',data))
4/72: sio.savemat('surf.mat',data)
4/73: pwd
4/74: fn(1:3)
4/75: fn[1:3)
4/76: fn[1:3]
4/77: whos
 5/1: %paste
 5/2: %paste
 5/3: help np.fft.fftfreq?
 6/1: fieldlist=["NAV_X","NAV_Y"]
 6/2: fieldlist
 6/3:
for i in range(len(fieldlist)):
    print fieldlist[i]
 6/4:
for i in range(len(fieldlist)):
    test[i]= fieldlist[i]
    print test[i]
 6/5: !less MOOSLog_3_11_2015_____16_21_08.alog
 6/6: tmptxt = '9.298           GPS_HEADING          iGPS_MB1        350.99000 '
 6/7: tmp = tmptxt.split()
 6/8: tmp
 6/9: tmp[0]
6/10: import regexp
6/11: re.match('GPS_HEADING',tmptxt)
6/12: import re
6/13: re.match('GPS_HEADING',tmptxt)
6/14: re.match('*\sGPS_HEADING\s*',tmptxt)
6/15: re.match('.*\sGPS_HEADING\s.*',tmptxt)
6/16: a = re.match('.*\sGPS_HEADING\s.*',tmptxt)
6/17: a.string
6/18: field = 'GPS_HEADING'
6/19: a = re.match('.*\s' + field + '\s.*',tmptxt)
6/20: a.string
6/21: a.string.split()
6/22: a = re.match('.*\' + field + '\s.*',tmptxt)
6/23: a = re.match('.*\d' + field + '\s.*',tmptxt)
6/24: a
6/25: a.__len__()
6/26: whos a
6/27: a.__len__
6/28: a == NoneType
6/29: whos a
6/30: a = re.match('.*\d' + field + '\s.*',tmptxt)
6/31: whos
6/32: type(a)
6/33: type(a) == 'NoneType'
6/34: type(a) == NoneType
6/35: !less MOOSLog_3_11_2015_____16_21_08.alog
6/36: F = file(MOOSLog_3_11_2015_____16_21_08.alog,'r')
6/37: F = file('MOOSLog_3_11_2015_____16_21_08.alog','r')
6/38: a  = F.readlines(4)
6/39: a
6/40: F.readlines?
6/41: a[4]
6/42: a[3]
6/43: a[3].split()
6/44: a[3].split()[2]
6/45: import datetime
6/46: dt = datetime.datetime()
6/47: a[3].split()[2]
6/48: dt = datetime.datetime.fromtimestamp(a[3].split()[2])
6/49: dt = datetime.datetime.fromtimestamp(float(a[3].split()[2]))
6/50: dt
6/51: ddt = dt + float('1.2')
6/52: ddt = dt + datetime.datetime.second(float('1.2'))
6/53: dt2 = datetime.datetime.fromtimestamp(float('1.2'))
6/54: print dt2
6/55: dt
6/56: dt2
6/57: ddt = dt+dt2
6/58: ddt = dt.dst?
 7/1: "A number {1.3f}.".format(float(12.345))
 7/2: a
 7/3: whos
 8/1: a = 'abc'
 8/2: a == 'abc'
 9/1: which mkdir
 9/2: import os
10/1: import pyaudio
10/2: CHUNK 1024
10/3: CHUNK = 1024
10/4: CHANNELS=1
10/5: RATE=44100
10/6: FORMAT pyaudio.paInt16
10/7: FORMAT=pyaudio.paInt16
10/8: SECS = 5;
10/9: p = pyaudio.PyAudio();
10/10: stream = p.open(format=FORMAT,channels=CHANNELS,rate=RATE,input=True,frames_per_buffer=CHUNK)
10/11: frames = []
10/12:
for i=range(0,int(RATE / CHUNK * SECS)):
    data = stream.read(CHUNK)
    frames.append(data)
10/13:
for i in range(0,int(RATE / CHUNK * SECS)):
    data = stream.read(CHUNK)
    frames.append(data)
10/14: stream = p.open(format=FORMAT,channels=CHANNELS,rate=RATE,input=True,frames_per_buffer=CHUNK)
10/15: data = stream.read(CHUNK)
10/16: stream.close()
10/17: stream = p.open(format=FORMAT,channels=CHANNELS,rate=RATE,input=True,frames_per_buffer=CHUNK)
10/18: stream.close()
10/19: stream.close()
10/20: stream.close()
10/21: clear all
10/22: who
10/23: clear stream
10/24: who
10/25: stream = null
10/26: steam = ''
10/27: CHUNK = 512
10/28: stream = p.open(format=FORMAT,channels=CHANNELS,rate=RATE,input=True,frames_per_buffer=CHUNK)
10/29: data = stream.read(CHUNK)
10/30: p.get_default_output_device_info
10/31: p.get_default_output_device_info()
10/32: p.get_device_count()
10/33: CHANNELS = 2
10/34: stream = p.open(format=FORMAT,channels=CHANNELS,rate=RATE,input=True,frames_per_buffer=CHUNK)
10/35: data = stream.read(CHUNK)
10/36: stream = p.is_format_supported(format=FORMAT,channels=CHANNELS,rate=RATE,input=True,frames_per_buffer=CHUNK)
10/37: stream
10/38: stream = p.is_format_supported(format=FORMAT,channels=CHANNELS,rate=RATE,input=True,Output=True,frames_per_buffer=CHUNK)
10/39: stream = p.open(format=FORMAT,channels=CHANNELS,rate=RATE,input=True,Output=True,frames_per_buffer=CHUNK)
10/40: stream = p.open(format=FORMAT,channels=CHANNELS,rate=RATE,input=True,output=True,frames_per_buffer=CHUNK)
10/41: data = stream.read(CHUNK)
10/42: stream.close()
11/1: import zmq
11/2: context = zmq.Context()
11/3: socket = context.socket(zmq.PUB)
11/4: socket.send?
12/1: import zmq
13/1: import sys
13/2: if sys.argv.__len__ == 0
13/3: if sys.argv.__len__() == 0
13/4: sys.argv.__len__
13/5: sys.argv.__len__()
14/1: import datetime as dt
14/2: dt.datetime.now().isoformat()
15/1: F = open("test/HLY0805-posnav.y2008d233",'r')
15/2: F.seek?
15/3: F.seek(0,2)
15/4: line = F.readline()
15/5: print line
15/6: line
15/7: eof(F)
16/1: import urllib2
16/2: I = urllib2.urlopen('http://192.168.8.96/axis-cgi/jpg/image.cgi')
16/3: import pil as p
16/4: ls
16/5: cd scratch/
16/6: fh = open('images.jpg','w')
16/7: fh.write(I.read())
16/8: fh.close()
17/1: import urllib2
17/2: I = urllib2.urlopen('http://192.168.8.96/axis-cgi/jpg/image.cgi')
17/3: import pil as p
17/4: import PIL as p
17/5: import Image
17/6: im = Image.open(I)
17/7: im = Image(I)
17/8: im = Image.frombuffer(I)
17/9: im = Image.frombuffer?
17/10: im = Image.new(I)
17/11: Image.new?
17/12: import cStringIO as StringIO
17/13: II = StringIO(I)
17/14: II = StringIO.StringIO(I)
17/15: whos
17/16: II = StringIO.StringIO(I.read())
17/17: im = Image.open(II)
17/18: I = urllib2.urlopen('http://192.168.8.96/axis-cgi/jpg/image.cgi')
17/19: II = StringIO.StringIO(I.read())
17/20: im = Image.open(II)
17/21: im.show()
17/22: im.show()
17/23: p = im.show()
17/24: whos
17/25: im.show?
17/26: im.format = 'jpg'
17/27: im.show()
17/28: import cv2
17/29: import Tkinter
17/30: top = Tkinter.Tk()
17/31: c = Tkinter.Canvas(top)
17/32: whos
17/33: import ImageTk
17/34: photo = ImageTk.PhotoImage(im)
17/35: c.create_image(image=photo)
17/36: c.create_image(photo.width,photo.height,image=photo)
17/37: photo.width
17/38: photo.width()
17/39: photo.height()
17/40: c.create_image(photo.width(),photo.height(),image=photo)
17/41: c.pack()
17/42: top.mainloop()
17/43: top.sizefrom?
17/44: top.size?
17/45: c.create_image(photo.width(),photo.height(),anchor=ne,image=photo)
17/46: c.create_image(photo.width(),photo.height(),anchor="ne",image=photo)
17/47: c.pack()
17/48: top.mainloop()
17/49: top.mainloop()
17/50: c.pack()
17/51: top = Tkinter.Tk()
17/52: top = Tkinter.Tk?
17/53: top = Tkinter.Tk()
17/54: c = Canvas(top, width=photo.width(), height=photo.height())
17/55: c = Tkinter.Canvas(top, width=photo.width(), height=photo.height())
17/56: c.pack()
17/57: c.create_image(photo.width(),photo.height(),anchor=ne,image=photo)
17/58: c.create_image((0,0),anchor="ne",image=photo)
17/59: who
17/60: whos
17/61: photo = ImageTk.PhotoImage(im)
17/62: c.create_image((0,0),anchor="ne",image=photo)
17/63: photo.height()
17/64: c.create_image?
17/65: c.create_image(x1=0,y1=0,anchor="ne",image=photo)
17/66: c.create_image(0,0,anchor="ne",image=photo)
17/67: whos
17/68: imshow(im)
17/69: im.show()
17/70: photo = ImageTk.PhotoImage(im)
17/71: whos
18/1: I = urllib2.urlopen('http://192.168.8.96/axis-cgi/jpg/image.cgi')
18/2: import urllib2
18/3: I = urllib2.urlopen('http://192.168.8.96/axis-cgi/jpg/image.cgi')
18/4: import cStringIO as StringIO
18/5: II = StringIO.StringIO(I.read())
18/6: im = Image.open(II)
18/7: import Image
18/8: im = Image.open(II)
18/9: im.show()
18/10: import ImageTK, Tkinter
18/11: import ImageTk, Tkinter
18/12: photo = ImageTk.PhotoImage(im)
18/13: top = Tkinter.Tk()
18/14: c = Tkinter.Canvas(top, width=700, height 700)
18/15: c = Tkinter.Canvas(top, width=700, height=700)
18/16: photo = ImageTk.PhotoImage(im)
18/17: c.create_image(0,0,anchor="ne",image=photo)
18/18: c.pack()
18/19: top.mainloop()
18/20: whos photo
18/21: whos
18/22: !ls
18/23: !cd scratch
18/24: ls
18/25: cd scratch
18/26: ls
18/27: photo = ImageTk.PhotoImage(file="image.jpg")
18/28: photo = ImageTk.PhotoImage(file="images.jpg")
18/29: c.create_image(0,0,anchor="ne",image=photo)
18/30: c.pack()
18/31: top.mainloop()
18/32: top = Tkinter.Tk()
18/33: c = Tkinter.Canvas(top, width=700, height=700)
18/34: photo = ImageTk.PhotoImage(file="images.jpg")
18/35: c.create_image(0,0,anchor="ne",image=photo)
18/36: c.pack()
18/37: top.mainloop
18/38: top.mainloop()
19/1: import urllib2
19/2: I = urllib2.urlopen('http://192.168.8.96/axis-cgi/jpg/image.cgi')
19/3: pwd
19/4: cd scratch
19/5: fh = open('image.jpg','w')
19/6: fh.write(I.read())
19/7: import Tkinter
19/8: from PIL import Image,ImageTk
19/9: import cStringIO as StringIO
19/10: II = StringIO.StringIO(I.read())
19/11: whos
19/12: top = Tkinter.Tk()
19/13: c = Tkinter.Canvas(top)
19/14: c.grid(row=0,column=0)
19/15: photo = Tkinter.PhotoImage(II)
19/16: c.create_image(0,0,image=photo)
19/17: im = Image.open(II)
19/18: whos
19/19: photo = Tkinter.PhotoImage(file = "image.jpg")
19/20: ls
19/21: photo = Tkinter.PhotoImage(file = "./image.jpg")
19/22: import datetime as dt
19/23: dt.datetime.now().secs()
19/24: dt.datetime.now().sec()
19/25: a = dt.datetime.now()
19/26: a.secs()
19/27: a.second()
19/28: a.second
20/1: import urllib2
20/2: I = urllib2.urlopen('http://192.168.8.96/axis-cgi/jpg/image.cgi')
20/3: whos
21/1: import datetime as dt
21/2: a = dt.datetime.now().second()
21/3: a = dt.datetime.now()
21/4: a.second()
21/5: a.second
22/1: import datetime as dt
22/2: print 'abc%02d.jpg' % dt.datetime.now().second
23/1: ls
23/2: cd scratch/
23/3: F = open('test.txt','w')
23/4: F.close()
23/5: F.close()
24/1: import os
24/2: os.path.join('/usr/local/test','abc')
24/3: os.path.join('/usr/local/test/','abc')
24/4: import datetime as dt
24/5: a = dt.datetime.now()
24/6: a.strftime?
24/7: import time
24/8: time.time()
24/9: time.time().round()
24/10: a = time.time()
24/11: int(a)
24/12: print "time: %02d" & int(time.time())
24/13: print "time: %02d" % int(time.time())
24/14: print "time: %d" % int(time.time())
25/1: import os
25/2: os.join?
25/3: os.path.join?
25/4: os.path.join('abc','cdf','ebg')
25/5: import glob
26/1: import os
26/2: a = 'abc/def/ghi'
26/3: os.path.basename(a)
26/4: a = ('def','abc')
26/5: a.sort()
26/6: sort(a)
26/7: sorted?
26/8: sorted(a)
27/1: from netCDF4 import Dataset
27/2: from netCDF4 import Dataset
27/3: pwd
27/4: f = Dataset('scratch/text.nc','w')
27/5: t = f.createVLType?
27/6: f
27/7: timestamp_dim = f.createDimension('timestamp_dim',None)
27/8: data_dim = f.createDimension('data_dim',None)
27/9: data_t = f.createVLType('u1','variable_data_t')
27/10: timestamp = f.createVariable('timestamp','d','timestamp_dim')
27/11: data = f.createVariable('data',data_t,'data_dim')
27/12: print f
27/13: import datetime as dt
27/14: timestamp[0] = dt.datetime.utcnow.isoformat()
27/15: dts = dt.datetime.utcnow()
27/16: dts.isoformat()
27/17: timestamp[0] = dts.isoformat()
27/18: dts
27/19: dts.epoch()
27/20: dts.time()
27/21: import time
27/22: dts = time.time()
27/23: dts
27/24: time.time?
27/25: whos dts
27/26: timestamp[0] = dts
27/27: import numpy, random
27/28: buf = numpy.empty(100)
27/29: buf[:] = random.randint?
27/30: buf[:] = numpy.ones?
27/31: buf[:] = numpy.ones(1,100)
27/32: buf = numpy.ones((1,100),'uint8')
27/33: data[0] = buf
27/34: f.close()
27/35: f = Dataset('scratch/text.nc','r')
27/36: print f
27/37: f.variables()
27/38: print f.variables
27/39: f.variables['timestamp'][:]
27/40: f.variables['data'][:]
27/41: f.close()
27/42: f = Dataset('scratch/text2.nc','w')
27/43:
timestamp_dim = f.createDimension('timestamp_dim',None)
data_dim = f.createDimension('data_dim',None)
data_t = f.createVLType('u1','variable_data_t')
timestamp = f.createVariable('timestamp','d','timestamp_dim')
data = f.createVariable('data',data_t,'data_dim')
27/44: print f
27/45: timestamp[:] = dts
27/46: print timestamp
27/47: data[:] = buf
27/48: data[0] = buf
27/49: f.close()
27/50: f = Dataset('scratch/text2.nc','w')
27/51:
timestamp_dim = f.createDimension('timestamp_dim',None)
data_dim = f.createDimension('data_dim',None)
data_t = f.createVLType('u1','variable_data_t')
timestamp = f.createVariable('timestamp','d','timestamp_dim')
data = f.createVariable('data',data_t,'data_dim')
27/52:
for i in range(100):
    timestamp[i] = time.time()
    data[i] = buf
27/53: f.close()
27/54: f = Dataset('scratch/text2.nc','r')
27/55: print f
27/56: f.close()
27/57: f = Dataset('scratch/text3.nc','w')
27/58:
dim = f.createDimension('timestamp_dim',None)
data_dim = f.createDimension('data_dim',None)
data_t = f.createVLType('u1','variable_data_t')
timestamp = f.createVariable('timestamp','d','timestamp_dim')
data = f.createVariable('data',data_t,'data_dim')
27/59:
for i in range(1000):
    timestamp[i] = time.time()
    data[i] = buf
27/60: f.close()
27/61: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/62: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/63: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/64: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/65: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/66: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/67: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/68: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/69: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/70: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/71: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/72: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/73: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/74: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/75: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/76: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/77: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/78: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/79: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/80: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/81: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/82: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/83: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/84: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/85: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/86: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/87: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/88: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/89: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/90: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/91: runfile('/Users/vschmidt/scratch/netcdftest.py', wdir='/Users/vschmidt/scratch')
27/92: pwd
27/93: cd ~/gitsrc/dataproxy/lib
27/94: ls
27/95: import TimeCompressedRotatingFileHandler as fh
27/96: import "TimeCompressedRotatingFileHandler" as fh
27/97: cd ../bin
27/98: ls
27/99: import mypath
27/100: _mypath.py
27/101: ls
27/102: python _mypath.py
27/103: python _mypath.py
27/104: python run _mypath.py
27/105: python ./_mypath.py
28/1: cd ~/gitsrc/dataproxy/lib
28/2: ls
28/3: import TimedCompressedRotatingFileHandler as fh
28/4: fh.interval?
28/5: log = fh.TimedCompressedRotatingFileHandler()
28/6: log = fh.TimedCompressedRotatingFileHandler?
28/7: log = fh.TimedCompressedRotatingFileHandler('~/scratch/test.txt',when='s',interval=20)
28/8: log = fh.TimedCompressedRotatingFileHandler('/Users/vschmidt/scratch/test.txt',when='s',interval=20)
28/9: import logging
28/10: logg = logging.Logger()
28/11: logg = logging.Logger?
28/12: logg = logging.Logger('test')
28/13: logg.addHandler(fh)
28/14: log.formatter?
28/15: for = logging.Formatter('%(asctime)s\t%(message)s')
28/16: fmt = logging.Formatter('%(asctime)s\t%(message)s')
28/17: fh.TimedCompressedRotatingFileHandler.setFormatter(fmt)
28/18: runfile('/Users/vschmidt/scratch/loggingtest.py', wdir='/Users/vschmidt/scratch')
28/19: runfile('/Users/vschmidt/scratch/loggingtest.py', wdir='/Users/vschmidt/scratch')
28/20: runfile('/Users/vschmidt/scratch/loggingtest.py', wdir='/Users/vschmidt/scratch')
28/21: runfile('/Users/vschmidt/scratch/loggingtest.py', wdir='/Users/vschmidt/scratch')
28/22: runfile('/Users/vschmidt/scratch/loggingtest.py', wdir='/Users/vschmidt/scratch')
29/1: runfile('/Users/vschmidt/scratch/loggingtest.py', wdir='/Users/vschmidt/scratch')
29/2: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/3: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/4: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/5: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/6: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/7: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/8: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/9: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/10: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/11: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/12: import time
29/13: time.localtime?
29/14: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/15: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/16: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/17: import zipfile
29/18: pwd
29/19: ff = zipfile.ZipFile('test.zip','w')
29/20: ff.write?
29/21: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
29/22: time.localtime(1)
29/23: time.localtime(int(time.time()))
29/24: time.localtime(int(time.time()))[-1]
29/25: runfile('/Users/vschmidt/gitsrc/dataproxy/lib/TimedCompressedRotatingFileHandler.py', wdir='/Users/vschmidt/gitsrc/dataproxy/lib')
29/26: runfile('/Users/vschmidt/gitsrc/dataproxy/lib/TimedCompressedRotatingFileHandler.py', wdir='/Users/vschmidt/gitsrc/dataproxy/lib')
29/27: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
30/1: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
30/2: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
31/1: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
32/1: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
33/1: runfile('/Users/vschmidt/gitsrc/dataproxy/bin/loggingtest.py', wdir='/Users/vschmidt/gitsrc/dataproxy/bin')
33/2: import os
33/3: os.path.join?
33/4: error?
33/5: warning?
33/6: warn?
33/7: os.path.join('abc','def')
33/8: import datetime as dt
33/9: dt.datetime.utcnow().isoformat()
34/1: import datetime as dt
34/2: dts = dt.datetime.fromordinal?
34/3: a = dt.datetime.now()
34/4: a.time()
34/5: a.timetuple()
34/6: import time
34/7: tt = time.time()
34/8: tt
34/9: dts = dt.datetime.fromtimestamp(tt)
34/10: dts.timetuple()
34/11: a.day
34/12: a.dst
34/13: a.dst()
34/14: dt.datetime()?
34/15: dt.datetime?
34/16: tt
34/17: a.total_seconds()
34/18: (a - datetime(1970,1,1)).total_seconds()
34/19: (a - dt.datetime(1970,1,1)).total_seconds()
34/20: tt
34/21: tt = time.time()
34/22: a = dt.datetime.utcfromtimestamp(tt)
34/23: tt
34/24: (a - dt.datetime(1970,1,1)).total_seconds()
34/25: timestamp = time.time()
34/26: dts = dt.datetime.utcfromtimestamp(timestamp)
34/27:         dts_midnight = dt.datetime(dts.year,dts.month,dts.day)
34/28:         epoch_time_midnight = (dts_midnight - dt.datetime(1970,1,1)).total_seconds()
34/29: timestamp
34/30: (dts - dt.datetime(1970,1,1)).total_seconds()
34/31: dts.tuple()
34/32: dts.timetuple()
34/33: dts_midnight.timetuple()
34/34: a = dts - dts_midnight
34/35: a.hours()
34/36: a.hour
34/37: a.days()
34/38: a.days
34/39: a.seconds
34/40: dt.timedelta?
34/41: aa = dt.timedelta(0,0,1)
34/42: aa.days
34/43: aa.seconds
34/44: aa = dt.timedelta()
34/45: aa.days=1
34/46: aa.timedelta?
34/47: dt.timedelta?
34/48: aa = dt.timedelta(1)
34/49: aa.days
34/50: (dt.datetime.now() + aa).timetuple()
34/51: dt.datetime.now()
35/1: import minidom
36/1: import ogr
36/2: import org
36/3: from osgeo import ogr
37/1: from osgeo import ogr
38/1: from osgeo import ogr
39/1: import proj4
39/2: import proj
40/1: import gdal
40/2: from osgeo import ogr
41/1: runfile('/Users/vschmidt/scratch/gdal_testing/gdaltests.py', wdir='/Users/vschmidt/scratch/gdal_testing')
41/2: whos
41/3: polygon1
41/4: pol1 = ogr.CreateGeometryFromWkt(polygon1)
41/5: pol1
41/6: polygon1
41/7: polygon1
41/8: runfile('/Users/vschmidt/scratch/gdal_testing/gdaltests.py', wdir='/Users/vschmidt/scratch/gdal_testing')
41/9: pol1
41/10: pol1.CloseRings()
41/11: runfile('/Users/vschmidt/scratch/gdal_testing/gdaltests.py', wdir='/Users/vschmidt/scratch/gdal_testing')
41/12: pol1.GetX()
41/13: pol1
41/14: print pol1
41/15: pol1.GetX?
41/16: pol1.GetX(:)
41/17: pol1.GetX(':')
41/18: pol1.GetX(2)
41/19: pol1.GetX(3)
41/20: pol1.GetX(4)
41/21: pol1.GetX(0)
41/22: pol1.GetPoints()
41/23:
a = pol1.GetX(

)
41/24: a = pol1.GetPoints()
41/25: a
41/26: print a
41/27: print pol1
41/28: pol2.GetX()
41/29: pol1.GetArea()
41/30: pol1.GetPointCount()
41/31: runfile('/Users/vschmidt/scratch/gdal_testing/gdaltests.py', wdir='/Users/vschmidt/scratch/gdal_testing')
41/32: whos
41/33: pol1.GetX()
41/34: pol1.GetX(1)
41/35: pol1.GetX(2)
41/36: pol1.GetX(3)
41/37: pol1.GetX(4)
41/38:
for p in pol1:
    print p
41/39: a = pol1.GetPoint()
41/40: whos
41/41: a
41/42: ogrinfo -al
41/43: ogrinfo
41/44: runfile('/Users/vschmidt/scratch/gdal_testing/gdaltests.py', wdir='/Users/vschmidt/scratch/gdal_testing')
41/45: a = pol1.GetPoint(0)
41/46: a
41/47: pol1.GetPointCount()
41/48: a = pol1.GetPoint(0)
41/49: print a
41/50: a = pol1.GetPoint(1)
41/51: print a
42/1:
from osgeo import ogr
import matplotlib.pyplot as plt

polygon1 = "POLYGON ((0.0 0.0, 0.0 10.0, 10.0 10.0, 10.0 0.0))"
pol1 = ogr.CreateGeometryFromWkt(polygon1)
pol1.CloseRings()

polygon2 = "POLYGON ((8.0 2.0, 12.0 2.0, 12.0 8.0, 8.0 12.0))"
pol2 = ogr.CreateGeometryFromWkt(polygon2)
pol2.CloseRings()
43/1: runfile('/Users/vschmidt/scratch/gdal_testing/gdaltests.py', wdir='/Users/vschmidt/scratch/gdal_testing')
43/2: whos
43/3: a = pol1.ExportToJson()
43/4: a
43/5: import geojson
43/6: import GeoJSON
43/7: from geojson import point
44/1: pwd
44/2: cd /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/
44/3: ls
44/4: which gpsparser
44/5: which gpsparser.py
44/6: gpsparser.py -h
44/7: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -h
44/8: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA
44/9: !less 20160318_1050.log
44/10: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA
44/11: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA
44/12: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA
44/13: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA
44/14: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA
44/15: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -f test.txt
44/16: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o test.txt
44/17: !less test.txt
44/18: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o test.txt
44/19: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o
44/20: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o
44/21: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o test.txt
44/22: import os
44/23: os.path('/home/data/test')
44/24: os.path.basename('/home/data/test')
44/25: filename = 'test.txt'
44/26: filename[-4:]+'parsed.txt'
44/27: filename[0:-4]+'parsed.txt'
44/28: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o test.txt
44/29: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o test.txt
44/30: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o --outfilename test.txt
44/31: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o --outputfilename test.txt
44/32: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o --outputfilname test.txt
44/33: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o --outfile test.txt
44/34: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o
44/35: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f 20160318_1050.log -s GGA -o
44/36: cd ~/gitsrc/gpsparser/gpsparser/
44/37: ls
44/38: gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160318_1050.log -s GPS -o
44/39: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160318_1050.log -s GPS -o
44/40: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160318_1050.log -s GPS -o
44/41: t = None
44/42:
if t == None:
    print "yes"
44/43: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160318_1050.log -s GPS -o
44/44: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160318_1050.log -s GPS -o
44/45: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160318_1050.log -s GPS -o
44/46: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160318_1050.log -s GPS -o
44/47: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160318_1050.log -s GGA -o
44/48: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160318_1050.log -s GGA -o
44/49: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160329.log -s GGA -o
44/50: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/51: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/52: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/53: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/54: run gpsparser.py -v -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/55: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/56: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/57: whos
44/58: gps.msg
44/59: gps.checksum(True)
44/60: gps.date
44/61: gps.datetimevec
44/62: gps.fields
44/63: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/64: fields.__len__()
44/65: gps.fields.__len__()
44/66: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/67: pwd
44/68: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/69: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/70: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/71: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/72: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/73: gps
44/74: gps
44/75: gps.identify()
44/76: gps.msg
44/77: gps.parse()
44/78: m
44/79: exp = '(?P<match>\$..GGA.*)\*(?P<chksum>..)'
44/80: re.search(exp,gps.msg)
44/81: exp
44/82: gps.msg
44/83: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/84: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/85: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/86: run gpsparser.py -vvv -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/87: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/88: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/89: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/90: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/91: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/92: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/93: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160329.log -s GGA -o
44/94: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/95: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160330.log -s GGA -o
44/96: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160329.log -s VTG -o
44/97: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160329.log -s VTG -o
44/98: exp
44/99: exp = '(?P<match>\$.*)\*(?P<chksum>..)'
44/100: m = re.search(exp,gps.msg)
44/101: m
44/102: gps.msg
44/103: gms.msg = 'Received[2016-03-29T11:25:44.962792]: $GPVTG,10.02,T,,M,14.48,N,26.83,K,D*0D'
44/104: gps.msg = 'Received[2016-03-29T11:25:44.962792]: $GPVTG,10.02,T,,M,14.48,N,26.83,K,D*0D'
44/105: gps.identify()
44/106: gps.checksum()
44/107: gps.checksum(True)
44/108: m = re.search(exp,gps.msg)
44/109: m
44/110: m.group('match')
44/111: data = m.group('match')
44/112: tmp = map(ord, data[1:])
44/113: tmp
44/114: checksum = hex(reduce(xor, tmp))
44/115: checksum
44/116: m.group('chksum')
44/117: checksum[2:4].upper()
44/118: hex?
44/119: reduce(xor,tmp)
44/120: hex(16)
44/121: hex(15)
44/122: checksum[2:4]
44/123: checksum[2]
44/124: checksum[0:1] + '0' + checksum[2]
44/125: checksum[0:2] + '0' + checksum[2]
44/126: run gpsparser.py -f /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160329.log -s VTG -o
44/127: run gpsparser.py -f -vv /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160329.log -s VTG -o
44/128: run gpsparser.py -vvv -f  /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160329.log -s VTG -o
44/129: gps
44/130: gps.msg = 'Received[2016-03-29T11:25:44.962792]: $GPVTG,10.02,T,,M,14.48,N,26.83,K,D*0D'
44/131: gps.identify()
44/132: gps.parse()
44/133: gps
44/134: gps.cog
44/135: run gpsparser.py -vvv -f  /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160329.log -s VTG -o
44/136: run gpsparser.py -vvv -f  /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160329.log -s VTG -o
44/137: run gpsparser.py -vvv -f  /Volumes/ENG2015ASV/vessels/rvgs/data/2016/20160401_Transit/log/gps/20160329.log -s VTG -o
45/1: from osgeo import gdal ogr
45/2: from osgeo import gdal
45/3: from osgeo import ogr
45/4: g = ogr.Open?
45/5: g = gdal.Open?
45/6: g = gdal.Open('/Users/vschmidt/Projects/Gavia/backups/20100323/iac/build874_2010-03-13/ControlCenter/res/maps/US2GC01M.000')
45/7: gdal.Open?
45/8: gdal.OpenEx?
45/9: gdal.VersionInfo
45/10: gdal.VersionInfo()
45/11: cnt = ogr.GetDriverCount()
45/12: cnt
45/13:
for n in range(cnt):
    print ogr.GetDriver(n)
45/14:
for n in range(cnt):
    print ogr.GetDriver(n).GetName()
45/15: g = gdal.Open('/Users/vschmidt/Projects/Gavia/backups/20100323/iac/build874_2010-03-13/ControlCenter/res/maps/US2GC01M.000')
45/16: g = gdal.Open('/Users/vschmidt/Projects/Gavia/backups/20100323/iac/build874_2010-03-13/ControlCenter/res/maps/US2GC01M.000','r')
45/17: g = ogr.Open('/Users/vschmidt/Projects/Gavia/backups/20100323/iac/build874_2010-03-13/ControlCenter/res/maps/US2GC01M.000')
45/18: g.GetDescription()
45/19: g.GetLayerCount()
45/20: g.GetMetadata()
45/21: L = g.GetLayerByIndex(1)
45/22: L.GetDescription()
45/23: L.GetName()
45/24:
for n in range(5):
    print g.GetLayerByIndex(n).GetName()
45/25: L.GetFeatureCount()
45/26: L.GetLayerDefn()
45/27: L.GetMetadata()
45/28: L.GetName()
45/29: F = L.GetFeature(0)
45/30: F = L.GetFeature(2)
45/31: F = L.GetFeature?
45/32: F = L.GetFeature('UWTROC')
45/33: L.GetFeature?
45/34: L.GetName()
45/35: L.GetFeatureCount()
45/36: F = L.GetNextFeature()
45/37: F.GetField()
45/38: F.GetFID()
45/39: F.GetFieldCount()
45/40: F.GetFieldType()
45/41: F.GetFieldType(1)
45/42: F.keys()
45/43: F.geometry()
45/44: p = F.geometry()
45/45: print p
45/46: F.DumpReadable()
45/47: F.GetDefnRef()
45/48: whos
45/49: d = F.GetDefnRef()
45/50: d.GetName()
45/51: d.GetFieldDefn()
45/52: d.GetFieldDefn(1)
45/53: F.GetStyleString()
45/54: F.keys()
45/55: F.DumpReadable()
45/56: F.GetFieldAsString(8)
45/57: F.GetFieldAsString?
45/58: F.GetFieldDefnRef?
45/59: d = F.GetDefnRef()
45/60: d = F.GetDefnRef(0)
45/61: d = F.GetDefnRef()
45/62: d.GetFieldCount()
45/63: d.GetFieldDefn(0)
45/64: z = d.GetFieldDefn(0)
45/65: z.GetTypeName()
45/66: z.GetName()
45/67: L.GetDescription()
45/68: F.DumpReadable()
45/69: whos
45/70: g.
46/1: import gdal
46/2: from osgeo import gdal
46/3: from osgeo import ogr
46/4: g = ogr.Open('/Users/vschmidt/Projects/Gavia/backups/201507/iac/build894_2010-06-21/ControlCenter/res/maps/US2GC01M.000')
46/5: g.GetLayerCount()
46/6: L = g.GetLayerByIndex(0)
46/7: L.GetName()
46/8: L = g.GetLayerByIndex(5)
46/9: L.GetName()
46/10: L.GetMetadata()
46/11: L.GetFeatureCount()
46/12: F = L.GetFeature(0)
46/13: F = L.GetNextFeature()
46/14: F.GetName
46/15: F.GetName()
46/16: F.DumpReadable()
46/17: j = F.ExportToJson()
46/18: print j
46/19: import simpleJSON as json
46/20: import simplejson as json
46/21: import json
46/22: json.decoder?
46/23: json.load?
46/24: jj = json.load(j)
46/25: jj = json.loads?
46/26: jj = json.loads(j)
46/27: print jj
46/28: jj.keys()
47/1: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -h
47/2: cd /Volumes/NO\ NAME
47/3: run ~/gitsrc/gpsparser/gpsparser/gpsparser.py -f GPS_log_Aug26_zboat4.txt -s GGA
47/4: ls
47/5: run teratermGPSParser.py -h
47/6: run teratermGPSParser.py -h
47/7: run teratermGPSParser.py -h
47/8: run teratermGPSParser.py -h
47/9: run teratermGPSParser.py -h
47/10: run teratermGPSParser.py -h
47/11: run teratermGPSParser.py -h
47/12: ls /home/vschmidt/gitsrc/gpsparser
47/13: ls /home/vschmidt/gitsrc
47/14: ls /home/users/vschmidt/gitsrc/gpsparser
47/15: ls /home/Users/vschmidt/gitsrc/gpsparser
47/16: ls /Users/vschmidt/gitsrc/gpsparser
47/17: run teratermGPSParser.py -h
47/18: run teratermGPSParser.py -h
47/19: run teratermGPSParser.py -h
47/20: run teratermGPSParser.py -h
47/21: run teratermGPSParser.py -h
47/22: run teratermGPSParser.py -h
47/23: run teratermGPSParser.py -h
47/24: import regexp as re
47/25: import re
47/26: str = '[Fri Aug 26 14:02:42.354 2016]'
47/27:
teraterm_exp = re.compile('[(?P<DOW>\s) (?P<MON>\s) (?P<day>\d\d) (?P<HR>\d\d):(?P<MN>\d\d):(?P<SD>\d\d\.\d\d\d) (?P<year>\d\d\d\d)]'
)
47/28: m = re.search(teraterm_exp,str)
47/29: m
47/30: m.group
47/31: print m
47/32: print m.group
47/33: print m.group('year')
47/34: m = re.search(teraterm_exp,str)
47/35: print m
47/36: m.string
47/37: m.group
47/38: m.group()
47/39: m = re.search(teraterm_exp,str)
47/40: m.group()
47/41: m.group
47/42: m.group('year')
47/43: m.group('DOW')
47/44: m.groupdict
47/45: m.groupdict()
47/46: print m.groupdict
47/47: print m.groupdict()
47/48:
teraterm_exp = re.compile(r '[(?P<DOW>\s) (?P<MON>\s) (?P<day>\d\d) (?P<HR>\d\d):(?P<MN>\d\d):(?P<SD>\d\d\.\d\d\d) (?P<year>\d\d\d\d)]'
)
47/49: teraterm_exp = re.compile('[(?P<DOW>\s) .*')
47/50: teraterm_exp = re.compile('\[(?P<DOW>\s) .*\]')
47/51: m = re.search(teraterm_exp,str)
47/52: m.groups
47/53: m.group()
47/54: teraterm_exp = re.compile('\[(?P<DOW>\s) .*\]')
47/55: m.group()
47/56: m = re.search(teraterm_exp,str)
47/57: m.group()
47/58: teraterm_exp = re.compile('\[(?P<DOW>\w) .*\]')
47/59: m = re.search(teraterm_exp,str)
47/60: m.group()
47/61: m.group
47/62: teraterm_exp = re.compile('\[(?P<DOW>\w) .* \]')
47/63: m = re.search(teraterm_exp,str)
47/64: m.group
47/65: teraterm_exp = re.compile('\[(?P<DOW>\w).*\]')
47/66: m = re.search(teraterm_exp,str)
47/67: str
47/68: m.group
47/69: m.group()
47/70: m.group('DOW')
47/71: teraterm_exp = re.compile('\[(?P<DOW>\w+).*\]')
47/72: m = re.search(teraterm_exp,str)
47/73: m.group('DOW')
47/74:
teraterm_exp = re.compile('[(?P<DOW>\w+) (?P<MON>\w+) (?P<day>\d\d) (?P<HR>\d\d):(?P<MN>\d\d):(?P<SD>\d\d\.\d\d\d) (?P<year>\d\d\d\d)]'
)
47/75: m = re.search(teraterm_exp,str)
47/76: m.group()
47/77: m.groups
47/78: m.group('DOW')
47/79:
teraterm_exp = re.compile('\[(?P<DOW>\w+) (?P<MON>\w+) (?P<day>\d\d) (?P<HR>\d\d):(?P<MN>\d\d):(?P<SD>\d\d\.\d\d\d) (?P<year>\d\d\d\d)\
]')
47/80: m = re.search(teraterm_exp,str)
47/81: m.group('DOW')
47/82: m.group('MON')
47/83: m.group('day')
47/84: m.group('year')
47/85: m.group('HR')
47/86: m.group('MN')
47/87: m.group('SD')
47/88: import datetime as datetime
47/89: dt = datetime.datetime()
47/90: dt = datetime.datetime(2016)
47/91: dt = datetime.datetime(2016,'Aug')
47/92: datetime.datetime.fromordinal?
47/93: dt = datetime.datetime.toordinal
47/94: dt = datetime.datetime.now
47/95: datetime.datetime.toordinal?
47/96: import dateutil
47/97: p = dateutil.parser(str)
47/98: from dateutil import parser
47/99: dt - parser.parse(str)
47/100: str = m.group('MON') + ' ' + m.group('day') + ' ' + m.group('year') + ' ' + m.group('HR') + ':' + m.group('MN') + ':' + m.group('SD')
47/101: str
47/102: dts = datetime.strptime(str,'%b %d %Y %H:%M:%S')
47/103: dts = datetime.datetime.strptime(str,'%b %d %Y %H:%M:%S')
47/104: dts = datetime.strptime(str,'%b %d %Y %H:%M:%S.%f')
47/105: dts = datetime.datetime.strptime(str,'%b %d %Y %H:%M:%S.%f')
47/106: dts.print
47/107: print dts
47/108: str
47/109: run teratermGPSParser.py -h
47/110: run teratermGPSParser.py -h
47/111: run teratermGPSParser.py -h
47/112: run teratermGPSParser.py -h
47/113: run teratermGPSParser.py -f GPS_log_Aug26_zboat4.txt
47/114: run teratermGPSParser.py -f -s GGA GPS_log_Aug26_zboat4.txt
47/115: run teratermGPSParser.py -f GPS_log_Aug26_zboat4.txt -s GGA
47/116: run teratermGPSParser.py -f GPS_log_Aug26_zboat4.txt -s GGA
47/117: run teratermGPSParser.py -f GPS_log_Aug26_zboat4.txt -s GGA
47/118: run teratermGPSParser.py -f GPS_log_Aug26_zboat4.txt -s GGA
47/119: run teratermGPSParser.py -f GPS_log_Aug26_zboat4.txt -s GGA
47/120: run teratermGPSParser.py -f GPS_log_Aug26_zboat4.txt -s GGA -f output.txt
47/121: run teratermGPSParser.py -f GPS_log_Aug26_zboat4.txt -s GGA -o output.txt
47/122: ls
50/1: pwd
50/2: cd scratch/zboat/
50/3: run teratermparser.py -h
50/4: run teratermparser.py -h
50/5: run teratermparser.py -h
50/6: import sys
50/7: sys.path.append("gpsparser")
50/8: from gpsparser import *
50/9: gpsparser.GPSString
50/10: run teratermparser.py -h
50/11: run teratermparser.py -h
50/12: message = '[Mon Aug 29 23:16:44.013 2016]'
50/13: tt_exp = re.compile('(?P<year>\w+) (?P<mon>\w+) (?P<day>\d\d) (?P<hour>\d\\d):(?P<minute>\d\d):(?P<seconds>\d\d\.\d+) (?<year>\d\d\d\d)')
50/14: import re
50/15: tt_exp = re.compile('(?P<year>\w+) (?P<mon>\w+) (?P<day>\d\d) (?P<hour>\d\\d):(?P<minute>\d\d):(?P<seconds>\d\d\.\d+) (?<year>\d\d\d\d)')
50/16: tt_exp = re.compile('(?P<year>\w+) (?P<mon>\w+) (?P<day>\d\d) (?P<hour>\d\\d):(?P<minute>\d\d):(?P<seconds>\d\d\.\d+) (?<year>\d\d\d\d)')
50/17: tt_exp = re.compile('(?P<year>\w+) (?P<mon>\w+) (?P<day>\d\d) (?P<hour>\d\\d)\:(?P<minute>\d\d)\:(?P<seconds>\d\d\.\d+) (?<year>\d\d\d\d)')
50/18: tt_exp = re.compile('(?P<year>\w+) (?P<mon>\w+) (?P<day>\d\d) (?P<hour>\d\\d)\:(?P<minute>\d\d)\:(?P<seconds>\d\d\.\d+) (?<year>\d\d\d\d)')
50/19: tt_exp = re.compile('(?P<year>\w+) (?P<mon>\w+) (?P<day>\d\d) (?P<hour>\d\\d)\:(?P<minute>\d\d)\:(?P<seconds>\d\d\.\d+)')
50/20: tt_exp = re.compile('(?P<year>\w+) (?P<mon>\w+) (?P<day>\d\d) (?P<hour>\d\\d)\:(?P<minute>\d\d)\:(?P<seconds>\d\d\.\d+) (?P<year>\d\d\d\d)')
50/21: tt_exp = re.compile('(?P<dow>\w+) (?P<mon>\w+) (?P<day>\d\d) (?P<hour>\d\\d)\:(?P<minute>\d\d)\:(?P<seconds>\d\d\.\d+) (?P<year>\d\d\d\d)')
50/22: m - re.search(tt_exp,message)
50/23: m= re.search(tt_exp,message)
50/24: m.groups()
50/25: import datetime
50/26: datetime.datetime.strftime?
50/27: datetime.datetime.strptime?
50/28: tt_exp = '\[(?<dtstring>.*\)]'
50/29: m = re.search(teraterm_exp,str)
50/30: m = re.search(tt_exp,str)
50/31: tt_exp = '\[(?P<dtstring>.*\)]'
50/32: m = re.search(tt_exp,str)
50/33: tt_exp = '\[(?P<dtstring>.*)\]'
50/34: m = re.search(tt_exp,str)
50/35: str
50/36: tt_exp
50/37: tt_exp = '\[(?P<dtstring>.*)\]'
50/38: str
50/39: m = re.search(tt_exp,message)
50/40: message
50/41: m
50/42: m.groups()
50/43: m.group()
50/44: m.group()[0]
50/45: a = m.group('dtstring')
50/46: a
50/47: dtstring = a
50/48: dtstring[:-5] + '000' + dtstring[-4:]
50/49: dtstring[:-5] + '000 ' + dtstring[-4:]
51/1: import os
51/2: os.path.basename('/type/of/file')
51/3: os.path.abspath('/type/of/file')
51/4: os.path.abspath('../of/file')
51/5: os.path.dirname('/type/of/file')
51/6: os.path.dirname('../of/file')
51/7: ID = {"a":1, "b":2, "c":3}
51/8: ID.get("b","")
51/9: ID.get?
51/10: ID.get("b")
51/11: ls
51/12: cd ~/gitsrc/asv_tools/testdata/
51/13: ls
51/14: filename = 'engine.csv'
51/15: import pandas
51/16: data = pandas.read_csv(filename,header=1,index_col=1)
51/17: data
51/18: data.head()
51/19: data.describe()
51/20: data.to_timestamp?
51/21: data.plot.line(1,2)
51/22: data.plot.line(2)
51/23: data.T?
51/24: size(data)
51/25: data.size()
51/26: data.size
51/27: data.shape
51/28: data.info
51/29: data.index?
51/30: data.index.summary()
51/31: data.index(1)
51/32: data.index.to_datetime?
51/33: data.index.view?
51/34: data.index.to_datetime?
51/35: data.index.to_datetime(unit='s')
51/36: data = pandas.read_csv(filename,header=1,index_col=1, parse_dates=True,infer_datetime_format=True)
51/37: data
51/38: data(1,1)
51/39: col0 = data[0]
51/40: print(data)
51/41: data.iloc?
51/42: print(data.iloc(0:3))
51/43: print(data.iloc(0:3,0:3))
51/44: print(data.iloc[0:3])
51/45: data.head?
51/46: data.head()
51/47: data = pandas.read_csv(filename,header=0,index_col=1, parse_dates=True,infer_datetime_format=True)
51/48: data.head()
51/49: data = pandas.read_csv(filename,header=0,index_col=0, parse_dates=True,infer_datetime_format=True)
51/50: data.head()
51/51: dt = data.index.values
51/52: dt[1]
51/53: whos
51/54: data = pandas.read_csv(filename,header=0,index_col=0)
51/55: data.head
51/56: data.index = pandas.to_datetime((data.index.values).astype(float64))
51/57: data.index = pandas.to_datetime((data.index.values).astype(float))
51/58: data.head
51/59: data.index = pandas.to_datetime((data.index.values),unit 's')
51/60: data.index = pandas.to_datetime((data.index.values),unit='s')
51/61: data.head()
51/62: data = pandas.read_csv(filename,header=0,index_col=0)
51/63: data.head(3)
51/64: data.index = pandas.to_datetime((data.index.values),unit='s')
51/65: data.head(3)
51/66: data.columns?
51/67: data.columns
51/68: data.plot()
51/69: import matplotlib.pyplot as plt
51/70: import matplotlib
51/71: matplotlib.style.use('ggplot')
51/72: plt.figure()
51/73: data.plot()
51/74: plt.figure()
51/75: data.plot()
52/1: import matplotlib.pyplot as plt
52/2: plt.figure()
52/3: pwd
52/4: cd ~/gitsrc/asv_tools/testdata/
52/5: ls
52/6: data = pandas.read_csv(filename,header=0,index_col=0)
52/7: import pandas
52/8: data = pandas.read_csv(filename,header=0,index_col=0)
52/9: filename = 'engine.csv'
52/10: data = pandas.read_csv(filename,header=0,index_col=0)
52/11: data.index = pandas.to_datetime((data.index.values),unit='s')
52/12: data.plot()
52/13: data.plot(subplots=True)
52/14: data.hist(columns=[2,3 4])
52/15: data.hist(columns=[2,3, 4])
52/16: data.hist(column=[2,3, 4])
52/17: data.hist(column=[2,3, 4],bins=50)
52/18: data.plot(column=[2,3,4])
52/19: data.plot(columns=[2,3,4])
52/20: data.plot.line(columns=[2,3,4])
52/21: data.plot.line(column=[2,3,4])
52/22: data.plot.line(x=0,y=3)
52/23: data.plot.line(y=3)
52/24: data.plot(y=3,linestyle='-')
52/25: data.plot(y=5,linestyle='-')
52/26: data.plot(y=5,linestyle='-',linewidth=3)
52/27: data.size()
52/28: data.size
52/29: data.shape
52/30: data = pandas.read_csv(filename,header=0,index_col=0)
52/31: data.index = pandas.to_datetime((data.index.values),unit='s')
52/32: data.plot(y=5,linestyle='-',linewidth=3)
52/33: a_dict = {col_name : df[col_name].values for col_name in df.columns.values}
52/34: a_dict = {col_name : data[col_name].values for col_name in data.columns.values}
52/35: a_dict
52/36: a_dict.keys()
52/37: keys = a_dict.keys()
52/38: key = keys[0]
52/39: key
52/40: key.join('One',key)
52/41: key.join?
52/42: key.startswith('1)
52/43: key.startswith('1')
52/44: keys
52/45: key = '1PPS'
52/46: key.alpha()
52/47: key.isaplha()
52/48: key.isalpha()
52/49: key.startswith('1')
52/50: key= 'One' + key[1:]
52/51: key
52/52: filename
52/53: filename[-3:]
52/54: filename[:-3]
52/55: filename[:-3] + 'mat'
52/56: pwd
52/57: import scypy.io as sio
52/58: import scipy.io as sio
52/59: a_dict
52/60:
for key in a_dict.keys():
        key.replace(' ','_')
        key.replace('(','_')
        key.replace(')','_')
        key.replace('%','Pct')
        key.replace('|','')
        if key.startswith('1'):
            key = 'One' + key[1:]
52/61: a_dict.keys()
52/62: a_dict.update?
52/63:
for key in a_dict.keys():
    oldkey = key
    key.replace(' ','_')
    key.replace('(','_')
    key.replace(')','_')
    key.replace('%','Pct')
    key.replace('|','')
    if key.startswith('1'):
        key = 'One' + key[1:]
    a_dict[key] = a_dict.pop(oldkey)
52/64: a_dict.keys()
52/65: key
52/66: key.replace(' ','_')
52/67:
for key in a_dict.keys():
    oldkey = key
    key = key.replace(' ','_')
    key = key.replace('(','_')
    key = key.replace(')','_')
    key = key.replace('%','Pct')
    key = key.replace('|','')
    if key.startswith('1'):
        key = 'One' + key[1:]
    a_dict[key] = a_dict.pop(oldkey)for key in a_dict.keys():
    oldkey = key
    key = key.replace(' ','_')
    key = key.replace('(','_')
    key = key.replace(')','_')
    key = key.replace('%','Pct')
    key = key.replace('|','')
    if key.startswith('1'):
        key = 'One' + key[1:]
    a_dict[key] = a_dict.pop(oldkey)
52/68: a_dict.keys()
52/69:
for key in a_dict.keys():
    oldkey = key
    key = key.replace(' ','_')
    key = key.replace('(','_')
    key = key.replace(')','_')
    key = key.replace('%','Pct')
    key = key.replace('|','')
    if key.startswith('1'):
        key = 'One' + key[1:]

    a_dict[key] = a_dict.pop(oldkey)
52/70: a_dict.keys()
52/71: key.rstrip?
52/72: sio.savemat('test.mat',a_dict)
52/73: tmp = {'engine': a_dict}
52/74: sio.savemat('test.mat',tmp)
52/75: filename
52/76: filename[:-4]
52/77: cd ~/gitsrc/asv_tools/pyasv/
52/78: ls
52/79: cd ..
52/80: ls
52/81: import pyasv
52/82: d = asvlog('testdata/engine.csv')
52/83: d = asvlog.asvlog('testdata/engine.csv')
52/84: ls
52/85: cd pyasv
52/86: ls
52/87: import asvlog
52/88: cd bin
52/89: ls
52/90: import asvlog
52/91: ls
52/92: cd ../lib
52/93: ls
52/94: import asvlog
52/95: import asvlog
52/96: df = asvlog('../../testdata/engine.csv')
52/97: df = asvlog.asvlog('../../testdata/engine.csv')
52/98: df = asvlog.asvlog('../../testdata/engine.csv')
52/99: df = asvlog('../../testdata/engine.csv')
52/100: import asvlog
52/101: df = asvlog.asvlog('../../testdata/engine.csv')
52/102: import asvlog
52/103: df = asvlog.asvlog('../../testdata/engine.csv')
52/104: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
52/105: reimport asvlog
52/106: reload(asvlog)
52/107: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
52/108: reload(asvlog)
52/109: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
52/110: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
52/111: reload(asvlog)
52/112: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
52/113: pwd
52/114:  cd ..
52/115: ls
52/116: cd bin
52/117: ls
52/118: import _mypath
52/119: import asvlog
52/120: df = asvlog.asvlog('../../testdata/engine.csv')
52/121: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
52/122: df = asvlog.asvlog.asvlog()
52/123: df
52/124: df.LOG_ID
52/125: reload(asvlog)
52/126: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
52/127: reload(asvlog)
52/128: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
52/129: reload(asvlog)
52/130: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
52/131: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
52/132: reload(asvlog)
52/133: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
53/1: cd ~/gitsrc/asv_tools/pyasv/
53/2: ls
53/3: cd bin
53/4: import _mypath
53/5: import asvlog
53/6: import asvlog
53/7: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
53/8: df.logtype
53/9: df.identify()
53/10: df.logtype
53/11: df.filename
53/12: df.parse()
53/13: df.parse()
53/14: clear all
53/15: whod
53/16: whos
53/17: reload(asvlog)
53/18: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
53/19: df.parse()
54/1: cd ~/gitsrc/asv_tools/pyasv/bin
54/2: import _mypath
54/3: import asvlog
54/4: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
54/5: df.parse()
54/6: df.data
54/7: pwd
54/8: ls
54/9: df.save_to_mat('~/scratch/test.mat')
54/10: df.save_to_mat('~/scratch/')
54/11: df.save_to_mat('~/scratch/test.mat')
54/12: import os
54/13: os.path.abspath('~/scratch/test.mat')
55/1: cd ~/gitsrc/asv_tools/pyasv/bin
55/2: import _mypath
55/3: import asvlog
55/4: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
55/5: df.parse()
55/6: df.save_to_mat('~/scratch/test.mat')
56/1: cd ~/gitsrc/asv_tools/pyasv/bin
56/2: import _mypath
56/3: import asvlog
56/4: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
56/5: df.parse()
56/6: df.save_to_mat('~/scratch/test.mat')
56/7: import os
56/8: os.path.realpath?
56/9: os.path.realpath('~/scratch/test.mat')
56/10: os.path.expanduser('~/scratch/test.mat')
57/1: cd ~/gitsrc/asv_tools/pyasv/bin
57/2: import _mypath
57/3: import asvlog
57/4: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
57/5: df.parse()
57/6: df.save_to_mat('~/scratch/test.mat')
57/7: key = 'abc '
57/8: key.rstrip()
57/9: key
57/10: key = 'abc  '
57/11: key.rstrip()
58/1: cd ~/gitsrc/asv_tools/pyasv/bin
58/2: import _mypath
58/3: import asvlog
58/4: df = asvlog.asvlog.asvlog('../../testdata/engine.csv')
58/5: df.parse()
58/6: df.save_to_mat('~/scratch/test.mat')
58/7: df.data.plot.line(columns[1,2,3,4],subplots=true)
58/8: df.data.plot.line(column[1,2,3,4],subplots=true)
58/9: df.plot.line(column[1,2,3,4],subplots=true)
58/10: df.data.plot.line(column[1,2,3,4],subplots=true)
58/11: df.data.plot.line(layout=(4,3),subplots=true)
58/12: df.data.plot.line(layout=(4,3),subplots=True)
58/13: df.data.plot.line(layout=(4,3),subplots=True,style={color:'black',linewidth:3})
58/14: df.data.plot.line(layout=(4,3),subplots=True,style={'color':'black','linewidth':3})
58/15: import math as m
58/16: m.mod(12/3)
58/17: m.modf(12/3)
58/18: m.modf?
58/19: a, b = m.modf(12/3)
58/20: a
58/21: b
58/22: a, b = m.modf(12/4)
58/23: a
58/24: b
58/25: a, b = m.modf(12/5)
58/26: a
58/27: b
58/28: 12%5
58/29: 12 % 5
58/30: 12 % 13
58/31: pwd
58/32: ls
58/33: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/34: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/35: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/36: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/37: ls /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/38: ls -l /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/39: statinfo = os.stat( /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/engine.csv)
58/40: statinfo = os.stat(/Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/engine.csv)
58/41: statinfo = os.stat("/Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/engine.csv")
58/42: statinfo
58/43: statinfo.st_size
58/44: statinfo.st_size / 1024
58/45: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/46: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/47: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/48: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/ -x
58/49: run cworker_logparser.py -h /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/ -x
58/50: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/51: pwd
58/52: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/53: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/54: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
58/55: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/1: cd ~/gitsrc/asv_tools/pyasv/
59/2: ls
59/3: cd bin
59/4: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/5: ls
59/6: less _mypath.py
59/7: ls ../lib
59/8: ls ../lib/asvlog
59/9: ls ../../../bag_mat/readBAG.m
59/10: ls
59/11: cd ..
59/12: ls
59/13: ls lib
59/14: ls lib/asvlog
59/15: less lib/asvlog/__init__.py
59/16: pwd
59/17: ls
59/18: cd bin
59/19: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/20: cat _mypath.py
59/21: which edit
59/22: ls
59/23: pwd
59/24: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/25: ls lib
59/26: ls ../lib/
59/27: ls ../lib/asvlog
59/28: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/29: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/30: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/31: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/32: cat _mypath.py
59/33: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/34: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/35: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/36: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/37: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/38: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/39: reload asvlog
59/40: reload?
59/41: reload "asvlog"
59/42: reload(asvlog)
59/43: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/44: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
59/45: reload(asvlog)
59/46: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
60/1: pwd
60/2: cd ~/gitsrc/asv_tools/pyasv/bin
60/3: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
60/4: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
60/5: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
61/1: cd ~/gitsrc/asv_tools/pyasv/bin
61/2: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
62/1: cd ~/gitsrc/asv_tools/pyasv/bin
62/2: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
63/1: cd ~/gitsrc/asv_tools/pyasv/bin
63/2: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
64/1: cd ~/gitsrc/asv_tools/pyasv/bin
64/2: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
65/1: cd ~/gitsrc/asv_tools/pyasv/bin
65/2: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
66/1: cd ~/gitsrc/asv_tools/pyasv/bin
66/2: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
67/1: cd ~/gitsrc/asv_tools/pyasv/bin
67/2: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
68/1: cd ~/gitsrc/asv_tools/pyasv/bin
68/2: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
69/1: cd ~/gitsrc/asv_tools/pyasv/bin
69/2: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
70/1: cd ~/gitsrc/asv_tools/pyasv/bin
70/2: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
70/3: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
70/4: ls
70/5: which git
70/6: ls
70/7: rm *.mat
70/8: ls
70/9: str.replace?
70/10: os.join('/a/b/c','d')
70/11: os.paht.join('/a/b/c','d')
70/12: os.path.join('/a/b/c','d')
70/13: ls
70/14: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
70/15: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
70/16: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
70/17: ls
70/18: rm *.mat
70/19: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/ -o ~/scratch/tmp/
70/20: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/ -o i
70/21: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/ -o i
70/22: python -V
70/23: run python -V
70/24: import glob
70/25: pwd
70/26: ls
70/27: glob.glob('../../*.py')
70/28: glob.glob('../**/*.py')
70/29: ls ../../
70/30: glob.glob('../../**/*.py')
70/31: glob.glob('../**/**/*.py')
70/32: glob.glob('../../**/**/*.py')
70/33: glob.glob?
70/34: glob.glob('../**/*.py',recursive=True)
70/35: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/ -o i
70/36: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/ -x -o i
70/37: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/ -x -o i
70/38: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/ -x -o i
70/39: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/ -x -o i
70/40: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/ -x -o i
70/41: run cworker_logparser.py -vvv -d  /Volumes/SCHMIDT/2016_SAT/extracted_logs/ -o i
70/42: import gpsparser
70/43: which gpsparser
70/44: which gpsparser.py
70/45: g = gpsparser.gpsparser.GPSString('1473622989.451 $GNGGA,194309.9,4308.15154,N,07056.35631,W,1,13,0.7,42.4,M,-31.9,M,,*43')
70/46: g.identify()
70/47: g.
70/48: g.GPS_IDs(g.identify)
70/49: g.GPS_IDs.fromkeys?
70/50: g.GPS_IDs.fromkeys(g.identify())
70/51: g.msg
70/52: epoch_exp = re.compile('(?P<epochtime>\d+\.\d+)?+\$')
70/53: import re
70/54: epoch_exp = re.compile('(?P<epochtime>\d+\.\d+)?+\$')
70/55: epoch_exp = re.compile('(?P<epochtime>\d+\.\d+).*\$')
70/56: m = re.search(epoch_exp,g.msg)
70/57: m
70/58: m.epochtime
70/59: m.group('epochtime)
70/60: m.group('epochtime')
70/61: import datetime
70/62: e = float(m.group('epochtime'))
70/63: dts = datetime.datetime.fromordinal?
70/64: dts = datetime.datetime.fromtimestamp?
70/65: dts = datetime.datetime.fromtimestamp(e)
70/66: dts
70/67: dts = datetime.datetime.fromtimestamp(e,0)
70/68: datetime.datetime.tzinfo?
70/69: datetime.datetime.tzinfo = 'UTC'
70/70: dts.utc
70/71: dts.utcfromtimestamp(e)
70/72: g.GPS_IDs.fromkeys(str(g.identify())))
70/73: g.GPS_IDs.fromkeys(str(g.identify()))
70/74: g.GPS_IDs.viewvalues()
70/75: k = g.GPS_IDs.keys()
70/76: print k[g.identify())
70/77:
print k[g.identify()
]
70/78: g.GPS_IDs
70/79: print k
70/80: g.id
71/1: cd ~/gitsrc/asv_tools/pyasv/bin
71/2: import gpsparser
71/3: ls
71/4: import _mpath
71/5: import _mypath
71/6: import gpsparser
71/7: g = gpsparser.gpsparser.GPSString('1473622989.451 $GNGGA,194309.9,4308.15154,N,07056.35631,W,1,13,0.7,42.4,M,-31.9,M,,*43')
71/8: g.identify
71/9: g.identify()
71/10: g.id
71/11: g.parse()
71/12: g.fields
71/13: dts = g.stripepochtime()
71/14: dts
71/15: g.GPS_IDs
71/16: g.GPS_IDs.sort()
71/17: g.fields
71/18: print g.fields.keys()
71/19: a = g.fields.keys()
71/20: join?
71/21: gpsparser.gpsparser.GPSString.GPS_IDs
71/22: gpsparser.gpsparser.GPSString.GPS_IDs.has_key('GGK')
71/23: gps.msg
71/24: g.msg
71/25: stringtype = 'GGA'
71/26: eval('stringtype = {}')
71/27: eval('"stringtype" = {}')
71/28: exec('stringtype = {}')
71/29: whos
71/30: stringtype
71/31: stringtype = 'GGA'
71/32: setattr(stringtype,{})
71/33: setattr?
71/34: a = {}
71/35: a.values
71/36: a.values()
71/37: a.items
71/38: locals?
71/39: locals
71/40: locals()
71/41: locals()['b']={}
71/42: whos
71/43: b
71/44: clear a
71/45: stringtype
71/46: local()[stringtype] = {}
71/47: locals()[stringtype] = {}
71/48: GGA
71/49: mat = {}
71/50: exec(mat[\'stringtype\']=stringtype)
71/51: stringtype
71/52: data = {}
71/53: mat[stringtype] = data
71/54: import datetime
71/55: dt1 = datetime.datetime.now()
71/56: dt2 = datetime.datetime.now()
71/57: ddt = dt2-dt1
71/58: whos
71/59: ddt.days()
71/60: ddt.days
71/61: ddt.seconds
71/62: ddt
71/63: ddt.total_seconds()
71/64: dt1 = datetime.datetime(2016,9,27,6,30,0)
71/65: ddt = dd1 -dt2
71/66: ddt = dt1 -dt2
71/67: ddt.total_seconds
71/68: ddt.total_seconds()
71/69: ddt
71/70: dt1 = datetime.datetime(2016,9,26,6,30,0)
71/71: ddt = dt1 -dt2
71/72: ddt.total_seconds()
71/73: matlabepoch = datetime.dateime(1900,1,1,0,0,0)
71/74: matlabepoch = datetime.datetime(1900,1,1,0,0,0)
71/75: dts = datetime.datetime(2016,9,27,0,0,0)
71/76: dt = dts-matlabepoch
71/77: dt.total_seconds/86400
71/78: dt.total_seconds()/86400
71/79: dts = datetime.datetime(2016,9,27,1,0,0)
71/80: dt = dts-matlabepoch
71/81: dt.total_seconds()/86400
71/82: matlabepoch = datetime.datetime(0,0,0,0,0,0)
71/83: matlabepoch = datetime.datetime(.1,0,0,0,0,0)
71/84: matlabepoch = datetime.datetime(1,0,0,0,0,0)
71/85: matlabepoch = datetime.datetime(1,1,1,0,0,0)
71/86: matlabepoch = datetime.datetime(0,1,1,0,0,0)
71/87: matlabepoch = datetime.datetime(1,1,1,0,0,0)
71/88: oneyr = datetime.deltatime(1)
71/89: from datetime import deltatime
71/90: from datetime import timedelta
71/91: oneyr = timedelta(1)
71/92: oneyr.total_seconds()
71/93: timedelta?
71/94: gpsparser.py -h
71/95: pwd
71/96: run ../lib/gpsparser/gpsparser.py -h
71/97: run ../lib/gpsparser/gpsparser.py -h -s GGA -f /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/2016-09-11T19-56-35_3.nmea0183
71/98: run ../lib/gpsparser/gpsparser.py -s GGA -f /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/2016-09-11T19-56-35_3.nmea0183
71/99: cat /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/2016-09-11T*.nmea0183 | ../lib/gpsparser/gpsparser.py -s GGA
71/100: debugfile('/Users/vschmidt/gitsrc/gpsparser/gpsparser/gpsparser.py', wdir='/Users/vschmidt/gitsrc/gpsparser/gpsparser')
71/101: debugfile('/Users/vschmidt/gitsrc/gpsparser/gpsparser/gpsparser.py', wdir='/Users/vschmidt/gitsrc/gpsparser/gpsparser')
71/102: dirglob = '/path/*.gps'
71/103: a,b = dirglob.split('*')
71/104: a
71/105: b
71/106: file = 'data.nmea1983'
71/107: file = 'data.nmea0183'
71/108: suffix = '.nmea0183'
71/109: file[-suffix.__len__():] == suffix
71/110: imoprt sys
71/111: import sys
71/112: sys.exec?
71/113: import os
71/114:
cmd = 'gpsparser.py ' +
    ' -d ' + os.path.join(directory,'device') + '::.nmea0183' +
    ' -s ' + logtype + 
    ' -o ' + outputdir
71/115:
cmd = 'gpsparser.py ' +
    ' -d ' + os.path.join(directory,'device') + '::.nmea0183' +
    ' -s ' + logtype + 
    ' -o ' + outputdir
71/116:
cmd = ('gpsparser.py ',
        ' -d ' + os.path.join(directory,'device') + '::.nmea0183',
        ' -s ' + logtype, 
        ' -o ' + outputdir)
72/1: import datetime
72/2: dts = datetime.datetime.utcnow.isoformat()
72/3: dts = datetime.datetime.utcnow()
72/4: dts.isoformat()
72/5: dts = datetime.datetime.utcnow().isoformat()
72/6: dts
72/7: import os
72/8: import sys
72/9: man wget
72/10: man wget
72/11: sleep(2)
72/12: import time
72/13: time.sleep(2)
73/1: ls
73/2: cd ~/gitsrc/asv_tools/pyasv/
73/3: ls
73/4: cd bin
73/5: ls
72/14: from __future__ import print_function
72/15: import sys
72/16:
def eprint(*args, **kwargs):
        print(*args, file=sys.stderr, **kwargs)
72/17: print "test"
72/18: print("test")
72/19: eprint("test")
72/20: print("test%s" % "123")
74/1: import os
74/2: ls
74/3: cd ~/scratch/gpsparsertest/
74/4: output = './GPS.txt'
74/5:
if output:
    print "test"
74/6: os.path.isfile(output)
74/7: ls
74/8: os.path.basename('/path/to/something/')
74/9: os.path.basename('/path/to/something')
74/10: os.path.isdir('/Users/vschmidt/scratch')
74/11: os.path.isdir('/Users/vschmidt/scratch/abc')
74/12: os.path.isdir('/Users/vschmidt/scratch/abc/')
74/13: pwd
74/14: cd ~/gitsrc/asv_tools/pyasv/bin/
74/15: ls
74/16: run parsenmea2000.py
74/17: run parsenmea2000.py -h
74/18: run parsenmea2000.py -d /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/ -v
74/19: ls /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/
74/20: ls /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/
74/21: pwd
74/22: run parsenmea2000.py -d /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/ -v
74/23: run parsenmea2000.py -d /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/ -v
74/24: run parsenmea2000.py -d /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/ -v
74/25: ls /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/
74/26: ls /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/
74/27: run cworker_logparser.py -d /Volumes/SCHMIDT/2016_SAT/extracted_logs/2016-09-15T17-28-04/
74/28: run parsenmea2000.py -d /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/ -v
74/29: run parsenmea2000.py -d /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/ -v
74/30: run parsenmea2000.py -d /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/ -v
74/31: run parsenmea2000.py -d /Volumes/SCHMIDT/2016_SAT/ccscm/scm-vp/2016-09-11T19-41-34/device/ -v
72/21: pwd
75/1: import time
75/2: time.sleep(2)
75/3: import sys
75/4: import numpy as np
75/5: a = np.array(1)
75/6: a
75/7: print a
76/1: import pandas as pd
76/2: import numpy as np
76/3: z = np.zeros?
76/4: z = np.zeros(86400,2)
76/5: z = np.zeros(86400,2,'float')
76/6: z = np.zeros?
76/7: z = np.zeros(86400,2,np.float64)
76/8: z = np.zeros((86400,2))
76/9: z.fill(np.nan)
76/10: z[1:10]
76/11: z = np.zeros((86400,1))
76/12: z.fill(np.nan)
76/13: import datetime
76/14: today = datetime.datetime.today()
76/15: now = datetime.datetime.now()
76/16: dt = now-today
76/17: dt.seconds()
76/18: dt.seconds
76/19: dt.total_seconds
76/20: dt.total_seconds()
76/21: dt.max
76/22: dt.min
76/23: dt.min()
76/24: dt.min
76/25: today.isoformat()
76/26: today.date()
76/27: today = datetime.datetime.now().date()
76/28: today
76/29: dt = now-today
76/30: today.today()
76/31: today.ctime()
76/32: datetime.datetime.combine?
76/33: td = datetime.datetime.today()
76/34: td
76/35: td.hour
76/36: td = datetime.datetime.utcnow()
76/37: td
76/38: td.hour = 0
76/39: datetime.date?
76/40: dts = datetime.datetime.now()
76/41: md = datetime.datetime(dts.year,dts.mon,dts.day)
76/42: md = datetime.datetime(dts.year,dts.month,dts.day)
76/43: md
76/44: dt = datetime.datetime.utcnow()-md
76/45: dt.total_seconds()
76/46: np.arange?
76/47: np.floor((datetime.datetime.utcnow()-md)).total_seconds())
76/48: np.floor((datetime.datetime.utcnow()-md)).total_seconds())
76/49: np.floor((datetime.datetime.utcnow()-md).total_seconds())
76/50: whos
76/51: z[np.floor((datetime.datetime.utcnow()-md).total_seconds())] = 3
76/52: z[int(np.floor((datetime.datetime.utcnow()-md).total_seconds()))] = 3
76/53: y = np.random((100,1))
76/54: y = np.random.rand?
76/55: y = np.random.rand((100,1))
76/56: y = np.random.rand(100)
76/57: whos y
76/58: y
76/59: z[np.arange(100,200)] = y
76/60: np.arange(100,200).size()
76/61: np.arange?
76/62: np.arange(10,20)
76/63: z[np.arange(100,201)] = y
76/64: y.shape()
76/65: whos
76/66: y = np.random.rand?
76/67: y = np.random.rand(100,1)
76/68: whos
76/69: z[np.arange(100,200)] = y
76/70: t = np.arange(0,86400)
76/71: whos
76/72: pd.DataFrame?
76/73: df = pd.DataFrame([t,z])
76/74: df
76/75: df = pd.DataFrame([t',z'])
76/76: df = pd.DataFrame([t.transpose(),z.transpose()])
76/77: df
76/78: whos
76/79: zz = [t,z]
76/80: whos
76/81: zz = (t,z)
76/82: whos
76/83: zz = np.array(t,z)
76/84: zz = np.array((t,z))
76/85: zz = np.array([t,z])
76/86: whos
76/87: np.arange?
76/88: t = np.array(np.arange(0,86400))
76/89: whos
76/90: t[0:3]
76/91: t = t.transpose()
76/92: whos
76/93: t[1:3]
76/94:
zz = np.concatenate([t,z]
)
76/95: zz = np.concatenate([t,z],1)
76/96: whos
76/97: t = r_[0.:86400,'c']
76/98: t = np.r_[0.:86400,'c']
76/99: t = np.arange(0,86400)[:,nexaxis]
76/100: t = np.arange(0,86400)[:,newaxis]
76/101: t = np.arange(0,86400)
76/102: t = t[:]
76/103: whos
76/104: t.size()
76/105: t.size
76/106: z.size
76/107: zz = np.concatenate((t,z))
76/108: t.shape()
76/109: t.shape
76/110: z.shape
76/111: z = np.zeros((86400,0))
76/112: whos
76/113: z = np.zeros((86400,1))
76/114: z = np.zeros((86400))
76/115: whos
76/116: z[np.arange(100,200)] = y
76/117: size(y)
76/118: y.shape
76/119: y = np.random.rand(100)
76/120: y.shape
76/121: z[np.arange(100,200)] = y
76/122: whos
76/123: df = pd.DataFrame?
76/124: df = pd.DataFrame(np.concatenate(t,z))
76/125: zz = np.concatenate((t,z))
76/126: whos
76/127: zz = np.concatenate((t,z),axis=1)
76/128: zz = np.concatenate((t,z),axis=0)
76/129: whos
76/130: zz = np.concatenate((t,z),axis=1)
76/131: np.concatinate?
76/132: np.concatenate?
76/133: zz = np.concatenate((t[:],z[:]),axis=1)
76/134: df = pd.DataFrame(t[:],z[:])
76/135: df
76/136: df[1:10,1:10]
76/137:
df([1:10,:]
)
76/138: df(1:10)
76/139: import sys
76/140: sys.stdin.realline()
76/141: sys.stdin.readline()
77/1: import datetime
77/2: dt = datetime.datetime.utcnow().unixseconds()
77/3: dt = datetime.datetime.utcnow().unixseconds
77/4: dt = datetime.datetime.utcnow().epochtime()
77/5: dt = datetime.datetime.utcnow()
77/6: dt.strftime?
77/7: dt.strptime?
77/8: dt.strptime?
77/9: dt.isoformat()
77/10: ddt = datetime.datetime.utcfromtimestamp(dt.isoformat())
77/11: ddt = datetime.datetime.fromtimestamp?
77/12: dt
77/13: dt.seconds()
77/14: dt.timestamp()
77/15: dt.timestamp
77/16: import time
77/17: time.mktime(dt)
77/18: time.mktime(dt.timetuple)
77/19: time.mktime(dt.timetuple())
77/20: time.gmtime()
77/21: time.mktime()
77/22: time.mktime(time.gmtime)
77/23: time.time()
77/24: time.time?
77/25: time.timezone?
77/26: time.time()
77/27: time.mktime(datetime.datetime.utcnow().timetuple())
77/28: time.time()
77/29: time.gmtime()
77/30: time.asctime?
77/31: time.ctime?
77/32: time.gmtime?
77/33: time.mktime()
77/34: time.mktime?
77/35: time.mktime(datetime.datetime.utcnow())
77/36: time.mktime(datetime.datetime.utcnow().timetuple())
77/37: time.mktime(datetime.datetime.utcnow().timetuple())
77/38: time.mktime(datetime.datetime.utcnow().timetuple())
77/39: time.mktime(datetime.datetime.utcnow().timetuple())
77/40: time.mktime(datetime.datetime.utcnow().timetuple())
77/41: time.time()
77/42: import calendar
77/43: g = time.gmtime()
77/44: calendar.timegm(g)
77/45: dts = datetime.datetime.utcnow()
77/46: time.mktime(dts.timetuple())
77/47: time.mktime(dts.timetuple()) + dts.microsecond/1e6
77/48: import datetime, time
77/49:     dts = datetime.datetime.utcnow()
77/50:     epochtime = time.mktime(dts.timetuple()) + dts.microseconds/1e6
77/51: dts = datetime.datetime.utcnow()
77/52: epochtime = time.mktime(dts.timetuple()) + dts.microseconds/1e6
77/53: epochtime = time.mktime(dts.timetuple()) + dts.microsecond/1e6
77/54: print epochtime
77/55: dts = datetime.datetime.utcnow()
77/56: epochtime = time.mktime(dts.timetuple()) + dts.microsecond/1e6
77/57: print epochtime
77/58: epochtime
77/59: calendar.timegm?
77/60: calendar.timegm(g)
77/61: str(epochtime)
77/62: print '%0.4f' % epochtime
77/63: print('%0.4f', epochtime)
77/64: print?
77/65: print()?
77/66: str(epochtime).format('%0.3f')
77/67: print({%0.4f}, epochtime)
77/68: str({0.5f}).format(epochtime)
77/69: str({a:0.5f}).format(a=epochtime)
77/70: str("{a:0.5f}").format(a=epochtime)
77/71: line='abc'
77/72: line+= "{a:0.6f}".format(a=epochtime)
77/73: line
77/74: line+= "{a:0.6f} ".format(a=epochtime)
77/75: line
77/76: line = 'abc'
77/77: line+= "{a:0.6f}\t".format(a=epochtime)
77/78: line
77/79: line = 'abc'
77/80: line = "{a:0.6f}\t".format(a=epochtime) + line
77/81: line
77/82: line = 'abc'
77/83: line = "{a:0.6f} ".format(a=epochtime) + line
77/84: line
72/22: import zmq
72/23: context = zmq.Context?
72/24: context = zmq.Context(1)
72/25: frontend = context.socket(zmq.SUB)
72/26: frontend.CONFLATE = True
72/27: frontend.HWM
72/28: frontend.HWM()
72/29: frontend.HWM?
72/30: frontend.setsockopt?
77/85: field = [['abc','112'],['cdf','333]]
77/86: field = [['abc','112'],['cdf','333']]
77/87: field
77/88:
for a, b in field:
    print a
77/89: field[0][0] = ''
77/90: print field
77/91:
for a, b in field:
    print a
77/92: field=['abc','def']
77/93: field.join(',')
77/94: ','.join(field)
77/95: field.count()
77/96: field
77/97: field.count('abc')
77/98: field.count('abcc')
79/1: import decimal as dec
79/2: dec.Decimal.InvalidOperation
79/3: dec.Decimal('asb')
79/4: import dateutils.parser
79/5: import dateutils.parse
79/6: from dateutil.parser import *
79/7: dts = parse('2016-04-13 20:00:07,889')
79/8: dts.isoformat()
79/9: import time
79/10: time.mktime()
79/11: time.gmtime()
79/12: time.mktime()
79/13: time.time()
79/14: dts = parse('1476555647.322106')
79/15: dts = parse(1476555647.322106)
79/16: dts = parse('2016-04-13 20:00:07,889,$GPGSV,4,1,13,28,61,332,38,01,60,070,30,30,55,211,37,11,47,053,35*7F')
79/17: dts = parse('2016-04-13 20:00:07,889,$GPGSV,4,1,13,28,61,332,38,01,60,070,30,30,55,211,37,11,47,053,35*7F',fuzzy=True)
80/1: import re
80/2: exp = '\d\d\d\d-\d\d-\d\d \d\d:\d\d:\d\d\.\d+'
80/3: str = '2016-04-13 20:00:07,889,$GPGSV,4,1,13,28,61,332,38,01,60,070,30,30,55,211,37,11,47,053,35*7F'
80/4: m = re.search(exp,str)
80/5: print m
80/6: exp = '\d\d\d\d-\d\d-\d\d \d\d:\d\d:\d\d?\.?\d+'
80/7: m = re.search(exp,str)
80/8: print m
80/9: m.group()
80/10: import dateutil
80/11: parse()
80/12: import dateutil.parser
81/1: import asvlog as asl
81/2: asl.asvlog?
81/3: p = asl.asvlog('/Volumes/SCHMIDT/cw4/extracted_logs/2016-09-14T13-54-55/pilot.csv')
81/4: p = asl.asvlog.asvlog('/Volumes/SCHMIDT/cw4/extracted_logs/2016-09-14T13-54-55/pilot.csv')
81/5: p.parse()
81/6: p.columns.values()
81/7: p.columns.values
81/8: p.data.columns.values
81/9: a_dict = {col_name : p.data[col_name].values for col_name in self.data.columns.values}
81/10: a_dict = {col_name : p.data[col_name].values for col_name in p.data.columns.values}
81/11: a_dict
81/12: a_dict['EpochTime'] = p.data.index
81/13: a_dict
81/14: import pandas as pp
81/15: d = pp.read_csv('/Volumes/SCHMIDT/cw4/extracted_logs/2016-09-14T13-54-55/pilot.csv',header=0)
81/16: d.columns
81/17: d.index = pp.to_datetime(d['Epoch Time (s)'],unit='s')
81/18: d.columns
81/19: pwd
81/20: directory = '/Volumes/SCHMIDT/cw4/extracted_logs/2016-08-10T11-06-43/'
81/21:
for root, dirnames, filenames in os.walk(directory):
    print filenames
81/22: import os
81/23:
for root, dirnames, filenames in os.walk(directory):
    print filenames
81/24:
for root, dirnames, filenames in os.walk(directory):
    for filename in fnmatch.filter(filenames,'*.csv'):
        print filename
81/25: import fnmatch
81/26:
for root, dirnames, filenames in os.walk(directory):
    for filename in fnmatch.filter(filenames,'*.csv'):
        print filename
81/27: csvfilestoprocess = []
81/28:
for root, dirnames, filenames in os.walk(directory):
    for filename in fnmatch.filter(filenames,'*.csv'):
        csvfilestoprocess.append(os.path.join(root,filename))
81/29: print csvfilestoprocess
82/1: pwd
82/2: cd ~/gitsrc/encs/
82/3: ls
82/4: run enc_survey_for_deep_obstacles.py -h
82/5: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000''/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000'
82/6: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000''/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000' -v
82/7: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000''/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000' -v
82/8: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000''/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000' -v
82/9: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000''/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000' -v
82/10: from osgeo import ogr
82/11: ogr.Open('/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000')
82/12: ds = ogr.Open('/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000')
82/13: ds
82/14: print ds
82/15: ds = ogr.Open('/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000')
82/16: print ds
82/17: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000' -v
82/18: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000' -v
82/19: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000' -v
82/20: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1AK90M/US1AK90M.000'
82/21: run enc_survey_for_deep_obstacles.py -d '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/'
82/22: run enc_survey_for_deep_obstacles.py -d '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/' -v
82/23: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1BS03M/US1BS03M.000'
82/24: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1BS03M/US1BS03M.000'
82/25: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1BS03M/US1BS03M.000'
82/26: run enc_survey_for_deep_obstacles.py -f '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US1BS03M/US1BS03M.000'
82/27: run enc_survey_for_deep_obstacles.py -d '/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/' -v
82/28: run enc_survey_for_deep_obstacles.py -f /Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US5FL12M/US5FL12M.000
82/29: ds = ogr.Open('/Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US5FL12M/US5FL12M.000')
82/30: wrecks = ds.GetLayerByName('WRECKS')
82/31: wrecks.getFeatureCount()
82/32: wrecks.GetFeatureCount
82/33: wrecks.GetFeatureCount()
82/34: f = wrecks.GetFeature(19)
82/35: print f
82/36: f = wrecks.GetFeature(18)
82/37: print f
82/38: f = wrecks.GetFeature?
82/39: f = wrecks.GetNextFeature()
82/40: print f
82/41: f = wrecks.GetFeature(1)
82/42: print f
82/43: wrecks.GetDescription
82/44: wrecks.GetFeature?
82/45: run enc_survey_for_deep_obstacles.py -f /Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US5FL12M/US5FL12M.000
82/46: debugfile('/Users/vschmidt/gitsrc/encs/enc_survey_for_deep_obstacles.py', wdir='/Users/vschmidt/gitsrc/encs')
82/47: debugfile('/Users/vschmidt/gitsrc/encs/enc_survey_for_deep_obstacles.py', args='-f /Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US5FL12M/US5FL12M.000 ', wdir='/Users/vschmidt/gitsrc/encs')
82/48: debugfile('/Users/vschmidt/gitsrc/encs/enc_survey_for_deep_obstacles.py', args='-f /Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US5FL12M/US5FL12M.000 ', wdir='/Users/vschmidt/gitsrc/encs')
82/49: debugfile('/Users/vschmidt/gitsrc/encs/enc_survey_for_deep_obstacles.py', args='-f /Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US5FL12M/US5FL12M.000 ', wdir='/Users/vschmidt/gitsrc/encs')
82/50: debugfile('/Users/vschmidt/gitsrc/encs/enc_survey_for_deep_obstacles.py', args='-f /Users/vschmidt/library.local/surveykit/chart/Charts_ENCs/ENC_ALL/US5FL12M/US5FL12M.000 ', wdir='/Users/vschmidt/gitsrc/encs')
83/1: import os
83/2: os.path.basename('/test/name')
84/1: import os
84/2: a = 'abc')
84/3: a = ['abc','cde']
84/4: ',',join(a)
84/5: ",",join('abc','def')
84/6: ",".join('abc','def')
84/7: ",".join(('abc','def'))
85/1: import os
85/2: import sys
85/3: sys.platform
85/4: os.name
86/1: import imageio
86/2: imageio.mimsave?
86/3: :func: `.help`
86/4: :imageio.mimsave: `.help`
86/5: import amth as m
86/6: import math as m
86/7: m.pow?
86/8: 256*256*256
87/1: a[0] = 'step'
87/2: a = list
87/3: a[0] = 'step'
87/4: whos
87/5: a = array
87/6: a = dict
87/7: a[0] = 'step'
87/8: a = list
87/9: a.append('abc')
87/10: a.insert('abc')
87/11: a = ['step']
87/12: a[0] == 'step'
87/13: '0:5:100,30'
87/14: a,b = '0:5:100,30'.split(',')
87/15: c,d,e = a.spit(':')
87/16: a
87/17: c,d,e = a.split(':')
87/18: c
87/19: d
87/20: e
87/21: range?
87/22: import time
87/23: time.mktime()
87/24: time.gmtime()
87/25: time.mktime(time.gmtime())
87/26: start_time = time.mktime(time.gmtime())
87/27: time.mktime(time.gmtime()) - start_time
87/28: time.mktime(time.gmtime()) - start_time
87/29: time.mktime(time.gmtime()) - start_time
87/30: time.mktime(time.gmtime()) - start_time
87/31: time.mktime(time.gmtime()) - start_time
87/32: time.mktime(time.gmtime()) - start_time
87/33: time.time()
87/34: start_time = time.time()
87/35: duration = time.time()-start_time
87/36: duration
87/37: duration = time.time()-start_time
87/38: duration
87/39: a
87/40: b
87/41: c
87/42: d
87/43:
print("Conducting Step test from {a:0.1f} to {b:0.1f} by {c:0.1f}, {d:0.1f} s per step".fo\
rmat(a=a,b=b,c=c,d=5
))
87/44:
print("Conducting Step test from {a:0.1f} to {b:0.1f} by {c:0.1f}, {d:0.1f} s per step".fo\
rmat(a=float(a),b=float(b),c=float(c),d=float(5)
)

)
87/45: a
87/46:
print("Conducting Step test from {a:0.1f} to {b:0.1f} by {c:0.1f}, {d:0.1f} s per step".fo\
rmat(a=float(c),b=float(b),c=float(c),d=float(5)
)

)
88/1: import sys
88/2: import os
88/3: ls
88/4: ls marine_sim/marine_sim/
88/5: cd marine_sim/
88/6: sys.path.insert(0,os.path.abspath('.'))
88/7: print sys.path
88/8: import marine_sim
88/9: marine_sim.marine_sim.R(45.0,45.0)
88/10: marine_sim.marine_sim.Rll(45.0,45.0)
88/11: marine_sim..Rll(45.0,45.0)
88/12: marine_sim.Rll(45.0,45.0)
88/13: ls
88/14: import marine_sim.marine_sim
88/15: import marine_sim.marine_sim
88/16: marine_sim.marine_sim.Rll(45.0,45.0)
88/17: marine_sim.marine_sim.Rll(45.0,50.0)
88/18: marine_sim.marine_sim.Rll(45.0,50.0)
88/19: reload(marine_sim.marine_sim)
88/20: marine_sim.marine_sim.Rll(45.0,50.0)
88/21: reload(marine_sim.marine_sim)
88/22: marine_sim.marine_sim.edef2latlon(10,10,0)
88/23: reload(marine_sim.marine_sim)
88/24: marine_sim.marine_sim.edef2latlon(10,10,0)
88/25: reload(marine_sim.marine_sim)
88/26: x,y,z  = marine_sim.marine_sim.edef2latlon(43.0,-70.0,0)
88/27: x,y,z  = marine_sim.marine_sim.latlon2ecef(43.0,-70.0,0)
88/28: print x,y,z
88/29: reload(marine_sim.marine_sim)
88/30: reload(marine_sim.marine_sim)
88/31: marine_sim.marine_sim.edef2latlon(10,10,0)
88/32: marine_sim.marine_sim.ecef2latlon(10,10,0)
88/33: x,y,z  = marine_sim.marine_sim.latlon2ecef(43.0,-70.0,0)
88/34: print x,y,z
88/35: lat,lon,height = marine_sim.marine_sim.ecef2latlonheight(x,y,z)
88/36: print lat,lon,height
88/37: reload(marine_sim.marine_sim)
88/38: x,y,z  = marine_sim.marine_sim.latlon2ecef(43.0,-70.0,0)
88/39: lat,lon,height = marine_sim.marine_sim.ecef2latlonheight(x,y,z)
88/40: print lat,lon,height
88/41: print x,y,z
88/42: x,y,z  = marine_sim.marine_sim.latlon2ecef(43.0,-70.0,0.0)
88/43: print x,y,z
88/44: print z
88/45: print "0.9f" % z
88/46: print "%0.9f" % z
88/47: reload(marine_sim.marine_sim)
88/48: x,y,z  = marine_sim.marine_sim.latlon2ecef(43.0,-70.0,0.0)
88/49: print x,y,z
88/50: sin(0)
88/51: from math import *
88/52: sin(0)
88/53: sin(43)
88/54: cos(60))
88/55: cos(60)
88/56: cos(60*pi/180)
88/57: height
88/58: x,y,z  = marine_sim.marine_sim.latlonheight2ecef(43.0,-70.0,0.0)
88/59: print x,y,z
88/60: lat,lon,height = marine_sim.marine_sim.ecef2latlonheight(x,y,z)
88/61: print lat,lon,height
88/62: sign(-3)
88/63: rem?
88/64: import math
88/65: math.radians?
88/66: radians(270)
88/67: reload(marine_sim.marine_sim)
88/68: marine_sim.marine_sim.rad2pipi(radians(270))
88/69: reload(marine_sim.marine_sim)
88/70: marine_sim.marine_sim.rad2pipi(radians(270))
88/71: reload(marine_sim.marine_sim)
88/72: marine_sim.marine_sim.Rzyx(10*pi/180,20*pi/180,30*pi/180)
88/73: a = np.array([1, 2, 3])
88/74: import numpy as np
88/75: a = np.array([1, 2, 3])
88/76: reload(marine_sim.marine_sim)
88/77: reload(marine_sim.marine_sim)
88/78: marine_sim.marine_sim.Smtrx(a)
88/79: reload(marine_sim.marine_sim)
88/80: marine_sim.marine_sim.Smtrx(a)
88/81: reload(marine_sim.marine_sim)
88/82: marine_sim.marine_sim.deg2deg180(270)
88/83: marine_sim.marine_sim.sign(0)
88/84: a
88/85: a == 3
88/86: reload(marine_sim.marine_sim)
88/87: marine_sim.marine_sim.sign(0)
88/88: marine_sim.marine_sim.deg2deg180(270)
88/89: reload(marine_sim.marine_sim)
88/90: marine_sim.marine_sim.deg2deg180(270)
88/91: reload(marine_sim.marine_sim)
88/92: marine_sim.marine_sim.deg2deg180(270)
88/93: R = np.array([4,4])
88/94: print R
88/95: R = np.zeros([4,4])
88/96: print R
88/97: R[0:2,0:2] = Rzyx(.5 .5 .5)
88/98: R[0:2,0:2] = Rzyx(.5, .5, .5)
88/99: R[0:2,0:2] = marine_sim.marine_sim.Rzyx(.5, .5, .5)
88/100: marine_sim.marine_sim.Rzyx(10*pi/180,20*pi/180,30*pi/180)
88/101: R[0:3,0:3] = marine_sim.marine_sim.Rzyx(10*pi/180,20*pi/180,30*pi/180)
88/102: print R
88/103: Rtmp = marine_sim.marine_sim.Rzyx(10*pi/180,20*pi/180,30*pi/180)
88/104: Rtmp.trace()
88/105: a
88/106: a.max()
88/107: R
88/108: R[4,4] = Rtmp.trace()
88/109: R[3,3] = Rtmp.trace()
88/110: print R
88/111: R.diagonal()
88/112: R.diagonal().max()
88/113: R.diagonal().max?
88/114: c,d = R.diagonal().max()
88/115: R.diagonal().max()
88/116: Rmax = R.diagonal().max()
88/117: Rmax == R.diagonal()
88/118: find(Rmax == R.diagonal())
88/119: sumd(Rmax == R.diagonal())
88/120: sum(Rmax == R.diagonal())
88/121: any(Rmax == R.diagonal())
88/122: Rmax == R.diagonal() and [1,2,3,4]
88/123: (Rmax == R.diagonal()).where()
88/124: np.where(Rmax == R.diagonal())
88/125: np.where(Rmax == R.diagonal())[0]
88/126: q = np.where(Rmax == R.diagonal())[0]
88/127: q == 3
88/128:
if q == 3:
    print "yes"
88/129: a
88/130: a.transpose()
88/131: print a
88/132: print a.transpose()
88/133: a.dot(a)
88/134: a.transpose().dot(a)
88/135: a.dot(a.transpose())
88/136: reload(marine_sim.marine_sim)
88/137: reload(marine_sim.marine_sim)
88/138: reload(marine_sim.marine_sim)
88/139: marein_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/140: marine_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/141: reload(marine_sim.marine_sim)
88/142: marine_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/143: reload(marine_sim.marine_sim)
88/144: marine_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/145: marine_sim.marine_sim.Rzyx(10*pi/180,20*pi/180,30*pi/180)
88/146: reload(marine_sim.marine_sim)
88/147: marine_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/148: reload(marine_sim.marine_sim)
88/149: marine_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/150: reload(marine_sim.marine_sim)
88/151: marine_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/152: reload(marine_sim.marine_sim)
88/153: marine_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/154: reload(marine_sim.marine_sim)
88/155: marine_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/156: reload(marine_sim.marine_sim)
88/157: marine_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/158: reload(marine_sim.marine_sim)
88/159: marine_sim.marine_sim.euler2q(10*pi/180,20*pi/180,30*pi/180)
88/160: A = np.ones(3,3)
88/161: A = np.ones(3,3)
88/162: A = np.ones([3,3])
88/163: B = np.array([A,A],[A,A]])
88/164: B = np.array([[A,A],[A,A]])
88/165: print B
88/166: reload(marine_sim.marine_sim)
88/167: marine_sim.marine_sim(10*pi/180,20*pi/180,30*pi/180)
88/168: marine_sim.marine_sim.eulerang(10*pi/180,20*pi/180,30*pi/180)
88/169: marine_sim.marine_sim(10*pi/180,20*pi/180,30*pi/180)
88/170: reload(marine_sim.marine_sim)
88/171: marine_sim.marine_sim.eulerang(10*pi/180,20*pi/180,30*pi/180)
88/172: marine_sim.marine_sim.eulerang(10*pi/180,20*pi/180,30*pi/180)
88/173: reload(marine_sim.marine_sim)
88/174: marine_sim.marine_sim.eulerang(10*pi/180,20*pi/180,30*pi/180)
88/175: J, J1, J2 = marine_sim.marine_sim.eulerang(10*pi/180,20*pi/180,30*pi/180)
88/176: print J
88/177: print J1
88/178: print J2
88/179: print np.eye([6,6])
88/180: print np.eye(6,6)
88/181: S = marine_sim.marine_sim.Smtrx(1)
88/182: S = marine_sim.marine_sim.Smtrx(np.array([1, 2 3]))
88/183: S = marine_sim.marine_sim.Smtrx(np.array([1, 2, 3]))
88/184: print S
88/185: S.transpose()
88/186: S.transpose()
88/187: reload(marine_sim.marine_sim)
88/188: marine_sim.marine_sim.Hmtrx(np.array([1,2,3]))
88/189: reload(marine_sim.marine_sim)
88/190: marine_sim.marine_sim.Hmtrx(np.array([1,2,3]))
88/191: reload(marine_sim.marine_sim)
88/192: marine_sim.marine_sim.Hmtrx(np.array([1,2,3]))
88/193: np.diag([1,2,3])
88/194: reload(marine_sim.marine_sim)
88/195: reload(marine_sim.marine_sim)
88/196: marine_sim.marine_sim(10,2,4,5,np.array([1,2,3]))
88/197: marine_sim.marine_sim.Gmtrx(10,2,4,5,np.array([1,2,3]))
88/198: marine_sim.marine_sim.Hmtrx(np.array([1,2,3]))
88/199: reload(marine_sim.marine_sim)
88/200: marine_sim.marine_sim.Gmtrx(10,2,4,5,np.array([1,2,3]))
88/201: reload(marine_sim.marine_sim)
88/202: marine_sim.marine_sim.Gmtrx(10,2,4,5,np.array([1,2,3]))
88/203: reload(marine_sim.marine_sim)
88/204: marine_sim.marine_sim.Gmtrx(10,2,4,5,np.array([1,2,3]))
88/205: reload(marine_sim.marine_sim)
88/206: marine_sim.marine_sim.Gmtrx(10,2,4,5,np.array([1,2,3]))
88/207: reload(marine_sim.marine_sim)
88/208: marine_sim.marine_sim.Gmtrx(10,2,4,5,np.array([1,2,3]))
88/209: reload(marine_sim.marine_sim)
88/210: marine_sim.marine_sim.m2c(np.ones(6,6),np.ones(6,1)*3)
88/211: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/212: marine_sim.marine_sim.m2c(np.ones(6,6),np.ones(6,1)*3)
88/213: reload(marine_sim.marine_sim)
88/214: marine_sim.marine_sim.m2c(np.ones(6,6),np.ones(6,1)*3)
88/215: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/216: marine_sim.marine_sim.m2c(np.ones(6,6),np.ones(6,1)*3)
88/217: reload(marine_sim.marine_sim)
88/218: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/219: reload(marine_sim.marine_sim)
88/220: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/221: reload(marine_sim.marine_sim)
88/222: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/223: reload(marine_sim.marine_sim)
88/224: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/225: reload(marine_sim.marine_sim)
88/226: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/227: reload(marine_sim.marine_sim)
88/228: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/229: reload(marine_sim.marine_sim)
88/230: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/231: reload(marine_sim.marine_sim)
88/232: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/233: reload(marine_sim.marine_sim)
88/234: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/235: reload(marine_sim.marine_sim)
88/236: marine_sim.marine_sim.m2c(np.ones([6,6]),np.ones([6,1])*3)
88/237: a
88/238: a.dot(a)
88/239: sqrt(a.dot(a))
88/240: reload(marine_sim.marine_sim)
88/241: b = np.array([1,2,3,4])
88/242: bb = b / sqrt(b.dot(b))
88/243: print bb
88/244: marine_sim.marine_sim(bb)
88/245: marine_sim.marine_sim.Rquat(bb)
88/246: marine_sim.marine_sim.Rquat(bb)
88/247: reload(marine_sim.marine_sim)
88/248: marine_sim.marine_sim.Rquat(bb)
88/249: reload(marine_sim.marine_sim)
88/250: marine_sim.marine_sim.Rquat(bb)
88/251: reload(marine_sim.marine_sim)
88/252: marine_sim.marine_sim.Rquat(bb)
88/253: print bb
88/254: reload(marine_sim.marine_sim)
88/255: marine_sim.marine_sim.Rquat(bb)
88/256: reload(marine_sim.marine_sim)
88/257: marine_sim.marine_sim.Rquat(bb)
88/258: reload(marine_sim.marine_sim)
88/259: marine_sim.marine_sim.Rquat(bb)
88/260: reload(marine_sim.marine_sim)
88/261: marine_sim.marine_sim.Rquat(bb)
88/262: reload(marine_sim.marine_sim)
88/263: marine_sim.marine_sim(bb)
88/264: marine_sim.marine_sim.q2euler(bb)
88/265: reload(marine_sim.marine_sim)
88/266: reload(marine_sim.marine_sim)
88/267: reload(marine_sim.marine_sim)
88/268: quatern(bb)
88/269: marine_sim.marine_sim.quatern(bb)
88/270: marine_sim.marine_sim.quatern(bb)
88/271: bb
88/272: reload(marine_sim.marine_sim)
88/273: marine_sim.marine_sim.quatern(bb)
88/274: marine_sim.marine_sim.quatern(bb)
88/275: reload(marine_sim.marine_sim)
88/276: marine_sim.marine_sim.quatern(bb)
88/277: reload(marine_sim.marine_sim)
88/278: marine_sim.marine_sim.quatern(bb)
88/279: J, J1, J2 = marine_sim.marine_sim.quatern(bb)
88/280: print J
88/281: print J2
88/282: J2.size(2)
88/283: J2.size()
88/284: J2.size
88/285: J2.size?
88/286: J2
88/287: J2[:1]
88/288: J2[:0]
88/289: J2[:1]
88/290: J2[:2]
88/291: J2[:,1]
88/292: K = rand([3,3])
88/293: K = np.rand([3,3])
88/294: K = np.random([3,3])
88/295: K = np.random.normal([3,3])
88/296: print K
88/297: K = np.random.normal?
88/298: K = np.random.normal(1,1,[3,3])
88/299: print K
88/300: J1
88/301: w,v = np.linalg.eig(J1)
88/302: print w
88/303: print v
88/304: W = np.array([1,2,3],[2,3,4],[3, 4, 5]]
88/305: W = np.array([1,2,3],[2,3,4],[3, 4, 5]])
88/306: W = np.array([[1,2,3],[2,3,4],[3, 4, 5]])
88/307: V = np.array([[3,2,1],[4,3,2],[5,4,3]])
88/308: reload(marine_sim.marine_sim)
88/309: R,q = marine_sim.marine_sim(W,V)
88/310: R,q = marine_sim.marine_sim.quest(W,V)
88/311: reload(marine_sim.marine_sim)
88/312: R,q = marine_sim.marine_sim.quest(W,V)
88/313: W.shape
88/314: x,y = W.shape
88/315: print x,y
88/316: reload(marine_sim.marine_sim)
88/317: R,q = marine_sim.marine_sim.quest(W,V)
88/318: reload(marine_sim.marine_sim)
88/319: R,q = marine_sim.marine_sim.quest(W,V)
88/320: reload(marine_sim.marine_sim)
88/321: R,q = marine_sim.marine_sim.quest(W,V)
88/322: reload(marine_sim.marine_sim)
88/323: R,q = marine_sim.marine_sim.quest(W,V)
88/324: reload(marine_sim.marine_sim)
88/325: R,q = marine_sim.marine_sim.quest(W,V)
88/326: print W
88/327: print V
88/328: np.cross(W[:,0],V[:,0])
88/329: reload(marine_sim.marine_sim)
88/330: R,q = marine_sim.marine_sim(W,V)
88/331: R,q = marine_sim.marine_sim.quest(W,V)
88/332: np.cross(W[:,0],V[:,0]).shape()
88/333: np.cross(W[:,0],V[:,0]).shape
88/334: np.cross(W[:,0],V[:,0].transpose()).shape
88/335: a = 1/3
88/336: Z = np.zeros([3,1])
88/337: Z = Z + a*np.cross(W[:,0],V[:,0])
88/338: print Z
88/339: Z = np.zeros([3,1])
88/340: print Z
88/341: print a*np.cross(W[:,0],V[:,0])
88/342: print a*np.cross(W[:,0],V[:,0]).transpose()
88/343: aa = a*np.cross(W[:,0],V[:,0])
88/344: print aa
88/345: cc = aa[:]
88/346: print cc
88/347: whos cc
88/348: who
88/349: whos
88/350: reload(marine_sim.marine_sim)
88/351: R,q = marine_sim.marine_sim.quest(W,V)
88/352: reload(marine_sim.marine_sim)
88/353: R,q = marine_sim.marine_sim.quest(W,V)
88/354: reload(marine_sim.marine_sim)
88/355: R,q = marine_sim.marine_sim.quest(W,V)
88/356: reload(marine_sim.marine_sim)
88/357: R,q = marine_sim.marine_sim.quest(W,V)
88/358: reload(marine_sim.marine_sim)
88/359: R,q = marine_sim.marine_sim.quest(W,V)
88/360: reload(marine_sim.marine_sim)
88/361: R,q = marine_sim.marine_sim.quest(W,V)
88/362: reload(marine_sim.marine_sim)
88/363: R,q = marine_sim.marine_sim.quest(W,V)
88/364: reload(marine_sim.marine_sim)
88/365: R,q = marine_sim.marine_sim.quest(W,V)
88/366: a
88/367: a = 1/3
88/368: a*W[:,0].dot(V[:,0].transpose())
88/369: W[:0]
88/370: W[:,0]
88/371: V[:,0].tranpose()
88/372: V[:,0].transpose()
88/373: a*W[:,0].dot(V[:,0])
88/374: W[:,0].dot(V[:,0])
88/375: a
88/376: a=1/3
88/377: print a
88/378: a = 1/float(3)
88/379: print a
88/380: reload(marine_sim.marine_sim)
88/381: R,q = marine_sim.marine_sim.quest(W,V)
88/382: reload(marine_sim.marine_sim)
88/383: R,q = marine_sim.marine_sim.quest(W,V)
88/384: reload(marine_sim.marine_sim)
88/385: R,q = marine_sim.marine_sim.quest(W,V)
88/386: idx = 0
88/387: W[:,idx].dot(V[:,idx].transpose())
88/388: W[:,idx].dot(V[:,idx])
88/389:
W[:,idx].dot(V[:,idx].reshape((-1,1))
)
88/390:
W[:,idx].outer(V[:,idx]
)
88/391: np.outer(W[:,idx],V[:,idx])
88/392: reload(marine_sim.marine_sim)
88/393: R,q = marine_sim.marine_sim.quest(W,V)
88/394: reload(marine_sim.marine_sim)
88/395: R,q = marine_sim.marine_sim.quest(W,V)
88/396: reload(marine_sim.marine_sim)
88/397: R,q = marine_sim.marine_sim.quest(W,V)
88/398: reload(marine_sim.marine_sim)
88/399: R,q = marine_sim.marine_sim.quest(W,V)
88/400: reload(marine_sim.marine_sim)
88/401: R,q = marine_sim.marine_sim.quest(W,V)
88/402: J
88/403: J1
88/404: J1[:,1]
88/405: reload(marine_sim.marine_sim)
88/406: R,q = marine_sim.marine_sim.quest(W,V)
88/407: reload(marine_sim.marine_sim)
88/408: R,q = marine_sim.marine_sim.quest(W,V)
88/409: reload(marine_sim.marine_sim)
88/410: R,q = marine_sim.marine_sim.quest(W,V)
88/411: R,q = marine_sim.marine_sim.quest(W,V)
88/412: reload(marine_sim.marine_sim)
88/413: R,q = marine_sim.marine_sim.quest(W,V)
88/414: aa = np.array([1,2,3,4])
88/415: bb = aa/sqrt(aa.dot(aa))
88/416: bb
88/417: sqrt(bb.dot(bb))
88/418: reload(marine_sim.marine_sim)
88/419: R,q = marine_sim.marine_sim.quest(W,V)
88/420: reload(marine_sim.marine_sim)
88/421: R,q = marine_sim.marine_sim.quest(W,V)
88/422: reload(marine_sim.marine_sim)
88/423: R,q = marine_sim.marine_sim.quest(W,V)
88/424: reload(marine_sim.marine_sim)
88/425: R,q = marine_sim.marine_sim.quest(W,V)
88/426: reload(marine_sim.marine_sim)
88/427: R,q = marine_sim.marine_sim.quest(W,V)
88/428: reload(marine_sim.marine_sim)
88/429: R,q = marine_sim.marine_sim.quest(W,V)
88/430: reload(marine_sim.marine_sim)
88/431: R,q = marine_sim.marine_sim.quest(W,V)
88/432: print np.zeros(4)
88/433: R,q = marine_sim.marine_sim.quest(W,V)
88/434: print np.zeros(4)
88/435: reload(marine_sim.marine_sim)
88/436: R,q = marine_sim.marine_sim.quest(W,V)
88/437: print R
88/438: print q
88/439: R,q = marine_sim.marine_sim.quest(W,V)
88/440: reload(marine_sim.marine_sim)
88/441: R,q = marine_sim.marine_sim.quest(W,V)
88/442: reload(marine_sim.marine_sim)
88/443: R,q = marine_sim.marine_sim.quest(W,V)
88/444: reload(marine_sim.marine_sim)
88/445: R,q = marine_sim.marine_sim.quest(W,V)
88/446: mb = np.arange(0,8)
88/447: mb
88/448: mb = np.arange(0,9)
88/449: mb.reshape(3,4)
88/450: mb.reshape(3,3)
88/451: mb
88/452: mb.reshape(3,3)
88/453: print mb
88/454: mb = mb.reshape(3,3)
88/455: mb
88/456: m1_b = mb[0:3]
88/457: m1_b
88/458: mb
88/459: mb = np.arange(0,9)
88/460:
 m1_b = mb[0:3]
 m2_b = mb[3:6]
 

m3_b = mb[6:9]
88/461: y=np.arange(0,9)
88/462:
y1_e = y[0:3]
y2_e = y[3:6]
y3_3 = y[6:9]
88/463: W = np.array([y1_e-y3_e, y2_e-y3_e -y1_e-y2_e])
88/464:
y1_e = y[0:3]
y2_e = y[3:6]
y3_e = y[6:9]
88/465: W = np.array([y1_e-y3_e, y2_e-y3_e -y1_e-y2_e])
88/466: print W
88/467: y1_e
88/468: W = np.array([y1_e-y3_e, y2_e-y3_e, -y1_e-y2_e])
88/469: W
88/470: mb = np.arange(0,9)
88/471: print mb
88/472: mb = np.arange(1,9)
88/473: print mb
88/474: mb = np.arange(1,10)
88/475: print mb
88/476: y = np.arange(1,10)
88/477:
y1_e = y[0:3]
y2_e = y[3:6]
y3_e = y[6:9]
88/478:
 m1_b = mb[0:3]
 m2_b = mb[3:6]
 

m3_b = mb[6:9]
88/479: W = np.array([y1_e-y3_e, y2_e-y3_e, -y1_e-y2_e])
88/480: print W
88/481: y1_e
88/482: y2_e
88/483: W = np.array([y1_e-y3_e, y2_e-y3_e, y1_e-y2_e])
88/484: print W
88/485: W = np.array([y1_e-y3_e, y2_e-y3_e, y1_e-y2_e]).transpose()
88/486: print W
88/487: V = np.array([m1_b-m3_b, m2_b-m3_b, m1_b-m2_b]).transpose()
88/488: print V
88/489: reload(marine_sim.marine_sim)
88/490: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/491: reload(marine_sim.marine_sim)
88/492: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/493: reload(marine_sim.marine_sim)
88/494: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/495: mb.shape
88/496: mb.view
88/497: mb.view()
88/498: mb.dim()
88/499: mb.ndim
88/500: mb.shape[1]
88/501: mb.shape
88/502: mb.shape[0]
88/503: mb.shape.size()
88/504: mb.shape.size
88/505: mb.shape.count()
88/506: mb.shape.count?
88/507: mb.shape
88/508: mb.shape == (9,)
88/509: reload(marine_sim.marine_sim)
88/510: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/511: reload(marine_sim.marine_sim)
88/512: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/513: np.nan
88/514: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/515: reload(marine_sim.marine_sim)
88/516: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/517: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/518: reload(marine_sim.marine_sim)
88/519: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/520: eta
88/521: reload(marine_sim.marine_sim)
88/522: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/523: rcamera
88/524: rcamera = np.array([1,1,1])
88/525: rcamera[:]
88/526: reload(marine_sim.marine_sim)
88/527: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/528: reload(marine_sim.marine_sim)
88/529: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/530: reload(marine_sim.marine_sim)
88/531: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/532: print eta
88/533: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/534: reload(marine_sim.marine_sim)
88/535: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/536: reload(marine_sim.marine_sim)
88/537: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/538: print eta
88/539: rcamera
88/540: (y1_e + y2_e + y3_e - R*(m1_b + m2_b + m3_b))/3.0
88/541: (y1_e + y2_e + y3_e - R.dot(m1_b + m2_b + m3_b))/3.0
88/542: reload(marine_sim.marine_sim)
88/543: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/544: reload(marine_sim.marine_sim)
88/545: eta,q,R = marine_sim.marine_sim.quest6DOF(y,mb,np.array([1,1,1]))
88/546: print eta
88/547: reload(marine_sim.marine_sim)
88/548: R
88/549: marine_sim.marine_sim.R2euler(R)
88/550: a,b,c = marine_sim.marine_sim.R2euler(R)
88/551: R
88/552: reload(marine_sim.marine_sim)
88/553: a,b,c = marine_sim.marine_sim.R2euler(R)
88/554: print a,b,c
88/555: reload(marine_sim.marine_sim)
88/556: tau_w, CX, CY, CK, CN = marine_sim.marine_sim.blendermann94(pi/3,5,6,2,0.5,1,4,14)
88/557: reload(marine_sim.marine_sim)
88/558: tau_w, CX, CY, CK, CN = marine_sim.marine_sim.blendermann94(pi/3,5,6,2,0.5,1,4,14)
88/559: reload(marine_sim.marine_sim)
88/560: tau_w, CX, CY, CK, CN = marine_sim.marine_sim.blendermann94(pi/3,5,6,2,0.5,1,4,14)
88/561: reload(marine_sim.marine_sim)
88/562: reload(marine_sim.marine_sim)
88/563: tau_w, CX, CY, CK, CN = marine_sim.marine_sim.blendermann94(pi/3,5,6,2,0.5,1,4,14)
88/564: reload(marine_sim.marine_sim)
88/565: tau_w, CX, CY, CK, CN = marine_sim.marine_sim.blendermann94(pi/3,5,6,2,0.5,1,4,14)
88/566: reload(marine_sim.marine_sim)
88/567: tau_w, CX, CY, CK, CN = marine_sim.marine_sim.blendermann94(pi/3,5,6,2,0.5,1,4,14)
88/568: print tau_w
88/569: CX
88/570: CY
88/571: CN
88/572: CK
88/573: reload(marine_sim.marine_sim)
88/574: tau_w, CX, CY, CK, CN = marine_sim.marine_sim.blendermann94(pi/3,5,6,2,0.5,1,4,14)
88/575: print CN
88/576: print CK
88/577: reload(marine_sim.marine_sim)
88/578: g = marine_sim.marine_sim.gvect(180,179.5,np.array([0,0,0.05]),np.array([0,0,0]))
88/579: g = marine_sim.marine_sim.gvect(180,179.5,pi/2,0,np.array([0,0,0.05]),np.array([0,0,0]))
88/580: print g
88/581: g
88/582: print g
88/583: g = marine_sim.marine_sim.gvect(180,179.5,pi/2,0,np.array([0,0,0.05]),np.array([0,0,0]))
88/584: print g
88/585: reload(marine_sim.marine_sim)
88/586: g = marine_sim.marine_sim.gvect(180,179.5,pi/2,0,np.array([0,0,0.05]),np.array([0,0,0]))
88/587: reload(marine_sim.marine_sim)
88/588: g = marine_sim.marine_sim.gvect(180,179.5,pi/2,0,np.array([0,0,0.05]),np.array([0,0,0]))
88/589: print g
88/590: erf(.3)
88/591: reload(marine_sim.marine_sim)
88/592: reload(marine_sim.marine_sim)
88/593:
marine_sim.marine_sim.HMmsi(0.5,np.array([1,2,3])
)
88/594: marine_sim.marine_sim.HMmsi(0.5,np.array([1,2,3]))
88/595: reload(marine_sim.marine_sim)
88/596: marine_sim.marine_sim.HMmsi(0.5,np.array([1,2,3]))
88/597: reload(marine_sim.marine_sim)
88/598: marine_sim.marine_sim.HMmsi(0.5,np.array([1,2,3]))
88/599: reload(marine_sim.marine_sim)
88/600: marine_sim.marine_sim.HMmsi(0.5,np.array([1,2,3]))
88/601: reload(marine_sim.marine_sim)
88/602: marine_sim.marine_sim.HMmsi(0.5,np.array([1,2,3]))
88/603: reload(marine_sim.marine_sim)
88/604: marine_sim.marine_sim.HMmsi(0.5,np.array([1,2,3]))
88/605: reload(marine_sim.marine_sim)
88/606: marine_sim.marine_sim.HMmsi(0.5,np.array([1,2,3]))
88/607: reload(marine_sim.marine_sim)
88/608:
marine_sim.marine_sim.encounter(1,1.5,pi/8
)
88/609: reload(marine_sim.marine_sim)
88/610: marine_sim.marine_sim.encounter(3)
88/611: marine_sim.marine_sim.ISOmsi(3)
88/612: range?
88/613: np.arange?
88/614: np.linspace?
88/615: reload(marine_sim.marine_sim)
88/616: marine_sim.marine_sim.ISOmsi(3)
88/617: reload(marine_sim.marine_sim)
88/618: marine_sim.marine_sim.ISOmsi(3)
88/619: reload(marine_sim.marine_sim)
88/620: marine_sim.marine_sim.ISOmsi(3)
88/621: whos
88/622: J1
88/623: np.invert(J1)
88/624: JJ = np.matrix(J1)
88/625: 1/JJ
88/626: JJ
88/627: np.linalg.inv(J1)
88/628: reload(marine_sim.marine_sim)
88/629: reload(marine_sim.marine_sim)
88/630: import marine_sim.marine_sim as s
89/1: a = {}
89/2: a.append('abc')
89/3: a = ()
89/4: a.append('abc')
89/5: a = []
89/6: a.append('abc')
89/7: print a
89/8: a.append('cde')
89/9: print a
89/10: import datetime
89/11: import deltatime
89/12: dt = datetime.datetime(0,0,0,0,0,1.3)
89/13: dt = datetime.datetime.fromordinal?
89/14: dt = datetime.datetime.fromtimestamp()
89/15: dt = datetime.datetime.fromtimestamp?
89/16: dt = datetime.datetime.fromtimestamp(2016)
89/17: print dt
89/18: dt = datetime.datetime.time(0,0,1.5)
89/19: dt = datetime.time(0,0,1.5)
89/20: dt = datetime.time(0,0,1,(1.6%1)/1000000)
89/21: dt = datetime.time(0,0,1,int(1.6%1)/1000000))
89/22: dt = datetime.time(0,0,1)
89/23: print dt
89/24: dt = datetime.time(0,0,1,1000)
89/25: print dt
89/26: dt = datetime.time(0,0,1,int(1.5%1))
89/27: print dt
89/28: 1.5%1
89/29: 1.5%1*1e6
89/30: int(1.5%1*1e6)
89/31: dt = datetime.time(0,0,1,int(1.5%1*1e6))
89/32: print dt
89/33: dt = datetime.time(0,0,3,int(1.5%1*1e6))
89/34: dt = datetime.time(0,0,1,int(1.5%1*1e6))
89/35: dt2 = datetime.time(0,0,3,int(1.5%1*1e6))
89/36: ddt = dt2-dt
90/1: import requests
90/2: r = requests.get('https://data.ngdc.noaa.gov/platforms/ocean/nos/coast/D00001-D02000/')
90/3: print r.content
90/4: from bs4 import BeautifulSoup
90/5: whos
90/6: soup = BeautifulSoup(r,'html.parser')
90/7: r.content
90/8: soup = BeautifulSoup(r,'html.parser')
90/9: r = requests.get('https://data.ngdc.noaa.gov/platforms/ocean/nos/coast/D00001-D02000/').text
90/10: soup = BeautifulSoup(r,'html.parser')
90/11: dlist = [url + '/' + node.get('href') for node in soup.find_all('a') if node.get('href').startswith('D')]
90/12: url = 'https://data.ngdc.noaa.gov/platforms/ocean/nos/coast/D00001-D02000/'
90/13: dlist = [url + '/' + node.get('href') for node in soup.find_all('a') if node.get('href').startswith('D')]
90/14: dlist
90/15: r = requests.get('https://data.ngdc.noaa.gov/platforms/ocean/nos/coast/D00001-D02000//D00217/').txt
90/16: r = requests.get('https://data.ngdc.noaa.gov/platforms/ocean/nos/coast/D00001-D02000//D00217/').text
90/17: r
90/18: r = requests.get('https://data.ngdc.noaa.gov/platforms/ocean/nos/coast/D00001-D02000//D00217/'+ 'BAG').text
90/19: r
90/20: soup = BeautifulSoup(r,'html.parser')
90/21: bagfile = [url + '/BAG/' + node.get('href') for node in soup.find_all('a') if node.get('href').contains('composite')]
90/22: bagfile = [url + '/BAG/' + node.get('href') for node in soup.find_all('a') if node.get('href').endswith('composite.BAG')]
90/23: bagfile
90/24: bagfile = [url + '/BAG/' + node.get('href') for node in soup.find_all('a') if node.get('href').endswith('composite.bag')]
90/25: bagfile
90/26: bagfile = [url + '/BAG/' + node.get('href') for node in soup.find_all('a') if node.get('href').endswith('bag')]
90/27: bagfile
90/28: a = requests.get(bagfile)
90/29: a = requests.get(bagfile.text)
90/30: a
90/31: a = requests.get(bagfile(0))
90/32: bagfile(0)
90/33: bagfile
90/34: bagfile[0]
90/35: a = requests.get(bagfile[0])
90/36: a.raw?
90/37: F = file('~/scratch/test.bag','w')
90/38: F = fopen('~/scratch/test.bag','w')
90/39: nfb = bytearray(a.content)
90/40: nf = open('~/scratch/text.bag','w')
90/41: ls ~/scratch
90/42: nf = open('~/scratch/text.bag','wb')
90/43: which open
90/44: open?
90/45: nf = open('/Users/vschmidt/scratch/text.bag','wb')
90/46: nf.write(nfb)
90/47: nf.close
90/48: nf.close()
90/49: !file /Users/vschmidt/scratch/text.bag
90/50: print a.content
91/1: import fastkml
92/1:
import sysconfig
print(sysconfig.get_config_vars())
92/2:
for key, value in sysconfig.get_config_vars():
    print key + ":" value
92/3:
for key, value in sysconfig.get_config_vars():
    print key + ":" + value
92/4: a = sysconfig.get_config_vars()
92/5:
for key,value in a:
    print key + ":" + value
92/6: a
93/1: from hydroffice.rawdata.kng._kng immport KngU
93/2: from hydroffice.rawdata.kng._kng import KngU
93/3: K = KngU()
93/4: print K
93/5: file_in = '/Volumes/SCHMIDT/cw4/201612EM2040Trials/20161207_em2040ptrials/em2040p '
93/6: K.open_to_read(file_in)
93/7: file_in = '/Volumes/SCHMIDT/cw4/201612EM2040Trials/20161207_em2040ptrials/em2040p/0003_20161207_160637_UNH_CW4.all '
93/8: K.open_to_read(file_in)
93/9: file_in = '/Volumes/SCHMIDT/cw4/201612EM2040Trials/20161207_em2040ptrials/em2040p/0003_20161207_160637_UNH_CW4.all'
93/10: K.open_to_read(file_in)
93/11: print K
93/12: p = K.read_next()
93/13: print p
93/14: print p.size
93/15: print p.size()
93/16: print p.type()
93/17: a = [1,2,3]
93/18: a.index(4)
92/7: a
92/8: a=[1 2 3]
92/9: a=[1,2,3]
92/10: a.add()
92/11: a.plus()
92/12: a
92/13: a.sum()
92/14: sum(a)
93/19: p = K.read_next()
93/20: p.type()
93/21: print p
93/22: K.close()
93/23: clear K
93/24: K = KngU()
93/25: K.read_next_type?
93/26: file_in = '/Volumes/SCHMIDT/cw4/201612EM2040Trials/20161207_em2040ptrials/em2040p/0003_20161207_160637_UNH_CW4.all'
93/27: K.open_to_read(file_in)
93/28: p = K.read_next_type(88)
93/29: K.read_next_type?
93/30: K.read_next_of_type(88)
93/31: p = K.read_next_of_type(88)
93/32: p
93/33: print p
93/34: a = p.read_xyz()
93/35: clear
93/36: print p
93/37: p.max_beams()
93/38: p.max_beams
93/39: K.tb_name(p.type())
93/40: clear
93/41: p.xyz.max_beams
93/42: p.xyz.beams
93/43: list(p.xyz.beams)
93/44: clear
93/45: p.xyz.size
93/46: p.xyz.size()
93/47: p.xyz.str
93/48: p.xyz.str()
93/49: clear
93/50: p.xyz.py_to_string
93/51: p.xyz.py_to_string()
93/52: clear
93/53: a = p.xyz.beams
93/54: a[1]
93/55: print a[1]
93/56: a = list(p.xyz.beams)
93/57: a[1]
93/58: print a[1]
93/59: a[1].depth
93/60: p.xyz.stx
93/61: p.xyz.id
93/62: p.xyz.date
93/63: p.xyz.time
93/64: p.xyz.dts
93/65: p.xyz.beams.acrosstrackdistance
93/66: p.xyz.beams
93/67: a[1].depth
93/68: a[1].acrosstrackdistance
93/69: print a[1]
93/70: a[1].x
93/71: a[1].y
93/72: a[1].z
93/73: a[1].BS
93/74: a[1].bs
93/75: a[1].reflectivity
93/76: a[1].detect
93/77: a[1].detection
93/78: a[1].detection_information
93/79: a[1].detectioninformation
93/80: a[1].str
93/81: a[1].str()
93/82: p.xyz.str()
93/83: p.header
93/84: p.header()
93/85: p.header.str
93/86: p.header.str()
93/87: p.header.datasize
93/88: p.header.stx
93/89: p.header
93/90: size(p.header)
93/91: p.header.size
93/92: p.header.size()
93/93: p.xyz.str()
93/94: import pickle
93/95: pickle.dump?
93/96: clear
93/97: p.header()
93/98: p.header
93/99: printp.header
93/100: print p.header
93/101: b = p.header
93/102: clear p
93/103: print b
93/104: clear K
93/105: print b
93/106: print b.datasize
93/107: print b.date
93/108: print b.valid
93/109: K = KngU()
93/110: K.open_to_read(file_in)
93/111: p = K.read_next_of_type(88)
93/112: a = {'abc',123}
93/113: prnt a
93/114: print a
93/115: a = ('abc',123)
93/116: print a
93/117: a('abc')
93/118: a[1]
93/119: a.keys()
93/120: a = {'abc',123}
93/121: a.keys()
96/1: import tensorflow as tf
97/1: import bzip2
97/2: import zip
97/3: import gzip
97/4: gzip help
97/5: gzip.GzipFile?
97/6: gzip.WRITE?
97/7: gzip.open?
97/8: ls
97/9: cd scratch/
97/10: ls
97/11: file?
97/12: import os
97/13: os.stat('test.dat')
97/14: os.stat?
97/15: import time
97/16: now = time.time()
97/17: print now
97/18: a = [1,2,3]
97/19: a[2].pop
97/20: a[2].pop()
97/21: whos a
97/22: print a
97/23: a
97/24: a[0]
97/25: a[2]
97/26: a.remove(1)
97/27: print a
97/28: a.remove(2)
97/29: print a
97/30: a = [2 3 4]
97/31: a = [2,3,4]
97/32: a.remove(1)
97/33: gzip.open?
97/34: gzip.GzipFile?
97/35: ls
97/36: F = file('test.dat','r')
97/37: gF = gzip.open('test.dat.gz')
97/38: gzip.io?
97/39: gzip.WRITE?
97/40: gzip.GzipFile?
97/41: gF = gzip.open('test.dat.gz','wb')
97/42: gF.write?
97/43: gF.write(F.read())
97/44: gF.close()
97/45: F.close()
97/46: ls
97/47: import gzip2
98/1: import gzip2
98/2: import gzip
98/3: cd ~/scratch/
98/4: ls
98/5: gzip.sys?
98/6: gzip.GzipFile.flush?
98/7: gzip.GzipFile.flush()?
98/8: gzip.GzipFile.flush?
98/9: gzip.GzipFile.detach?
98/10: gzip.GzipFile.max_read_chunk?
99/1: import cv2
100/1: import cv
102/1: cd ~/gitsrc/data_zipper/
102/2: ls
102/3: import data_zipper as d
102/4: import data_zipper as d
102/5: dz = d.data_zipper(directory='/Users/vschmidt/data_zipper_test/')
102/6: dz.id_files_to_zip()
102/7: reload(data_zipper) as d
102/8: reload(data_zipper)
102/9: reload(data_zipper as d)
102/10: reload('data_zipper as d')
103/1: import data_zipper
103/2: cd ~/gitsrc/data_zipper/
103/3: import data_zipper
103/4: dz = data_zipper.data_zipper(directory='/Users/vschmidt/scratch/data_zipper_test/')
103/5: dz.id_files_to_zip()
103/6: reload(data_zipper)
103/7: dz = data_zipper.data_zipper(directory='/Users/vschmidt/scratch/data_zipper_test/')
103/8: dz.id_files_to_zip()
103/9: ls
103/10: stat = os.stat('data_zipper.py')
103/11: import os
103/12: stat = os.stat('data_zipper.py')
103/13: stat.st_mtime
103/14: reload(data_zipper)
103/15: dz = data_zipper.data_zipper(directory='/Users/vschmidt/scratch/data_zipper_test/')
103/16: dz.id_files_to_zip()
103/17: print dz.files_to_zip
103/18: print dz.files_to_zip.join('\n')
103/19: print '\n'.join(dz.files_to_zip)
103/20: reload(data_zipper)
103/21: dz = data_zipper.data_zipper(directory='/Users/vschmidt/scratch/data_zipper_test/')
103/22: dz.id_files_to_zip()
103/23: print '\n'.join(dz.files_to_zip)
103/24: print '\t'.join(dz.files_to_zip)
103/25: print dz.files_to_zip
103/26: print '\n'.join(dz.files_to_zip)
103/27: tmp = []
103/28:
if tmp:
    print 'no'
103/29: tmp = ['abc','123']
103/30: print tmp
103/31:
if tmp:
    print 'no'
103/32: reload(data_zipper)
103/33: dz = data_zipper.data_zipper(directory='/Users/vschmidt/scratch/data_zipper_test/')
103/34: dz.id_files_to_zip()
103/35: print '\n'.join(dz.files_to_zip)
103/36:
if None:
    print 'no'
104/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
104/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
104/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
104/4:
Wpt = (10,20)
Wscale = 1
Wsigma = 10
x = np.array(range(gridwidth))
y = np.array(range(gridheight))
#Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
W = np.sqrt(pow(xx,2)+pow(yy,2))
W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
104/5:
start = (0,0)
goal = (33,33)
104/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
104/7: CSF = A.graph_data_to_np(cost_so_far)
104/8:
A.plotgrid(G)
plt.imshow(CSF)

px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
104/9:
start = (0,0)
goal = (33,33)
goal = (99,99)
104/10:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
104/11: CSF = A.graph_data_to_np(cost_so_far)
104/12:
A.plotgrid(G)
plt.imshow(CSF)

px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
104/13:
start = (0,0)
goal = (33,33)
#goal = (99,99)
104/14:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
104/15: CSF = A.graph_data_to_np(cost_so_far)
104/16:
A.plotgrid(G)
plt.imshow(CSF)

px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
104/17:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W1 = CreateWeightPt((20,30),1,10)
W2 = CreateWeightPt((30,40),1,10)
W3 = CreateWeightPt((50,50),1,10)
W4 = CreateWeightPt((80,90),1,10)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
104/18:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W

W1 = CreateWeightPt((20,30),1,10)
W2 = CreateWeightPt((30,40),1,10)
W3 = CreateWeightPt((50,50),1,10)
W4 = CreateWeightPt((80,90),1,10)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
104/19:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W

W1 = CreateWeightPt((20,30),1,10)
W2 = CreateWeightPt((40,20),1,10)
W3 = CreateWeightPt((50,50),1,10)
W4 = CreateWeightPt((80,90),1,10)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
104/20:
start = (0,0)
goal = (33,33)
goal = (99,99)
104/21:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
104/22: CSF = A.graph_data_to_np(cost_so_far)
104/23:
A.plotgrid(G)
plt.imshow(CSF)

px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
105/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
105/2:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
105/3:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
105/4:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
105/5:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W

W1 = CreateWeightPt((20,30),1,10)
W2 = CreateWeightPt((40,20),1,10)
W3 = CreateWeightPt((50,50),1,10)
W4 = CreateWeightPt((80,90),1,10)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
105/6:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
105/7:
start = (0,0)
goal = (33,33)
goal = (99,99)
105/8:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
105/9: CSF = A.graph_data_to_np(cost_so_far)
105/10:
A.plotgrid(G)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
107/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
107/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
107/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
107/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
107/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
107/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
107/7: CSF = A.graph_data_to_np(cost_so_far)
107/8:
A.plotgrid(G)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
108/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
108/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
108/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
108/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
108/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
108/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
109/1: import time
109/2: time.time()
110/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
110/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
110/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
110/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
110/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
110/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
111/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
111/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
111/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
111/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
111/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
111/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
112/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
112/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
112/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
112/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
112/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
112/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
113/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
113/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
113/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
113/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
113/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
113/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
113/7: CSF = A.graph_data_to_np(cost_so_far)
113/8:
A.plotgrid(G)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
114/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
114/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
114/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
114/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
114/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
114/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
114/7: CSF = A.graph_data_to_np(cost_so_far)
114/8:
A.plotgrid(G)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
114/9:
A.plotgrid(G,path)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
114/10:
A.plotgrid(G,path = path)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
115/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
115/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
115/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
115/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
115/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
115/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
115/7: CSF = A.graph_data_to_np(cost_so_far)
115/8:
A.plotgrid(G,path = path)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
116/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
116/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
116/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
116/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
116/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
116/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
116/7: CSF = A.graph_data_to_np(cost_so_far)
116/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
117/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
117/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
117/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
117/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
117/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
117/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
117/7: CSF = A.graph_data_to_np(cost_so_far)
117/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
117/9:
gridheight = 1000
gridwidth = 1000
G = A.GridWithWeights(gridheight,gridwidth)
117/10:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
117/11:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
117/12:
start = (0,0)
goal = (33,33)
goal = (999,999)
117/13:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
117/14: CSF = A.graph_data_to_np(cost_so_far)
117/15:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
117/16:
gridheight = 10000
gridwidth = 10000
G = A.GridWithWeights(gridheight,gridwidth)
117/17:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
117/18:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
117/19:
start = (0,0)
goal = (33,33)
goal = (9999,9999)
117/20:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
117/21: CSF = A.graph_data_to_np(cost_so_far)
117/22:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
117/23:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
117/24:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
117/25:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
117/26:
start = (0,0)
goal = (33,33)
goal = (99,99)
117/27:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
117/28: CSF = A.graph_data_to_np(cost_so_far)
117/29:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
118/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
118/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
118/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
118/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
118/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
118/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
118/7: CSF = A.graph_data_to_np(cost_so_far)
118/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
118/9: print(path)
119/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
119/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
119/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
119/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
119/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
119/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
119/7: CSF = A.graph_data_to_np(cost_so_far)
119/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
119/9: print(path)
119/10:
start = (0,10)
goal = (33,33)
goal = (99,99)
119/11:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
119/12: CSF = A.graph_data_to_np(cost_so_far)
119/13:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
119/14:
start = (10,0)
goal = (33,33)
goal = (99,99)
119/15:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
119/16: CSF = A.graph_data_to_np(cost_so_far)
119/17:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
119/18:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridwidth):
    for j in range(gridheight):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
119/19:
start = (10,0)
goal = (33,33)
goal = (99,99)
119/20:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
119/21: CSF = A.graph_data_to_np(cost_so_far)
119/22:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
119/23:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
119/24:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
119/25:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
119/26:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridwidth):
    for j in range(gridheight):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
119/27:
start = (10,0)
goal = (33,33)
goal = (99,99)
119/28:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
119/29: CSF = A.graph_data_to_np(cost_so_far)
119/30:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
120/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
120/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
120/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
120/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridwidth):
    for j in range(gridheight):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
120/5:
start = (10,0)
goal = (33,33)
goal = (99,99)
120/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
120/7: CSF = A.graph_data_to_np(cost_so_far)
120/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
120/9: print(path)
120/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[0])
    py.append(node[1])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[0],start[1],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[0],goal[1],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
120/11:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(j,i)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
120/12:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
120/13:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
120/14:
start = (10,0)
goal = (33,33)
goal = (99,99)
120/15:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
120/16: CSF = A.graph_data_to_np(cost_so_far)
120/17:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
121/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
121/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
121/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
121/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
121/5:
start = (10,0)
goal = (33,33)
goal = (99,99)
121/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
121/7: CSF = A.graph_data_to_np(cost_so_far)
121/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
121/9: print(path)
122/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
122/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
122/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
122/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
122/5:
start = (10,0)
goal = (33,33)
goal = (99,99)
122/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
122/7: CSF = A.graph_data_to_np(cost_so_far)
122/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
122/9: print(path)
123/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
123/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
123/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
123/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
123/5:
start = (10,0)
goal = (33,33)
goal = (99,99)
123/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
123/7: CSF = A.graph_data_to_np(cost_so_far)
123/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
124/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
125/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
125/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
125/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
125/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
125/5:
start = (10,0)
goal = (33,33)
goal = (99,99)
125/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
125/7: CSF = A.graph_data_to_np(cost_so_far)
125/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
109/3: import datetime
109/4: dts = datetime.datetime.now()
126/1:
start = (10,0)
goal = (33,33)
goal = (99,99)
126/2:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
126/3:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
126/4:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
126/5:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
126/6:
start = (10,0)
goal = (33,33)
goal = (99,99)
126/7:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
127/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
127/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
127/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
127/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
127/5:
start = (10,0)
goal = (33,33)
goal = (99,99)
127/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
128/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
128/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
128/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
128/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
128/5:
start = (10,0)
goal = (33,33)
goal = (99,99)
128/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
128/7:
start = (0,0)
goal = (33,33)
goal = (99,99)
128/8:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
129/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
129/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
129/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
129/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
129/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
129/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
129/7: CSF = A.graph_data_to_np(cost_so_far)
129/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
130/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
130/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
130/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
130/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
130/5:
start = (0,0)
goal = (33,33)
goal = (99,99)
130/6:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
130/7: CSF = A.graph_data_to_np(cost_so_far)
130/8:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
#R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
#print(np.min(R))
130/9:
start = (0,0)
goal = (33,33)
goal = (99,99)
130/10:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
130/11: CSF = A.graph_data_to_np(cost_so_far)
130/12:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
130/13:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * Wscale
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
130/14:
start = (0,0)
goal = (33,33)
goal = (99,99)
130/15:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
130/16: CSF = A.graph_data_to_np(cost_so_far)
130/17:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
130/18:
start = (0,0)
goal = (33,33)
goal = (79,79)
130/19:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
130/20: CSF = A.graph_data_to_np(cost_so_far)
130/21:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
109/5: import numpy as np
109/6: np.arange?
109/7: import scipy
109/8: scipy.interpolate.interp2d?
109/9: import scipy.interpolate
109/10: scipy.interpolate.interp2d?
109/11: a = range(10)
109/12: print a
109/13: sum(a)
130/22:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar
131/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
131/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
131/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
131/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * scale

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
131/5:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * Wscale

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
131/6:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
imshow(Wtest)
131/7:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
131/8:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar
131/9:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()
131/10:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,type=int)
131/11:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
131/12:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
131/13:
start = (0,0)
goal = (33,33)
#goal = (79,79)
131/14:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/15: CSF = A.graph_data_to_np(cost_so_far)
131/16:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
131/17:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 3

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
131/18:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
131/19:
start = (0,0)
goal = (33,33)
#goal = (79,79)
131/20:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/21: CSF = A.graph_data_to_np(cost_so_far)
131/22:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
131/23:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 1

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
131/24:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
131/25:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 3

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
131/26:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
131/27:
start = (0,0)
goal = (66,66)
#goal = (79,79)
131/28:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/29: CSF = A.graph_data_to_np(cost_so_far)
131/30:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
131/31:
start = (0,0)
goal = (66,66)
goal = (79,79)
131/32:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/33: CSF = A.graph_data_to_np(cost_so_far)
131/34:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
131/35:
start = (0,0)
goal = (66,66)
goal = (79,79)
goal = (99,99)
131/36:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/37: CSF = A.graph_data_to_np(cost_so_far)
131/38:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
131/39:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 1

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
131/40:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
131/41:
start = (0,0)
goal = (66,66)
goal = (79,79)
goal = (99,99)
131/42:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/43: CSF = A.graph_data_to_np(cost_so_far)
131/44:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
131/45:
start = (0,0)
goal = (66,66)
#goal = (79,79)
#goal = (99,99)
131/46:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/47: CSF = A.graph_data_to_np(cost_so_far)
131/48:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
131/49:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
131/50:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
131/51:
start = (0,0)
goal = (66,66)
#goal = (79,79)
#goal = (99,99)
131/52:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/53: CSF = A.graph_data_to_np(cost_so_far)
131/54:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
131/55:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 3.33

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
131/56:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
131/57:
start = (0,0)
goal = (66,66)
#goal = (79,79)
#goal = (99,99)
131/58:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/59: CSF = A.graph_data_to_np(cost_so_far)
131/60:
start = (0,0)
goal = (33,33)
#goal = (66,66)
#goal = (79,79)
#goal = (99,99)
131/61:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/62: CSF = A.graph_data_to_np(cost_so_far)
131/63:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
131/64:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
131/65:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/66: CSF = A.graph_data_to_np(cost_so_far)
131/67:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
131/68:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
131/69:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
131/70:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
131/71:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
131/72: CSF = A.graph_data_to_np(cost_so_far)
132/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
132/2:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
133/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
133/2:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
133/3:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
134/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
134/2:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
134/3:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
134/4:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
134/5:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
134/6:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
134/7:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
134/8:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
134/9:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
134/10:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
134/11: CSF = A.graph_data_to_np(cost_so_far)
134/12:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
135/1:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
135/2:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/3:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
135/4:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
135/5:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
135/6:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/7:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = sqrt(dWdx**2 + dWdy**2) * float(dWdx <0 | dWdy < 0)

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/8:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2) * float(dWdx <0 | dWdy < 0)

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/9:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2) * float(np.logical_or( dWdx <0, dWdy < 0))

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/10:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2) * float(np.logical_or( np.less(dWdx,0), np.less(dWdy, 0)))

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/11:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2) * float(np.logical_or( np.less(dWdx,np.zeros(dWdx.shape())), np.less(dWdy, np.zeros(dWdx.shape()))))

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/12:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2) * float(np.logical_or( np.less(dWdx,np.zeros(dWdx.shape), np.less(dWdy, np.zeros(dWdx.shape)))

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/13:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = float(np.logical_or( np.less(dWdx,np.zeros(dWdx.shape), np.less(dWdy, np.zeros(dWdx.shape)))
DW = DW*lessthan0
                                
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/14:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = float(np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape))))
DW = DW*lessthan0
                                
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/15:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))
DW = DW*lessthan0
                                
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/16:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))
DW = DW*lessthan0
                                
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(DW)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/17:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))
DW = DW*lessthan0
                                
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WW = DW
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/18:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))
DW = DW*lessthan0
                                
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WW = DW
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/19:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))
DW = DW*lessthan0
                                
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
#WW = A.weightedgrid2numpy(G)
WW = DW
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/20:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))
#DW = DW*lessthan0
                                
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
#WW = A.weightedgrid2numpy(G)
WW = DW
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/21:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))
if lessthan0: DW = -DW
                                
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
#WW = A.weightedgrid2numpy(G)
WW = DW
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/22:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

dWdx,dWdy = np.gradient(W)

DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))
#DW = DW*lessthan0
                                
#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
#WW = A.weightedgrid2numpy(G)
WW = DW
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
135/23:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
135/24:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
136/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
136/2:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
136/3:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
136/4:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
136/5:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WW = DW
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
136/6:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
136/7:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
136/8:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
136/9:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
136/10:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
136/11:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
136/12:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
136/13: CSF = A.graph_data_to_np(cost_so_far)
136/14:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
136/15:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
136/16:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
137/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
137/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
137/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
137/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
137/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
137/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
137/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
137/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
137/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
137/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
138/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
138/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
138/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
138/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
138/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
138/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
138/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
138/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
138/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
138/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
139/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
139/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
139/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
139/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
139/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
139/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
139/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
139/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
139/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
139/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
140/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
140/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
140/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
140/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
140/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
140/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
140/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
140/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
140/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
140/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
141/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
141/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
141/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
141/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
141/5:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
141/6:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
141/7:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
141/8: CSF = A.graph_data_to_np(cost_so_far)
141/9:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
142/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
142/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
142/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
142/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
142/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
142/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
142/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
142/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
142/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
142/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
143/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
143/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
143/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
143/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((50,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
143/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
143/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
143/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
143/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
143/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
143/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
143/11:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
143/12:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
143/13:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
143/14:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
143/15:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
143/16:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
143/17:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
144/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
144/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
144/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
144/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
144/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
144/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
144/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
144/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
144/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
144/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
145/1:
#%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
145/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
145/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
145/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
145/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
145/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
145/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
145/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
145/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
145/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
146/1:
#%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
146/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
146/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
146/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
146/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
146/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
146/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
146/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
146/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
146/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
147/1:
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
147/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
147/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
147/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
147/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
147/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
147/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
147/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
147/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
147/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
147/11:
%matplotlib inline  
import mpld3
mpld3.enable_notebook()
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
148/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
148/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
148/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
148/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
148/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
148/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
148/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
148/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
148/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
148/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
148/11:
%matplotlib notebook  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
148/12:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
148/13:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
148/14:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
148/15:
%matplotlib inline
import mpld3
mpld3.enable_notebook()
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
148/16:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
148/17:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
148/18:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
148/19:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
148/20:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
148/21:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
148/22:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
148/23:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
148/24:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
148/25:
%matplotlib notebook
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
148/26:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
148/27:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
149/1:
%matplotlib notebook
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
149/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
149/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
149/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
149/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
149/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
149/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
149/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
149/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
149/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
149/11:
%matplotlib inline
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
149/12:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
149/13:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
149/14:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
149/15:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
149/16:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
149/17:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
149/18:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
149/19:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
149/20:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
150/1:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
150/2:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
150/3:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
150/4:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
150/5:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
150/6:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
150/7:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
150/8:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
150/9: CSF = A.graph_data_to_np(cost_so_far)
150/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
151/1:
%matplotlib inline  
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
151/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
151/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
151/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6

#W = Wscale - W/maxW * Wscale

for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
151/5:
# Dump weight matrix.
import pandas as p
Wtest = (1-W)*2000
plt.imshow(Wtest)
plt.colorbar()

Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
151/6:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
151/7:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
151/8: CSF = A.graph_data_to_np(cost_so_far)
151/9:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
152/1:
%matplotlib inline
import implementation as A
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (10,6)
152/2:
gridheight = 100
gridwidth = 100
G = A.GridWithWeights(gridheight,gridwidth)
152/3:
GG = A.weightedgrid2numpy(G)
GGimg = plt.imshow(GG)
plt.colorbar()
plt.show()
152/4:
def CreateWeightPt(Wpt,Wcale,Wsigma):
    x = np.array(range(gridwidth))
    y = np.array(range(gridheight))
    #Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
    xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
    W = np.sqrt(pow(xx,2)+pow(yy,2))
    W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))
    return W
Wscale = 1
Wsigma = 10
W1 = CreateWeightPt((20,30),Wscale,Wsigma)
W2 = CreateWeightPt((40,20),Wscale,Wsigma)
W3 = CreateWeightPt((80,50),Wscale,Wsigma)
W4 = CreateWeightPt((80,90),Wscale,Wsigma)
    
#Wpt = (10,20)
#Wscale = 1
#Wsigma = 10
#x = np.array(range(gridwidth))
#y = np.array(range(gridheight))
##Wpt = (np.floor(gridwidth/2),np.floor(gridheight/2))
#xx, yy = np.meshgrid(x-Wpt[0],y-Wpt[1])
#W = np.sqrt(pow(xx,2)+pow(yy,2))
#W = np.exp(-pow(W,2)/(2*pow(Wsigma,2)))

W = W1+W2+W3+W4
#W = W1
Wpt=(20,30)
maxW = np.max(W[:])
W = W/maxW * 6


for i in range(gridheight):
    for j in range(gridwidth):
        G.weights[(i,j)] = W[i,j]
        
# Plot it: 
WW = A.weightedgrid2numpy(G)
WWimg = plt.imshow(WW)
plt.colorbar()
plt.show()
152/5:
 
dWdx,dWdy = np.gradient(W)
DW = np.sqrt(dWdx**2 + dWdy**2)
lessthan0 = np.logical_or( np.less(dWdx,np.zeros(dWdx.shape)), np.less(dWdy, np.zeros(dWdx.shape)))

WWimg = plt.imshow(DW)
plt.colorbar()
plt.show()
152/6:
#   def cost_w_gradient(self,from_node,to_node):
#       c = 1   # graident weight
#       return self.weights.get(to_node,1) + c*(self.weights.get(from_node,1) - self.weights.get(to_node,1))
152/7:
# Dump weight matrix.
#import pandas as p
#Wtest = (1-W)*2000
#plt.imshow(Wtest)
#plt.colorbar()

#Wdf = p.DataFrame(Wtest,dtype=int)
#Wdf.to_csv('/Users/vschmidt/Dropbox/nauticalchartASV/A_Star/valsisland.csv')
152/8:
start = (0,0)
goal = (33,33)
#goal = (66,66)
goal = (79,79)
#goal = (99,99)
152/9:
camefrom, cost_so_far = A.a_star_search(G,start,goal)
path = A.reconstruct_path(camefrom,start,goal)
CSF = A.graph_data_to_np(cost_so_far)
152/10:
A.plotgrid(G,path = path,start=start,goal=goal)

plt.imshow(CSF)
px = []
py = []
# Swapped x and y here. I can't immediately see why it's necessary - maybe a matplotlib thing with images?
for node in path:
    px.append(node[1])
    py.append(node[0])
plt.plot(px,py,color='k',linewidth=3)
plt.plot(start[1],start[0],'o',color='g',markersize=15,linewidth=3)
plt.plot(goal[1],goal[0],'o',color='m',markersize=15,linewidth=3)
plt.xlim((0,gridwidth))
plt.ylim((gridheight,0))
plt.colorbar()
plt.show()

# What's the closest distance to Wpt?
R = np.sqrt((np.array(px)-Wpt[0])**2 + (np.array(py)-Wpt[1])**2)
print(np.min(R))
153/1:
import json
import datetime
import numpy as np

infile = open(sys.argv[1])
newline = True
jsonbuffer = ''

times = []
datasets = {}
153/2: !ls
153/3:
import json
import datetime
import numpy as np

infile = open('2017-04-18_radio.log')
newline = True
jsonbuffer = ''

times = []
datasets = {}
153/4: l = infile.readlines()
153/5: print l
153/6: print(l)
153/7: ts,l = l.split(',',1)
154/1: import json
154/2: import dateime
154/3: import datetime
154/4: import numpy as np
154/5: infile = open('2017-04-18_radio.log','r')
154/6: line = infile.readlines()
154/7: line
154/8: print(line)
154/9: infile.readlines?
154/10: whos
154/11: ll = line[0]
154/12: ts,l = ll.split(',',1)
154/13: print(ts)
154/14: print(l)
154/15: ts = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f")
154/16: ll.strip?
154/17:
for ll in line:
    if newline:
        ts,l = ll.split(',',1)
        ts = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f")
        newline = False
    if len(ll.strip()) == 0:
        data = json.loads(jsonbuffer)
        times.append(ts)
        newline = True
        jsonbuffer = ''
        break
    else
153/8:
for l in infile.readlines():
    if newline:
        ts,l = l.split(',',1)
        ts = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f")
        newline = False
    if len(l.strip()) == 0:
        data = json.loads(jsonbuffer)
        times.append(ts)
        for di in data_items:
            datasets[di[0]].append(getItem(data,di[1]))
        newline = True
        jsonbuffer = ''
        break
    else:
        jsonbuffer += l
153/9: print data
153/10: print(data)
153/11:
import json
import datetime
import numpy as np

infile = open('2017-04-18_radio.log','r')
newline = True
jsonbuffer = ''

times = []
datasets = {}
153/12:
for l in infile.readlines():
    if newline:
        ts,l = l.split(',',1)
        ts = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f")
        newline = False
    if len(l.strip()) == 0:
        data = json.loads(jsonbuffer)
        times.append(ts)
        for di in data_items:
            datasets[di[0]].append(getItem(data,di[1]))
        newline = True
        jsonbuffer = ''
        break
    else:
        jsonbuffer += l
153/13:
import json
import datetime
import numpy as np

infile = open('2017-04-18_radio.log','r')
newline = True
jsonbuffer = ''

times = []
datasets = {}

data_items = (
        ('snr 7',('remoteStatus',7,'demodStatus','snr',8)),
        ('sigLevA 7',('remoteStatus',7,'demodStatus','sigLevA',8)),
        ('sigLevB 7',('remoteStatus',7,'demodStatus','sigLevB',8)),
        ('sigLevA0 7',('remoteStatus',7,'demodStatus','sigLevA0')),
        ('sigLevB0 7',('remoteStatus',7,'demodStatus','sigLevB0')),
        ('snr 8',('remoteStatus',8,'demodStatus','snr',7)),
        ('sigLevA 8',('remoteStatus',8,'demodStatus','sigLevA',7)),
        ('sigLevB 8',('remoteStatus',8,'demodStatus','sigLevB',7)),
        ('sigLevA0 8',('remoteStatus',8,'demodStatus','sigLevA0')),
        ('sigLevB0 8',('remoteStatus',8,'demodStatus','sigLevB0')),
    )
153/14:
for l in infile.readlines():
    if newline:
        ts,l = l.split(',',1)
        ts = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f")
        newline = False
    if len(l.strip()) == 0:
        data = json.loads(jsonbuffer)
        times.append(ts)
        for di in data_items:
            datasets[di[0]].append(getItem(data,di[1]))
        newline = True
        jsonbuffer = ''
        break
    else:
        jsonbuffer += l
153/15:
import json
import datetime
import numpy as np

infile = open('2017-04-18_radio.log','r')
newline = True
jsonbuffer = ''

times = []
datasets = {}

data_items = (
        ('snr 7',('remoteStatus',7,'demodStatus','snr',8)),
        ('sigLevA 7',('remoteStatus',7,'demodStatus','sigLevA',8)),
        ('sigLevB 7',('remoteStatus',7,'demodStatus','sigLevB',8)),
        ('sigLevA0 7',('remoteStatus',7,'demodStatus','sigLevA0')),
        ('sigLevB0 7',('remoteStatus',7,'demodStatus','sigLevB0')),
        ('snr 8',('remoteStatus',8,'demodStatus','snr',7)),
        ('sigLevA 8',('remoteStatus',8,'demodStatus','sigLevA',7)),
        ('sigLevB 8',('remoteStatus',8,'demodStatus','sigLevB',7)),
        ('sigLevA0 8',('remoteStatus',8,'demodStatus','sigLevA0')),
        ('sigLevB0 8',('remoteStatus',8,'demodStatus','sigLevB0')),
    )

def getItem(data,path):
    if len(path) == 1:
        return data[path[0]]
    return getItem(data[path[0]],path[1:])
153/16:
for l in infile.readlines():
    if newline:
        ts,l = l.split(',',1)
        ts = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f")
        newline = False
    if len(l.strip()) == 0:
        data = json.loads(jsonbuffer)
        times.append(ts)
        for di in data_items:
            datasets[di[0]].append(getItem(data,di[1]))
        newline = True
        jsonbuffer = ''
        break
    else:
        jsonbuffer += l
153/17:
import json
import datetime
import numpy as np

infile = open('2017-04-18_radio.log','r')
newline = True
jsonbuffer = ''

times = []
datasets = {}

data_items = (
        ('snr 7',('remoteStatus',7,'demodStatus','snr',8)),
        ('sigLevA 7',('remoteStatus',7,'demodStatus','sigLevA',8)),
        ('sigLevB 7',('remoteStatus',7,'demodStatus','sigLevB',8)),
        ('sigLevA0 7',('remoteStatus',7,'demodStatus','sigLevA0')),
        ('sigLevB0 7',('remoteStatus',7,'demodStatus','sigLevB0')),
        ('snr 8',('remoteStatus',8,'demodStatus','snr',7)),
        ('sigLevA 8',('remoteStatus',8,'demodStatus','sigLevA',7)),
        ('sigLevB 8',('remoteStatus',8,'demodStatus','sigLevB',7)),
        ('sigLevA0 8',('remoteStatus',8,'demodStatus','sigLevA0')),
        ('sigLevB0 8',('remoteStatus',8,'demodStatus','sigLevB0')),
    )

def getItem(data,path):
    if len(path) == 1:
        return data[path[0]]
    return getItem(data[path[0]],path[1:])

for di in data_items:
    datasets[di[0]]=[]
153/18:
for l in infile.readlines():
    if newline:
        ts,l = l.split(',',1)
        ts = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f")
        newline = False
    if len(l.strip()) == 0:
        data = json.loads(jsonbuffer)
        times.append(ts)
        for di in data_items:
            datasets[di[0]].append(getItem(data,di[1]))
        newline = True
        jsonbuffer = ''
        break
    else:
        jsonbuffer += l
153/19: print(data)
153/20: print(data.keys())
153/21: print(data['signalQualityTable'])
153/22: print(data)
153/23: print(data['snr'])
153/24: print(data.keys())
153/25:
for k,v in data:
    print(k + ':' + v)
153/26:
for k in data.keys():
    print(k + ':' + data[k])
153/27: print(data.keys())
153/28: print(data.keys(0))
153/29: whos data
153/30: print(data['audioCardPresent'])
153/31: k = data.keys()
153/32:
k = data.keys()
print(k)
153/33: print(data[k[0]])
153/34: print(datasets)
155/1:
import json
import datetime
import numpy as np

infile = open('2017-04-18_radio.log','r')
newline = True
jsonbuffer = ''

times = []
datasets = {}

data_items = (
        ('snr 7',('remoteStatus',7,'demodStatus','snr',8)),
        ('sigLevA 7',('remoteStatus',7,'demodStatus','sigLevA',8)),
        ('sigLevB 7',('remoteStatus',7,'demodStatus','sigLevB',8)),
        ('sigLevA0 7',('remoteStatus',7,'demodStatus','sigLevA0')),
        ('sigLevB0 7',('remoteStatus',7,'demodStatus','sigLevB0')),
        ('snr 8',('remoteStatus',8,'demodStatus','snr',7)),
        ('sigLevA 8',('remoteStatus',8,'demodStatus','sigLevA',7)),
        ('sigLevB 8',('remoteStatus',8,'demodStatus','sigLevB',7)),
        ('sigLevA0 8',('remoteStatus',8,'demodStatus','sigLevA0')),
        ('sigLevB0 8',('remoteStatus',8,'demodStatus','sigLevB0')),
    )

def getItem(data,path):
    if len(path) == 1:
        return data[path[0]]
    return getItem(data[path[0]],path[1:])

for di in data_items:
    datasets[di[0]]=[]
155/2:
for l in infile.readlines():
    if newline:
        ts,l = l.split(',',1)
        ts = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f")
        newline = False
    if len(l.strip()) == 0:
        data = json.loads(jsonbuffer)
        times.append(ts)
        for di in data_items:
            datasets[di[0]].append(getItem(data,di[1]))
        newline = True
        jsonbuffer = ''
        
    else:
        jsonbuffer += l
155/3: print(datasets)
155/4: print(di[0])
155/5: print(di)
155/6: print(datasets.__len__())
155/7: print(datasets[di[0]).__len__())
155/8: print(datasets[di[0]].__len__())
155/9: print(datasets.keys()
155/10: print(datasets.keys())
155/11: np.array?
155/12: d = datasets['snr 8']
155/13: whos d
155/14: who d
155/15: print(d)
155/16: print(d[0])
155/17: print(d[0] + 1)
155/18:
dd = {}
for k in datasets.keys():
    dd[k]=np.array(datasets[k])
data['cobham']=dd
155/19: print(data['cobham'])
155/20:
dd = {}
for k in datasets.keys():
    dd[k]=np.array(datasets[k])
    print(dd[k].__len__())
data['cobham']=dd
155/21:
dd = {}
for k in datasets.keys():
    dd[k]=np.array(datasets[k])
    print(dd[k].__len__())
data['cobham']=dd
155/22:
dd = {}
for k in datasets.keys():
    dd[k]=np.array(datasets[k])
    print(dd[k].__len__())
data['cobham']=dd
155/23:
k='a b'
print(k.strip())
155/24:
k='a b'
print(k.strip(' '))
155/25: print(k.rstrip())
155/26: k.strip?
155/27: k.rstrip?
155/28:
k.replace(' ','_')
print(k)
155/29: k.replace?
155/30:
kk = k.replace(' ','_')
print(kk)
156/1: a = ['abc\ndef\n']
156/2: print a
156/3: a = ['abc','def']
156/4: print a
156/5: a.pop()
156/6: print(a)
156/7: import datetime
156/8: datetime.datetime.fromtimestamp?
156/9: datetime.datetime.fromtimestamp(time.mktime())
156/10: import time
156/11: time.mktime
156/12: time.mktime()
156/13: ts = datetime.datetime.now()
156/14: ts.timetuple()
156/15: time.mktime(ts.timetuple())
156/16: datetime.datetime.fromtimestamp(time.mktime(ts.timetuple()))
156/17: a = datetime.datetime.fromtimestamp(time.mktime(ts.timetuple()))
156/18: a.isoformat()
158/1: import pandas as p
158/2: cd /Volumes/ENG2015ASV/data/cworker4/extracted_logs/2017-03-28T17-36-59
158/3: d = p.DataFrame()
158/4: ls
158/5: d = p.read_csv('nmea2000_vessel_heading_pgn127250.txt')
158/6: d
158/7: d = p.read_table('nmea2000_vessel_heading_pgn127250.txt')
158/8: d
158/9: d = p.read_table('nmea2000_vessel_heading_pgn127250.txt','\s+')
158/10: d
158/11: d(2)
158/12: d[2]
158/13: d
158/14: d.head()
158/15: d.describe()
158/16: h = d['heading_sensor_reading']
158/17: import matplotlib as plt
158/18: plt.show()
158/19: plt.figure(); d.plot('heading_sensor_reading')
158/20: d.plot()
158/21: plt.show()
158/22: import matplotlib.pyplot as plt
158/23: plt.figure()
158/24: d.plot()
159/1: import datetime
159/2: ts = '2017-04-18T12:12:12.1234'
159/3: tts = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f")
159/4: ttsu = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f",tzinfo='UTC')
159/5: import pytz
159/6: ttsu = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f",tzinfo='UTC')
159/7: tts.timetz
159/8: tts.timetz?
159/9: tts.timetz()
159/10: tz = pytz.utc
159/11: print tz
159/12: tts.timetz(tz)
159/13: ttsu = datetime.datetime.strptime(ts,"%Y-%m-%dT%H:%M:%S.%f",tzinfo='UTC')
159/14: ttsu = pyzt.utc.localize(tts)
159/15: ttsu = pytz.utc.localize(tts)
159/16: print tsu
159/17: print ttsu
159/18: import time
159/19: time.mktime(ttsu.timetuple())
160/1: cd ~/scratch/data_zipper_test/
160/2: ls
160/3: cd test1
160/4: ls
160/5: run ~/gitsrc/data_zipper/data_zipper.py -d .
160/6: run ~/gitsrc/data_zipper/data_zipper.py -d .
160/7: run ~/gitsrc/data_zipper/data_zipper.py -d .
160/8: run ~/gitsrc/data_zipper/data_zipper.py -d .
160/9:
quit
exit
160/10: a = 'abc.gz'
160/11: a[-2:]
160/12: ls
160/13: !rm *.gz
160/14: ls
160/15: run ~/gitsrc/data_zipper/data_zipper.py -d .
160/16: run ~/gitsrc/data_zipper/data_zipper.py -d .
160/17: run ~/gitsrc/data_zipper/data_zipper.py -d .
160/18: run ~/gitsrc/data_zipper/data_zipper.py -d .
160/19: run ~/gitsrc/data_zipper/data_zipper.py -d .
160/20: run ~/gitsrc/data_zipper/data_zipper.py -d .
160/21: run ~/gitsrc/data_zipper/data_zipper.py -d . -v
160/22: run ~/gitsrc/data_zipper/data_zipper.py -d . -v
160/23: run ~/gitsrc/data_zipper/data_zipper.py -d . -v
160/24: b = 'abc'
160/25: b.strip?
160/26: print b
160/27: print b[:-2]
160/28: run ~/gitsrc/data_zipper/data_zipper.py -d . -v
160/29: a = []
160/30:
if a:
    print "true"
160/31:
if a is emtpy:
    print "true"
160/32:
if a is empty:
    print "true"
160/33:
if a.__len__() == 0:
    print 'true'
160/34: run ~/gitsrc/data_zipper/data_zipper.py -d . -v
160/35: run ~/gitsrc/data_zipper/data_zipper.py -d . -v
160/36: run ~/gitsrc/data_zipper/data_zipper.py -d . -vvv
160/37: run ~/gitsrc/data_zipper/data_zipper.py -d . -vvv
160/38: import logging
160/39: log = logging.getLogger()
160/40: log.setLevel(logging.DEBUG)
160/41: ch = logging.StreamHandler?
160/42: ch = logging.StreamHandler()
160/43: log.addHandler(ch)
160/44: log.debug('test')
160/45: log.setLevel(logging.INFO)
160/46: log.debug('test')
160/47: log.setLevel(logging.DEBUG)
160/48: log.debug('test')
160/49: log.info('test')
160/50: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d . -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
160/51: ls
160/52: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d /Users/vschmidt/scratch/data_zipper_test/test1/ -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
161/1: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d /Users/vschmidt/scratch/data_zipper_test/test1/ -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
162/1: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d . -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
163/1: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d . -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
163/2: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d /Users/vschmidt/scratch/data_zipper_test/test1/ -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
163/3: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d /Users/vschmidt/scratch/data_zipper_test/test1/ -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
164/1: cd ~/scratch/data_zipper_test/test1
164/2: run ~/gitsrc/data_zipper/data_zipper.py -d . -vvv
164/3: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d /Users/vschmidt/scratch/data_zipper_test/test1/ -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
164/4: import os
164/5: ls
164/6: a = 'data_zipper.py'
164/7: import sys
164/8: os.path.isdir(a)
164/9: os.path.isfile(a)
164/10: pwd = cwd
164/11: pwd
164/12: b = pwd
164/13: pwd
164/14: a = os.system?
164/15: a = os.system('pwd')
164/16: print a
164/17: a = os.system(pwd)
164/18: os.system?
164/19: !pwd
164/20: a=!pwd
164/21: print a
164/22: aa = a[0]
164/23: print aa
164/24: os.path.join(aa,a)
164/25: a
164/26: b
164/27: ls
164/28: b = 'data_zipper.py'
164/29: os.path.join(aa,b)
164/30: os.path.join(aa,b).isfile()
164/31: os.paht.isfile(os.path.join(aa,b))
164/32: os.path.isfile(os.path.join(aa,b))
164/33: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
164/34: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
164/35: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
164/36: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
164/37: a = ['abc','def']
164/38: a contains 'abc'
164/39: import fnmatch
164/40: fnmatch?
164/41: a
164/42: a.__contains__('abc')
164/43: b
164/44: b[:-3]
164/45: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
164/46: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d /Users/vschmidt/scratch/data_zipper_test/test1/ -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
165/1: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
165/2: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
165/3: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
165/4: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
165/5: F = '/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T15-47-09_plot1.png'
165/6: F[-2:] == 'gz'
165/7: F[-2:]
165/8: F = '/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T15-47-09_plot1.png.gz'
165/9: F[-2:] == 'gz'
165/10: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
165/11: a
165/12: a = ['abc','def','ghi')
165/13: a = ['abc','def','ghi']
165/14: a.remove('ghi')
165/15: print a
165/16: a.remove('abc')
165/17: print a
165/18: a.remove('ccc')
165/19: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
165/20: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
165/21: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
165/22:
a = '/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T15-47-09_plot1.fig
/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T15-47-09_plot1.fig.gz
/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T15-47-09_plot1.png
/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T15-47-09_plot1.png.gz
/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T15-47-09_plot2.fig
/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T15-47-09_plot2.fig.gz
/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T15-47-09_plot2.png
/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T15-47-09_plot2.png.gz
/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T18-49-36_plot2.fig
/Users/vschmidt/scratch/data_zipper_test/test1/2017-03-31T18-49-36_plot2.fig.gz'
165/23: ls
165/24: cd ~/scratch/data_zipper_test/test1/
165/25: ls
165/26: os.path.walk('.')
165/27: os.walk('.')
165/28: dir('.')
165/29: directory?
165/30: ls
165/31: import glob
165/32: a = glob.glob('*')
165/33: print a
165/34: fnmatch.filter(a,'*.gz')
165/35: b = fnmatch.filter(a,'*.gz')
165/36: a
165/37: b
165/38: set(a).intersection(set(b))
165/39: set(a).difference(set(b))
165/40: a
165/41: aa
165/42: aa = 'abc'
165/43: aa.join?
165/44: aa.endswith('c')
165/45: aa.partition?
165/46: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
165/47: a
165/48: b
165/49: c
165/50: c = a[0]
165/51: print c
165/52: c = c+'.gz'
165/53: print c
165/54: c[:-3]
165/55: c[-3:]
165/56: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
165/57: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
166/1: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
166/2: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
166/3: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
166/4: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d /Users/vschmidt/scratch/data_zipper_test/test1/ -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
167/1: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d /Users/vschmidt/scratch/data_zipper_test/test1/ -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
168/1: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
168/2: import fnmatch
168/3: ls
168/4: cd ~/scratch/data_zipper_test/test1/
168/5: import glob
168/6: a = glob.glob('*')
168/7: print a
168/8: b = fnmatch.filter(a,'*.gz')
168/9: print b
168/10: c = set(a).difference(set(b))
168/11: print c
168/12: print a
168/13: allfiles = a
168/14: alreadyzipped = fnmatch.filter(allfiles,'*.gz')
168/15: print alreadyzipped
168/16:
alreadyzippednotgz = []
        for F in alreadyzipped:
            alreadyzippednotgz.append(F[:-3])
168/17:
alreadyzippednotgz = []
    for F in alreadyzipped:
        alreadyzippednotgz.append(F[:-3])
168/18:
alreadyzippednotgz = []
for F in alreadyzipped:
    alreadyzippednotgz.append(F[:-3])
168/19: print alreadyzippednotgz
168/20: print allfiles
168/21: print alreadyzipped
168/22: print allreadyzippednotgz
168/23: print allreadyzippednotgz
168/24: pirnt alreadyzippednotgz
168/25: print alreadyzippednotgz
168/26: ls
168/27: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
168/28: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
168/29: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
168/30:
for i in range(10):
    print("%s\r",%i)
169/1:
for i in range(10):
    print("%s\r" % i)
169/2: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
169/3: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
169/4: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
169/5: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
169/6: a = 'a/b/c/d.gz'
169/7: b = 'a/b/c/e/'
169/8: a.replace(a[:-3],b)
169/9: dir(a)
169/10: directory(a)
169/11: print a
169/12: print b
169/13: a.replace(os.path.dirname(a),b)
169/14: a.replace(os.path.basename(a),b)
169/15: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
169/16: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
169/17: debugfile('/Users/vschmidt/gitsrc/data_zipper/data_zipper.py', args='-d /Users/vschmidt/scratch/data_zipper_test/test1/ -vv', wdir='/Users/vschmidt/gitsrc/data_zipper')
169/18: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
169/19: run ~/gitsrc/data_zipper/data_zipper.py -d /Users/vschmidt/scratch/data_zipper_test/test1/ -vvv
171/1: from dateutil.parser import parse
171/2: a = parse('06/22/2017,18:44:03.421')
171/3: from dateutil.parser import parserinfo
171/4: parserinfo('06/22/2017,18:44:03.421')
171/5: a = parserinfo('06/22/2017,18:44:03.421')
171/6: print a
171/7: a.HMS
171/8: a.HMS()
171/9: a = parserinfo('06/22/2017 18:44:03.421')
171/10: print a
171/11: a = parse('06/22/2017 18:44:03.421')
171/12: print a
171/13: a = parse('06/22/2017 18:44:03.421, $GPGGA')
171/14: a = parse('06/22/2017 18:44:03.421')
171/15: a = parse('06/22/2017 18:44:03.421,')
171/16: msg = '06/22/2017,18:44:17.180,$GPGGA,184422.86,,,,,0,,,,M,,M,,*4F'
171/17: F = split(msg,',')
171/18: F = msg.split(',')
171/19: F = msg.split('$GPGGA')
171/20: print F
171/21: print msg.split('$')
172/1: from dateutils import parser as parser
172/2: from dateutil import parser as parser
172/3: import time
172/4: a = time.time.mktime()
172/5: a = time.time()
172/6: print a
172/7: a = parser(a)
172/8: b = parser.parse(a)
172/9: b = parser.parse(str(a)))
172/10: b = parser.parse('%0.6f' % a)
172/11: '%0.6f' % a
173/1: import sys
173/2: sys.argv?
173/3: sys.argv?
173/4: import os
173/5: os.system?
173/6: which ping
173/7: os.system('which ping')
173/8: d
174/1: import plotly as py
174/2: import plotly.graph_obs as go
174/3: import plotly.graph_objs as go
174/4: import numpy as np
174/5: x = np.random?
174/6: x = np.random.randn?
174/7: x = np.array(range(10))
174/8: y = np.random.randn(1,10)
174/9: trace0 = Scatter(x,y)
174/10: trace0 = go.Scatter(x,y)
174/11: trace0 = go.Scatter(x=x,y=y)
174/12: data = go.Data([trace0])
174/13: py.plot(data,'~/testplot')
174/14: py.plotly(data,'~/testplot')
174/15: py.plotly.plot(data,'~/testplot')
174/16: trace0 = go.Scatter(x=x.data,y=y.data)
174/17: data = go.Data([trace0])
174/18: py.plotly.plot(data,'~/testplot')
175/1: import utm
175/2:
if False:
    pass
elif:
175/3: vi utm.py
178/1: pwd
178/2: cd library.local/courses/python/
178/3: ls
178/4: pwd
178/5: ls
179/1: from osgeo import ogr
179/2: ENC_filename = '/Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000'
179/3: ds = ogr.Open(ENC_filename)
179/4: print(ds.GetMetadata_List)
179/5: print(ds.GetMetadata_List())
179/6: ds.GetDescription()
179/7: ds.GetLayer?
179/8: ds.GetLayerCount()
179/9: a = ds.GetLayerByIndex(0)
179/10: print a
179/11: print(a.GetDescription())
179/12: s = ds.GetLayerByName('M_CSCL')
179/13: s.GetDescription()
179/14: s.GetFeatureCount()
179/15: feat = s.GetNextFeature()
179/16: feat.GetField()
179/17: feat.GetField('CSCALE')
179/18:
for i in range(ds.GetLayerCount()):
    layer = ds.GetLayerByIndex(i)
    print(layer.GetDesciption())
179/19: i
179/20: layer = ds.GetLayerByIndex(i)
179/21: layer.GetDescription()
179/22:
for i in range(ds.GetLayerCount()):
    layer = ds.GetLayerByIndex(i)
    print(layer.GetDesciption())
179/23: layer = ds.GetLayerByIndex(i)
179/24: layer.GetDescription()
179/25: print(layer.GetDescription())
179/26: i
179/27: layer.GetFeatureCount()
179/28:
for i in range(ds.GetLayerCount()):
    layer = ds.GetLayerByIndex(i)
    desc = layer.GetDesciption()
    Nfeat = layer.GetFeatureCount()
    print(desc + ':' + str(Nfeat))
179/29: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/30: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/31: ds.GetLayerByIndex?
179/32: layer?
179/33: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/34: layer
179/35: layer.GetName()
179/36: layer.GetDescription()
179/37: layer.GetFeature?
179/38: feat = layer.GetFeature()
179/39: feat = layer.GetFeatureCount
179/40: feat
179/41: layer.GetFeatureCount()
179/42: feat = layer.GetFeature()
179/43: layer.GetGeomType()
179/44: layer.GetLayerDefn()
179/45: feat = layer.GetNextFeature()
179/46: feat.GetName()
179/47: feat.GetNativeData()
179/48: feat.GetFieldCount()
179/49: feat.GetFieldType()
179/50: feat.GetFieldType(0)
179/51: feat.GetFieldType(1)
179/52: feat.GetFID()
179/53: feat.keys()
179/54: feat.GetFieldCount()
179/55: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/56: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/57: feat.DumpReadable()
179/58: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/59: feat.GetFID()
179/60: feat.getFID()
179/61: feat.GetFID()
179/62: feat.GetDefnRef()
179/63: feat.GetField()
179/64: feat.GetStyleString()
179/65: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/66: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/67: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/68: ll = ds.GetLayerByName('M_CSCL')
179/69: ll.GetName()
179/70: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/71: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/72: ff = feat.keys()
179/73: feat.GetField(ff[0])
179/74: feat.GetField(ff[2])
179/75:
feat.GetField(ff[3)
]
179/76: feat.GetField(ff[3])
179/77: feat.GetFieldAsString(ff[3])
179/78: runfile('/Users/vschmidt/gitsrc/encs/gdal_testing_w_encs.py', wdir='/Users/vschmidt/gitsrc/encs')
179/79: layer.GetFeature('RCID')
179/80: ls
179/81: run enc_dump_feature_info_tool.py -h
179/82: run enc_dump_feature_info_tool.py -h
179/83: print ENC_filename
179/84: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE
179/85: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE
179/86: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -v
179/87: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/88: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/89: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/90: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/91: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/92: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/93: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/94: a = 'a,b,c'
179/95: split(a,'c')
179/96: a.split(',')
179/97: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/98: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/99: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/100: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE
179/101: run enc_dump_feature_info_tool.py -f /Users/vschmidt/Downloads/ENC_ROOT/US5NH02M/US5NH02M.000 -l M_CSCL -F CSCALE -vv
179/102: run enc_dump_feature_info_tool.py -d /Users/vschmidt/Downloads/ENC_ROOT/.000 -l M_CSCL -F CSCALE -vv
179/103: run enc_dump_feature_info_tool.py -d /Users/vschmidt/Downloads/ENC_ROOT/ -l M_CSCL -F CSCALE -vv
179/104: import os
179/105: os.path.basename('/test/file/thing')
179/106: run enc_dump_feature_info_tool.py -d /Users/vschmidt/Downloads/ENC_ROOT/ -l M_CSCL -F CSCALE -vv
179/107: run enc_dump_feature_info_tool.py -d /Users/vschmidt/Downloads/ENC_ROOT/ -l M_CSCL -F CSCALE
179/108: layer = ds.GetLayerByName('M_NPUB')
179/109: layer.GetFeatureCount()
179/110: feat = layer.GetNextFeature()
179/111: geom = feat.GetGeometryRef()
179/112: poly = ogr.Geometry(ogr.wkbPolygon)
179/113: poly = ogr.CreateGeometryFromWkb(geom.ExportToIsoWkb)
179/114: poly = ogr.CreateGeometryFromWkb(geom.ExportToIsoWkb())
179/115: print(poly)
180/1: impor woa
180/2: import woa
180/3: cd ~/gitsrc/svpeditor/Tools/svp_editor_20130911/
180/4: import woa
180/5: import datetime as dt
180/6: import sys
180/7: woa_path = '/Users/vschmidt/gitsrc/svpeditor/WOA2009/'
180/8:
w = woa.WOA()
    w.load_grids(woa_path)
180/9: w = woa.WOA()w.load_grids(woa_path)
180/10: w = woa.WOA()
180/11: w.load_grids(woa_path)
180/12: latitude = 40
180/13: longitude = -60
180/14: year = 2010
180/15: month = 1
180/16: day = 1
180/17:     date = dt.date(int(year),int(month),int(day))
180/18: date = dt.date(int(year),int(month),int(day))
180/19: data, data_min, data_max = w.query(float(latitude),float(longitude),date)
180/20: data
180/21: A = data.data.transpose()
180/22: print A
180/23: import pandas
180/24: import pandas as pd
180/25: import numpy as np
180/26: df = pd.DataFrame(A)
180/27: df
180/28: print df
180/29: df = pd.DataFrame(data.data))
180/30: df = pd.DataFrame(data.data)
180/31: df
180/32: df = pd.DataFrame(data.data.transpose())
180/33: print df
180/34: df = pd.DataFrame(data.data.transpose(),columns=('Depth','SVP','T','S','N'))
180/35: print df
180/36: import matplotlib.pyplot as plt
180/37: plt.figure(); df.plot();
180/38: plt.show()
180/39: df.plot?
180/40: df.plot?
180/41: plt.figure(); df.plot.line('T','Depth'); plt.show()
180/42: plt.figure(); df.plot.line('Depth','T'); plt.show()
180/43: df.plot.line('T','Depth'); plt.show()
180/44: df.plot.line('T','Depth');plt.gca().invert_yaxis(); plt.show()
180/45: df.plot.line('T','Depth');plt.gca().invert_yaxis(); plt.show() plt.axes?
180/46: df.plot.line('T','Depth');plt.gca().invert_yaxis(); plt.show() plt.Axes?
180/47: latitude = 20
180/48: longitude = -150
180/49: data, data_min, data_max = w.query(float(latitude),float(longitude),date)
180/50: df = pd.DataFrame(data.data.transpose(),columns=('Depth','SVP','T','S','N'))
180/51: plot(df)
180/52: df.plot.line('T','Depth');plt.gca().invert_yaxis(); plt.show()
180/53: df
180/54: plt.figure(); df.plot.line('Depth','T'); plt.show()
180/55: df.plot.line('Depth','T');plt.gca().invert_yaxis(); plt.show()
180/56: df.plot.line('T','Depth');plt.gca().invert_yaxis(); plt.show()
180/57: df.plot.line('T','Depth');plt.gca().invert_yaxis(); plt.gca().invert_x_axis(); plt.show()
180/58: df.plot.line('T','Depth');plt.gca().invert_yaxis();
180/59: plt.gca().invert_xaxis()
180/60: plt.show()
180/61: df.plot.line('T','Depth');plt.gca().invert_yaxis(); plt.gca().invert_x_axis(); plt.xlabel('Temp, C') plt.ylabel('Depth, m')
180/62: df.plot.line('T','Depth');plt.gca().invert_yaxis(); plt.gca().invert_x_axis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m')
180/63: df.plot.line('T','Depth');plt.gca().invert_yaxis();plt.gca().invert_x_axis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m')
180/64: df.plot.line('T','Depth');plt.gca().invert_yaxis();
180/65: plt.gca().invert_x_axis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m')
180/66: plt.gca().invert_xaxis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m')
180/67: plt.show()
180/68: df.plot.line('T','Depth',legend=None);plt.gca().invert_yaxis();plt.gca().invert_xaxis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m')
180/69: plt.show()
180/70: month = 1
180/71: date = dt.date(int(year),int(month),int(day))
180/72: data, data_min, data_max = w.query(float(latitude),float(longitude),date)
180/73: df = pd.DataFrame(data.data.transpose(),columns=('Depth','SVP','T','S','N'))
180/74: df.plot.line('T','Depth',legend=None);plt.gca().invert_yaxis();plt.gca().invert_xaxis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m'); plt.show()
180/75: latitude = 50
180/76: data, data_min, data_max = w.query(float(latitude),float(longitude),date)
180/77: df = pd.DataFrame(data.data.transpose(),columns=('Depth','SVP','T','S','N'))
180/78: df.plot.line('T','Depth',legend=None);plt.gca().invert_yaxis();plt.gca().invert_xaxis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m'); plt.show()
180/79: latitude = 50
180/80: longitude = 30
180/81: data, data_min, data_max = w.query(float(latitude),float(longitude),date)
180/82: df = pd.DataFrame(data.data.transpose(),columns=('Depth','SVP','T','S','N'))
180/83: longitude = 40
180/84: data, data_min, data_max = w.query(float(latitude),float(longitude),date)
180/85: df = pd.DataFrame(data.data.transpose(),columns=('Depth','SVP','T','S','N'))
180/86: longitude = -30
180/87: data, data_min, data_max = w.query(float(latitude),float(longitude),date)
180/88: df = pd.DataFrame(data.data.transpose(),columns=('Depth','SVP','T','S','N'))
180/89: df.plot.line('T','Depth',legend=None);plt.gca().invert_yaxis();plt.gca().invert_xaxis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m'); plt.show()
180/90: latitude = 40
180/91: data, data_min, data_max = w.query(float(latitude),float(longitude),date)
180/92: df = pd.DataFrame(data.data.transpose(),columns=('Depth','SVP','T','S','N'))
180/93: df.plot.line('T','Depth',legend=None);plt.gca().invert_yaxis();plt.gca().invert_xaxis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m'); plt.show()
180/94: latitude = 40
180/95: longitude = -60
180/96: data, data_min, data_max = w.query(float(latitude),float(longitude),date)
180/97: df.plot.line('T','Depth',legend=None);plt.gca().invert_yaxis();plt.gca().invert_xaxis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m'); plt.show()
180/98: df = pd.DataFrame(data.data.transpose(),columns=('Depth','SVP','T','S','N'))
180/99: df.plot.line('T','Depth',legend=None);plt.gca().invert_yaxis();plt.gca().invert_xaxis(); plt.xlabel('Temp, C'); plt.ylabel('Depth, m'); plt.show()
180/100: print df
180/101: latitude
180/102: longitude
181/1: import pandas as pd
181/2: import pandas as pd
181/3: import pandas as pd
181/4: ls
181/5: ls 2017-09-14T13-39-29/
181/6: df = pd.DataFrame()
181/7: nav = pd.read_table('GGA_3.txt')
181/8: nav = pd.read_table('2017-09-14T13-39-29/GGA_3.txt')
181/9:
ls 
nav = pd.read_table('2017-09-14T13-39-29/GGA_3.txt')
181/10: ls 2017-09-14T13-39-29/
181/11:  nav = pd.read_table('2017-09-14T13-39-29/GGA_3_.txt')
181/12: nav
181/13: pd.read_table?
181/14:  nav = pd.read_table('2017-09-14T13-39-29/GGA_3_.txt',delimiter = '\t')
181/15: nav
181/16:  nav = pd.read_table('2017-09-14T13-39-29/GGA_3_.txt',sep='\s+')
181/17: nav
181/18:  nav = pd.read_table('2017-09-14T13-39-29/GGA_3_.txt',sep='\s+',parse_dates = True)
181/19: nav
181/20:  nav = pd.read_table('2017-09-14T13-39-29/GGA_3_.txt',sep='\s+',parse_dates = True)
181/21: nav
181/22:  nav = pd.read_table('2017-09-14T13-39-29/GGA_3_.txt',sep='\s+',parse_dates = True,infer_datetime_format = True)
181/23: nav
181/24:
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
182/1: import pandas as pd
182/2: cd 2017-09-14T13-39-29/
182/3: nav = pd.read_csv('GGA_3_.txt',sep = '\s+',parse_dates=[[1,2,3,4,5,6],[7,8,9,10,11,12,13,14]])
182/4: print(nav.head)
182/5: nav = pd.read_csv('GGA_3_.txt',sep = '\s+',parse_dates=[[1,2,3,4,5,6],[7,8,9,10,11,12,13,14]],infer_datetime_format=True)
182/6: print(nav.head)
182/7: nav = pd.read_csv('GGA_3_.txt',sep = '\s+',parse_dates=[[0,1,2,3,4,5],[6,7,8,9,10,11,12,13]],infer_datetime_format=True)
182/8: print(nav.head)
182/9: nav = pd.read_csv('GGA_3_.txt',sep = '\s+')
182/10: print(nav.head)
182/11: nav = pd.read_csv('GGA_3_.txt',sep = '\s+',header=None)
182/12: print(nav.head)
182/13: dts =pd.to_datetime(nav[0:5],format='%Y\t%\m\t%\d\t%\H\t%\M\t%\s.%f')
182/14: nav[0:5].head
182/15: nav[0:5,:].head
182/16: nav[:,0:5].head
182/17: nav[(0,1,2,3,4,5)].head
182/18: dts = nav[0:5]
182/19: print(dts)
182/20: dts = nav[:,0:5]
182/21: dts = nav[:,:5]
182/22: dts = nav[:,:5]
182/23: dts = nav[('0','1','2','3','4','5')
182/24: dts = nav[('0','1','2','3','4','5')]
182/25: print(nav)
182/26: nav
182/27: nav['0']
182/28: nav[0]
182/29: nav[[0,1]
182/30: nav[[0,1]
182/31: nav[[0,1]]
182/32: dts = nav[range(5)]
182/33: dts = nav[[range(5)]
182/34: dts = nav[[range(5)]]
182/35: dts = nav[[0,1,2,3,4,5]]
182/36: dts
182/37: print(pd.to_datetime(dts))
182/38: dts.columns=['year','month','day','hour','minute','second']
182/39: print(dts)
182/40: dd = pd.to_datetime(dts)
182/41: print dd
182/42: print(dd)
182/43: nav = pd.read_csv('GGA_3_.txt',sep = '\s+',header=None,columns=['year','month','day','hour','minute','second','year','month','day','hour','minute','second','latitude','longitude','fix_type','Nsats','hdop','height_msl','height_ellipsoid'])
182/44: nav = pd.read_csv('GGA_3_.txt',sep = '\s+',header=None,names=['year','month','day','hour','minute','second','year','month','day','hour','minute','second','latitude','longitude','fix_type','Nsats','hdop','height_msl','height_ellipsoid'])
182/45: dts = nav[1:5]
182/46: dts.columns=['year','month','day','hour','minute','second']
183/1: range?
183/2: range(0,3)
183/3: range(0,3,.5)
183/4:
import numpy as np
from math import *
183/5:
def sign(x):
    return x/abs(x)
183/6:
if len(x) != 12:
    print("Error x-vector must have dimension 12!")
183/7: x = np.array(range(10))
183/8: x = np.array(range(12))
183/9: print(x)
183/10: ui = np.array(range(6))
183/11: print(ui)
183/12:
if len(x) != 12:
    print("Error x-vector must have dimension 12!")
183/13:
    if len(ui) != 6:
        print("Error ui vector must have dimension 6!")
183/14:
    u = x[0]
    v = x[1]
    w = x[2]
    p = x[3]
    q = x[4]
    r = x[5]
    phi = x[11]
    theta = x[10]
    psi = x[11]

    U = sqrt(u**2+v**2+w**2)
183/15: u
183/16: v
183/17: w
183/18: p
183/19: q
183/20: r
183/21: phi
183/22: theta
183/23: psi
183/24: U
183/25:
    max_ui = np.zeros((6,1))
    max_ui[0]  = 20*pi/180        # max value delta_r   (rad)
    max_ui[1]  = 20*pi/180        # max value delta_s   (rad)
    max_ui[2]  = 20*pi/180        # max value delta_b   (rad)
    max_ui[3]  = 20*pi/180        # max value delta_bp  (rad)
    max_ui[4]  = 20*pi/180        # max value delta_bs  (rad)
    max_ui[5]  = 1500             # max value n         (rpm)
183/26: max_ui
183/27:
    c1 = cos(phi)
    c2 = cos(theta)
    c3 = cos(psi)
    s1 = sin(phi)
    s2 = sin(theta)
    s3 = sin(psi)
    t2 = tan(theta)
183/28: c1
183/29: c2
183/30: c3
183/31: s1
183/32: s2
183/33: s3
183/34: t2
183/35: cos?
183/36: phi
183/37:
    u = x[0]
    v = x[1]
    w = x[2]
    p = x[3]
    q = x[4]
    r = x[5]
    phi = x[9]
    theta = x[10]
    psi = x[11]

    U = sqrt(u**2+v**2+w**2) # speed

    # Rudder and propeller
    max_ui = np.zeros((6,1))
    max_ui[0]  = 20*pi/180        # max value delta_r   (rad)
    max_ui[1]  = 20*pi/180        # max value delta_s   (rad)
    max_ui[2]  = 20*pi/180        # max value delta_b   (rad)
    max_ui[3]  = 20*pi/180        # max value delta_bp  (rad)
    max_ui[4]  = 20*pi/180        # max value delta_bs  (rad)
    max_ui[5]  = 1500             # max value n         (rpm)

    # Parameters, hydrodynamic derivatives and main dimensions
    c1 = cos(phi)
    c2 = cos(theta)
    c3 = cos(psi)
    s1 = sin(phi)
    s2 = sin(theta)
    s3 = sin(psi)
    t2 = tan(theta)
183/38: c1
183/39: c2
183/40: c3
183/41: s1
183/42: s2
183/43: s3
183/44: t2
183/45:
    L   = 5.3
    g   = 9.8
    xG  = 0.0
    yG  = 0.0
    zG = 0.061
    xB  = 0.0
    yB  = 0.0
    zB = 0.0
    rho = 1000.0
    m   = 5454.54/(rho/2*L^3)
    W   = 53400.0
    B   = 53400.0
    Ix  = 2038.0
    Iy  = 13587.0
    Iz  = 13587.0
    Ixy = -13.58
    Iyz = -13.58
    Ixz = -13.58
    Cdy = 0.5
    Cdz = 0.6
    Cy  = 0.0
    Cz  = 0.0
    Cm  = 0.0
    Cn  = 0.0

    r2 = rho * L^2.0 / 2
    r3 = rho * L^3.0 / 2
    r4 = rho * L^4.0 / 2
    r5 = rho * L^5.0 / 2
183/46: 3**2
183/47:
    L   = 5.3
    g   = 9.8
    xG  = 0.0
    yG  = 0.0
    zG = 0.061
    xB  = 0.0
    yB  = 0.0
    zB = 0.0
    rho = 1000.0
    m   = 5454.54/(rho/2*L**3)
    W   = 53400.0
    B   = 53400.0
    Ix  = 2038.0
    Iy  = 13587.0
    Iz  = 13587.0
    Ixy = -13.58
    Iyz = -13.58
    Ixz = -13.58
    Cdy = 0.5
    Cdz = 0.6
    Cy  = 0.0
    Cz  = 0.0
    Cm  = 0.0
    Cn  = 0.0

    r2 = rho * L**2.0 / 2
    r3 = rho * L**3.0 / 2
    r4 = rho * L**4.0 / 2
    r5 = rho * L**5.0 / 2
183/48:
    # X
    Xpp = 7.0e-3
    Xqq = -1.5e-2
    Xrr = 4.0e-3
    Xpr = 7.5e-4
    Xudot = -7.6e-3
    Xwq = -2.0e-1
    Xvp = -3.0e-3
    Xvr = 2.0e-2
    Xqds = 2.5e-2
    Xqdb2 = -1.3e-3
    Xrdr = -1.0e-3
    Xvv = 5.3e-2
    Xww = 1.7e-1
    Xvdr = 1.7e-3
    Xwds = 4.6e-2
    Xwdb2 = 0.5e-2
    Xdsds = -1.0e-2
    Xdbdb2 = -4.0e-3
    Xdrdr = -1.0e-2
    Xqdsn = 2.0e-3
    Xwdsn = 3.5e-3
    Xdsdsn = -1.6e-3

    # Y
    Ypdot = 1.2e-4
    Yrdot = 1.2e-3
    Ypq = 4.0e-3
    Yqr = -6.5e-3
    Yvdot = -5.5e-2
    Yp = 3.0e-3
    Yr = 3.0e-2
    Yvq = 2.4e-2
    Ywp = 2.3e-1
    Ywr = -1.9e-2
    Yv = -1.0e-1
    Yvw = 6.8e-2
    Ydr = 2.7e-2

    # Z
    Zqdot = -6.8e-3
    Zpp = 1.3e-4
    Zpr = 6.7e-3
    Zrr = -7.4e-3
    Zwdot = -2.4e-1
    Zq = -1.4e-1
    Zvp = -4.8e-2
    Zvr = 4.5e-2
    Zw = -3.0e-1
    Zvv = -6.8e-2
    Zds = -7.3e-2
    Zdb2 = -1.3e-2
    Zqn = -2.9e-3
    Zwn = -5.1e-3
    Zdsn = -1.0e-2

    # K
    Kpdot = -1.0e-3
    Krdot = -3.4e-5
    Kpq = -6.9e-5
    Kqr = 1.7e-2
    Kvdot = 1.2e-4
    Kp = -1.1e-2
    Kr = -8.4e-4
    Kvq = -5.1e-3
    Kwp = -1.3e-4
    Kwr = 1.4e-2
    Kv = 3.1e-3
    Kvw = -1.9e-1
    Kdb2 = 0
    Kpn = -5.7e-4
    Kprop = 0

    # M
    Mqdot = -1.7e-2
    Mpp = 5.3e-5
    Mpr = 5.0e-3
    Mrr = 2.9e-3
    Mwdot = -6.8e-3
    Muq = -6.8e-2
    Mvp = 1.2e-3
    Mvr = 1.7e-2
    Muw = 1.0e-1
    Mvv = -2.6e-2
    Mds = -4.1e-2
    Mdb2 = 3.5e-3
    Mqn = -1.6e-3
    Mwn = -2.9e-3
    Mdsn = -5.2e-3

    # N
    Npdot = -3.4e-5
    Nrdot = -3.4e-3
    Npq = -2.1e-2
    Nqr = 2.7e-3
    Nvdot = 1.2e-3
    Np = -8.4e-4
    Nr = -1.6e-2
    Nvq = -1.0e-2
    Nwp = -1.7e-2
    Nwr = 7.4e-3
    Nv = -7.4e-3
    Nvw = -2.7e-2
    Ndr = -1.3e-2
    Nprop = 0
183/49:
 # Handle rudder and shaft saturations
    for i in range(len(ui)):
        if abs(ui[i]) > max_ui[i]:
            ui[i] = sign(ui[i]) * max_ui[i]

    # Control input(rudder and propeller)
    delta_r = ui[0]
    delta_s = ui[1]
    delta_b = ui[2]
    delta_bp = ui[3]
    delta_bs = ui[4]
    n = ui[5] / 60.0 * 2.0 * pi

    Cd0 = 0.00385
    prop = 0.012 * n / u
    Xprop = Cd0 * (abs(prop) * prop - 1.0)
    Ct = 0.008 * L**2 * abs(prop) * prop / 2.0
    Ct1 = 0.008 * L**2 / 2.0
    epsi = -1.0 + sign(n) / sign(u) * (sqrt(Ct + 1.0) - 1.0) / (sqrt(Ct1 + 1.0) - 1.0)
183/50:
    for i in range(len(ui)):
        if abs(ui[i]) > max_ui[i]:
            ui[i] = sign(ui[i]) * max_ui[i]
183/51:
    # Control input(rudder and propeller)
    delta_r = ui[0]
    delta_s = ui[1]
    delta_b = ui[2]
    delta_bp = ui[3]
    delta_bs = ui[4]
    n = ui[5] / 60.0 * 2.0 * pi

    Cd0 = 0.00385
    prop = 0.012 * n / u
    Xprop = Cd0 * (abs(prop) * prop - 1.0)
    Ct = 0.008 * L**2 * abs(prop) * prop / 2.0
    Ct1 = 0.008 * L**2 / 2.0
    epsi = -1.0 + sign(n) / sign(u) * (sqrt(Ct + 1.0) - 1.0) / (sqrt(Ct1 + 1.0) - 1.0)
183/52: u
183/53: prop
183/54: x[0] = 1
183/55:     u = x[0]
183/56:
    delta_r = ui[0]
    delta_s = ui[1]
    delta_b = ui[2]
    delta_bp = ui[3]
    delta_bs = ui[4]
    n = ui[5] / 60.0 * 2.0 * pi

    Cd0 = 0.00385
    prop = 0.012 * n / u
    Xprop = Cd0 * (abs(prop) * prop - 1.0)
    Ct = 0.008 * L**2 * abs(prop) * prop / 2.0
    Ct1 = 0.008 * L**2 / 2.0
    epsi = -1.0 + sign(n) / sign(u) * (sqrt(Ct + 1.0) - 1.0) / (sqrt(Ct1 + 1.0) - 1.0)

    tau1 = (r3*(Xrdr*u*r*delta_r + (Xqds*delta_s + Xqdb2*delta_bp +
            Xqdb2*delta_bs)*u*q) +
            r2*(Xvdr*u*v*delta_r + (Xwds*delta_s + Xwdb2*delta_bs +
            Xwdb2*delta_bp)*u*w + (Xdsds*delta_s**2 +
            Xdbdb2*delta_b**2 + Xdrdr*delta_r**2)*u**2) +
            r3*Xqdsn*u*q*delta_s*epsi + r2*(Xwdsn*u*w*delta_s + Xdsdsn*u**2*delta_s**2)*epsi + r2*u**2*Xprop)
    tau2 = r2*Ydr*u**2*delta_r
    tau3 = (r2 * u**2 * (Zds * delta_s + Zdb2 * delta_bs + Zdb2 * delta_bp) +
            r3 * Zqn * u * q * epsi + r2 * (Zwn * u * w + Zdsn * u**2 * delta_s) * epsi)
    tau4 = (r4 * Kpn * u * p * epsi + r3 * u**3 * Kprop +
            r3 * u**2 * (Kdb2 * delta_bp + Kdb2 * delta_bs))
    tau5 = (r4 * Mqn * u * q * epsi + r3 * (Mwn * w * n + Mdsn * u**2 * delta_s) * epsi +
            r3 * u**2 * (Mds * delta_s + Mdb2 * delta_bp + Mdb2 * delta_bs))
    tau6 = r3 * u**2 * Nprop + r3 * u**2 * Ndr * delta_r
183/57: tau1
183/58: r2
183/59: delta_4
183/60: delta_r
183/61: delta_s
183/62: Xprop
183/63: epsi
183/64:
r3*(Xrdr*u*r*delta_r + (Xqds*delta_s + Xqdb2*delta_bp +
            Xqdb2*delta_bs)*u*q)
183/65: r3*(Xrdr*u*r*delta_r + (Xqds*delta_s + Xqdb2*delta_bp + Xqdb2*delta_bs)*u*q)
183/66: Xrdr
183/67: r3
183/68: u
183/69: q
183/70: Xrdr*u*r*delta_r
183/71:
Xqds*delta_s + Xqdb2*delta_bp +
            Xqdb2*delta_bs
183/72: Xqds*delta_s + Xqdb2*delta_bp + Xqdb2*delta_bs
183/73: Xqds*delta_s
183/74: delta_s
183/75: max_ui
183/76: ui
183/77: ui = np.array(range(6))
183/78: ui
183/79:
    for i in range(len(ui)):
        if abs(ui[i]) > max_ui[i]:
            ui[i] = sign(ui[i]) * max_ui[i]
183/80: ui
183/81: sign(ui[1])
183/82: ui = np.array(range(6))
183/83: i=0
183/84: abs(ui[i]) > max_ui[i]
183/85:
if abs(ui[i]) > max_ui[i]:
    print('true')
183/86: ui
183/87: i=1
183/88: abs(ui[i]) > max_ui[i]
183/89:
if abs(ui[i]) > max_ui[i]:
    print('true')
183/90: sign(ui[i])
183/91: max_ui[i]
183/92: sign(ui[i])*max_ui[i]
183/93: ui[i] = sign(ui[i])*max_ui[i]
183/94: ui
183/95: np.array?
183/96: ui = np.array(range(6),dtype='DOUBLE'))
183/97: ui = np.array(range(6),dtype=np.float))
183/98: ui = np.array?
183/99: ui = np.array(range(6),dtype=double))
183/100: ui = np.array(range(6),dtype=float))
183/101: ui = np.array(range(6),dtype=float64))
183/102: ui = np.array?(range(6),dtype=float64))
183/103: ui = np.array?
183/104: ui = np.array(np.arange(0,5,1))
183/105: ui
183/106: ui = np.array(1.8*np.arange(0,5,1))
183/107: ui
183/108: ui = np.array(1*np.arange(0,5,1))
183/109: ui
183/110: ui = np.array(1.0*np.arange(0,5,1))
183/111: ui
183/112:
delta_r = ui[0]
    delta_s = ui[1]
    delta_b = ui[2]
    delta_bp = ui[3]
    delta_bs = ui[4]
    n = ui[5] / 60.0 * 2.0 * pi

    Cd0 = 0.00385
    prop = 0.012 * n / u
    Xprop = Cd0 * (abs(prop) * prop - 1.0)
    Ct = 0.008 * L**2 * abs(prop) * prop / 2.0
    Ct1 = 0.008 * L**2 / 2.0
    epsi = -1.0 + sign(n) / sign(u) * (sqrt(Ct + 1.0) - 1.0) / (sqrt(Ct1 + 1.0) - 1.0)

    tau1 = (r3*(Xrdr*u*r*delta_r + (Xqds*delta_s + Xqdb2*delta_bp +
            Xqdb2*delta_bs)*u*q) +
            r2*(Xvdr*u*v*delta_r + (Xwds*delta_s + Xwdb2*delta_bs +
            Xwdb2*delta_bp)*u*w + (Xdsds*delta_s**2 +
            Xdbdb2*delta_b**2 + Xdrdr*delta_r**2)*u**2) +
            r3*Xqdsn*u*q*delta_s*epsi + r2*(Xwdsn*u*w*delta_s + Xdsdsn*u**2*delta_s**2)*epsi + r2*u**2*Xprop)
    tau2 = r2*Ydr*u**2*delta_r
    tau3 = (r2 * u**2 * (Zds * delta_s + Zdb2 * delta_bs + Zdb2 * delta_bp) +
            r3 * Zqn * u * q * epsi + r2 * (Zwn * u * w + Zdsn * u**2 * delta_s) * epsi)
    tau4 = (r4 * Kpn * u * p * epsi + r3 * u**3 * Kprop +
            r3 * u**2 * (Kdb2 * delta_bp + Kdb2 * delta_bs))
    tau5 = (r4 * Mqn * u * q * epsi + r3 * (Mwn * w * n + Mdsn * u**2 * delta_s) * epsi +
            r3 * u**2 * (Mds * delta_s + Mdb2 * delta_bp + Mdb2 * delta_bs))
    tau6 = r3 * u**2 * Nprop + r3 * u**2 * Ndr * delta_r
183/113:
    delta_r = ui[0]
    delta_s = ui[1]
    delta_b = ui[2]
    delta_bp = ui[3]
    delta_bs = ui[4]
    n = ui[5] / 60.0 * 2.0 * pi

    Cd0 = 0.00385
    prop = 0.012 * n / u
    Xprop = Cd0 * (abs(prop) * prop - 1.0)
    Ct = 0.008 * L**2 * abs(prop) * prop / 2.0
    Ct1 = 0.008 * L**2 / 2.0
    epsi = -1.0 + sign(n) / sign(u) * (sqrt(Ct + 1.0) - 1.0) / (sqrt(Ct1 + 1.0) - 1.0)

    tau1 = (r3*(Xrdr*u*r*delta_r + (Xqds*delta_s + Xqdb2*delta_bp +
            Xqdb2*delta_bs)*u*q) +
            r2*(Xvdr*u*v*delta_r + (Xwds*delta_s + Xwdb2*delta_bs +
            Xwdb2*delta_bp)*u*w + (Xdsds*delta_s**2 +
            Xdbdb2*delta_b**2 + Xdrdr*delta_r**2)*u**2) +
            r3*Xqdsn*u*q*delta_s*epsi + r2*(Xwdsn*u*w*delta_s + Xdsdsn*u**2*delta_s**2)*epsi + r2*u**2*Xprop)
    tau2 = r2*Ydr*u**2*delta_r
    tau3 = (r2 * u**2 * (Zds * delta_s + Zdb2 * delta_bs + Zdb2 * delta_bp) +
            r3 * Zqn * u * q * epsi + r2 * (Zwn * u * w + Zdsn * u**2 * delta_s) * epsi)
    tau4 = (r4 * Kpn * u * p * epsi + r3 * u**3 * Kprop +
            r3 * u**2 * (Kdb2 * delta_bp + Kdb2 * delta_bs))
    tau5 = (r4 * Mqn * u * q * epsi + r3 * (Mwn * w * n + Mdsn * u**2 * delta_s) * epsi +
            r3 * u**2 * (Mds * delta_s + Mdb2 * delta_bp + Mdb2 * delta_bs))
    tau6 = r3 * u**2 * Nprop + r3 * u**2 * Ndr * delta_r
183/114: ui = np.array(1.0*np.arange(0,6,1))
183/115:
    delta_r = ui[0]
    delta_s = ui[1]
    delta_b = ui[2]
    delta_bp = ui[3]
    delta_bs = ui[4]
    n = ui[5] / 60.0 * 2.0 * pi

    Cd0 = 0.00385
    prop = 0.012 * n / u
    Xprop = Cd0 * (abs(prop) * prop - 1.0)
    Ct = 0.008 * L**2 * abs(prop) * prop / 2.0
    Ct1 = 0.008 * L**2 / 2.0
    epsi = -1.0 + sign(n) / sign(u) * (sqrt(Ct + 1.0) - 1.0) / (sqrt(Ct1 + 1.0) - 1.0)

    tau1 = (r3*(Xrdr*u*r*delta_r + (Xqds*delta_s + Xqdb2*delta_bp +
            Xqdb2*delta_bs)*u*q) +
            r2*(Xvdr*u*v*delta_r + (Xwds*delta_s + Xwdb2*delta_bs +
            Xwdb2*delta_bp)*u*w + (Xdsds*delta_s**2 +
            Xdbdb2*delta_b**2 + Xdrdr*delta_r**2)*u**2) +
            r3*Xqdsn*u*q*delta_s*epsi + r2*(Xwdsn*u*w*delta_s + Xdsdsn*u**2*delta_s**2)*epsi + r2*u**2*Xprop)
    tau2 = r2*Ydr*u**2*delta_r
    tau3 = (r2 * u**2 * (Zds * delta_s + Zdb2 * delta_bs + Zdb2 * delta_bp) +
            r3 * Zqn * u * q * epsi + r2 * (Zwn * u * w + Zdsn * u**2 * delta_s) * epsi)
    tau4 = (r4 * Kpn * u * p * epsi + r3 * u**3 * Kprop +
            r3 * u**2 * (Kdb2 * delta_bp + Kdb2 * delta_bs))
    tau5 = (r4 * Mqn * u * q * epsi + r3 * (Mwn * w * n + Mdsn * u**2 * delta_s) * epsi +
            r3 * u**2 * (Mds * delta_s + Mdb2 * delta_bp + Mdb2 * delta_bs))
    tau6 = r3 * u**2 * Nprop + r3 * u**2 * Ndr * delta_r
183/116: tau1
183/117: ui
183/118:
    for i in range(len(ui)):
        if abs(ui[i]) > max_ui[i]:
            ui[i] = sign(ui[i]) * max_ui[i]

    # Control input(rudder and propeller)
    delta_r = ui[0]
    delta_s = ui[1]
    delta_b = ui[2]
    delta_bp = ui[3]
    delta_bs = ui[4]
    n = ui[5] / 60.0 * 2.0 * pi

    Cd0 = 0.00385
    prop = 0.012 * n / u
    Xprop = Cd0 * (abs(prop) * prop - 1.0)
    Ct = 0.008 * L**2 * abs(prop) * prop / 2.0
    Ct1 = 0.008 * L**2 / 2.0
    epsi = -1.0 + sign(n) / sign(u) * (sqrt(Ct + 1.0) - 1.0) / (sqrt(Ct1 + 1.0) - 1.0)

    tau1 = (r3*(Xrdr*u*r*delta_r + (Xqds*delta_s + Xqdb2*delta_bp +
            Xqdb2*delta_bs)*u*q) +
            r2*(Xvdr*u*v*delta_r + (Xwds*delta_s + Xwdb2*delta_bs +
            Xwdb2*delta_bp)*u*w + (Xdsds*delta_s**2 +
            Xdbdb2*delta_b**2 + Xdrdr*delta_r**2)*u**2) +
            r3*Xqdsn*u*q*delta_s*epsi + r2*(Xwdsn*u*w*delta_s + Xdsdsn*u**2*delta_s**2)*epsi + r2*u**2*Xprop)
    tau2 = r2*Ydr*u**2*delta_r
    tau3 = (r2 * u**2 * (Zds * delta_s + Zdb2 * delta_bs + Zdb2 * delta_bp) +
            r3 * Zqn * u * q * epsi + r2 * (Zwn * u * w + Zdsn * u**2 * delta_s) * epsi)
    tau4 = (r4 * Kpn * u * p * epsi + r3 * u**3 * Kprop +
            r3 * u**2 * (Kdb2 * delta_bp + Kdb2 * delta_bs))
    tau5 = (r4 * Mqn * u * q * epsi + r3 * (Mwn * w * n + Mdsn * u**2 * delta_s) * epsi +
            r3 * u**2 * (Mds * delta_s + Mdb2 * delta_bp + Mdb2 * delta_bs))
    tau6 = r3 * u**2 * Nprop + r3 * u**2 * Ndr * delta_r
183/119: tau1
183/120: tau2
183/121: tau3
183/122: tau4
183/123: tau5
183/124:
    dxL = L / 10.0
    xL = 0.0
    Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)

    if Ucf != 0.0:
        for xL in  np.arange(0.0, L, dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r)**2 + 0.6 * (w - xL * q)**2) * (v + xL * r) / Ucf
            Cy = Cy + dxL * temp

        for xL in np.arange(0.0,L,dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r) **2 + 0.6 * (w - xL * q)**2) * (w - xL * q) / Ucf
            Cz = Cz + dxL * temp

        for xL = np.arange(0,0,L,dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r)**2 + 0.6 * (w - xL * q)**2) * (w + xL * q) / Ucf * xL
            Cm = Cm + dxL * temp

        for xL = np.arange(0,L,dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r)**2 + 0.6 * (w - xL * q)**2) * (v + xL * r) / Ucf * xL
            Cn = Cn + dxL * temp
183/125:
 # Drag forces and moment assuming block shaped body
    dxL = L / 10.0
    xL = 0.0
    Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)

    if Ucf != 0.0:
        for xL in  np.arange(0.0, L, dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r)**2 + 0.6 * (w - xL * q)**2) * (v + xL * r) / Ucf
            Cy = Cy + dxL * temp

        for xL in np.arange(0.0,L,dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r) **2 + 0.6 * (w - xL * q)**2) * (w - xL * q) / Ucf
            Cz = Cz + dxL * temp

        for xL in np.arange(0,0,L,dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r)**2 + 0.6 * (w - xL * q)**2) * (w + xL * q) / Ucf * xL
            Cm = Cm + dxL * temp

        for xL in np.arange(0,L,dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r)**2 + 0.6 * (w - xL * q)**2) * (v + xL * r) / Ucf * xL
            Cn = Cn + dxL * temp
183/126:
    # Drag forces and moment assuming block shaped body
    dxL = L / 10.0
    xL = 0.0
    Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)

    if Ucf != 0.0:
        for xL in  np.arange(0.0, L, dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r)**2 + 0.6 * (w - xL * q)**2) * (v + xL * r) / Ucf
            Cy = Cy + dxL * temp

        for xL in np.arange(0.0,L,dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r) **2 + 0.6 * (w - xL * q)**2) * (w - xL * q) / Ucf
            Cz = Cz + dxL * temp

        for xL in np.arange(0,0,L,dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r)**2 + 0.6 * (w - xL * q)**2) * (w + xL * q) / Ucf * xL
            Cm = Cm + dxL * temp

        for xL in np.arange(0,L,dxL):
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r)**2 + 0.6 * (w - xL * q)**2) * (v + xL * r) / Ucf * xL
            Cn = Cn + dxL * temp
183/127: np.arange(0.0,L,dxL)
183/128: q = np.arange(0.0,L,dxL)
183/129:
for p in q.item():
    print q
183/130: q.itemset?
183/131:
for p in q.itemset():
    print q
183/132: q.itemset()
183/133: q.itemset?
183/134:
        LL = np.arange(0.0,L,dxL)
        for i in  range(len(LL)):
            xL = LL[i]
            Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)
            temp = (0.5 * 0.6 * (v + xL * r)**2 + 0.6 * (w - xL * q)**2) * (v + xL * r) / Ucf
            Cy = Cy + dxL * temp
183/135: LL
183/136: len(LL)
183/137: range(len(LL))
183/138:
        xL = np.arange(0.0,L,dxL)
        for i in  range(len(LL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
            Cy = Cy + dxL * temp
183/139: xl[i]
183/140: xL[i]
183/141: v
183/142: Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
183/143:  q = x[4]
183/144:
        xL = np.arange(0.0,L,dxL)
        for i in  range(len(LL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
            Cy = Cy + dxL * temp
183/145: Cy=0
183/146:
    if Ucf != 0.0:
        xL = np.arange(0.0,L,dxL)
        for i in  range(len(LL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
            Cy = Cy + dxL * temp

        for i in range(len(LL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xLi] * q)**2)
            temp = (0.5 * 0.6 * (v + xLi] * r) **2 + 0.6 * (w - xLi] * q)**2) * (w - xLi] * q) / Ucf
            Cz = Cz + dxL * temp

        for i in range(len(LL)):
            Ucf = sqrt((v + xLi] * r)**2 + (w - xLi] * q)**2)
            temp = (0.5 * 0.6 * (v + xLi] * r)**2 + 0.6 * (w - xLi] * q)**2) * (w + xLi] * q) / Ucf * xLi]
            Cm = Cm + dxL * temp

        for i in range(len(LL)):
            Ucf = sqrt((v + xLi] * r)**2 + (w - xLi] * q)**2)
            temp = (0.5 * 0.6 * (v + xLi] * r)**2 + 0.6 * (w - xLi] * q)**2) * (v + xLi] * r) / Ucf * xLi]
            Cn = Cn + dxL * temp
183/147:
    if Ucf != 0.0:
        xL = np.arange(0.0,L,dxL)
        for i in  range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
            Cy = Cy + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r) **2 + 0.6 * (w - xL[i] * q)**2) * (w - xL[i] * q) / Ucf
            Cz = Cz + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (w + xL[i] * q) / Ucf * xL[i]
            Cm = Cm + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf * xL[i]
            Cn = Cn + dxL * temp
183/148: Cy
183/149: Cz
183/150: Cm
183/151: Cn
183/152: np.Arange(0,0,L,dxL)
183/153: np.arange(0,0,L,dxL)
183/154: :
183/155: L
183/156: dxL
183/157: np.arange?
183/158: np.arange(0.0,L,dxL)
183/159: i=0
183/160: Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
183/161: Ucf
183/162: temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
183/163: temp
183/164: Cy=0
183/165: Cz=0
183/166: Cm=0
183/167: Cn=0
183/168:
    Cy  = 0.0
    Cz  = 0.0
    Cm  = 0.0
    Cn  = 0.0
183/169:
    # Drag forces and moment assuming block shaped body
    dxL = L / 10.0
    xL = 0.0
    Ucf = sqrt((v + xL * r)**2 + (w - xL * q)**2)

    if Ucf != 0.0:
        xL = np.arange(0.0,L,dxL)
        for i in  range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
            Cy = Cy + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r) **2 + 0.6 * (w - xL[i] * q)**2) * (w - xL[i] * q) / Ucf
            Cz = Cz + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (w + xL[i] * q) / Ucf * xL[i]
            Cm = Cm + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf * xL[i]
            Cn = Cn + dxL * temp
183/170: Cy
183/171: v
183/172: w
183/173: q
183/174: r
183/175: dxL
183/176: Cy = 0
183/177: Cy = 0.0
183/178: i=0
183/179:
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
            Cy = Cy + dxL * temp
183/180: Cy
183/181: i=1
183/182:
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
            Cy = Cy + dxL * temp
183/183: Cy
183/184: XL
183/185: xL
183/186:
    Cy  = 0.0
    Cz  = 0.0
    Cm  = 0.0
    Cn  = 0.0
183/187:

    if Ucf != 0.0:
        xL = np.arange(0.0,(L+dxL),dxL)
        for i in  range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
            Cy = Cy + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r) **2 + 0.6 * (w - xL[i] * q)**2) * (w - xL[i] * q) / Ucf
            Cz = Cz + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (w + xL[i] * q) / Ucf * xL[i]
            Cm = Cm + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf * xL[i]
            Cn = Cn + dxL * temp
183/188:

    if Ucf != 0.0:
        xL = np.arange(0.0,(L+dxL),dxL)
        for i in  range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
            Cy = Cy + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r) **2 + 0.6 * (w - xL[i] * q)**2) * (w - xL[i] * q) / Ucf
            Cz = Cz + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (w + xL[i] * q) / Ucf * xL[i]
            Cm = Cm + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf * xL[i]
            Cn = Cn + dxL * temp
183/189:
    if Ucf != 0.0:
        xL = np.arange(0.0,(L+dxL),dxL)
        for i in  range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf
            Cy = Cy + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r) **2 + 0.6 * (w - xL[i] * q)**2) * (w - xL[i] * q) / Ucf
            Cz = Cz + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (w + xL[i] * q) / Ucf * xL[i]
            Cm = Cm + dxL * temp

        for i in range(len(xL)):
            Ucf = sqrt((v + xL[i] * r)**2 + (w - xL[i] * q)**2)
            temp = (0.5 * 0.6 * (v + xL[i] * r)**2 + 0.6 * (w - xL[i] * q)**2) * (v + xL[i] * r) / Ucf * xL[i]
            Cn = Cn + dxL * temp
183/190: Cy
183/191: Cz
183/192: Cm
183/193: Cn
183/194:
    # Hydrodynamic forces and moments
    X = (r3 * ((m + Xvr) * v * r + (Xwq - m) * w * q + Xvp * v * p) +
         r4 * ((m * xG / L + Xqq) * q**2 + (m * xG / L + Xrr) * r**2 - m * yG / L * p * q +
        (Xpr - m * zG / L) * p * r + Xpp * p**2) +
         r2 * (Xvv * v**2 + Xww * w ** 2) - (W - B) * sin(theta) + tau1)

    Y = (r2*(Yv*u*v + Yvw*v*w) +
         r3*(Yp*u*p + Yr*u*r +Yvq*v*q + Ywp*w*p + Ywr*w*r) +
         r4*(Ypq*p*q + Yqr*q*r) + (W-B)*cos(theta)*sin(phi) -
         m*(rho/2.0*L**3)*(u*r -w*p + xG*p*q - yG*(p**2+r**2) + zG*q*r)+tau2-rho/2*Cy)

    Z = (r2 * (Zw * w * u + Zvv * v**2) +
        r3 * (Zq * u * q + Zvp * v * p + Zvr * v * r) +
         r4 * (Zpp * p**2 + Zpr * p * r + Zrr * r**2) +
         (W - B) * cos(theta) * cos(phi) -
         m * (rho / 2.0 * L**3) * (v * p - u * q + xG * p * r + yG * q * r - zG * (p**2 + q**2)) + tau3 + rho / 2.0 * Cz)

    K = ( r3 * (Kv * u * v + Kvw * v * w) + r4 *
          (Kp * u * p + Kr * u * r + Kvq * v * q + Kwp * w * p + Kwr * w * r) +
          r5 * (Kpq * p * q + Kqr * q * r) +
          (Iy - Iz) * q * r - Ixy * p * r - (r**2 - q**2) * Iyz + Ixz * p * q -
          m * (rho / 2.0 * L**3) * (yG * (v * p - u * q) - zG * (u * r - w * p)) +
          (yG * W - yB * B) * c1 * c2 - (zG * W - zB * B) * c2 * s1 + tau4 )

    M = ( r3 * (Muw * u * w + Mvv * v ** 2) +
          r4 * (Muq * u * q + Mvp * v * p + Mvr * v * r) +
          r5 * (Mpp * p**2 + Mpr * p * r + Mrr * r**2) -
          (xG * W - xB * B) * c1 * c2 - (zG * W - zB * B) * s2 +
          (Iz - Ix) * p * r + Ixy * q * r - Iyz * p * q - (p**2 - r**2) * Ixz +
          m * (rho / 2.0 * L**3) * (xG * (v * p - u * q) - zG * (w * q - v * r)) + tau5 - rho / 2.0 * Cm )

    N = (r3 * (Nv * u * v + Nvw * v * w) +
         r4 * (Np * u * p + Nr * u * r + Nvq * v * q + Nwp * w * p + Nwr * w * r) +
         r5 * (Npq * p * q + Nqr * q * r) +
         (xG * W - xB * B) * s1 * c2 + (yG * W - yB * B) * s2 +
         (Ix - Iy) * p * q + (p**2 - q**2) * Ixy + Iyz * p * r - Ixz * q * r -
         m * (rho / 2.0 * L ** 3) * (xG * (u * r - w * p) - yG * (w * q - v * r)) + tau6 - rho / 2.0 * Cn)
183/195: X
183/196: Y
183/197: Z
183/198:
    # Dimensional state derivatives(xdot= in (M) * f(x) is expanded to avoid inv(M) on - line )
    xdot = np.array(1,12)
    xdot[0] = 1.662e-4 * X + 1.846e-10 * Y + 1.303e-7 * Z + 3.726e-9 * K - 1.132e-6 * M + 7.320e-10 * N
    xdot[1] = 1.846e-10 * X + 1.052e-4 * Y + 3.843e-10 * Z + 9.638e-6 * K - 3.340e-9 * M + 2.368e-6 * N
    xdot[2] = 1.303e-7 * X + 3.843e-10 * Y + 4.315e-5 * Z + 7.757e-9 * K - 2.357e-6 * M + 1.524e-9 * N
    xdot[3] = 3.726e-9 * X + 9.638e-6 * Y + 7.757e-9 * Z + 2.431e-4 * K - 6.742e-8 * M - 7.740e-7 * N
    xdot[4] = -1.132e-6 * X -3.340e-9 * Y - 2.357e-6 * Z - 6.742e-8 * K + 2.049e-5 * M - 1.324e-8 * N
    xdot[5] = 7.320e-10 * X + 2.368e-6 * Y + 1.524e-9 * Z - 7.740e-7 * K - 1.324e-8 * M + 4.838e-5 * N
    xdot[6] = c3 * c2 * u + (c3 * s2 * s1 - s3 * c1) * v + (s3 * s1 + c3 * c1 * s2) * w
    xdot[7] = s3 * c2 * u + (c1 * c3 + s1 * s2 * s3) * v + (c1 * s2 * s3 - c3 * s1) * w
    xdot[8] = -s2 * u + c2 * s1 * v + c1 * c2 * w
    xdot[9] = p + s1 * t2 * q + c1 * t2 * r
    xdot[10] = (c1 * q - s1 * r)
    xdot[11] = s1 / c2 * q + c1 / c2 * r
183/199:
    xdot = np.zeros(1,12)
    xdot[0] = 1.662e-4 * X + 1.846e-10 * Y + 1.303e-7 * Z + 3.726e-9 * K - 1.132e-6 * M + 7.320e-10 * N
    xdot[1] = 1.846e-10 * X + 1.052e-4 * Y + 3.843e-10 * Z + 9.638e-6 * K - 3.340e-9 * M + 2.368e-6 * N
    xdot[2] = 1.303e-7 * X + 3.843e-10 * Y + 4.315e-5 * Z + 7.757e-9 * K - 2.357e-6 * M + 1.524e-9 * N
    xdot[3] = 3.726e-9 * X + 9.638e-6 * Y + 7.757e-9 * Z + 2.431e-4 * K - 6.742e-8 * M - 7.740e-7 * N
    xdot[4] = -1.132e-6 * X -3.340e-9 * Y - 2.357e-6 * Z - 6.742e-8 * K + 2.049e-5 * M - 1.324e-8 * N
    xdot[5] = 7.320e-10 * X + 2.368e-6 * Y + 1.524e-9 * Z - 7.740e-7 * K - 1.324e-8 * M + 4.838e-5 * N
    xdot[6] = c3 * c2 * u + (c3 * s2 * s1 - s3 * c1) * v + (s3 * s1 + c3 * c1 * s2) * w
    xdot[7] = s3 * c2 * u + (c1 * c3 + s1 * s2 * s3) * v + (c1 * s2 * s3 - c3 * s1) * w
    xdot[8] = -s2 * u + c2 * s1 * v + c1 * c2 * w
    xdot[9] = p + s1 * t2 * q + c1 * t2 * r
    xdot[10] = (c1 * q - s1 * r)
    xdot[11] = s1 / c2 * q + c1 / c2 * r
183/200: np.zeros?
183/201:
    xdot = np.zeros((12,1))
    xdot[0] = 1.662e-4 * X + 1.846e-10 * Y + 1.303e-7 * Z + 3.726e-9 * K - 1.132e-6 * M + 7.320e-10 * N
    xdot[1] = 1.846e-10 * X + 1.052e-4 * Y + 3.843e-10 * Z + 9.638e-6 * K - 3.340e-9 * M + 2.368e-6 * N
    xdot[2] = 1.303e-7 * X + 3.843e-10 * Y + 4.315e-5 * Z + 7.757e-9 * K - 2.357e-6 * M + 1.524e-9 * N
    xdot[3] = 3.726e-9 * X + 9.638e-6 * Y + 7.757e-9 * Z + 2.431e-4 * K - 6.742e-8 * M - 7.740e-7 * N
    xdot[4] = -1.132e-6 * X -3.340e-9 * Y - 2.357e-6 * Z - 6.742e-8 * K + 2.049e-5 * M - 1.324e-8 * N
    xdot[5] = 7.320e-10 * X + 2.368e-6 * Y + 1.524e-9 * Z - 7.740e-7 * K - 1.324e-8 * M + 4.838e-5 * N
    xdot[6] = c3 * c2 * u + (c3 * s2 * s1 - s3 * c1) * v + (s3 * s1 + c3 * c1 * s2) * w
    xdot[7] = s3 * c2 * u + (c1 * c3 + s1 * s2 * s3) * v + (c1 * s2 * s3 - c3 * s1) * w
    xdot[8] = -s2 * u + c2 * s1 * v + c1 * c2 * w
    xdot[9] = p + s1 * t2 * q + c1 * t2 * r
    xdot[10] = (c1 * q - s1 * r)
    xdot[11] = s1 / c2 * q + c1 / c2 * r
183/202: xdot
184/1: import cv2
184/2: import imutils
184/3: stitcher = cv2.createStitcher(False)
185/1: import cv2
186/1: import imutils
187/1: import numpy as np
187/2: import imutils
187/3: import cv2
187/4: ls
189/1: from panorama.py import Stitcher
189/2: from panorama import Stitcher
189/3: from panorama import Stitcher
189/4: from panorama import Stitcher
189/5:
import imutils
import cv2
189/6:
imageA = cv2.imread('IMG_9144.jpg')
imageB = cv2.imread('IMG_9145.jpg')
189/7: stitcher = Stitcher()
189/8: (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
189/9:
cv2.imshow("Image A", imageA)
cv2.imshow("Image B", imageB)
cv2.imshow("Keypoint Matches", vis)
cv2.imshow("Result", result)
cv2.waitKey(0)
190/1: from panorama import Stitcher
190/2:
import imutils
import cv2
190/3:
imageA = cv2.imread('IMG_9144.jpg')
imageB = cv2.imread('IMG_9145.jpg')
imageA = imutils.resize(imageA, width=400)
imageB = imutils.resize(imageB, width=400)
190/4: stitcher = Stitcher()
190/5: (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
190/6: from panorama import Stitcher
190/7:
import imutils
import cv2
import numpy as np
%matplotlib inline
190/8:
imageA = cv2.imread('IMG_9144.jpg')
imageB = cv2.imread('IMG_9145.jpg')
imageA = imutils.resize(imageA, width=400)
imageB = imutils.resize(imageB, width=400)
h,w = imageA.shape[:2]
190/9: stitcher = Stitcher()
190/10: (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
190/11:
print im.shape
plt.imshow(imageA)

#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/12:
#print im.shape
plt.imshow(imageA)

#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/13:
import imutils
import cv2
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
190/14:
imageA = cv2.imread('IMG_9144.jpg')
imageB = cv2.imread('IMG_9145.jpg')
imageA = imutils.resize(imageA, width=400)
imageB = imutils.resize(imageB, width=400)
h,w = imageA.shape[:2]
190/15: stitcher = Stitcher()
190/16: (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
190/17:
#print im.shape
plt.imshow(imageA)

#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/18:
#print im.shape
plt.imshow(imageA,'color')

#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/19:
#print im.shape
plt.imshow(imageA,cmap = 'color')

#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/20:
#print im.shape
plt.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB),cmap = 'color')

#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/21:
#print im.shape
plt.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB))

#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/22:
#print im.shape
f,(ax1,ax2) = plt.subplots(1,2)
ax1.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB))
ax2.imshow(cv2.cvtColor(imageB,cv2.COLOR_BGR2RGB))
#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/23:
#print im.shape
f,(ax1,ax2) = plt.subplots(1,2,figsize=(4,3))
ax1.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB))
ax2.imshow(cv2.cvtColor(imageB,cv2.COLOR_BGR2RGB))
#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/24:
#print im.shape
f,(ax1,ax2) = plt.subplots(1,2,figsize=(8,6))
ax1.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB))
ax2.imshow(cv2.cvtColor(imageB,cv2.COLOR_BGR2RGB))
#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/25:
#print im.shape
f,(ax1,ax2) = plt.subplots(1,2,figsize=(16,12))
ax1.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB))
ax2.imshow(cv2.cvtColor(imageB,cv2.COLOR_BGR2RGB))
#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/26:
#print im.shape
f,(ax1,ax2) = plt.subplots(1,2,figsize=(16,12))
ax1.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB))
ax2.imshow(cv2.cvtColor(imageB,cv2.COLOR_BGR2RGB))
plt.imshow(cv2.cvtColor(result,cv2.COLOR_BGR2RGB))
#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/27:
#print im.shape
f,(ax1,ax2) = plt.subplots(1,2,figsize=(16,12))
ax1.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB))
ax2.imshow(cv2.cvtColor(imageB,cv2.COLOR_BGR2RGB))
#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/28: plt.imshow(cv2.cvtColor(result,cv2.COLOR_BGR2RGB))
190/29: plt.imshow(cv2.cvtColor(vis,cv2.COLOR_BGR2RGB),figsize=(32,24))
190/30:
plt.figure(figsize=(32,24))
plt.imshow(cv2.cvtColor(vis,cv2.COLOR_BGR2RGB)
190/31:
plt.figure(figsize=(32,24))
plt.imshow(cv2.cvtColor(vis,cv2.COLOR_BGR2RGB))
190/32:
plt.figure(figsize(32,24))
plt.imshow(cv2.cvtColor(result,cv2.COLOR_BGR2RGB))
190/33:
plt.figure(figsize=(32,24))
plt.imshow(cv2.cvtColor(result,cv2.COLOR_BGR2RGB))
190/34:
imageB = cv2.imread('IMG_9144.jpg')
imageA = cv2.imread('IMG_9145.jpg')
imageA = imutils.resize(imageA, width=400)
imageB = imutils.resize(imageB, width=400)
h,w = imageA.shape[:2]
190/35: stitcher = Stitcher()
190/36: (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
190/37:
#print im.shape
f,(ax1,ax2) = plt.subplots(1,2,figsize=(16,12))
ax1.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB))
ax2.imshow(cv2.cvtColor(imageB,cv2.COLOR_BGR2RGB))
#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/38:
plt.figure(figsize=(32,24))
plt.imshow(cv2.cvtColor(vis,cv2.COLOR_BGR2RGB))
190/39:
plt.figure(figsize=(32,24))
plt.imshow(cv2.cvtColor(result,cv2.COLOR_BGR2RGB))
190/40:
imageB = cv2.imread('IMG_9144.jpg')
imageA = cv2.imread('IMG_9145.jpg')
imageA = imutils.resize(imageA, width=2000)
imageB = imutils.resize(imageB, width=2000)
h,w = imageA.shape[:2]
190/41: stitcher = Stitcher()
190/42: (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
190/43:
#print im.shape
f,(ax1,ax2) = plt.subplots(1,2,figsize=(16,12))
ax1.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB))
ax2.imshow(cv2.cvtColor(imageB,cv2.COLOR_BGR2RGB))
#cv2.imshow("Image A", imageA)
#cv2.imshow("Image B", imageB)
#cv2.imshow("Keypoint Matches", vis)
#cv2.imshow("Result", result)
#cv2.waitKey(0)
190/44:
plt.figure(figsize=(32,24))
plt.imshow(cv2.cvtColor(vis,cv2.COLOR_BGR2RGB))
190/45:
plt.figure(figsize=(32,24))
plt.imshow(cv2.cvtColor(result,cv2.COLOR_BGR2RGB))
191/1: import os
191/2: pwd
191/3: cd ~/Dropbox/matlabdesktopstudies/stitch/
191/4: import os
191/5: import path
191/6: ls 2017-09-14T17-25/
190/46:
import glob
f = glob.glob('2017-09-14T17-25/*.jpg')
190/47: print(f[0])
190/48:
istart = 36
iend = 81
interval = 1

ii = range(istart,iend,interval)
190/49:
istart = 36
iend = 81
interval = 1

ii = range(istart,iend,interval)
print(ii)
192/1: import path
192/2: import glob
192/3: f = glob.glob('2017-09-14T17-25/*.jpg')
192/4: istart = 36
192/5: print(path.Path.basename(f[istart]))
192/6: p = Path(f[36])
192/7: p = path.Path(f[36])
192/8: p.basename()
192/9: print(p.basename())
192/10: import os
192/11: p.join('abc.jpg')
192/12: print p
192/13: pp = path.Path('2017-09-14T17-25/')
192/14: pp.join('abc.jpg')
192/15: print(pp)
192/16: ppp = path.Path('abc,jpg')
192/17: pp.join(ppp)
192/18: print(pp.join(ppp))
192/19: print(pp)
192/20: os.path.join(pp,'abc')
192/21: print(os.path.join(pp,'abc'))
192/22: os.path.basename('2017-09-14T17-25/2.jpg')
192/23: import cv2
192/24: cv2.imwrite?
190/50:
import glob
import path
import os
f = glob.glob('2017-09-14T17-25/*.jpg')
190/51:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
istart = 36
#iend = 81
iend = 38
interval = 1
stitcher = Stitcher()

results_dir = 'results_'+ str(interval)
os.mkdir(results_dir)
results_path = path.Path(results_dir)


for image_index in range(istart,iend,interval):
    
    Limg_name = os.path.basename(f[image_idx])
    Rimg_name = os.path.basename(f[image_idx + 1])
    result_filename = os.path.join('results' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')
    vis_filename = os.path.join('vis' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')


    
    imageA = cv2.imread(f[image_index])
    imageB = cv2.imread(f[image_index])
    (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
    
    cv2.imwrite(result_filename,result)
    cv2.imwrite(vis_filename,vis)
190/52:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
#iend = 81
iend = 38
interval = 1
stitcher = Stitcher()

results_dir = 'results_'+ str(interval)
os.mkdir(results_dir)
results_path = path.Path(results_dir)


for image_index in range(istart,iend,interval):
    
    Limg_name = os.path.basename(f[image_index])
    Rimg_name = os.path.basename(f[image_index + 1])
    result_filename = os.path.join('results' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')
    vis_filename = os.path.join('vis' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')


    
    imageA = cv2.imread(f[image_index])
    imageB = cv2.imread(f[image_index])
    (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
    
    cv2.imwrite(result_filename,result)
    cv2.imwrite(vis_filename,vis)
190/53:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
#iend = 81
iend = 38
interval = 1
stitcher = Stitcher()

try:
    results_dir = 'results_'+ str(interval)
except:
    pass

os.mkdir(results_dir)
results_path = path.Path(results_dir)


for image_index in range(istart,iend,interval):
    
    Limg_name = os.path.basename(f[image_index])
    Rimg_name = os.path.basename(f[image_index + 1])
    result_filename = os.path.join('results' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')
    vis_filename = os.path.join('vis' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')


    
    imageA = cv2.imread(f[image_index])
    imageB = cv2.imread(f[image_index])
    (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
    
    cv2.imwrite(result_filename,result)
    cv2.imwrite(vis_filename,vis)
190/54:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
#iend = 81
iend = 38
interval = 1
stitcher = Stitcher()

results_dir = 'results_'+ str(interval)
try:
    os.mkdir(results_dir)
except:
    pass

results_path = path.Path(results_dir)


for image_index in range(istart,iend,interval):
    
    Limg_name = os.path.basename(f[image_index])
    Rimg_name = os.path.basename(f[image_index + 1])
    result_filename = os.path.join('results' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')
    vis_filename = os.path.join('vis' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')


    
    imageA = cv2.imread(f[image_index])
    imageB = cv2.imread(f[image_index])
    (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
    
    cv2.imwrite(result_filename,result)
    cv2.imwrite(vis_filename,vis)
190/55:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
#iend = 81
iend = 38
interval = 1
stitcher = Stitcher()

results_dir = 'results_'+ str(interval)
try:
    os.mkdir(results_dir)
except:
    pass

results_path = path.Path(results_dir)


for image_index in range(istart,iend,interval):
    
    Limg_name = os.path.basename(f[image_index])
    Rimg_name = os.path.basename(f[image_index + 1])
    result_filename = os.path.join('results' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')
    vis_filename = os.path.join('vis' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')

    print('Left image: ' + Limg_name)
    print('Right image: ' + Rimg_name)
    print('Result image: ' + result_filename)
    print('Vis image: ' + vis_filename)
    print('got here.')
    #imageA = cv2.imread(f[image_index])
    #imageB = cv2.imread(f[image_index])
    #(result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
    
    #cv2.imwrite(result_filename,result)
    #cv2.imwrite(vis_filename,vis)
190/56:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
#iend = 81
iend = 38
interval = 1
stitcher = Stitcher()

results_dir = 'results_'+ str(interval)
try:
    os.mkdir(results_dir)
except:
    pass

results_path = path.Path(results_dir)


for image_index in range(istart,iend,interval):
    
    Limg_name = os.path.basename(f[image_index])
    Rimg_name = os.path.basename(f[image_index + 1])
    result_filename = os.path.join('results' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')
    vis_filename = os.path.join('vis' + '_' + 
                                   results_path,Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')

    print('Left image: ' + Limg_name)
    print('Right image: ' + Rimg_name)
    print('Result image: ' + result_filename)
    print('Vis image: ' + vis_filename)
    print('got here.')
    #imageA = cv2.imread(f[image_index])
    #imageB = cv2.imread(f[image_index])
    #(result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
    
    #cv2.imwrite(result_filename,result)
    #cv2.imwrite(vis_filename,vis)
190/57:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
#iend = 81
iend = 38
interval = 1
stitcher = Stitcher()

results_dir = 'results_'+ str(interval)
try:
    os.mkdir(results_dir)
except:
    pass

results_path = path.Path(results_dir)


for image_index in range(istart,iend,interval):
    
    Limg_name = os.path.basename(f[image_index])
    Rimg_name = os.path.basename(f[image_index + 1])
    result_filename = os.path.join(results_path,'results_' + 
                                   Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')
    vis_filename = os.path.join(results_path,'vis_' + Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + str(interval) 
                                   + '.jpg')

    print('Left image: ' + Limg_name)
    print('Right image: ' + Rimg_name)
    print('Result image: ' + result_filename)
    print('Vis image: ' + vis_filename)
    print('got here.')
    #imageA = cv2.imread(f[image_index])
    #imageB = cv2.imread(f[image_index])
    #(result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
    
    #cv2.imwrite(result_filename,result)
    #cv2.imwrite(vis_filename,vis)
190/58:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
#iend = 81
iend = 38
interval = 1
stitcher = Stitcher()

results_dir = 'results_'+ str(interval)
try:
    os.mkdir(results_dir)
except:
    pass

results_path = path.Path(results_dir)


for image_index in range(istart,iend,interval):
    
    Limg_name = os.path.basename(f[image_index])
    Rimg_name = os.path.basename(f[image_index + 1])
    result_filename = os.path.join(results_path,'results_' + 
                                   Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + 'INT_' + str(interval) 
                                   + '.jpg')
    vis_filename = os.path.join(results_path,'vis_' + Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + 'INT_' + str(interval) 
                                   + '.jpg')

    print('Left image: ' + Limg_name)
    print('Right image: ' + Rimg_name)
    print('Result image: ' + result_filename)
    print('Vis image: ' + vis_filename)
    print('got here.')
    #imageA = cv2.imread(f[image_index])
    #imageB = cv2.imread(f[image_index])
    #(result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
    
    #cv2.imwrite(result_filename,result)
    #cv2.imwrite(vis_filename,vis)
190/59:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
#iend = 81
iend = 38
interval = 1
stitcher = Stitcher()

results_dir = 'results_'+ str(interval)
try:
    os.mkdir(results_dir)
except:
    pass

results_path = path.Path(results_dir)


for image_index in range(istart,iend,interval):
    
    Limg_name = os.path.basename(f[image_index])
    Rimg_name = os.path.basename(f[image_index + 1])
    result_filename = os.path.join(results_path,'results_' + 
                                   Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + 'INT_' + str(interval) 
                                   + '.jpg')
    vis_filename = os.path.join(results_path,'vis_' + Limg_name + '_' 
                                   + Rimg_name + '_' 
                                   + 'INT_' + str(interval) 
                                   + '.jpg')

    print('Left image: ' + Limg_name)
    print('Right image: ' + Rimg_name)
    print('Result image: ' + result_filename)
    print('Vis image: ' + vis_filename)
    
    imageA = cv2.imread(f[image_index])
    imageB = cv2.imread(f[image_index])
    (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)
    
    cv2.imwrite(result_filename,result)
    cv2.imwrite(vis_filename,vis)
192/25: print(range(10))
192/26: print((range(10)+1))
192/27: import numpy as np
192/28: print(np.arange(10))
192/29: print(np.arange(10)+1))
192/30: print((np.arange(10)+1))
190/60:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
iend = 81
#iend = 38
interval = 1
stitcher = Stitcher()

for interval in (np.arange(10) + 1)
    results_dir = 'results_'+ str(interval)
    try:
        os.mkdir(results_dir)
    except:
        pass

    results_path = path.Path(results_dir)


    for image_index in range(istart,iend,interval):

        Limg_name = os.path.basename(f[image_index])
        Rimg_name = os.path.basename(f[image_index + 1])
        result_filename = os.path.join(results_path,'results_' + 
                                       Limg_name + '_' 
                                       + Rimg_name + '_' 
                                       + 'INT_' + str(interval) 
                                       + '.jpg')
        vis_filename = os.path.join(results_path,'vis_' + Limg_name + '_' 
                                       + Rimg_name + '_' 
                                       + 'INT_' + str(interval) 
                                       + '.jpg')

        print('Left image: ' + Limg_name)
        print('Right image: ' + Rimg_name)
        print('Result image: ' + result_filename)
        print('Vis image: ' + vis_filename)

        imageA = cv2.imread(f[image_index])
        imageB = cv2.imread(f[image_index])
        (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)

        cv2.imwrite(result_filename,result)
        cv2.imwrite(vis_filename,vis)
190/61:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
iend = 81
#iend = 38
interval = 1
stitcher = Stitcher()

for interval in (np.arange(10) + 1):
    results_dir = 'results_'+ str(interval)
    try:
        os.mkdir(results_dir)
    except:
        pass

    results_path = path.Path(results_dir)


    for image_index in range(istart,iend,interval):

        Limg_name = os.path.basename(f[image_index])
        Rimg_name = os.path.basename(f[image_index + 1])
        result_filename = os.path.join(results_path,'results_' + 
                                       Limg_name + '_' 
                                       + Rimg_name + '_' 
                                       + 'INT_' + str(interval) 
                                       + '.jpg')
        vis_filename = os.path.join(results_path,'vis_' + Limg_name + '_' 
                                       + Rimg_name + '_' 
                                       + 'INT_' + str(interval) 
                                       + '.jpg')

        print('Left image: ' + Limg_name)
        print('Right image: ' + Rimg_name)
        print('Result image: ' + result_filename)
        print('Vis image: ' + vis_filename)

        imageA = cv2.imread(f[image_index])
        imageB = cv2.imread(f[image_index])
        (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)

        cv2.imwrite(result_filename,result)
        cv2.imwrite(vis_filename,vis)
190/62:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
iend = 81
#iend = 38
interval = 1
stitcher = Stitcher()

for interval in (np.arange(10) + 1):
    results_dir = 'results_'+ str(interval)
    try:
        os.mkdir(results_dir)
    except:
        pass

    results_path = path.Path(results_dir)


    for image_index in range(istart,iend,interval):

        Limg_name = os.path.basename(f[image_index])
        Rimg_name = os.path.basename(f[image_index + interval])
        result_filename = os.path.join(results_path,'results_' + 
                                       Limg_name + '_' 
                                       + Rimg_name + '_' 
                                       + 'INT_' + str(interval) 
                                       + '.jpg')
        vis_filename = os.path.join(results_path,'vis_' + Limg_name + '_' 
                                       + Rimg_name + '_' 
                                       + 'INT_' + str(interval) 
                                       + '.jpg')

        print('Left image: ' + Limg_name)
        print('Right image: ' + Rimg_name)
        print('Result image: ' + result_filename)
        print('Vis image: ' + vis_filename)

        imageA = cv2.imread(f[image_index])
        imageB = cv2.imread(f[image_index])
        (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)

        cv2.imwrite(result_filename,result)
        cv2.imwrite(vis_filename,vis)
192/31: print((np.arange(10,2)+1))
192/32: np.arange?
190/63:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
iend = 100
#iend = 38
interval = 1
stitcher = Stitcher()

for interval in (np.arange(1,30,5)):
    results_dir = 'results_'+ str(interval)
    try:
        os.mkdir(results_dir)
    except:
        pass

    results_path = path.Path(results_dir)


    for image_index in range(istart,iend,interval):

        Limg_name = os.path.basename(f[image_index])
        Rimg_name = os.path.basename(f[image_index + interval])
        result_filename = os.path.join(results_path,'results_' + 
                                       Limg_name + '_' 
                                       + Rimg_name + '_' 
                                       + 'INT_' + str(interval) 
                                       + '.jpg')
        vis_filename = os.path.join(results_path,'vis_' + Limg_name + '_' 
                                       + Rimg_name + '_' 
                                       + 'INT_' + str(interval) 
                                       + '.jpg')

        print('Left image: ' + Limg_name)
        print('Right image: ' + Rimg_name)
        print('Result image: ' + result_filename)
        print('Vis image: ' + vis_filename)

        imageA = cv2.imread(f[image_index])
        imageB = cv2.imread(f[image_index])
        (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)

        cv2.imwrite(result_filename,result)
        cv2.imwrite(vis_filename,vis)
190/64:
# Pick a subset of images in which the boat's heading is changing rapidly. 
# This particular subset contains the RVGS in close proximity. (good and bad)
# Loop through them taking successive images to stitch. Then do the same at greater intervals.
istart = 36
iend = 100
#iend = 38
interval = 1
stitcher = Stitcher()

for interval in (np.arange(1,30,2)):
    results_dir = 'results_'+ str(interval)
    try:
        os.mkdir(results_dir)
    except:
        pass

    results_path = path.Path(results_dir)


    for image_index in range(istart,iend,interval):

        Limg_name = os.path.basename(f[image_index])
        Rimg_name = os.path.basename(f[image_index + interval])
        result_filename = os.path.join(results_path,'results_' + 
                                       Limg_name + '_' 
                                       + Rimg_name + '_' 
                                       + 'INT_' + str(interval) 
                                       + '.jpg')
        vis_filename = os.path.join(results_path,'vis_' + Limg_name + '_' 
                                       + Rimg_name + '_' 
                                       + 'INT_' + str(interval) 
                                       + '.jpg')

        print('Left image: ' + Limg_name)
        print('Right image: ' + Rimg_name)
        print('Result image: ' + result_filename)
        print('Vis image: ' + vis_filename)

        imageA = cv2.imread(f[image_index])
        imageB = cv2.imread(f[image_index+interval])
        (result, vis) = stitcher.stitch([imageA, imageB], showMatches=True)

        cv2.imwrite(result_filename,result)
        cv2.imwrite(vis_filename,vis)
188/1: import cv2
188/2: ls
188/3: cd ~/Dropbox/matlabdesktopstudies/stitch/
188/4: ls
188/5: cd 2017-09-14T17-25/
188/6: lss
188/7: ls
188/8: imageA = cv2.imread('1505409911.046.jpg')
188/9: imageB = cv2.imread('1505409913.947.jpg')
188/10: import matplotlib.pyplot as pt
188/11: pt.figure()
188/12: f = pt.figure()
188/13: pt.imshow(imageA)
188/14: pt.imshow(cv2.cvtColor(imageA,cv2.COLOR_BGR2RGB))
188/15: pt.imshow(cv2.cvtColor(imageB,cv2.COLOR_BGR2RGB))
188/16: (kpsA, featuresA) = self.detectAndDescribe(imageA)
188/17: grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)
188/18: pt.imshow(grayA)
188/19: descriptor = cv2.xfeatures2d.SIFT_create()
188/20: [kps, features] = descriptor.detectAndCompute(image, None)
188/21: [kps, features] = descriptor.detectAndCompute(imageA, None)
188/22: whos
188/23: features
188/24: import matplotlib.pyplot as plt
188/25: fig, ax = plt.subplots()
188/26: ax.imshow(imageA)
188/27: ax.plot(features,'go')
188/28: plt.show()
188/29: plt.plot(features,'g')
188/30: plt.plot(features[:0],'g')
188/31: plt.plot(features[:0],features[:1],'g')
188/32: features.size()
188/33: features.__len__()
188/34: features.size()
188/35: who
188/36: whos
188/37: kps = np.float32([kp.pt for kp in kps])
188/38: import numpy as np
188/39: kps = np.float32([kp.pt for kp in kps])
188/40: plt.plot(kps,'g')
188/41: plt.plot(kps,'g.')
188/42: ax = plt.imshow(imageA)
188/43: plt.plot(kps,'g.')
188/44: plt.show()
193/1: import numpy as np
193/2: np.nonzero?
194/1: import hyo.soundspeed
194/2: ls hyo
194/3: import hyo
194/4: import hyo.soundspeed
195/1: ls
195/2: import hyo.soundspeed.atlas
195/3: import hyo.soundspeed.atlas.woa09 as w
195/4: w?
195/5: import hyo.soundspeed.atlas.woa09.woa09 as w
197/1: import shapefile
198/1: import geopandas as gp
198/2: gs = gp.read_file('depth.shp')
198/3: gs.head()
198/4: gs.plot()
199/1: import geopandas as gpd
199/2: gpd.read_file('depth.shp')
199/3: ds = gpd.read_file('depth.shp')
199/4:
%matplotlib inline
import geopandas as gpd
199/5: ds = gpd.read_file('depth.shp')
199/6: ds.plot()
199/7:
%matplotlib nbagg
import geopandas as gpd
199/8: ds = gpd.read_file('depth.shp')
199/9: ds.plot()
200/1:
%matplotlib nbagg
import geopandas as gpd
200/2: ds = gpd.read_file('depth.shp')
200/3: ds.plot()
200/4: ds.head()
200/5: depth = ds.depth
200/6: depth = ds.depth()
200/7: depth = ds.as_matrix()
200/8: print(depth)
200/9: depth = ds.Depth()
200/10: depth = ds.Depth
200/11: print(depth)
200/12: gpd.geopandas()
200/13: gpd.geopandas?
200/14: whos
200/15: depth.plot()
200/16: depth.plot()
200/17:
%matplotlib nbagg
import geopandas as gpd
200/18: ds = gpd.read_file('depth.shp')
200/19: ds.plot()
200/20: ds.head()
200/21: depth = ds.Depth()
200/22: depth.plot()
200/23: depth = ds.Depth
200/24: depth.plot()
200/25: ds.Depth.plot()
200/26:
%matplotlib nbagg
import geopandas as gpd
201/1:
%matplotlib nbagg
import geopandas as gpd
201/2: ds = gpd.read_file('depth.shp')
201/3: ds.plot()
201/4: ds.head()
201/5: depth = ds.Depth
201/6: ds.Depth.plot()
201/7:
%matplotlib nbagg
import matplotlib.pyplot as plt
import geopandas as gpd
201/8: ds = gpd.read_file('depth.shp')
201/9: ds.plot()
201/10: ds.head()
201/11: depth = ds.Depth
201/12: ds.Depth.plot()
201/13: ds.Depth.as_matrix()
201/14: plt.plot(ds.Depth.as_matrix(),'.')
201/15:
plt.plot(ds.Depth.as_matrix(),'.')
plt.show()
201/16:
plt.figure()
plt.plot(ds.Depth.as_matrix(),'.')
plt.show()
201/17: ds.plot()
201/18:
for d in ds:
    print d.Depth
201/19: d = ds[0]
201/20: d = ds.Depth[0]
201/21: print(d)
201/22: ds.head()
201/23: p = ds.geometry[0]
201/24: print(p)
201/25: p.plot()
201/26: gpd.GeoSeries = p
201/27: pg = gpd.GeoSeries = p
201/28: pg.plot()
201/29: pg = gpd.GeoSeries(p)
201/30:
%matplotlib nbagg
import matplotlib.pyplot as plt
import geopandas as gpd
201/31: ds = gpd.read_file('depth.shp')
201/32: ds.plot()
201/33: depth = ds.Depth
201/34:
%matplotlib nbagg
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon
from matplotlib.collections import PatchCollection
import geopandas as gpd
201/35: ds.length()
201/36: ds.length
201/37: whos ds
201/38: ds = gpd.read_file('depth.shp')
201/39: ds.plot()
201/40:
for item in ds:
    print item
201/41:
for Depth, Geometry in ds:
    print Geometry
201/42: ds.len()
201/43: len(ds)
201/44:
for geom in ds:
    print geom.type
201/45: whos
201/46: ds.plot(column="Depth")
201/47: ds.plot(column="Depth",legend=True)
203/1: import gdal as G
203/2: from osgeo omport ogr
203/3: from osgeo import ogr
203/4: pt = ogr.Geometry(ogr.wkbPoint)
203/5: pt.AddPoint(0,0,0)
203/6: pt.AddPoint(10,10,10)
203/7: pt.AddPoint(20,0,0)
203/8: print pt.ExportToWkkt()
203/9: print(pt.ExportToWkt())
203/10: pt = ogr.Geometry(ogr.wkbMultiPoint)
203/11: pt.AddPoint(0,0,0)
203/12: mp = ogr.Geometry(ogr.wkbMultiPoint)
203/13: pt = ogr.Geometry(ogr.wkbPoint)
203/14: pt.AddPoint(0,0,0)
203/15: mp.AddGeometry(pt)
203/16: pt.AddPoint(10,10,10)
203/17: mp.AddGeometry(pt)
203/18: pt.AddPoint(20,0,0)
203/19: mp.AddGeometry(pt)
203/20: print(mp.ExportToWkt())
203/21: ds2 = G.Grid?
203/22: ds2 = G.Grid?
203/23: !ls
203/24: G.Grid('test2.tiff','test.vrt',layers='test',algorithm='linear:radius=0.0')
203/25: G.Grid('test2.tiff','test.vrt',layers='test',algorithm='linear:radius=0.0')
203/26: G.Grid('test2.tiff','test.vrt',layers='test',algorithm='linear:radius=0.0')
203/27: G.Grid('test2.tiff','test.vrt',layers='test',algorithm='linear:radius=0.0')
203/28: mp
203/29: print(mp)
203/30: mp.ExportToWkb?
203/31: F = file('test.wkb')
203/32: F = file('test.wkb','w')
203/33: F.write(mp.ExportToWkb)
203/34: F.write?
203/35: F.close()
203/36: F = file('test.wkb','wbw')
203/37: F.write(mp.ExportToWkb)
203/38: F.write(mp.ExportToWkb.print())
203/39: wkb = mp.ExportToWkb()
203/40: F.write(wkb)
203/41: F.close()
203/42: G.Grid('test2.tiff','test.vrt',layers='test',algorithm='linear:radius=0.0')
203/43: G.Grid('test2.tiff','test2.vrt',layers='test',algorithm='linear:radius=0.0')
203/44: G.Grid('test2.tiff','test2.vrt',layers='test',algorithm='linear:radius=0.0')
205/1: pwd
205/2: cd ~/Projects/ASV/ASV/fieldstudies/SilviusRadioTesting/Silvus/BWmonitor/
205/3: ls
205/4: ls
205/5: import BWmonitor
205/6: B = BWmonitor.BWmonitor()
205/7: B.readDataDir('.')
205/8: reload(BWmonitor)
205/9: B = BWmonitor.BWmonitor()
205/10: B.readDataDir('.')
205/11: reload(BWmonitor)
205/12: B = BWmonitor.BWmonitor()
205/13: B.readDataDir('.')
205/14: reload(BWmonitor)
205/15: B = BWmonitor.BWmonitor()
205/16: B.readDataDir('.')
205/17: reload(BWmonitor)
205/18: B = BWmonitor.BWmonitor()
205/19: B.readDataDir('.')
205/20: import os
205/21: os.path.join('/test','test2')
205/22: os.path.join('/test','*.json')
205/23: import glob
205/24: glob.glob('*.json')
205/25: glob.glob('./*.json')
205/26: glob.glob(os.path.join('./','*.json'))
205/27: B.readDataDir('./')
205/28: directory='./'
205/29: glob.glob(os.path.join("./",'*.json'))
205/30: B.readDataDir("./")
205/31: reload(BWmonitor)
205/32: B = BWmonitor.BWmonitor()
205/33: B.readDataDir("./")
205/34: reload(BWmonitor)
205/35: B = BWmonitor.BWmonitor()
205/36: B.readDataDir("./")
205/37: reload(BWmonitor)
205/38: B = BWmonitor.BWmonitor()
205/39: B.readDataDir("./")
205/40: B.readDataDir("./")
205/41: reload(BWmonitor)
205/42: B.readDataDir("./")
205/43: whos
205/44: reload(BWmonitor)
205/45: B = BWmonitor.BWmonitor()
205/46: B.readDataDir("./")
205/47: reload(BWmonitor)
205/48: B = BWmonitor.BWmonitor()
205/49: B.readDataDir("./")
205/50: reload(BWmonitor)
205/51: B = BWmonitor.BWmonitor()
205/52: B.readDataDir("./")
205/53: reload(BWmonitor)
205/54: B = BWmonitor.BWmonitor()
205/55: B.readDataDir("./")
205/56: reload(BWmonitor)
205/57: B = BWmonitor.BWmonitor()
205/58: B.readDataDir("./")
205/59: B
205/60: B.parseddata.plot()
205/61: B.parseddata
205/62: B.parseddata.keys()
205/63: B.parseddata.set_index('Time')
205/64: B.parseddata.plot()
205/65: B.parseddata.to_timestamp?
205/66: print(B.parseddata)
205/67: B.parseddata.set_index('Time')
205/68: print(B.parseddata)
205/69: B.parseddata
205/70: B.parseddata.set_index('Time',inplace=True)
205/71: B.plot()
205/72: B.parseddata.plot()
205/73: B.parsedata
205/74: B.parseddata
205/75: B.parseddata.shift(-1)
205/76: B.parseddata
205/77: B.parseddata.shift(-1)
205/78: B.parseddata.shift(-1,inplace=True)
205/79: B.parseddata[:-1]
205/80: B.parseddata
205/81: B.parseddata[:-1]
205/82: import datetime
205/83: B.parseddata.append((datetime.datetime.now(),1,2))
205/84: B.parseddata.append?
205/85: import pandas as pd
205/86: B.parseddata[datetime.datetime.now()] = [1,2]
205/87: B.parseddata[pd.Timestamp(datetime.datetime.now())] = [1,2]
205/88: B.parseddata[pd.Timestamp(datetime.datetime.now())] = [0, 1,2]
205/89: B.parseddata
205/90: B.parseddata["2018-02-22 20:04:20+00:00"]
205/91: B.parseddata[pd.Timestamp(datetime.datetime.isoformat())] = [0, 1,2]
205/92: B.parseddata[pd.Timestamp(datetime.datetime.now().isoformat())] = [0, 1,2]
205/93: ts = pd.to_datetime(datetime.datetime.now())
205/94: newrow = pd.DataFrame([1,2],index=[ts])
205/95: newrow = pd.DataFrame([1;2],index=[ts])
205/96: newrow = pd.DataFrame([[1 2]],index=[ts])
205/97: newrow = pd.DataFrame([[1] [2]],index=[ts])
205/98: B.parseddata.keys()
205/99: newrow = pd.DataFrame([1,2],columnes=["MBytes/s Received", 'MBytes/s Sent'], index=[ts])
205/100: newrow = pd.DataFrame([1,2],columns=["MBytes/s Received", 'MBytes/s Sent'], index=[ts])
205/101: ts
205/102: B.parseddata.loc[ts]=[1,2]
205/103: B.parsedata
205/104: B.parseddata
205/105: B.parseddata.loc[datetime.datetime.now()]=[1,2]
205/106: B.parseddata
205/107: B.parseddata = B.parseddata[:-1,:]
205/108: B.parseddata.index.min()
205/109: import pytz
205/110: a = pytz.utc()
205/111: a = pytz.utc
205/112: a
205/113: B.parseddata.tz_localize(pytz.utc)
205/114: B.parseddata
205/115: reload(BWmonitor)
205/116: reload(BWmonitor)
205/117: reload(BWmonitor)
205/118: reload(BWmonitor)
205/119: B = BWmonitor.BWmonitor()
205/120: B.readDataDir("./")
205/121: B.readDataDir("./")
205/122: reload(BWmonitor)
205/123: B = BWmonitor.BWmonitor()
205/124: B.readDataDir("./")
205/125: reload(BWmonitor)
205/126: B = BWmonitor.BWmonitor()
205/127: B.readDataDir("./")
205/128: reload(BWmonitor)
205/129: B = BWmonitor.BWmonitor()
205/130: B.readDataDir("./")
205/131: reload(BWmonitor)
205/132: B = BWmonitor.BWmonitor()
205/133: B.readDataDir("./")
205/134: reload(BWmonitor)
205/135: reload(BWmonitor)
205/136: B.readDataDir("./")
205/137: B = BWmonitor.BWmonitor()
205/138: B.readDataDir("./")
205/139: B.readDataDir("./")
205/140: reload(BWmonitor)
205/141: B = BWmonitor.BWmonitor()
205/142: B.readDataDir("./")
205/143: reload(BWmonitor)
205/144: B = BWmonitor.BWmonitor()
205/145: B.readDataDir("./")
205/146: B.parseddata.plot()
205/147: import geopandas as geop
205/148: gdf = B.parseddata.copy()
205/149: ship = pd.read_table?
205/150: ship = pd.read_table
205/151: ship = pd.read_table('../POSMV/Silvius.002_parsed_GGA.txt')
205/152: ship.head()
205/153: dt = pd.to_datetime(ship[:,0:5])
205/154: ship[:,0:5]
205/155: ship.head()
205/156: ship[:,[1]]
205/157: ship.columns
205/158: ship.columns=['year','montth','day','hour','minute','second','lat','lon','type','sats','hdop','height','nan']
205/159: ship.rename(columns=['year','montth','day','hour','minute','second','lat','lon','type','sats','hdop','height','nan'],inplace=True)
205/160: ship = pd.read_table('../POSMV/Silvius.002_parsed_GGA.txt',columns = ['year','montth','day','hour','minute','second','lat','lon','type','sats','hdop','height','nan'])
205/161: ship = pd.read_table('../POSMV/Silvius.002_parsed_GGA.txt',names = ['year','montth','day','hour','minute','second','lat','lon','type','sats','hdop','height','nan'])
205/162: ship
205/163: ship.columns
205/164: ship.head()
205/165: ship = pd.read_table('../POSMV/Silvius.002_parsed_GGA.txt',names = ['year','month','day','hour','minute','second','lat','lon','type','sats','hdop','height','nan'])
205/166: ship['year']
205/167: ship = pd.read_table('../POSMV/Silvius.002_parsed_GGA.txt',names = ['unix','year','month','day','hour','minute','second','lat','lon','type','sats','hdop','height','nan'])
205/168: ship['year']
205/169: B.parseddata.to_csv('ParsedBW.csv')
205/170: ls
205/171: a = [datetime.datetime.now(),datetime.datetime.now(),datetime.datetime.now()]
205/172: a.isoformat()
205/173: help zip
205/174: zip?
205/175: datetime.datetime.now().toordinal()
205/176: datetime.datetime.now().timestamp()
205/177: dd = datetime.datetime.now()
205/178: import time
205/179: reload(BWmonitor)
205/180: B.parseddata.to_csv('ParsedBW.csv')
205/181: B.readDataDir("./")
205/182: reload(BWmonitor)
205/183: B.parseddata.to_csv('ParsedBW.csv')
205/184: B.readDataDir("./")
205/185: reload(BWmonitor)
205/186: B.parseddata.to_csv('ParsedBW.csv')
205/187: B = BWmonitor.BWmonitor()
205/188: B.readDataDir("./")
205/189: reload(BWmonitor)
205/190: B = BWmonitor.BWmonitor()
205/191: B.readDataDir("./")
205/192: B.parseddata
205/193: reload(BWmonitor)
205/194: B = BWmonitor.BWmonitor()
205/195: B.readDataDir("./")
206/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
%pylab inline
206/2: rvgs = pd.Series.from_csv('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
206/3: rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
206/4: rvgs_dates = pd.Timestamp(rvgs[:,:6])
206/5: rvgs.head()
206/6: rvgs[0:3,:]
206/7: rvgs[0:3,0:6]
206/8: pd.to_datetime(rvgs[0:3,0:6])
206/9:
pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
206/10:
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
206/11: rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
206/12: rvgsdf.head()
206/13: rvgsS = pd.Series(rvgs[:,6:],index=dates)
206/14: rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
206/15: galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
206/16:
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
206/17: dates.head()
206/18: galendf = pd.DataFrame(galen[:,6:],index=dates)
206/19: galendf.head()
206/20: bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
206/21: bw.head()
206/22: dates = pd.to_datetime(bw.unixtime,'s')
206/23: dates = pd.to_datetime(bw.Unixtime,'s')
206/24:
bw.head()
#dates = pd.to_datetime(bw.Unixtime,'s')
206/25:
#bw.head()
dates = pd.to_datetime(bw['Unixtime'],'s')
206/26:
#bw.head()
dates = pd.to_datetime(bw['Unixtime'],unit='s')
206/27: dates.head()
206/28: bw.set_index(dates,inplace=True)
206/29: bw.head()
206/30:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw.head()
206/31: rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
206/32:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.head()
206/33:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.head()
206/34: data = pd.concat([rvgsdf galendf bw rvgs_rssi galen_rssi])
206/35: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
206/36: data.head()
206/37: data.interpolate(method='linear',inplace=True)
207/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
%pylab inline
207/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.head()
207/3:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.head()
207/4:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(index=str,columns={"0":"rvgs_lat","1":"rvgs_lon"})
rvgsdf.head()
207/5:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(index=str,columns={0:"rvgs_lat",1:"rvgs_lon"})
rvgsdf.head()
207/6:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"})
rvgsdf.head()
207/7:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={"0":"rvgs_lat","1":"rvgs_lon"})
rvgsdf.head()
207/8:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={"0":"rvgs_lat","1":"rvgs_lon"},inplace=True)
rvgsdf.head()
207/9:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgsdf.head()
207/10:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)


galendf.head()
207/11:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw.head()
207/12:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"})
rvgs_rssi.head()
207/13:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.head()
207/14:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.head()
207/15: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
207/16: data.head()
207/17: data.interpolate(method='linear',inplace=True)
207/18: data.head()
207/19: import geopandas as gpd
207/20: gdata = gpd.GeoDataFrame(data)
207/21: gdata
207/22: from shapely.geometry import asPoint
207/23: rvgs = asPoint?
207/24: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
207/25: data.head()
207/26: data.interpolate(method='linear',inplace=True)
207/27: data["galen_lat"]
207/28: rvgs = asPoint(data[["rvgs_lon","rvgs_lat"]])
207/29: rvgs
207/30: rvgs = map(asPoint, data[["rvgs_lon","rvgs_lat"])
207/31: rvgs = map(asPoint, data[["rvgs_lon","rvgs_lat"]])
207/32: rvgs
207/33: data[["rvgs_lon","rvgs_lat"]]
207/34: rvgs = [Point(xy) for xy in zip(data['rvgs_lon'],data['rvgs_lat'])]
207/35: from shapely.geometry import Point
207/36: rvgs = [Point(xy) for xy in zip(data['rvgs_lon'],data['rvgs_lat'])]
207/37: rvgs.head()
207/38: rvgs.count()
207/39: gdf_rvgs_nav = gpd.GeoDataFrame(rvgs,geometry=geometry)
207/40: gdf_rvgs_nav = gpd.GeoDataFrame(rvgs,geometry=rvgs)
207/41: gdf_rvgs_nav.plot()
207/42: gdf_rvgs_nav.plot(figsize=5,5)
207/43: gdf_rvgs_nav.plot(figsize=(5,5)
207/44: gdf_rvgs_nav.plot(figsize=(5,5))
207/45: gdf_rvgs_nav.plot(figsize=(10,10, grid=True))
207/46:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point
import matplotlib.pyplot as plt
%pylab inline
207/47:
gdf_rvgs_nav.plot(figsize=(10,10))
plt.grid(True)
207/48: gdf_rvgs_nav.crs
207/49: print(gdf_rvgs_nav.crs)
207/50: gdf_rvgs_nav.crs = {'init':'epsg4326'}
207/51:
gdf_rvgs_nav.plot(figsize=(10,10))
plt.grid(True)
207/52: gdf_rvgs_nav.crs = {"init":"+proj=utm +zone=33 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"}
207/53: gdf_rvgs_nav.plot(figsize=(10,10))
207/54: gdf_rvgs_nav.head()
207/55: gdf_rvgs_nav.to_crs = {"init":"+proj=utm +zone=33 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"}
207/56: gdf_rvgs_nav.plot(figsize=(10,10))
207/57: gdf_rvgs_nav.head()
207/58: gdf_rvgs_nav.to_crs = {"init":"+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"}
207/59: gdf_rvgs_nav.plot(figsize=(10,10))
207/60: gdf_rvgs_nav.head()
207/61: gdf_rvgs_nav.crs
207/62:
gdf_rvgs_nav = gpd.GeoDataFrame(rvgs,geometry=rvgs)
gdf_rvgs_nav.crs = {'init':'epsg4326'}
207/63: gdf_rvgs_nav.to_crs = {"init":"+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"}
207/64: gdf_rvgs_nav.crs
207/65: gdf_rvgs_nav = gdf_rvgs_nav.to_crs = {"init":"+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"}
207/66:
gdf_rvgs_nav = gpd.GeoDataFrame(rvgs,geometry=rvgs)
gdf_rvgs_nav.crs = {'init':'epsg4326'}
207/67: gdf_rvgs_nav = gdf_rvgs_nav.to_crs = {"init":"+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"}
207/68: whos
207/69:
gdf_rvgs_nav = gpd.GeoDataFrame(rvgsdf,geometry=rvgs)
gdf_rvgs_nav.crs = {'init':'epsg4326'}
207/70:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_pts = [Point(xy) for xy in zip(data['rvgs_lon'],data['rvgs_lat'])]
rvgs_gdf = gpd.GeoDataFrame(rvgsdf,geometry=rvgs_pts)
rvgs_gdf.crs = {'init':'epsg4326'}
rvgsdf.head()
207/71: length(rvgs_pts)
207/72: rvgs_pts.length()
207/73: rvgs_pts.length
207/74: whos
207/75:
data = {'name': ['a', 'b', 'c'],
        'lat': [45, 46, 47.5],
        'lon': [-120, -121.2, -122.9]}

df = pd.DataFrame(data)
207/76:
data = {'name': ['a', 'b', 'c'],
        'lat': [45, 46, 47.5],
        'lon': [-120, -121.2, -122.9]}

df = pd.DataFrame(data)
df
207/77:
data = {'name': ['a', 'b', 'c'],
        'lat': [45, 46, 47.5],
        'lon': [-120, -121.2, -122.9]}

df = pd.DataFrame(data)
df
geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]
gdf = GeoDataFrame(df, geometry=geometry)
207/78:
data = {'name': ['a', 'b', 'c'],
        'lat': [45, 46, 47.5],
        'lon': [-120, -121.2, -122.9]}

df = pd.DataFrame(data)
df
geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]
gdf = gpd.GeoDataFrame(df, geometry=geometry)
207/79:
data = {'name': ['a', 'b', 'c'],
        'lat': [45, 46, 47.5],
        'lon': [-120, -121.2, -122.9]}

df = pd.DataFrame(data)
df
geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]
gdf = gpd.GeoDataFrame(df, geometry=geometry)
gdf
207/80: rvgs_df
207/81: rvgsdf
207/82:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_pts = [Point(xy) for xy in zip(data['rvgs_lon'],data['rvgs_lat'])]
rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {'init':'epsg4326'}
rvgsdf.head()
207/83:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_pts = [Point(xy) for xy in zip(data["rvgs_lon"],data["rvgs_lat"])]
rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {"init":"epsg4326"}
rvgsdf.head()
207/84: rvgsdf
207/85:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)

rvgs_pts = [Point(xy) for xy in zip(data["rvgs_lon"],data["rvgs_lat"])]

rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {"init":"epsg4326"}
rvgsdf.head()
207/86:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)

rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]

rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {"init":"epsg4326"}
rvgsdf.head()
207/87: rvgsdf
207/88:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)

rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]

rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {"init":"epsg4326"}
rvgs_gdf.head()
207/89:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_pts = [Point(xy) for xy in zip(galendf["rvgs_lon"],galendf["rvgs_lat"])]

galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
galen_gdf.crs = {"init":"epsg4326"}
galen_gdf.head()


galendf.head()
207/90:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]

galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
galen_gdf.crs = {"init":"epsg4326"}
galen_gdf.head()


galendf.head()
207/91: galen_gdf.crs
207/92:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]

galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
galen_gdf.crs = {"init":"epsg:4326"}
galen_gdf.head()


galendf.head()
207/93: galen_gdf.crs
207/94: galen_gdf.to_crs({"init":"+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"})
207/95: galen_gdf.to_crs(+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
207/96: galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
207/97: d = galen_gdf.distance(rvgs_gdf)
207/98: d
207/99: d.plot()
207/100: rvgs_gdf[1]
207/101: rvgs_gdf[1,:]
207/102: rvgs_gdf.head()
207/103: nav = pd.concat([galen_gdf,rvgs_gdf])
207/104: nav.head()
207/105:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)

rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]

rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {"init":"epsg4326"}
rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

rvgs_gdf.head()
207/106:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)

rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]

rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {"init":"epsg4326"}
rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

rvgs_gdf.head()
208/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point
import matplotlib.pyplot as plt
%pylab inline
208/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)

rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]

rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {"init":"epsg4326"}
rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

rvgs_gdf.head()
208/3:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)

rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]

rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {"init":"epsg:4326"}
rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

rvgs_gdf.head()
208/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]

galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
galen_gdf.crs = {"init":"epsg:4326"}
galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
galen_gdf.head()


galendf.head()
208/5:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]

galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
galen_gdf.crs = {"init":"epsg:4326"}
galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
galen_gdf.head()
208/6: galen_gdf.crs
208/7:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]

galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
galen_gdf.crs = {"init":"epsg:4326"}
galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
galen_gdf.head()
208/8:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)

rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]

rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {"init":"epsg:4326"}
rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

rvgs_gdf.head()
208/9: nav = pd.concat([galen_gdf,rvgs_gdf])
208/10: nav.head()
208/11:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,Line
import matplotlib.pyplot as plt
%pylab inline
208/12:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
%pylab inline
208/13: line = [LineString(xy) for xy in zip(rvgs_gdf["geometry"],galen_gdf["geometry"])]
208/14: line
208/15: line_gdf = gpd.GeoDataFrame(geometry=line)
208/16:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw.head()
208/17:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.head()
208/18:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.head()
208/19: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
208/20: data.head()
208/21: data.interpolate(method='linear',inplace=True)
208/22: data.head()
209/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
%pylab inline
209/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)

rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]

rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
rvgs_gdf.crs = {"init":"epsg:4326"}
rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

rvgs_gdf.head()
209/3:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]

galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
galen_gdf.crs = {"init":"epsg:4326"}
galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
galen_gdf.head()
209/4: #line = [LineString(xy) for xy in zip(rvgs_gdf["geometry"],galen_gdf["geometry"])]
209/5:
#line_gdf = gpd.GeoDataFrame(geometry=line)
#line_gdf.
209/6:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw.head()
209/7:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.head()
209/8:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.head()
209/9: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
209/10: data.head()
210/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
%pylab inline
whos
210/2:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
%pylab inline
who
210/3:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)

rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]

#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

#rvgs_gdf.head()
210/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]

#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()
210/5: #line = [LineString(xy) for xy in zip(rvgs_gdf["geometry"],galen_gdf["geometry"])]
210/6:
#line_gdf = gpd.GeoDataFrame(geometry=line)
#line_gdf.
210/7:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw.head()
210/8:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.head()
210/9:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.head()
210/10: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
210/11: data.head()
210/12: data.interpolate(method='linear',inplace=True)
210/13: data.head()
210/14:
data.head()
data.plot(x="rvgs_lon",y="rvgs_lat")
plt.hold(True)
plt.grid(True)
data.plot(x="galen_lon",y="galen_lat")
211/1: import nvector
212/1: import nvector as *
212/2: from nvector import *
213/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
import proj4

%pylab inline
213/2:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
import proj4

%pylab inline

proj_latlon = Proj(init='epsg4326')
proj_utm = Proj(init="+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
213/3:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
import pyproj

%pylab inline

proj_latlon = Proj(init='epsg4326')
proj_utm = Proj(init="+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
213/4:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

%pylab inline

proj_latlon = Proj(init='epsg4326')
proj_utm = Proj(init="+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
213/5:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

%pylab inline

proj_latlon = Proj(init='epsg:4326')
proj_utm = Proj(init="+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
213/6:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

%pylab inline

proj_latlon = Proj('init=epsg:4326')
proj_utm = Proj(init="+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
213/7:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

%pylab inline

proj_latlon = Proj(init='EPSG:4326')
proj_utm = Proj(init="+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
213/8:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

%pylab inline

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj(init="+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
213/9:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

%pylab inline

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
213/10:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lat'],rvgsdf['rvgs_lon'])
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]



#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

#rvgs_gdf.head()
213/11:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lat'].tolist(),rvgsdf['rvgs_lon'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]



#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

#rvgs_gdf.head()
213/12:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lat'].tolist(),rvgsdf['rvgs_lon'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
213/13:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
213/14:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['rvgs_lon'].tolist(),galendf['rvgs_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
213/15:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
213/16:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw.head()
213/17:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.head()
213/18:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.head()
213/19: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
213/20: data.head()
213/21: data.interpolate(method='linear',inplace=True)
213/22:
data.head()
data.plot(x="rvgs_lon",y="rvgs_lat")
#plt.hold(True)
#plt.grid(True)
#data.plot(x="galen_lon",y="galen_lat")
213/23:
data.head()
data.plot(x="rvgs_lon",y="rvgs_lat",figsize=(10,10))
#plt.hold(True)
#plt.grid(True)
#data.plot(x="galen_lon",y="galen_lat")
213/24: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
213/25:
data.head()
data.plot(x="rvgs_lon",y="rvgs_lat",figsize=(10,10))
#plt.hold(True)
#plt.grid(True)
#data.plot(x="galen_lon",y="galen_lat")
213/26:
#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",figsize=(10,10))
rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)
#data.plot(x="galen_lon",y="galen_lat")
213/27:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
#rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
#rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
#rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
#rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
213/28:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
213/29: rvgs[0:10,:]
213/30: plt.plot(np[:,7],np([:,6]),figsize(10,10))
213/31: plt.plot(rvgs[:,7],rvgs([:,6]),figsize(10,10))
213/32: plt.plot(rvgs[:,7],rvgs[:,6],figsize(10,10))
213/33: plt.plot(rvgs[...,7],rvgs[...,6],figsize(10,10))
213/34: plt.plot(rvgs[:,7],rvgs[:,6],'.',figsize(10,10))
213/35: plt.plot(x=rvgs[:,7],y=rvgs[:,6],'.',figsize(10,10))
213/36: plt.plot(x=rvgs[:,7],y=rvgs[:,6],'.',figsize=(10,10))
213/37: plt.plot(x=rvgs[:,7],y=rvgs[:,6],'.')
213/38: plt.plot(x=rvgs[:,7],y=rvgs[:,6])
213/39: plt.plot(x=rvgs[:,7],y=rvgs[:,6],'o')
213/40: plt.plot(x=rvgs[:,7],y=rvgs[:,6],'bo')
213/41: plt.plot(rvgs[:,7],rvgs[:,6],'bo')
213/42:
rvgsdf.plot(x='rvgs_lon',y='rvgs_lat','bo')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
213/43:
rvgsdf.plot('rvgs_lon','rvgs_lat','bo')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
213/44:
rvgsdf.plot('rvgs_lon','rvgs_lat')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
213/45:
rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',kind='line')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
213/46:
rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',kind='scatter')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
213/47:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
213/48:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw.head()
213/49:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.head()
213/50:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.head()
213/51: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
213/52: data.head()
213/53: data.interpolate(method='linear',inplace=True)
213/54:
#data.head()
data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)
#data.plot(x="galen_lon",y="galen_lat")
213/55:
#data.head()
data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
plt.hold(True)
data.plot(x="galen_lon",y="galen_lat",kind='scatter')
plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)
#data.plot(x="galen_lon",y="galen_lat")
213/56:
#data.head()
data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)
#data.plot(x="galen_lon",y="galen_lat")
213/57: data.plot(x="galen_lon",y="galen_lat",kind='scatter')
213/58:
#data.head()
data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#plt.hold(True)
data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)
#data.plot(x="galen_lon",y="galen_lat")
213/59:
#data.head()
data.plot(x="rvgs_lon",y="rvgs_lat",x='galen_lon',y='galen_lat',kind='scatter',figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)
#data.plot(x="galen_lon",y="galen_lat")
213/60: dist = np.sqrt( (data["rvgs_e"]-data["galen_e"]).^2 + (data["rvgs_n"]-data["galen_n"]).^2)
213/61: dist = np.sqrt( (data["rvgs_e"]-data["galen_e"])^2 + (data["rvgs_n"]-data["galen_n"])^2)
213/62: np.power?
213/63: dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
213/64: plot(dist,'o')
213/65:
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
213/66: ## Plots
213/67: data.plot(x="index",y="distance",kind='scatter',figsize=(15,10))
213/68: data.plot(y="distance",kind='scatter',figsize=(15,10))
213/69: data.plot(y="distance",kind='line',figsize=(15,10))
213/70: plt.plot(data.index,data.distance,'b.')
213/71:
plt.plot(data.index,data.distance,'b.')
plt.grid(True)
213/72:
T = data.index > "02-23:05"
#plt.plot(data.index,data.distance,'b.')
#plt.grid(True)
213/73:
T = data.index > "2018-02=22 23:05:00"
#plt.plot(data.index,data.distance,'b.')
#plt.grid(True)
213/74:
T = data.index > "2018-02-22 23:05:00"
#plt.plot(data.index,data.distance,'b.')
#plt.grid(True)
213/75:
T = data.index > "2018-02-22 23:05:00"
plt.plot(data.index[T],data.distance[T],'b.')
plt.grid(True)
213/76:
T = data.index > "2018-02-22 23:16:00"
plt.plot(data.index[T],data.distance[T],'b.')
plt.grid(True)
213/77:
T = data.index > "2018-02-22 23:26:00"
plt.plot(data.index[T],data.distance[T],'b.')
plt.grid(True)
213/78:
T = data.index > "2018-02-22 23:26:00"
plt.plot(data.index[T],'b.')
plt.grid(True)
213/79:
T = data.index > "2018-02-22 23:26:00"
plt.plot(data.index,'b.')
plt.grid(True)
213/80:
T = data.index > "2018-02-22 23:26:00"
plt.plot(rvgs[:,1],'b.')
plt.grid(True)
213/81:
T = data.index > "2018-02-22 23:26:00"
plt.plot(rvgs[:,2],'b.')
plt.grid(True)
213/82:
T = data.index > "2018-02-22 23:26:00"
plt.plot(rvgs[:,3],'b.')
plt.grid(True)
213/83:
T = data.index > "2018-02-22 23:26:00"
plt.plot(rvgs[:,4],'b.')
plt.grid(True)
213/84:
T = data.index > "2018-02-22 23:26:00"
plt.plot(rvgs[:,5],'b.')
plt.grid(True)
213/85:
T = data.index > "2018-02-22 23:26:00"
plt.plot(rvgs[:,3],'b.')
plt.grid(True)
213/86:
data.sort_index(inplace=True)
T = data.index > "2018-02-22 23:26:00"
plt.plot(
plt.grid(True)
213/87:
data.sort_index(inplace=True)
T = data.index > "2018-02-22 23:26:00"
plt.plot(data.distance,'.')
plt.grid(True)
213/88: data.plot()
213/89: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
213/90: data.head()
213/91:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
213/92:
data.sort_index(inplace=True)
T = data.index > "2018-02-22 23:26:00"
plt.plot(data.distance,'.')
plt.grid(True)
213/93:
T = data.index > "2018-02-22 23:26:00"
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time')
plt.ylabel('Distance, m')
212/3: import geopandas as gpd
212/4: lat = [1, 1.5, 2]
212/5: lon = [0 0 0]
212/6: lon = [0, 0, 0]
212/7: p = [gpd.Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
212/8: p = [gpd.Point(xy) for xy in zip(lon,lat)]
212/9: from shapely.geometry import Point
212/10: p = [gpd.Point(xy) for xy in zip(lon,lat)]
212/11: p = [Point(xy) for xy in zip(lon,lat)]
212/12: import pandas as pd
212/13: dts = pd.Timestamp.now()
212/14: dts
212/15: dts+pd.Timedelta(s=10)
212/16: dts+pd.Timedelta(seconds=10)
212/17: dts
212/18: tt = [dts, dts+pd.Timedelta(seconds=10), + pd.Timedelta(seconds=20)]
212/19: gts = gpd.GeoSeries(index=dts,geometry=pts)
212/20: gts = gpd.GeoSeries(index=dts,geometry=p)
212/21: gts = gpd.GeoSeries(index=tt,p)
212/22: gts = gpd.GeoSeries(p)
212/23: gts.index = tt
212/24: gts.head()
212/25: tt = [dts, dts+pd.Timedelta(seconds=10), dts + pd.Timedelta(seconds=20)]
212/26: gts.index = tt
212/27: gts.head()
212/28: gts.geometry.x
212/29: gts.geometry.y
212/30: import numpy as np
212/31: np.interp?
212/32: import scipy.interpolate
212/33: dts
212/34: pd.types(Timestamp)
212/35: pd.isTimestamp()
212/36: tmp = pd.Timestamp(dts)
212/37: whos
212/38: dts
212/39: length(tt)
212/40: tt.length()
212/41: tt.__len__()
212/42: pwd
212/43: ls
212/44: cd ~/gitsrc/GeoTimeSeries/
212/45: ls
212/46: ls
212/47: import geotimeseries
212/48: import geotimeseries
212/49: import geotimeseries
212/50: latitude
212/51: lat
212/52: lon
212/53: dts
212/54: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=dts)
212/55: g = geotimeseries.from_latlontime(latitude=lat,longitude=lon,timedata=dts)
212/56: reload(geotimeseries)
212/57: g = geotimeseries.from_latlontime(latitude=lat,longitude=lon,timedata=dts)
212/58: reload(geotimeseries)
212/59: g = geotimeseries.from_latlontime(latitude=lat,longitude=lon,timedata=dts)
212/60:
if dts is list:
    print "yes"
212/61: whos
212/62: whos dts
212/63: reload(geotimeseries)
212/64: g = geotimeseries.from_latlontime(latitude=lat,longitude=lon,timedata=dts)
212/65: g = geotimeseries.from_latlontime(latitude=lat,longitude=lon,timedata=dts)
212/66: reload(geotimeseries)
212/67: g = geotimeseries.from_latlontime(latitude=lat,longitude=lon,timedata=dts)
212/68: reload(geotimeseries)
212/69: g = geotimeseries.from_latlontime(latitude=lat,longitude=lon,timedata=dts)
212/70: dts
212/71: dtss = pd.TimeSeries?
212/72: whos
212/73: g = geotimeseries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/74: reload(geotimeseries)
212/75: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/76: reload(geotimeseries)
212/77: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/78: reload(geotimeseries)
212/79: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/80: reload(geotimeseries)
212/81: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/82: reload(geotimeseries)
212/83: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/84: reload(geotimeseries)
212/85: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/86: g
212/87: print(g)
212/88: reload(geotimeseries)
212/89: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/90: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/91: reload(geotimeseries)
212/92: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/93: reload(geotimeseries)
212/94: g = geotimeseries.GeoTimeSeries.from_latlontime(latitude=lat,longitude=lon,timedata=tt)
212/95: tt = [dts, dts+pd.Timedelta(seconds=10), dts + pd.Timedelta(seconds=20)]
212/96: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/97: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/98: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/99: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/100: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/101: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/102: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/103: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/104: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/105: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/106: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/107: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/108: debugfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/109: debugfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/110: runfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
212/111: debugfile('/Users/vschmidt/gitsrc/GeoTimeSeries/geotimeseries.py', wdir='/Users/vschmidt/gitsrc/GeoTimeSeries')
214/1:
T = data.index > "2018-02-22 23:26:00"
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
214/2:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

%pylab inline

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
214/3:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
214/4:
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',kind='scatter')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
214/5:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
214/6:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw.head()
214/7:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.head()
214/8:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.head()
214/9: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
214/10: data.head()
214/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
214/12:

#data.head()
data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

data.plot(x="galen_lon",y="galen_lat")
214/13: data.head()
214/14:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
214/15: data.head()
214/16:

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
214/17:
plt.plot(galendf.index,'bo')
#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
214/18:
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
214/19:
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
214/20:
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
214/21:
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
214/22:
plt.plot(galendf.index,'bo',figsize=(10,15))
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
214/23:
plt.figure(figsize=(10,15))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
214/24: galendf.index[0]-bw.index[0]
214/25:
galendf.index[0]-bw.index[0]
galendf.index[0]-galen_rssi.index[0]
214/26:
print(galendf.index[0]-bw.index[0])
print(galendf.index[0]-galen_rssi.index[0])
214/27:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
214/28:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
214/29:
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',kind='scatter')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
214/30:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
214/31:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw.head()
214/32:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.head()
214/33:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.head()
214/34: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
214/35: data.head()
214/36:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
214/37:
print(galendf.index[0]-bw.index[0])
print(galendf.index[0]-galen_rssi.index[0])
214/38:
plt.figure(figsize=(10,15))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)


#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
214/39:
plt.figure(figsize=(10,15))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
215/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
215/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
215/3:
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',kind='scatter')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
215/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
215/5:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw.head()
215/6:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.head()
215/7:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.head()
215/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
215/9: data.head()
215/10:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
215/11:
print(galendf.index[0]-bw.index[0])
print(galendf.index[0]-galen_rssi.index[0])
215/12:
plt.figure(figsize=(10,15))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
215/13:
plt.figure(figsize=(5,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
215/14:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw = bw[bw.index > '2018-02-23 00:00:00']
bw.head()
215/15:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
#bw = bw[bw.index > '2018-02-23 00:00:00']
bw.head()
215/16:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw = bw[bw.index > '2018-02-23 00:00:00']
bw.head()
215/17:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.head()
215/18:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.head()
215/19: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
215/20: data.head()
215/21:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
215/22:
print(galendf.index[0]-bw.index[0])
print(galendf.index[0]-galen_rssi.index[0])
215/23:
plt.figure(figsize=(5,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
215/24:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
rvgs_rssi.index = rvgs_rssi.index + pd.Timedelta(hours=24)
rvgs_rssi.head()
215/25:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
#rvgs_rssi.index = rvgs_rssi.index + pd.Timedelta(hours=24)
rvgs_rssi.head()
215/26:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Correct for day-light-savings-time.
rvgs_rssi.index = rvgs_rssi.index + pd.Timedelta(hours=24)
rvgs_rssi.head()
215/27:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
215/28: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
215/29: data.head()
215/30:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
215/31:
print(galendf.index[0]-bw.index[0])
print(galendf.index[0]-galen_rssi.index[0])
215/32:
plt.figure(figsize=(5,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
215/33:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
216/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
216/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
216/3:
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',kind='scatter')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
216/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
216/5:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=5)
bw.head()
216/6:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Correct for day-light-savings-time.
rvgs_rssi.index = rvgs_rssi.index + pd.Timedelta(hours=24)
rvgs_rssi.head()
216/7:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
216/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
216/9: data.head()
216/10:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
216/11:
print(galendf.index[0]-bw.index[0])
print(galendf.index[0]-galen_rssi.index[0])
216/12:
plt.figure(figsize=(5,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
216/13:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/14:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Correct for day-light-savings-time.
rvgs_rssi.index = rvgs_rssi.index + pd.Timedelta(hours=24)
rvgs_rssi.head()
216/15:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
216/16: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
216/17: data.head()
216/18:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
216/19:
print(galendf.index[0]-bw.index[0])
#print(galendf.index[0]-galen_rssi.index[0])
216/20:
plt.figure(figsize=(5,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
216/21:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/22:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Correct for day-light-savings-time.
rvgs_rssi.index = rvgs_rssi.index + pd.Timedelta(hours=24)
rvgs_rssi.head()
216/23:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
216/24: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
216/25: data.head()
216/26:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
216/27:
print(galendf.index[0]-bw.index[0])
#print(galendf.index[0]-galen_rssi.index[0])
216/28:
plt.figure(figsize=(5,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
217/1: import BWmonitor
217/2: B = BWmonitor.BWmonitor()
217/3: F = file('BWmonitorlog_1519244815.json')
217/4: data = F.read()
217/5: F.close()
217/6: data
217/7: dataj = json.loads(data)
217/8: import json
217/9: dataj = json.loads(data)
217/10: dataj
217/11: dataj['end']
217/12: dataj['start']
217/13: dataj.keys()
217/14: dataj['start']
217/15: F = file('BWmonitorlog_1519325234.json')
217/16: data = F.read()
217/17: F.close()
217/18: dataj = json.loads(data)
217/19: dataj['start']
217/20: dataj.keys()
217/21: dataj['server_output_json']
217/22: dataj['start']
217/23: dataj['server_output_json']
216/29:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/30:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime(bw['Unixtime'],unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/31:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime({'seconds':bw['Unixtime']},unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/32:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
dates = pd.to_datetime({'seconds':bw['Unixtime']},unit='s')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/33:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
import datetime
dt = datetime.datetime.fromtimestamp(bw['Unixtime'])
dates = pd.TimeSeries(dt)
#dates = pd.to_datetime({'seconds':bw['Unixtime']},unit='s')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/34:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
dates = pd.TimeSeries(dt)
#dates = pd.to_datetime({'seconds':bw['Unixtime']},unit='s')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/35:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
dates = pd.Timestamp(dt)
#dates = pd.to_datetime({'seconds':bw['Unixtime']},unit='s')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/36:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
import datetime
dt = datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']
dates = pd.Timestamp(dt)
#dates = pd.to_datetime({'seconds':bw['Unixtime']},unit='s')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/37:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/38:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/39:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
dates = pd.to_datetime(pd.Series(dt)

#dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/40:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
dates = pd.to_datetime(pd.Series(dt))

#dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/41:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
dates = pd.to_datetime(pd.Series(dt[:]))

#dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/42: bw
216/43: bw['Unixtime'][0]
216/44: ut = bw['Unixtime']
216/45:
ut = bw['Unixtime']
ut[0]
216/46:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
dates = pd.to_datetime(pd.Series(dt[:]))

#dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/47:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/48:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
216/49:
ut = bw['Unixtime']
ut[0]
216/50:
ut = bw['Unixtime']
print(datetime.datetime.fromtimestamp(ut[0]))
216/51:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
#bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
218/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
218/3:
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',kind='scatter')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
218/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
218/5:
ut = bw['Unixtime']
print(datetime.datetime.fromtimestamp(ut[0]))
218/6:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/7:
bw=pd.DataFrame.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/8:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/9:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/10:
ut = bw['Unixtime']
print(datetime.datetime.fromtimestamp(ut[0]))
218/11:
import datetime
ut = bw['Unixtime']
print(datetime.datetime.fromtimestamp(ut[0]))
218/12:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/13:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Correct for day-light-savings-time.
rvgs_rssi.index = rvgs_rssi.index + pd.Timedelta(hours=24)
rvgs_rssi.head()
218/14:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
218/15: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
218/16: data.head()
218/17:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
218/18:
print(galendf.index[0]-bw.index[0])
#print(galendf.index[0]-galen_rssi.index[0])
218/19:
plt.figure(figsize=(5,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
218/20:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
218/21:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
218/22:
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',kind='scatter')
#plt.plot(rvgs[:,7],rvgs[:,6],'bo')
218/23:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
218/24:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-23 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/25:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
218/26:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Correct for day-light-savings-time.
#rvgs_rssi.index = rvgs_rssi.index + pd.Timedelta(hours=24)
rvgs_rssi.head()
218/27:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
218/28: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
218/29: data.head()
218/30:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
218/31:
print(galendf.index[0]-bw.index[0])
#print(galendf.index[0]-galen_rssi.index[0])
218/32:
plt.figure(figsize=(5,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
218/33:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-21 00:00:00']
# Adjust to GMT
#bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/34:
plt.figure(figsize=(5,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
218/35:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-21 00:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/36:
plt.figure(figsize=(5,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
218/37:
plt.figure(figsize=(5,7))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
218/38:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 00:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/39:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Correct for day-light-savings-time.
#rvgs_rssi.index = rvgs_rssi.index + pd.Timedelta(hours=24)
rvgs_rssi.head()
218/40:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
218/41: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
218/42: data.head()
218/43:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
218/44:
print(galendf.index[0]-bw.index[0])
#print(galendf.index[0]-galen_rssi.index[0])
218/45:
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
218/46:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
218/47:
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
218/48:
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
218/49: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
218/50: data.head()
218/51:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
218/52:
#T = data.index > "2018-02-22 23:26:00"
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
218/53:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
218/54:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
218/55:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'bo')
plt.plot(data.distance,data['MBytes/s Sent'],'go')
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
legend(['Received from Galen','Sent from Galen'])
218/56:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'bo')
plt.plot(data.distance,data['MBytes/s Sent'],'go')
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
218/57:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
218/58:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
218/59:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
218/60:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)
218/61:
plt.figure(figsize=(7,5))
plt.plot(data.distance,np.log10(data['rvgs_antenna_1_raw']./data['rvgs_noise_raw']),'ob')
218/62:
plt.figure(figsize=(7,5))
plt.plot(data.distance,np.log10(data['rvgs_antenna_1_raw']/data['rvgs_noise_raw']),'ob')
218/63:
plt.figure(figsize=(7,5))
plt.plot(np.log10(data['rvgs_antenna_1_raw']/data['rvgs_noise_raw']),'ob')
218/64:
plt.figure(figsize=(7,5))
plt.plot(np.log10(data['rvgs_antenna_1_raw']/data['rvgs_noise_raw']),'ob')
plt.plot(np.log10(data['galen_antenna_1_raw']/data['galen_noise_raw']),'og')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.legend('RVGS','Galen')
plt.label('Raw SNR')
218/65:
plt.figure(figsize=(7,5))
plt.plot(np.log10(data['rvgs_antenna_1_raw']/data['rvgs_noise_raw']),'ob')
plt.plot(np.log10(data['galen_antenna_1_raw']/data['galen_noise_raw']),'og')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.legend('RVGS','Galen')
plt.ylabel('Raw SNR')
218/66:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'ob')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'og')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.legend('RVGS','Galen')
plt.ylabel('SNR')
218/67:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'ob')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'og')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend('RVGS','Galen')
plt.ylabel('SNR')
218/68:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)
218/69:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'ob')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'og')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend('RVGS','Galen')
plt.ylabel('SNR')
218/70:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'ob')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'og')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Gale digital'])
plt.grid(True)
plt.ylabel('SNR')
218/71:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
218/72:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Gale digital'])
plt.grid(True)
plt.ylabel('SNR')
218/73:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
218/74:
plt.figure(figsize=(10,5))
M = data.index > '2018-02-22 18:30:00'
plt.plot(data.distance[M],data.galen_SNR_db[M],'.b')
plt.grid(True)
plt.figure(figsize(10,5))
plt.plot(data.distance[M],data['MBytes/s Received'][M],'.b')
plt.grid(True)
218/75:
plt.figure(figsize=(10,5))
M = data.index > '2018-02-22 18:30:00'
plt.plot(data.distance[M],data.galen_SNR_db[M],'.b')
plt.grid(True)
plt.figure(figsize=(10,5))
plt.plot(data.distance[M],data['MBytes/s Received'][M],'.b')
plt.grid(True)
218/76:
plt.figure(figsize=(10,5))
M = data.index > '2018-02-22 18:30:00' & data.index < '2018-02-22 19:55:00'
plt.plot(data.distance[M],data.galen_SNR_db[M],'.b')
plt.grid(True)
plt.figure(figsize=(10,5))
plt.plot(data.distance[M],data['MBytes/s Received'][M],'.b')
plt.grid(True)
218/77:
plt.figure(figsize=(10,5))
M = data.index > '2018-02-22 18:30:00' && data.index < '2018-02-22 19:55:00'
plt.plot(data.distance[M],data.galen_SNR_db[M],'.b')
plt.grid(True)
plt.figure(figsize=(10,5))
plt.plot(data.distance[M],data['MBytes/s Received'][M],'.b')
plt.grid(True)
218/78:
plt.figure(figsize=(10,5))
M = data.index > '2018-02-22 18:30:00' and data.index < '2018-02-22 19:55:00'
plt.plot(data.distance[M],data.galen_SNR_db[M],'.b')
plt.grid(True)
plt.figure(figsize=(10,5))
plt.plot(data.distance[M],data['MBytes/s Received'][M],'.b')
plt.grid(True)
218/79:
plt.figure(figsize=(10,5))
M = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:55:00')
plt.plot(data.distance[M],data.galen_SNR_db[M],'.b')
plt.grid(True)
plt.figure(figsize=(10,5))
plt.plot(data.distance[M],data['MBytes/s Received'][M],'.b')
plt.grid(True)
218/80:
plt.figure(figsize=(10,5))
M = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:55:00')
plt.plot(data.distance[M],data['galen_antenna_1_raw'][M] - data['galen_noise_raw'][M],'.b')
plt.grid(True)
plt.figure(figsize=(10,5))
plt.plot(data.distance[M],data['MBytes/s Received'][M],'.b')
plt.grid(True)
218/81:
plt.figure(figsize=(10,5))
plt.plot(data.index.difference())
218/82:
plt.figure(figsize=(10,5))
plt.plot(data.index.diff,'.b')
218/83:
plt.figure(figsize=(10,5))
plt.plot(np.diff(data.index.second),'.b')
218/84:
plt.figure(figsize=(10,5))
tmp = np.diff(data.index.second)
tmp = tnp(np.abs(tmp) < 1)
plt.plot(tmp,'.b')
218/85:
plt.figure(figsize=(10,5))
tmp = np.diff(data.index.second)
tmp = tnp[np.abs(tmp) < 1]
plt.plot(tmp,'.b')
218/86:
plt.figure(figsize=(10,5))
tmp = np.diff(data.index.second)
tmp = tmp[np.abs(tmp) < 1]
plt.plot(tmp,'.b')
218/87:
plt.figure(figsize=(10,5))
tmp = np.diff(data.index.second)
tmp = tmp[np.abs(tmp) < 1]
np.mean(tmp)
plt.plot(tmp,'.b')
218/88:
plt.figure(figsize=(10,5))
tmp = np.diff(data.index.second)
tmp = tmp[np.abs(tmp) < 1]
print(np.mean(tmp))
plt.plot(tmp,'.b')
218/89: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
218/90:
plt.figure(figsize=(10,5))
tmp = np.diff(data.index.second)
tmp = tmp[np.abs(tmp) < 1]
print(np.mean(tmp))
plt.plot(tmp,'.b')
218/91:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=100)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
218/92:
plt.figure(figsize=(10,5))
tmp = np.diff(data.index.time)
tmp = tmp[np.abs(tmp) < 1]
print(np.mean(tmp))
plt.plot(tmp,'.b')
218/93:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=100)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
218/94:
plt.figure(figsize=(10,5))
dt = pd.Timedelta(data.index[1:]-data.index[:-1])
218/95:
plt.figure(figsize=(10,5))
dt = data.index[1:]-data.index[:-1]
218/96:
plt.figure(figsize=(10,5))
dt = data.index[1:]-data.index[:-1]
dt.plot()
218/97:
plt.figure(figsize=(10,5))
dt = data.index[1:]-data.index[:-1]
plt.plot(dt.value)
218/98:
plt.figure(figsize=(10,5))
dt = data.index[1:]-data.index[:-1]
plt.plot(dt.total_seconds())
218/99: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
218/100: data.head()
218/101:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=100)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
218/102:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
218/103:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=100)
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
218/104:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)
218/105:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()

#data.head()
#data.plot(x="rvgs_lon",y="rvgs_lat",kind='scatter',figsize=(10,10))
#data.plot(y="galen_lon",figsize=(10,10))
#plt.hold(True)
#data.plot(x="galen_lon",y="galen_lat",kind='scatter')
#plt.hold(False)
#rvgsdf.plot(x='rvgs_lon',y='rvgs_lat',figsize=(10,10))
#plt.hold(True)
#plt.grid(True)

#data.plot(x="galen_lon",y="galen_lat")
218/106:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
218/107:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
218/108:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
218/109:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Gale digital'])
plt.grid(True)
plt.ylabel('SNR')
218/110:
plt.figure(figsize=(10,5))
M = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:55:00')
plt.plot(data.distance[M],data['galen_antenna_1_raw'][M] - data['galen_noise_raw'][M],'.b')
plt.grid(True)
plt.figure(figsize=(10,5))
plt.plot(data.distance[M],data['MBytes/s Received'][M],'.b')
plt.grid(True)
218/111:
plt.figure(figize=(10,5))
plt.scatter?
218/112:
plt.figure(figize=(10,5))
plt.scatter[data,index,data.distance,data['MBytes/s Received'],'o']
218/113:
plt.figure(figsize=(10,5))
plt.scatter[data,index,data.distance,data['MBytes/s Received'],'o']
218/114:
plt.figure(figsize=(10,5))
plt.scatter[data.index,data.distance,8,data['MBytes/s Received'],'o']
218/115:
plt.figure(figsize=(10,5))
dataplot.scatter(x=index,y='distance',8,c='MBytes/s Received','o')
218/116:
plt.figure(figsize=(10,5))
dataplot.scatter(x='index',y='distance',8,c='MBytes/s Received','o')
218/117:
plt.figure(figsize=(10,5))
dataplot.scatter(x='index',y='distance',8,c='MBytes/s Received')
218/118:
plt.figure(figsize=(10,5))
data.plot.scatter(x='index',y='distance',8,c='MBytes/s Received')
218/119:
plt.figure(figsize=(10,5))
data.plot.scatter(x='index',y='distance',s=8,c='MBytes/s Received')
218/120:
plt.figure(figsize=(10,5))
data.plot.scatter(y='distance',s=8,c='MBytes/s Received')
218/121: data.size()
218/122: data.size
218/123:
plt.figure(figsize=(10,5))
data.plot.scatter(x=data.index(y='distance',s=8,c='MBytes/s Received')
218/124:
plt.figure(figsize=(10,5))
data.plot.scatter(x=data.index,y='distance',s=8,c='MBytes/s Received')
218/125:
plt.figure(figsize=(10,5))
data.plot.scatter(x=data.index.total_seconds(),y='distance',s=8,c='MBytes/s Received')
218/126:
plt.figure(figsize=(10,5))
timefromstart = data.index-data.index[0]
data.plot.scatter(x=timefromstart.total_seconds()/60,y='distance',s=8,c='MBytes/s Received')
218/127: timefromstart
218/128: timefromstart.total_seconds()
218/129:
plt.figure(figsize=(10,5))
timefromstart = data.index-data.index[0]
data.plot.scatter(x=float(timefromstart.total_seconds())/60,y='distance',s=8,c='MBytes/s Received')
218/130:
plt.figure(figsize=(10,5))
timefromstart = data.index-data.index[0]
data.plot.scatter(x=np.float(timefromstart.total_seconds())/60,y='distance',s=8,c='MBytes/s Received')
218/131:
a = timefromstart.total_seconds()
b = [np.float(x) for x in a]
218/132: b
218/133:
plt.figure(figsize=(10,5))
timefromstart = data.index-data.index[0]
a = timefromstart.total_seconds()
b = [np.float(x) for x in a]
data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/134:
plt.figure(figsize=(10,5))
timefromstart = data.index-data.index[0]
a = timefromstart.total_seconds()
b = np.array([np.float(x) for x in a])
data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/135:
plt.figure(figsize=(10,5))
plt.scatter(data.index.to_pydatetime(),data.distance,s=8,c='MBytes/s Received')
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/136:
plt.figure(figsize=(10,5))
plt.scatter(data.index.to_pydatetime(),data.distance,s=8,c=data[]'MBytes/s Received'])
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/137:
plt.figure(figsize=(10,5))
plt.scatter(data.index.to_pydatetime(),data.distance,s=8,c=data['MBytes/s Received'])
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/138:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=8,c=data['MBytes/s Received'][M])
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/139:
plt.figure(figsize=(10,5))
M = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:55:00')
plt.plot(data.distance[M],data['galen_antenna_1_raw'][M] - data['galen_noise_raw'][M],'.b')
plt.grid(True)
plt.figure(figsize=(10,5))
plt.plot(data.distance[M],data['MBytes/s Received'][M],'.b')
plt.grid(True)
218/140:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=8,c=data['MBytes/s Received'][M])
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/141:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=8,c=data['MBytes/s Received'][M])
plt.axes(('2018-02-22 18:30:00' '2018-02-22 19:55:00' 0 5000))
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/142:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=8,c=data['MBytes/s Received'][M])
plt.axes(('2018-02-22 18:30:00', '2018-02-22 19:55:00', 0, 5000))
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/143:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=8,c=data['MBytes/s Received'][M])
plt.set_xlim('2018-02-22 18:30:00', '2018-02-22 19:55:00')
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/144:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=8,c=data['MBytes/s Received'][M])
plt.set_xlim('2018-02-22 18:30:00', '2018-02-22 19:55:00')
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/145:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=8,c=data['MBytes/s Received'][M])
plt.set_xlim('2018-02-22 18:30:00', '2018-02-22 19:55:00')
plt.set_xlim?
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/146: plt.set_xlim?
218/147: plt.xlim?
218/148:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=8,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 19:55:00')

#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/149:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=8,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')

#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/150:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=data['MBytes/s Sent'],c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')

#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/151:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=12,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')

#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/152:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')

#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/153:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels')
plt.colorbar()
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/154:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels')
plt.colorbar()
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/155:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
plt.colorbar()
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
#timefromstart = data.index-data.index[0]
#a = timefromstart.total_seconds()
#b = np.array([np.float(x) for x in a])
#data.plot.scatter(x=b/60,y='distance',s=8,c='MBytes/s Received')
218/156:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M]*8*1024*1024/1e6)
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
plt.colorbar()
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
218/157:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M]*8*1024*1024/1e6)
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
218/158:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
218/159: dgb = data.groupby(data.distance.map(lambda d: np.round(d,decimls=2)))
218/160: dgb = data.groupby(data.distance.map(lambda d: np.round(d,decimals=2)))
218/161: dgb = data.groupby(data.distance.map(lambda d: np.round(d,decimals=2))).mean()
218/162: dgb.head()
218/163: dgb.plot(dgb.distance,dgb['MBytes/s Received'],'.')
218/164: dgb.plot(dgb.distance,dgb['MBytes/s Received'],kind='line')
218/165: dgb = data.groupby(data.distance.map(lambda d: np.round(d,decimals=-2))).mean()
218/166:
plt.figure(figsize=(10,5))
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.')
218/167:
plt.figure(figsize=(10,5))
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-')
218/168:
data2 = data[M]
dgb = data2.groupby(data.distance.map(lambda d: np.round(d,decimals=-2))).mean()
218/169:
data2 = data[M]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
218/170:
plt.figure(figsize=(10,5))
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-')
218/171:
plt.figure(figsize=(10,5))
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
218/172:
plt.figure(figsize=(10,5))
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second, 500 M Average')
218/173:
plt.figure(figsize=(10,5))
plt.plot(data.distance[M],data['MBytes/s Received'][M],'.b')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second, 500 M Average')
218/174:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 18:31:30') & (data.index < '2018-02-22 19:55:00')
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b')
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g')

plt.grid(True)
218/175:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 18:31:30') & (data.index < '2018-02-22 19:55:00')
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b')
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=4)

plt.grid(True)
218/176:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 18:31:30') & (data.index < '2018-02-22 19:55:00')
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=3)

plt.grid(True)
218/177:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 18:31:30') & (data.index < '2018-02-22 19:55:00')
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)

plt.grid(True)
218/178:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 18:31:30') & (data.index < '2018-02-22 19:55:00')
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.subplot(211)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)

plt.grid(True)
218/179:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 18:31:30') & (data.index < '2018-02-22 19:55:00')
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)

plt.grid(True)
218/180:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 18:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)

plt.grid(True)
218/181:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 18:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
218/182:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 18:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 8 Ft Antenna Height')
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 5 Ft Antenna Height')
218/183:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 18:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 8 Ft Antenna Height')
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 5 Ft Antenna Height')
plt.tight_layout()
218/184:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second')
218/185:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
218/186:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
218/187:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second')
218/188:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
218/189:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second')
218/190:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 8 Ft Antenna Height')
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 5 Ft Antenna Height')
plt.tight_layout()
218/191:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
218/192:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second')
218/193:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
218/194:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second')
218/195:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second')
plt.legend(['MBytes/s 8ft','MBytes/s 5ft','MBytes/s 8ft','MBytes/s 5ft'])
218/196:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','MBytes/s 2.6 m','MBytes/s 1.5 m'])
218/197:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.tight_layout()
218/198:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received']*8*1024*1024/1e6,'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received']*8*1024*1024/1e6,'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits/s ')
plt.title('MBits/s')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','MBits/s 2.6 m','MBits/s 1.5 m'])
218/199:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received']*8*1024*1024/1e6,'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received']*8*1024*1024/1e6,'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits/s ')
plt.title('MBits/s vs Distance')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','MBits/s 2.6 m','MBits/s 1.5 m'])
218/200:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','MBytes/s 2.6 m','MBytes/s 1.5 m'])
218/201:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
218/202:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received']*8*1024*1024/1e6,'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received']*8*1024*1024/1e6,'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits/s ')
plt.title('MBits/s vs Distance')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
218/203:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received']*8*1024*1024/1e6,'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received']*8*1024*1024/1e6,'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits/s ')
plt.title('MBits/s vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
218/204: Here the time stamps of each data set are plotted to ensure they have all been parsed properly and are in the same zone.
218/205:
dt = rvgs.index[1:] - rvgs.index[:-1]
np.mean(np.diff(dt.total_seconds()))
218/206:
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(np.diff(dt.total_seconds()))
218/207:
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
dt
np.mean(np.diff(dt.total_seconds()))
218/208:
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
dt.head()
np.mean(np.diff(dt.total_seconds()))
218/209:
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
dt.total_seconds()
np.mean(np.diff(dt.total_seconds()))
218/210:
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
218/211:
plt.figure()
plt.plot(galen_rssi.galen_unixtimestamp,'.')
218/212:
plt.figure()
tt = pd.Timestamp(galen_rssi.galen_unixtimestamp)
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
plt.plot(tt.index,'.')
218/213:
plt.figure()
tt = pd.Timestamp(galen_rssi.galen_unixtimestamp)
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
tt.head()
#plt.plot(tt.index,'.')
218/214:
plt.figure()
tt = pd.Timestamp(galen_rssi.galen_unixtimestamp)
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
tt
#plt.plot(tt.index,'.')
218/215:
#plt.figure()
tt = pd.Timestamp(galen_rssi.galen_unixtimestamp)
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
tt
#plt.plot(tt.index,'.')
218/216:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
tt
#plt.plot(tt.index,'.')
218/217:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
tt.head()
#plt.plot(tt.index,'.')
218/218:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
plt.plot(tt.index,'.')
218/219:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt.index[1:]-dt.index[:-1]
plt.plot(dt.total_seconds(),'.')
218/220:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[:1]-tt[:-1]
plt.plot(dt.total_seconds(),'.')
218/221:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[:1]-tt[:-1]
plt.plot(dt,'.')
218/222:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
plt.plot(dt,'.')
218/223:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
plt.plot(dt(np.abs(dt)<1),'.')
218/224:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
plt.plot(dt(np.abs(dt[:])<1),'.')
218/225:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt = dt[dt>-1]
plt.plot(dt,'.')
218/226:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt.head()
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/227:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt = dt[1:]
#dt = dt[dt>-1]
plt.plot(dt,'.')
218/228:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt = dt[1:-1]
#dt = dt[dt>-1]
plt.plot(dt,'.')
218/229:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt.head()
dt = dt[1:-1]
#dt = dt[dt>-1]
plt.plot(dt,'.')
218/230:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt.head()
dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/231:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt.head()
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/232:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt.head()
dt.total_seconds()
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/233:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/234:
#plt.figure()
#tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
tt = pd.Timestamp(galen_rssi.galen_unixtimestamp)
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/235:
#plt.figure()
#tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[1:])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/236:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/237:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt.head()
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/238:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt.seconds
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/239:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
dt.head()
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/240:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
tt.head()
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/241:
#plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
plt.plot(tt.diff(),'.')
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/242:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
plt.plot(tt.diff(),'.')
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/243:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
plt.plot(tt.diff(),'.')
plt.ylim(-1,1)
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/244:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
plt.plot(tt.diff(),'.')
#plt.ylim(-1,1)
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/245:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
plt.plot(tt.diff()/1e9,'.')
#plt.ylim(-1,1)
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/246:
plt.figure()
tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])
#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = tt[1:]-tt[:-1]
plt.plot(tt.diff()/1e9,'.')
plt.ylim(-1,1)
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/247:
plt.figure()
#tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])

#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
#plt.plot(tt.diff()/1e9,'.')
plt.ylim(-1,1)
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/248:
plt.figure()
#tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])

#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
#plt.plot(tt.diff()/1e9,'.')
#plt.ylim(-1,1)
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/249:
plt.figure()
#tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])

#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.g')
plt.grid(True)
#plt.plot(tt.diff()/1e9,'.')
#plt.ylim(-1,1)
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/250:
plt.figure()
#tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])

#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
#plt.plot(tt.diff()/1e9,'.')
#plt.ylim(-1,1)
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/251:
plt.figure()
#tt = pd.to_datetime(pd.Series(galen_rssi.galen_unixtimestamp),unit='s',origin='unix')
#tt = pd.Timestamp(galen_rssi.galen_unixtimestamp[])

#plt.plot(galen_rssi.galen_unixtimestamp,'.')
#tt.head()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
#plt.plot(tt.diff()/1e9,'.')
plt.ylim(-1,1)
#s = dt.seconds + dt.microseconds
#dt = dt[1:-1]
#dt = dt[dt>-1]
#plt.plot(dt,'.')
218/252:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
218/253:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)
218/254:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
218/255:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
218/256:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
218/257:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
218/258:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
218/259:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Gale digital'])
plt.grid(True)
plt.ylabel('SNR')
218/260:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.tight_layout()
218/261:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
218/262:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
218/263:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received']*8*1024*1024/1e6,'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received']*8*1024*1024/1e6,'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits/s ')
plt.title('MBits/s vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
218/264:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
218/265:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M]*8*1024*1024/1e6)
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
218/266:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()
218/267:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()
218/268:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()
219/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
219/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
219/3:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
219/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
219/5:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
219/6:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
219/7:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
219/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
219/9: data.head()
219/10:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
219/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
219/12:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)
219/13:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
219/14:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
219/15:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
219/16:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
219/17:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
219/18:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
219/19:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()
219/20:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
219/21:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
219/22:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received']*8*1024*1024/1e6,'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received']*8*1024*1024/1e6,'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits/s ')
plt.title('MBits/s vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
219/23:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
219/24:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)
219/25:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
219/26:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
219/27:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
219/28:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
219/29:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
219/30:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
219/31:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()
219/32:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
219/33:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
219/34:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received']*8*1024*1024/1e6,'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received']*8*1024*1024/1e6,'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits/s ')
plt.title('MBits/s vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
219/35:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
220/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
220/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
220/3:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
220/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
220/5:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
220/6:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
220/7:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
220/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
220/9: data.head()
220/10:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
220/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
220/12:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)
220/13:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
220/14:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
220/15:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
220/16:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
220/17:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
220/18:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
220/19:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()
220/20:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
220/21:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/22:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received']*8*1024*1024/1e6,'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received']*8*1024*1024/1e6,'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits/s ')
plt.title('MBits/s vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
220/23:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
220/24:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][M])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
220/25:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_antenna_1_raw'][T1] - data['galen_noise_raw'][T1],'.b',markersize=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_antenna_1_raw'][T2] - data['galen_noise_raw'][T2],'.g',markersize=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()
220/26:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/27:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received']*8*1024*1024/1e6,'.-r',linewidth=2)
plt.plot(dgb2.distance,dgb2['MBytes/s Received']*8*1024*1024/1e6,'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits/s ')
plt.title('MBits/s vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
220/28:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
220/29:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
220/30:
plt.figure(figsize=(10,5))

plt.scatter(data.index[M].to_pydatetime(),data.distance[M],s=50,c=data['MBytes/s Received'][M]*8*1024*1024/1e6)
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
220/31:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
220/32:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
220/33:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.errorbar(dgb.distance,dgb['MBytes/s Received'],yerr=dgb_std[dgb['MBytes/s Received'],fmt='.-r',linewidth=2)


plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/34:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
220/35:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.errorbar(dgb.distance,dgb['MBytes/s Received'],yerr=dgb_std['MBytes/s Received'],fmt='.-r',linewidth=2)


plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/36:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.errorbar(dgb.distance,dgb['MBytes/s Received'],yerr=dgb_std['MBytes/s Received'],fmt='.-r',linewidth=2)


plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.errorbar(dgb2.distance,dgb2['MBytes/s Received'],yerr=dgb2_std['MBytes/s Received'],fmt='.-m',linewidth=2)


plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/37:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).std()
220/38:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).mean()
dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-2))).std()
220/39:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.errorbar(dgb.distance,dgb['MBytes/s Received'],yerr=dgb_std['MBytes/s Received'],fmt='.-r',linewidth=2)


plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.errorbar(dgb2.distance,dgb2['MBytes/s Received'],yerr=dgb2_std['MBytes/s Received'],fmt='.-m',linewidth=2)


plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/40:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
220/41:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
220/42:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.errorbar(dgb.distance,dgb['MBytes/s Received'],yerr=dgb_std['MBytes/s Received'],fmt='.-r',linewidth=2)


plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.errorbar(dgb2.distance,dgb2['MBytes/s Received'],yerr=dgb2_std['MBytes/s Received'],fmt='.-m',linewidth=2)


plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/43:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.errorbar(dgb.distance,dgb['MBytes/s Received'],yerr=dgb_std['MBytes/s Received'],fmt='.-r',linewidth=2,capsize=10)


plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.errorbar(dgb2.distance,dgb2['MBytes/s Received'],yerr=dgb2_std['MBytes/s Received'],fmt='.-m',linewidth=2)


plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/44:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance,dgb['MBytes/s Received'],'.-r',linewidth=2)
plt.errorbar(dgb.distance,dgb['MBytes/s Received'],yerr=dgb_std['MBytes/s Received'],fmt='.-r',linewidth=2,capsize=10)


plt.plot(dgb2.distance,dgb2['MBytes/s Received'],'.-m',linewidth=2)
plt.errorbar(dgb2.distance,dgb2['MBytes/s Received'],yerr=dgb2_std['MBytes/s Received'],fmt='.-m',linewidth=2,capsize=10)


plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/45:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

data['rvgs_SNR_raw'] = np.mean([data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],
                                data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']],2)
data['galen_SNR_raw'] = np.mean([data['galen_antenna_1_raw'] - data['galen_noise_raw'],
                                 data['galen_antenna_1_raw'] - data['galen_noise_raw']],2)
220/46:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

data['rvgs_SNR_raw'] = np.mean([data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],
                                data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']],axis=1)
data['galen_SNR_raw'] = np.mean([data['galen_antenna_1_raw'] - data['galen_noise_raw'],
                                 data['galen_antenna_1_raw'] - data['galen_noise_raw']],axis=1)
220/47:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

data['rvgs_SNR_raw'] = np.mean([data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'];
                                data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']],axis=1)
data['galen_SNR_raw'] = np.mean([data['galen_antenna_1_raw'] - data['galen_noise_raw'];
                                 data['galen_antenna_1_raw'] - data['galen_noise_raw']],axis=1)
220/48:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw']],
                                [data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']],axis=1)
data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']],axis=1)
220/49:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw']],
                                [data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']], axis=1)
data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']]], axis=1)
220/50:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw']],
                                [data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']]], axis=1)
data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']]], axis=1)
220/51:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

snr = [[data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw']],
                                [data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']]]

#data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw']],
#                                [data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']]], axis=1)
#data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
#                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']]], axis=1)
220/52:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

snr = [[data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw']],
                                [data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']]]
snr

#data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw']],
#                                [data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']]], axis=1)
#data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
#                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']]], axis=1)
220/53:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

snr = [[data['rvgs_antenna_1_raw'].tolist() - data['rvgs_noise_raw'].tolist()],
                                [data['rvgs_antenna_2_raw'].tolist() - data['rvgs_noise_raw'].tolist()]]
snr

#data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw']],
#                                [data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']]], axis=1)
#data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
#                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']]], axis=1)
220/54:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

snr = [[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]]
snr

#data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw']],
#                                [data['rvgs_antenna_2_raw'] - data['rvgs_noise_raw']]], axis=1)
#data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
#                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']]], axis=1)
220/55:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

#snr = [[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]]
#snr

data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]], axis=0)
#data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
#                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']]], axis=1)
220/56:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

#snr = [[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]]
#snr

data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]], axis=0)
#data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
#                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']]], axis=1)
220/57:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

#snr = [[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
#                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]]
#snr

data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]], axis=0)
#data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
#                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']]], axis=1)
220/58:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
snr

#data['rvgs_SNR_raw'] = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
#                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]], axis=0)
#data['galen_SNR_raw'] = np.mean([[data['galen_antenna_1_raw'] - data['galen_noise_raw']],
#                                 [data['galen_antenna_1_raw'] - data['galen_noise_raw']]], axis=1)
220/59:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)


snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
data['rvgs_SNR_raw'] = snr

snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
data['galen_SNR_raw'] = snr
220/60:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)


snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
#data['rvgs_SNR_raw'] = snr

#snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
#                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
#data['galen_SNR_raw'] = snr
220/61:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)


snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
#data['rvgs_SNR_raw'] = snr

#snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
#                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
#data['galen_SNR_raw'] = snr
snr.size
220/62:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)


snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
#data['rvgs_SNR_raw'] = snr

#snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
#                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
#data['galen_SNR_raw'] = snr
snr.size
data.size
220/63:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)


snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
#data['rvgs_SNR_raw'] = snr

#snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
#                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
#data['galen_SNR_raw'] = snr
print(snr.size)
print(data.size)
220/64:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

SNR = [[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]]
snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
#data['rvgs_SNR_raw'] = snr

#snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
#                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
#data['galen_SNR_raw'] = snr
print(SNR.size)
print(snr.size)
print(data.size)
220/65:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

SNR = np.array([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]])
snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
#data['rvgs_SNR_raw'] = snr

#snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
#                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
#data['galen_SNR_raw'] = snr
print(SNR.size)
print(snr.size)
print(data.size)
220/66:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

SNR = np.array([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]])
snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
#data['rvgs_SNR_raw'] = snr

#snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
#                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
#data['galen_SNR_raw'] = snr
print(SNR.shape[1])
print(snr.shape[1])
print(data.shape[1])
220/67:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

SNR = np.array([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]])
snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
#data['rvgs_SNR_raw'] = snr

#snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
#                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
#data['galen_SNR_raw'] = snr
print(SNR.shape[0])
print(snr.shape[2])
print(data.shape[0])
220/68:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

SNR = np.array([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]])
snr = np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0)
#data['rvgs_SNR_raw'] = snr

#snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
#                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
#data['galen_SNR_raw'] = snr
print(SNR.shape[0])
print(snr.shape[1])
print(data.shape[0])
220/69:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

SNR = np.array([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]])
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

#snr = np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
#                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0)
#data['galen_SNR_raw'] = snr
print(SNR.shape[0])
print(snr.shape[1])
print(data.shape[0])
220/70:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
220/71:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
220/72:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance,dgb['galen_SNR_raw'],'.y')
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],'.y')

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()
220/73:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance,dgb['galen_SNR_raw'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()
220/74:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance,dgb['galen_SNR_raw'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

figure(figsiz=(10,5))
plt.plot(dgb.distance,dgb['galen_SNR_raw'],'.-b',linewidth=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],'.-g',linewidth=2)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR vs Distance at 2 Rover Antenna Heights')
220/75:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance,dgb['galen_SNR_raw'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsiz=(10,5))
plt.errorbar(dgb.distance,dgb['galen_SNR_raw'],yerr=dgb_std['galen_SNR_raw']'.-b',linewidth=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],yerr=dgb2_std['galen_SNR_raw']'.-g',linewidth=2)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR vs Distance at 2 Rover Antenna Heights')
220/76:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance,dgb['galen_SNR_raw'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsiz=(10,5))
plt.errorbar(dgb.distance,dgb['galen_SNR_raw'],yerr=dgb_std['galen_SNR_raw'],fmt='.-b',linewidth=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],yerr=dgb2_std['galen_SNR_raw'],fmt='.-g',linewidth=2)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR vs Distance at 2 Rover Antenna Heights')
220/77:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance,dgb['galen_SNR_raw'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance,dgb['galen_SNR_raw'],yerr=dgb_std['galen_SNR_raw'],fmt='.-b',linewidth=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],yerr=dgb2_std['galen_SNR_raw'],fmt='.-g',linewidth=2)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR vs Distance at 2 Rover Antenna Heights')
220/78:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance,dgb['galen_SNR_raw'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance,dgb['galen_SNR_raw'],yerr=dgb_std['galen_SNR_raw'],fmt='.-b',linewidth=2)
plt.errorbar(dgb2.distance,dgb2['galen_SNR_raw'],yerr=dgb2_std['galen_SNR_raw'],fmt='.-g',linewidth=2)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR vs Distance at 2 Rover Antenna Heights')
220/79:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance,dgb['galen_SNR_raw'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance,dgb['galen_SNR_raw'],yerr=dgb_std['galen_SNR_raw'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance,dgb2['galen_SNR_raw'],yerr=dgb2_std['galen_SNR_raw'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR vs Distance at 2 Rover Antenna Heights')
220/80:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).mean()
dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
dgb_stats = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
220/81: dbg_stats.head()
220/82: dgb_stats.head()
220/83: dgb_stats['rvgs_SNR_db']['count']
220/84: dgb_stats['rvgs_SNR_db']
220/85:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance,dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance,dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance,dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR vs Distance at 2 Rover Antenna Heights')
220/86:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
220/87:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance,dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance,dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance,dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance,dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR vs Distance at 2 Rover Antenna Heights')
220/88:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR vs Distance at 2 Rover Antenna Heights')
220/89:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/1 1 sigma vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/1 1 std err vs Distance at 2 Rover Antenna Heights')
220/90:
plt.figure(figsize=(10,5))
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
220/91:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],'.-r',linewidth=2)
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],yerr=dgb['MBytes/s Received']['std'],fmt='.-r',linewidth=2,capsize=10)


plt.plot(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],'.-m',linewidth=2)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],yerr=dgb2_std['MBytes/s Received']['std'],fmt='.-m',linewidth=2,capsize=10)


plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/92:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.plot(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],'.-r',linewidth=2)
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],yerr=dgb['MBytes/s Received']['std'],fmt='.-r',linewidth=2,capsize=10)


plt.plot(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],'.-m',linewidth=2)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],yerr=dgb2['MBytes/s Received']['std'],fmt='.-m',linewidth=2,capsize=10)


plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/93:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
#plt.plot(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],'.-r',linewidth=2)
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],yerr=dgb['MBytes/s Received']['std'],fmt='.-r',linewidth=2,capsize=10)


#plt.plot(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],'.-m',linewidth=2)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],yerr=dgb2['MBytes/s Received']['std'],fmt='.-m',linewidth=2,capsize=10)


plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/94:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
#plt.plot(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],'.-r',linewidth=2)
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)


#plt.plot(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],'.-m',linewidth=2)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)


plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/95:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/96:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
220/97:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBytes/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBit/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBit/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBit per Second')
plt.title('MBit per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
220/98:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBytes/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBit/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBit per Second')
plt.title('MBit per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
220/99:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBytes/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBit per Second')
plt.title('MBit per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
220/100:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
import gmaps

gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
222/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
import gmaps

gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
222/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
222/3:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
222/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
222/5:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
222/6:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
222/7:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
222/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
222/9: data.head()
222/10:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
222/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
222/12:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
222/13:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
222/14:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
222/15:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
222/16:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
222/17:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
222/18:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
222/19:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
222/20:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
222/21:
fig = gmaps.figure()
navlayer1 = gmaps.heatmap_layer(data['rvgs_lat','rvgs_lon'],weights=data['MBytes/s Received'],point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/22:
fig = gmaps.figure()
navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']],weights=data['MBytes/s Received'],point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/23:
fig = gmaps.figure()
navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']][data['rvgs_lat'] is not np.nan],weights=data['MBytes/s Received'][data['rvgs_lat'] is not np.nan],point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/24:
fig = gmaps.figure()
navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']][data['rvgs_lat'].values is not np.nan],weights=data['MBytes/s Received'][data['rvgs_lat'].values is not np.nan],point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/25:
fig = gmaps.figure()
navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']][data['rvgs_lat'].values ~= np.nan],weights=data['MBytes/s Received'][data['rvgs_lat'].values ~= np.nan],point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/26:
fig = gmaps.figure()
navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=data['MBytes/s Received'].dropna(),point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/27:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = lat[:,0] == np.nan
mbr = data['MBytes/s Received'][ii]

navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/28:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = latlon[:,0] == np.nan
mbr = data['MBytes/s Received'][ii]

navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/29:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = latlon[:,0] == np.nan
mbr = data['MBytes/s Received'][ii]
mbr.shape()
#navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/30:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = latlon[:,0] == np.nan
mbr = data['MBytes/s Received'][ii].values
mbr.shape()
#navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/31:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = latlon[:,0] == np.nan
mbr = data['MBytes/s Received'][ii].values
mbr.shape
#navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
fig.add_layer(navlayer1)
fig
222/32:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = latlon[:,0] == np.nan
mbr = data['MBytes/s Received'][ii].values
mbr.shape
#navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
#fig.add_layer(navlayer1)

#fig
222/33:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = latlon[:,0] == np.nan
mbr = data['MBytes/s Received'][ii]
mbr.shape
#navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
#fig.add_layer(navlayer1)

#fig
222/34:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = latlon[:,0] == np.nan
ii.head()
mbr = data['MBytes/s Received'][ii]
mbr.shape
#navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
#fig.add_layer(navlayer1)

#fig
222/35:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = latlon[:,0] == np.nan
ii
mbr = data['MBytes/s Received'][ii]
mbr.shape
#navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
#fig.add_layer(navlayer1)

#fig
222/36:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = np.isnan(latlon[:,0])
ii
mbr = data['MBytes/s Received'][ii]
mbr.shape
#navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
#fig.add_layer(navlayer1)

#fig
222/37:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = np.isnan(latlon[:,0])
ii
mbr = data['MBytes/s Received'][ii]
mbr.shape
latlon.shape
#navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
#fig.add_layer(navlayer1)

#fig
222/38:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = np.isnan(latlon[:,0])
ii
mbr = data['MBytes/s Received'][ii]

navlayer1 = gmaps.heatmap_layer(data[['rvgs_lat','rvgs_lon']].dropna(),weights=mbr,point_radius=4.0)
fig.add_layer(navlayer1)

fig
222/39:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = np.isnan(latlon[:,0])
ii
mbr = data['MBytes/s Received'][ii]

navlayer1 = gmaps.heatmap_layer(latlon[ii,:],weights=mbr,point_radius=4.0)
fig.add_layer(navlayer1)

fig
222/40:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = ~np.isnan(latlon[:,0])
ii
mbr = data['MBytes/s Received'][ii]

navlayer1 = gmaps.heatmap_layer(latlon[ii,:],weights=mbr,point_radius=4.0)
fig.add_layer(navlayer1)

fig
223/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
import gmaps

gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
223/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
223/3:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
223/4:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
223/5:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
223/6:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
223/7: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
223/8: data.head()
223/9:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
223/10:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
223/11:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
223/12:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
223/13:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
223/14:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
223/15:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
223/16:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
223/17:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
223/18:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
223/19:
data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
223/20:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
223/21: dgb_stats['rvgs_SNR_db']
223/22:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
223/23:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
223/24: #dgb_stats['rvgs_SNR_db']
223/25:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.plot(data.distance[T1],data['galen_SNR_raw'][T1],'.b',markersize=3)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
223/26:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
223/27:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBytes/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBit per Second')
plt.title('MBit per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
223/28:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
223/29:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
223/30:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = ~np.isnan(latlon[:,0])
ii
mbr = data['MBytes/s Received'][ii]

navlayer1 = gmaps.heatmap_layer(latlon[ii,:],weights=mbr,point_radius=4.0)
fig.add_layer(navlayer1)

fig
223/31:
fig = gmaps.figure()
latlon = data[['rvgs_lat','rvgs_lon']].values
ii = ~np.isnan(latlon[:,0])
ii
mbr = data['MBytes/s Received'][ii]

navlayer1 = gmaps.heatmap_layer(latlon[ii,:],weights=mbr,point_radius=4.0)
fig.add_layer(navlayer1)

fig
224/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
#import gmaps
from mpl_toolkits.basemap import Basemap

#gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
224/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
224/3:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
224/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
224/5:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
224/6:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
224/7:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
224/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
224/9: data.head()
224/10:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
224/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
224/12:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
224/13:
llcrnrlon = min(data[['rvgs_lon','galen_lon']])
#map = Basemap(llcrnrlon=,llcrnrlat=39.75,urcrnrlon=4.35,urcrnrlat=40.15, epsg=2033)
#http://server.arcgisonline.com/arcgis/rest/services

#map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)
#plt.show()
224/14: llcrnrlon
224/15:
data.head()
llcrnrlon = min(data[['rvgs_lon','galen_lon']])
#map = Basemap(llcrnrlon=,llcrnrlat=39.75,urcrnrlon=4.35,urcrnrlat=40.15, epsg=2033)
#http://server.arcgisonline.com/arcgis/rest/services

#map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)
#plt.show()
224/16:
data.head()
#llcrnrlon = min(data[['rvgs_lon','galen_lon']])
#map = Basemap(llcrnrlon=,llcrnrlat=39.75,urcrnrlon=4.35,urcrnrlat=40.15, epsg=2033)
#http://server.arcgisonline.com/arcgis/rest/services

#map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)
#plt.show()
224/17:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
224/18:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
224/19:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
224/20:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
224/21:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
224/22:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
224/23: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
224/24: data.head()
224/25:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
224/26: data.keys()
224/27:
data.head()
llcrnrlon = np.min([data[['rvgs_lon'],data['galen_lon']])
#map = Basemap(llcrnrlon=,llcrnrlat=39.75,urcrnrlon=4.35,urcrnrlat=40.15, epsg=2033)
#http://server.arcgisonline.com/arcgis/rest/services

#map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)
#plt.show()
224/28:
data.head()
llcrnrlon = np.min([data['rvgs_lon'],data['galen_lon']])
#map = Basemap(llcrnrlon=,llcrnrlat=39.75,urcrnrlon=4.35,urcrnrlat=40.15, epsg=2033)
#http://server.arcgisonline.com/arcgis/rest/services

#map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)
#plt.show()
224/29: llcrnrlon
224/30:
data.head()
llcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
#map = Basemap(llcrnrlon=,llcrnrlat=39.75,urcrnrlon=4.35,urcrnrlat=40.15, epsg=2033)
#http://server.arcgisonline.com/arcgis/rest/services

#map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)
#plt.show()
224/31: llcrnrlon
224/32:
data.head()
llcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
llcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
urcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
urcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=,llcrnrlat=39.75,urcrnrlon=4.35,urcrnrlat=40.15, epsg=2033)
#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)
plt.show()
224/33:
data.head()
llcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
llcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
urcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
urcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=llcrnrlon,llcrnrlat=llcrnrlat,urcrnrlon=urcrnrlon,urcrnrlat=urcrnrlat, epsg=2033)
#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)
plt.show()
224/34:
data.head()
llcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
llcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
urcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
urcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=llcrnrlon,llcrnrlat=llcrnrlat,urcrnrlon=urcrnrlon,urcrnrlat=urcrnrlat, epsg=4326)
#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)
plt.show()
225/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
#import gmaps
from mpl_toolkits.basemap import Basemap

#gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
225/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
225/3:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
225/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
225/5:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
225/6:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
225/7:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
225/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
225/9: data.head()
225/10:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
225/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
225/12:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
225/13:
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=LLcrnrlon,llcrnrlat=LLcrnrlat,urcrnrlon=URcrnrlon,urcrnrlat=URcrnrlat, epsg=4326)
#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
226/1:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=LLcrnrlon,llcrnrlat=LLcrnrlat,urcrnrlon=URcrnrlon,urcrnrlat=URcrnrlat, epsg=4326)
#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
226/2:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
#import gmaps
from mpl_toolkits.basemap import Basemap

#gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
226/3:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
226/4:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
226/5:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
226/6:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
226/7:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
226/8:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
226/9: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
226/10: data.head()
226/11:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
226/12:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
226/13:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
226/14:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
226/15:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=LLcrnrlon,llcrnrlat=LLcrnrlat,urcrnrlon=URcrnrlon,urcrnrlat=URcrnrlat, epsg=4326)
#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
227/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
#import gmaps
from mpl_toolkits.basemap import Basemap

#gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
227/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
227/3:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
227/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
227/5:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
227/6:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
227/7:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
227/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
227/9: data.head()
227/10:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
227/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
227/12:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
227/13:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=LLcrnrlon,llcrnrlat=LLcrnrlat,urcrnrlon=URcrnrlon,urcrnrlat=URcrnrlat, epsg=4326)
#http://server.arcgisonline.com/arcgis/rest/services

#map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
228/1: llcrnrlon
228/2:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=LLcrnrlon,llcrnrlat=LLcrnrlat,urcrnrlon=URcrnrlon,urcrnrlat=URcrnrlat, epsg=4326)
#http://server.arcgisonline.com/arcgis/rest/services

#map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
229/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
#import gmaps
from mpl_toolkits.basemap import Basemap

#gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
229/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
229/3:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
229/4:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
229/5:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
229/6:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
229/7:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
229/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
229/9: data.head()
229/10:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
229/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
229/12:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
229/13:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


#map = Basemap(llcrnrlon=LLcrnrlon,llcrnrlat=LLcrnrlat,urcrnrlon=URcrnrlon,urcrnrlat=URcrnrlat, epsg=4326)
#http://server.arcgisonline.com/arcgis/rest/services

#map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
#plt.show()
229/14: LLcrnrlon
229/15:
print(LLcrnrlon)
print(LLcrnrlat)
print(URcrnrlon)
print(URcrnrlat)
229/16:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              projection='llc')

#http://server.arcgisonline.com/arcgis/rest/services

#map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
#plt.show()
229/17:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              projection='llc')

#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
229/18:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])


map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              projection='tmerc')

#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
229/19:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])
Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
233/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
#import gmaps
from mpl_toolkits.basemap import Basemap

#gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj(("+proj=utm +zone=19 +ellps=WGS84",
               " +datum=WGS84 +units=m +no_defs"))
233/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
233/3:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
233/4:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},inplace=True)
# Calculate SNR


rvgs_rssi.head()
233/5:
galen_rssi = pd.DataFrame.from_csv('../galinJ/udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
233/6: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
233/7:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
233/8:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
233/9:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
#import gmaps
from mpl_toolkits.basemap import Basemap

#gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj(["+proj=utm +zone=19 +ellps=WGS84",
               " +datum=WGS84 +units=m +no_defs"])
233/10:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
#import gmaps
from mpl_toolkits.basemap import Basemap

#gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
233/11:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
233/12:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
233/13:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
233/14:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
233/15:
rvgs_rssi = pd.DataFrame.from_csv(()'../rvgs/BWmonitor/',
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
# Calculate SNR


rvgs_rssi.head()
233/16:
rvgs_rssi = pd.DataFrame.from_csv(('../rvgs/BWmonitor/',
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
# Calculate SNR


rvgs_rssi.head()
233/17:
rvgs_rssi = pd.DataFrame.from_csv(('../rvgs/BWmonitor/',
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt'))
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
# Calculate SNR


rvgs_rssi.head()
233/18:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
# Calculate SNR


rvgs_rssi.head()
233/19:
galen_rssi = pd.DataFrame.from_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
233/20:
galen_rssi = pd.DataFrame.from_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
233/21: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
233/22: data.head()
233/23:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds())
233/24:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
233/25:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
233/26:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
233/27:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],c='b',markersize=3,alpha=.4)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
233/28:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
233/29: #dgb_stats['rvgs_SNR_db']
233/30:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],c='b',markersize=3,alpha=.4)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
233/31:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],c='b',s=3,alpha=.4)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
233/32:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],c='b',s=3,alpha=.2)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
233/33:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],c='b',s=3,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.plot(data.distance[T2],data['galen_SNR_raw'][T2],'.g',markersize=2)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
233/34:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
233/35:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=3)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=3)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
233/36:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],'.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
233/37:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],'.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],yerr=dgb['galen_SNR_raw']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],yerr=dgb2['galen_SNR_raw']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count']),fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
233/38:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])
Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
233/39:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])
Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
233/40:
plt.figure()
LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']])
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']])
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']])
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']])
Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=6,c='y')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
233/41:
plt.figure()

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.1
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=6,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=6,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 800, verbose= True)
plt.show()
233/42:
plt.figure()

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.1
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=6,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=6,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= True)
plt.show()
233/43:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.1
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=6,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=6,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 1500, verbose= False)
plt.show()
233/44:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.05
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=6,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=6,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)
plt.show()
233/45:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=6,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=6,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 3000, verbose= False)
plt.show()
233/46:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=6,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=6,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2500, verbose= False)
plt.show()
233/47:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=6,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=6,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)
plt.show()
233/48:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services

map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=6,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=6,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)
map.drawmapboundary()
plt.show()
233/49:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary()
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/50:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fillcolor=None)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/51:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color=None)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/52:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='w')
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/53:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
map.drawmapscale()
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/54:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
map.drawscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/55:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/56:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc'
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/57:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/58:
plt.figure(figsize=(8,8))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.01
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/59:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.show()
233/60:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.xlabel('Vertical Scale %s' % vscale )
plt.show()
233/61:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.xlabel('Vertical Scale %0.1f' % vscale/1000 )
plt.show()
233/62:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.xlabel('Vertical Scale %0.1f' % vscale/1000 )
plt.show()
233/63:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.xlabel('Vertical Scale %0.1f' % vscale/1000.0 )
plt.show()
233/64:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.xlabel('Vertical Scale %0.1f' % (vscale/1000.0) )
plt.show()
233/65:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
legend([]'RVGS','GALEN'])
plt.show()
233/66:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
legend(['RVGS','GALEN'])
plt.show()
233/67:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=3,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=3,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
233/68:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=1,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
233/69:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
#from nvector import *
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
#import gmaps
from mpl_toolkits.basemap import Basemap

#gmaps.configure(api_key=os.environ["GOOGLE_API_KEY"])

#%pylab inline
%matplotlib notebook
#import mpld3
#mpld3.enable_notebook()

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
233/70:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBytes/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBit per Second')
plt.title('MBit per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])


Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget.png")
233/71:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBytes/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBit per Second')
plt.title('MBit per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])


Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
233/72:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
233/73:
Image("Silviustesting/IMG_0781.JPG")
Image('Silviustesting/IMG_0788.JPG')
233/74:
<img style="float:left;transform: rotate(90deg); width:300px" src="Silviustesting/IMG_0788.JPG" />

#Image("Silviustesting/IMG_0781.JPG")

#Image('Silviustesting/IMG_0788.JPG')
233/75:
%%html
<img style="float:left;transform: rotate(90deg); width:300px" src="Silviustesting/IMG_0788.JPG" />

#Image("Silviustesting/IMG_0781.JPG")

#Image('Silviustesting/IMG_0788.JPG')
233/76:
%%html
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />


#Image("Silviustesting/IMG_0781.JPG")

#Image('Silviustesting/IMG_0788.JPG')
233/77:
%%html
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
%%
Radio installation aboard the RV Gulf Surveyory. Height of antennas above the water line is approximately 14 ft.
%%html
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />


#Image("Silviustesting/IMG_0781.JPG")

#Image('Silviustesting/IMG_0788.JPG')
233/78:
%html <img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />

Radio installation aboard the RV Gulf Surveyory. Height of antennas above the water line is approximately 14 ft.
%html <img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />


#Image("Silviustesting/IMG_0781.JPG")

#Image('Silviustesting/IMG_0788.JPG')
233/79:
%html 
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<p>Radio installation aboard the RV Gulf Surveyory. Height of antennas above the water line is approximately 14 ft.</p>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />


#Image("Silviustesting/IMG_0781.JPG")

#Image('Silviustesting/IMG_0788.JPG')
233/80:
%%html 
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<p>Radio installation aboard the RV Gulf Surveyory. Height of antennas above the water line is approximately 14 ft.</p>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />


#Image("Silviustesting/IMG_0781.JPG")

#Image('Silviustesting/IMG_0788.JPG')
233/81:
%%html 
<div>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
</div>
<p>Radio installation aboard the RV Gulf Surveyory. Height of antennas above the water line is approximately 14 ft.</p>
<div>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
233/82:
%%html 
<div>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<br /></div>
<p>Radio installation aboard the RV Gulf Surveyory. Height of antennas above the water line is approximately 14 ft.</p>
<div>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
233/83:
%%html 
<div>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
</div>
<p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p>
<div>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
<p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is now shown at 2.6 m</p>
233/84:
%%html 
<div>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
</div>
<p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p>
<div>
<img style="float:right;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
<p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is now shown at 2.6 m</p>
233/85:
%%html 
<div>
<img style="float:center;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
</div>
<p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p>
<div>
<img style="float:right;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
<p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is now shown at 2.6 m</p>
233/86:
%%html 
<div>
<img style="float:center;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
</div>
<p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p>
<div>
<img style="float:right;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
<p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is now shown at 2.6 m</p>
233/87:
%%html 
<div>
<img style="float:center;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
</div>
<p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p>
<div>
<img style="float:center;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
<p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is now shown at 2.6 m</p>
233/88:
%%html 
<div class=image>
<img style="float:center;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p> </div>
</div>

<div>
<img style="float:center;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
<p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is now shown at 2.6 m</p>
233/89:
%%html 
<div class=image>
<img style="float:center;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p> </div>
</div>

<div class=image>
<img style="float:center;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is now shown at 2.6 m</p>
</div>
</div>
233/90:
%%html 
<div class=image>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p> </div>
</div>

<div class=image>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is now shown at 2.6 m</p>
</div>
</div>
233/91:
%%html 
<div class=image>
<img style="transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p> </div>
</div>

<div class=image>
<img style="float:left;transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
233/92:
%%html 
<div class=image>
<img style="transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p> </div>
</div>

<div class=image>
<img style="transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" /></div>
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
233/93:
%%html 
<div class=image>
<img style="transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p> </div>
</div>

<div class=image>
<img style="transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
233/94:
%%html 
<div class=image>
<img style="transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p> </div>
</div>
233/95:
<div class=image>
<img style="transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
233/96:
%%html 
<div class=image>
<img style="transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
233/97:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft.</p> </div>
</div>
233/98:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
233/99:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
234/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
from mpl_toolkits.basemap import Basemap

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook
234/2:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
234/3:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
234/4:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
234/5:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
234/6:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
234/7:
bw=pd.DataFrame.from_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
234/8:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
# Calculate SNR


rvgs_rssi.head()
234/9:
galen_rssi = pd.DataFrame.from_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
234/10: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
234/11: data.head()
234/12:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
234/13:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
234/14:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
234/15:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
234/16:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
234/17:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
234/18:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
234/19:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
234/20:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
234/21:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
234/22: #dgb_stats['rvgs_SNR_db']
234/23:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
234/24:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
234/25:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBytes/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBit per Second')
plt.title('MBit per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])


Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
234/26:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
234/27:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
234/28:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=1,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
234/29:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
234/30:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])


Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
234/31:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.scatter(x=np.log10(data.distance[T1]),y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plt.scatter(x=np.log10(data.distance[T1]),y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
234/32:
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.scatter(x=np.log10(data.distance[T1]),y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T1]),y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
234/33:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.scatter(x=np.log10(data.distance[T1]),y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T1],
            c='g',s=2,alpha=.1)
234/34:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.scatter(x=np.log10(data.distance[T1]),y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
234/35:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=np.log10(data.distance[T1]),y=data['galen_SNR_raw'][T1],
            c='b's=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,40)
234/36:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=np.log10(data.distance[T1]),y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,40)
234/37:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,40)
234/38:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1][not np.isnan(data.distance[T1])],y=data['galen_SNR_raw'][T1][not np.isnan(data.distance[T1])],
            c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,40)
234/39:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1][np.isnan(data.distance[T1].not())],y=data['galen_SNR_raw'][T1][np.isnan(data.distance[T1]).not()],
            c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,40)
234/40:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1][np.isnan(data.distance[T1].not],
             y=data['galen_SNR_raw'][T1][np.isnan(data.distance[T1]).not],
            c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,40)
234/41:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1][~np.isnan(data.distance[T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data.distance[T1])],
            c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,40)
234/42:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1][~np.isnan(data.distance[T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data.distance[T1])],
            c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/43:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
d = data.distance[T1][~np.isnan(data.distance[T1])]
d.shape
plt.semilogx(x=data.distance[T1][~np.isnan(data.distance[T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data.distance[T1])],
            c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/44:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
d = data.distance[T1][~np.isnan(data.distance[T1])]
print(d.shape)
plt.semilogx(x=data.distance[T1][~np.isnan(data.distance[T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data.distance[T1])],
            c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/45:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1][~np.isnan(data.distance[T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data.distance[T1])],'.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/46:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1][~np.isnan(data.distance[T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data.distance[T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/47:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1][~np.isnan(data.['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data.['galen_SNR_raw'[T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/48:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1][~np.isnan(data.['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data.['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/49:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.semilogx(x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/50:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])]
print(np.sum(np.isnan(x))))
                    
plt.semilogx(x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/51:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])]
print(np.sum(np.isnan(x)))
                    
plt.semilogx(x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/52:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])]
print(np.sum(np.isinf(x)))
                    
plt.semilogx(x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/53:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])]
print(np.sum(x<-))
                    
plt.semilogx(x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/54:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])]
print(np.sum(x<-)))
                    
plt.semilogx(x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/55:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])]
print(np.sum(x<0)))
                    
plt.semilogx(x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/56:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])]
print(np.sum(x<0))
                    
plt.semilogx(x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/57:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])]
print(np.sum(x<=0))
                    
plt.semilogx(x=data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])],
             y=data['galen_SNR_raw'][T1][~np.isnan(data['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/58:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1][~np.isnan(data['galen_SNR_raw'][T1])]),
             y=data['galen_SNR_raw'][T1][~np.isnan(data['galen_SNR_raw'][T1])],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/59:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],fmt='.')

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/60:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],c='b',s=2,alpha=-.1)

#             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/61:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
#plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
#            c='g',s=2,alpha=.1)
plt.autoscale()
#plt.grid(True)
#plt.xlim(0,7000)
#plt.ylim(0,40)
234/62:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('SNR vs LOG10(Distance)')
234/63:
# 2.6 m
plt.figure(figsize=(10,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(10,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
234/64:
# 2.6 m
plt.figure(figsize=(12,7))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(12,7))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(12,7))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
234/65:
# 2.6 m
plt.figure(figsize=(12,7))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(12,7))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(12,7))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
234/66:
# 2.6 m
plt.figure(figsize=(12,7))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(12,7))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(12,7))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
235/1:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
235/2:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
from mpl_toolkits.basemap import Basemap

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook
235/3:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
235/4:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
235/5:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
235/6:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
235/7:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
235/8:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
235/9:
rvgs_rssi = pd.DataFrame.from_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
# Calculate SNR


rvgs_rssi.head()
235/10:
galen_rssi = pd.DataFrame.from_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
235/11: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
235/12: data.head()
235/13:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
235/14:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
235/15:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*4)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*4)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
235/16:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
235/17:
z = (data.rvgs_sync_noise_power - data.rvgs_sync_signal_power) / 51
SNRmw = (data.rvgs_sync_signal_power - 12) * z / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

z = (data.galen_sync_noise_power - data.galen_sync_signal_power) / 51
SNRmw = (data.galen_sync_signal_power - 12) * z / (64*z)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
235/18:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
235/19:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
235/20:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
235/21:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
235/22:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
235/23:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
235/24:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.show()
235/25:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
235/26:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
235/27:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
235/28:
x = data.rvgs_sync_signal_power
y = data.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12) * z / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

x = data.galen_sync_signal_power
y = data.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12) * z / (64*z)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
235/29:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
235/30:
x = data.rvgs_sync_signal_power
y = data.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

x = data.galen_sync_signal_power
y = data.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
235/31:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
235/32:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
# Calculate SNR


rvgs_rssi.head()
235/33:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)
#galen_rssi.index = galen_rssi.index + pd.Timedelta(hours=24)
galen_rssi.head()
235/34:
x = data.rvgs_sync_signal_power
y = data.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw(SNRmw > 0)) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

x = data.galen_sync_signal_power
y = data.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
235/35:
x = data.rvgs_sync_signal_power
y = data.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw(SNRmw.values > 0)) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

x = data.galen_sync_signal_power
y = data.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
235/36:
x = data.rvgs_sync_signal_power
y = data.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
data['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

x = data.galen_sync_signal_power
y = data.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw) 
data['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[data['rvgs_antenna_1_raw'].values - data['rvgs_noise_raw'].values],
                                [data['rvgs_antenna_2_raw'].values - data['rvgs_noise_raw'].values]],axis=0))
data['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[data['galen_antenna_1_raw'].values - data['galen_noise_raw'].values],
                                [data['galen_antenna_2_raw'].values - data['galen_noise_raw'].values]],axis=0))
data['galen_SNR_raw'] = snr
235/37:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
235/38: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
235/39: data.head()
235/40:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
235/41:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
235/42:
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
rvgs_rssi['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=data.index)

x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_db'] = pd.Series(galen_SNR_db,index=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = snr
235/43:
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
rvgs_rssi['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,rvgs_rssi=data.index)

x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_db'] = pd.Series(galen_SNR_db,galen_rssi=data.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = snr
235/44:
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
rvgs_rssi['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_db'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = snr
235/45:
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
#rvgs_rssi['rvgs_SNR_db'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)
rvgs_rssi['rvgs_SNR_db'] = rvgs_SNR_db


x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_db'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = snr
235/46:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
rvgs_rssi['rvgs_SNR_db'] = rvgs_SNR_db

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_db'] = galen_SNR_db

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = snr
235/47: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
235/48: data.head()
235/49:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
235/50:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
235/51:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.show()
235/52:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
235/53:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
235/54:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
rvgs_rssi['rvgs_SNR_db'] = rvgs_SNR_db

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_db'] = galen_SNR_db

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = snr
235/55: galen_rssi.head()
235/56:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
rvgs_rssi['rvgs_SNR_digital'] = rvgs_SNR_db

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_digital'] = galen_SNR_db

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = snr
235/57:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
235/58:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
235/59:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
rvgs_rssi['rvgs_SNR_digital'] = rvgs_SNR_db

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_digital'] = galen_SNR_db

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = snr
235/60: galen_rssi.head()
235/61: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
235/62: data.head()
235/63:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
235/64:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
235/65:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = snr

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = snr
235/66: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
235/67: data.head()
235/68:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
235/69:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
235/70:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = pd.Series(snr,index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(snr,index=rvgs_rssi.index)
235/71:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
rvgs_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
galen_SNR_db = 10*np.log10(SNRmw[SNRmw > 0]) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = pd.Series(snr,index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(snr,index=galen_rssi.index)
235/72: rvgs_rssi.index.shape()
235/73: rvgs_rssi['rvgs_antenna_1_raw'].shape()
235/74: rvgs_rssi['rvgs_antenna_1_raw'].values.shape()
235/75: snr.shape()
235/76:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
rvgs_rssi['rvgs_SNR_raw'] = pd.Series(snr,index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(snr,index=galen_rssi.index)
235/77:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
235/78:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
235/79: snr.size()
235/80:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
#snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
#                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))
snr = np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0)


rvgs_rssi['rvgs_SNR_raw'] = pd.Series(snr,index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(snr,index=galen_rssi.index)
235/81: whos
235/82:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(snr[:],index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(snr,index=galen_rssi.index)
235/83:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.transpose(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(snr,index=galen_rssi.index)
235/84:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=1))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(snr,index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(snr,index=galen_rssi.index)
235/85: whos
235/86:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(snr,index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(snr,index=galen_rssi.index)
235/87: snr.ndim
235/88: snr.shape
235/89: snr[:].shape
235/90: snr[:-1].shape
235/91: np.squeeze(snr).shape
235/92:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
235/93: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
235/94: data.head()
235/95:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
235/96:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
235/97:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',index_col=iso_timestamp)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
235/98:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',index_col='iso_timestamp')
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
235/99:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp')
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
235/100: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
235/101: data.head()
235/102:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
235/103:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
235/104:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
235/105:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
235/106:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
235/107:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
235/108: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
235/109: data.head()
235/110:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
235/111:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
235/112: rvgs.index
235/113: rvgs_rssi.index
235/114:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
235/115: rvgs_rssi.index
235/116:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
235/117:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
235/118: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
235/119: data.head()
235/120:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
235/121:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
235/122:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
235/123: data.info(memory_usage='deep')
236/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib notebook
236/2:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = file(self.Kfilename,'r')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',FID.read(4))

        pkt_buf = file.read(len)
        print(pkt_buf(0:2))
236/3:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = file(self.Kfilename,'r')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',FID.read(4))

        pkt_buf = file.read(len)
        print(pkt_buf[0:2])
236/4:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
236/5:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'r')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',FID.read(4))

        pkt_buf = file.read(len)
        print(pkt_buf[0:2])
236/6:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
236/7:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import struct
%matplotlib notebook
236/8:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'r')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',FID.read(4))

        pkt_buf = file.read(len)
        print(pkt_buf[0:2])
236/9:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
236/10:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'r')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))

        pkt_buf = file.read(len)
        print(pkt_buf[0:2])
236/11:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
236/12:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))

        pkt_buf = file.read(len)
        print(pkt_buf[0:2])
236/13:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
236/14:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))

        pkt_buf = self.FID.read(len)
        print(pkt_buf[0:2])
236/15:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
236/16:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
        print(len)
        pkt_buf = self.FID.read(len)
        print(pkt_buf[0:2])
236/17:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
236/18:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        (len) = struct.unpack('I',self.FID.read(4))
        print(len)
        pkt_buf = self.FID.read(len)
        print(pkt_buf[0:2])
236/19:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
236/20:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
       
        pkt_buf = self.FID.read(len[0])
        print(pkt_buf[0:2])
236/21:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
236/22:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
       
        pkt_buf = self.FID.read(len[0])
        print(struct.unpack('ccc',pkt_buf[0:2])
236/23:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
       
        pkt_buf = self.FID.read(len[0])
        print(struct.unpack('ccc',pkt_buf[0:2])

    def close():
        self.FID.close()
236/24:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
       
        pkt_buf = self.FID.read(len[0])
        print(struct.unpack('ccc',pkt_buf[0:2])

    def close(self):
        self.FID.close()
236/25:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
       
        pkt_buf = self.FID.read(len[0])
        print(struct.unpack('ccc',pkt_buf[0:2]))

    def close(self):
        self.FID.close()
236/26:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
K.close()
236/27:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
        print(len[0])
        pkt_buf = self.FID.read(len[0])
        print(struct.unpack('ccc',pkt_buf[0:2]))

    def close(self):
        self.FID.close()
236/28:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
K.close()
236/29:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
        print(len[0])
        pkt_buf = self.FID.read(len[0])
        print(struct.unpack('3c',pkt_buf[0:2]))

    def close(self):
        self.FID.close()
236/30:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
K.close()
236/31:
a = [1,2,3,4]
b=a[0:2]
len(b)
236/32:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
        print(len[0])
        pkt_buf = self.FID.read(len[0])
        print(struct.unpack('3c',pkt_buf[0:3]))

    def close(self):
        self.FID.close()
236/33:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
K.close()
236/34:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
        print(len[0])
        pkt_buf = self.FID.read(len[0])
        print(struct.unpack('4c',pkt_buf[0:4]))

    def close(self):
        self.FID.close()
236/35:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
K.close()
236/36:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
        print(len[0])
        self.FID.seek(0)
        pkt_buf = self.FID.read(len[0])
        print(struct.unpack('4c',pkt_buf[0:4]))

    def close(self):
        self.FID.close()
236/37:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
K.close()
236/38:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
        print(len[0])
        self.FID.seek(0)
        pkt_buf = self.FID.read(len[0])
        pkt_type = struct.unpack('4c',pkt_buf[0:4])
        print(pkt_type[:])

    def close(self):
        self.FID.close()
236/39:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
K.close()
236/40:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
        print(len[0])
        self.FID.seek(0)
        pkt_buf = self.FID.read(len[0])
        pkt_type = struct.unpack('4s',pkt_buf[0:4])
        print(pkt_type[:])

    def close(self):
        self.FID.close()
236/41:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
K.close()
236/42:
class kmall:
    def __init__(self,Kfilename):
        self.Kfilename = Kfilename
        self.FID = None
        
    def open_for_reading(self):
        self.FID = open(self.Kfilename,'rb')
        
    def read_next_pkt(self):
        
        # Read packet length
        len = struct.unpack('I',self.FID.read(4))
        print(len[0])
        self.FID.seek(0)
        pkt_buf = self.FID.read(len[0])
        pkt_type = struct.unpack('4s',pkt_buf[0:4])
        print(pkt_type[0])

    def close(self):
        self.FID.close()
236/43:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
K.read_next_pkt()
K.close()
236/44:
K = kmall('0000_20170711_171120_UNH_CW4.all')
K.open_for_reading()
236/45:
len = struct.unpack('I',self.FID.read(4))
print[len[0]]
236/46:
len = struct.unpack('I',K.FID.read(4))
print[len[0]]
239/1: source list
237/1: N = np.range(4)
237/2:
import numpy as np
N = np.range(4)
237/3:
import numpy as np
N = np.nrange(4)
237/4:
import numpy as np
N = range(4)
237/5:
import numpy as np
N = np.array(range(4))
237/6:
import numpy as np
import matplotlib.pyplot.plt
%matplotlib inline
N = np.array(range(4))
Beam = np.array([1,2,4,6,8,10])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
237/7:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
N = np.array(range(4))
Beam = np.array([1,2,4,6,8,10])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
237/8:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
N = np.array(range(4))
Beam = np.array([1,2,4,6,8,10])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
237/9:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
N = np.array(range(4))
Beam = np.array([1,2,4,6,8,10,12,14,16,18])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
237/10:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
N = np.array(range(4))
Beam = np.array([1,2,4,6,8,10,12,14,16,18])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,20)
237/11:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
N = np.array(range(4))
Beam = np.array([1,2,4,6,8,10,12,14,16,18,20,30,40])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,20)
237/12:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
N = np.array(range(4))
Beam = np.array([1,2,4,6,8,10,12,14,16,18,20,30,40])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,20)
plt.show()
237/13:
#import numpy as np
#import matplotlib.pyplot as plt
%matplotlib inline
Beam = np.array([1,2,4,6,8,10,12,14,16,18,20,30,40])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,20)
plt.show()
240/1:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
Beam = np.array([1,2,4,6,8,10,12,14,16,18,20,30,40])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,20)
plt.show()
240/2: print(Beam)
240/3: print(DI)
240/4:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
Beam = np.array([1,2,4,6,8,10,12,14,16,18,20,30,40])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,50)
plt.show()
240/5:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
Beam = np.array([1,2,4,6,8,10, 12, 14,16,18,20,30,40])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,50)
plt.show()
240/6:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
Beam = np.array([1,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,50)
plt.show()
240/7:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
Beam = np.array([1,2,4,6,8,10, 12.0, 14, 16, 18, 20, 30, 40])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,50)
plt.show()
240/8:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
Beam = np.array([1,2,4,6,8,10, 12.0, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,50)
plt.show()
240/9:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
Beam = np.array([1,2,4,6,8,10, 12.0, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure()
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
240/10:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'.')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
240/11:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
240/12:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
from mpl_toolkits.basemap import Basemap
import warnings:
warnings.filterwarnings('ignore')

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook
240/13:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
from mpl_toolkits.basemap import Basemap
import warnings
warnings.filterwarnings('ignore')

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook
240/14:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
240/15:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
240/16:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
240/17:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
240/18:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
240/19:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
240/20:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
240/21: rvgs_rssi.index
240/22:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
240/23:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
240/24: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
240/25: data.head()
240/26:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
240/27:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
240/28:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
240/29:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.show()
240/30:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.show()
240/31:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
240/32:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
240/33:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_db'],'.c')
plt.plot(data['galen_SNR_db'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
240/34:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
240/35:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
240/36:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
240/37:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
240/38:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
240/39:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
240/40:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
240/41: #dgb_stats['rvgs_SNR_db']
240/42:
# 2.6 m
plt.figure(figsize=(12,7))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()

plt.figure(figsize=(12,7))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')

plt.figure(figsize=(12,7))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
240/43:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
240/44:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])


Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
240/45:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
240/46:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
240/47:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
240/48:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
240/49:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
240/50:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
241/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
from mpl_toolkits.basemap import Basemap
import warnings
warnings.filterwarnings('ignore')

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook
241/2:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
241/3:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
241/4:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")


rvgsdf.head()
241/5:
# Checking the sample rate of the RVGS nav.
dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
np.mean(dt.total_seconds())
241/6:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
241/7:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
241/8:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
241/9: rvgs_rssi.index
241/10:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
241/11:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
241/12: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
241/13: data.head()
241/14:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
241/15:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
241/16:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
241/17:
plt.figure()
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.show()
241/18:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(10,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.show()
241/19:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
241/20:
plt.figure(figsize=(10,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
241/21:
plt.figure(figsize=(10,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
241/22:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
241/23: #dgb_stats['rvgs_SNR_db']
241/24:
# 2.6 m
plt.figure(figsize=(12,7))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12,7))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(12,7))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(12,7))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
241/25:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
241/26:
plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(10,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
241/27:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
241/28:
plt.figure(figsize=(10,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
241/29:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
241/30:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
242/1: ![]("Image004.png")
242/2: ![]("./Image004.png")
242/3:
# Thurst curve data:
knots = np.array(range(10))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
242/4:
import numpy as np
# Thurst curve data:
knots = np.array(range(10))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
242/5:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.array(range(10))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
242/6:
import numpy as np
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.array(range(10))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100
242/7:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.array(range(10))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.Dataframe([knots, ThrustkN,JetPower,JetEfficiency],index=knots)
242/8:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.array(range(10))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame([knots, ThrustkN,JetPower,JetEfficiency],index=knots)
242/9:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.array(range(10))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame([knots, ThrustkN,JetPower,JetEfficiency],index=knots[:])
242/10:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(10)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame([knots, ThrustkN,JetPower,JetEfficiency],index=knots)
242/11: print(knots)
242/12: print(np.transpose(knots)
242/13: print(np.transpose(knots))
242/14:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(10)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame([knots, ThrustkN,JetPower,JetEfficiency])
242/15: power.head()
242/16:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(10)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame([knots.reshape(-1), ThrustkN.reshape(-1),JetPower.reshape(-1),JetEfficiency.reshape(-1)])
242/17: power.head()
242/18:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,10)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame([knots.reshape(-1,10), ThrustkN.reshape(-1),JetPower.reshape(-1),JetEfficiency.reshape(-1)])
242/19:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

#power = pd.DataFrame([knots.reshape(-1,10), ThrustkN.reshape(-1),JetPower.reshape(-1),JetEfficiency.reshape(-1)])
242/20:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame([knots.reshape(-1), ThrustkN.reshape(-1),JetPower.reshape(-1),JetEfficiency.reshape(-1)])
242/21: power.head()
242/22: print(power)
242/23:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame([knots, ThrustkN,JetPower,JetEfficiency].transpose())
242/24:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame()
power['knots'] = knots
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetEfficiency'] = JetEfficiency
242/25: print(power)
242/26:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame()
power['knots'] = knots
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetEfficiency'] = JetEfficiency
power.set_index(index=knots,inplace=True)
242/27:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame()
power['knots'] = knots
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetEfficiency'] = JetEfficiency
power.set_index(knots,inplace=True)
242/28: print(power)
242/29:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame()
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetEfficiency'] = JetEfficiency
power.set_index(knots,inplace=True)
242/30: print(power)
242/31:
plt.figure()
power.plot()
242/32:
plt.figure()
plt.plot(knots,ThurstKN)
plt.plot(knots,JetPower/1000)
plt.plot(knots,JetEfficiency)
plt.grid(True)
plt.show()
242/33:
plt.figure()
plt.plot(knots,ThrustKN)
plt.plot(knots,JetPower/1000)
plt.plot(knots,JetEfficiency)
plt.grid(True)
plt.show()
242/34:
plt.figure()
plt.plot(knots,ThrustkN)
plt.plot(knots,JetPower/1000)
plt.plot(knots,JetEfficiency)
plt.grid(True)
plt.show()
242/35:
plt.figure()
plt.plot(knots,ThrustkN)
plt.plot(knots,JetPower/1000)
plt.plot(knots,JetEfficiency)
plt.grid(True)
legend(['Thrust','JetPower','Jet Efficiency')
plt.show()
242/36:
plt.figure()
plt.plot(knots,ThrustkN)
plt.plot(knots,JetPower/1000)
plt.plot(knots,JetEfficiency)
plt.grid(True)
legend(['Thrust','JetPower','Jet Efficiency'])
plt.show()
242/37:
plt.figure()
plt.plot(knots,ThrustkN)
plt.plot(knots,JetPower/1000)
plt.plot(knots,JetEfficiency)
plt.grid(True)
plt.legend(['Thrust','JetPower','Jet Efficiency'])
plt.show()
242/38:
plt.figure()
plt.plot(knots,ThrustkN)
plt.plot(knots,JetPower/1000)
plt.plot(knots,JetEfficiency)
plt.grid(True)
plt.legend(['Thrust','JetPower - KW','Jet Efficiency'])
plt.show()
242/39: print(power)
242/40:
plt.figure()
plt.plot(knots,ThrustkN)
plt.plot(knots,JetPower/1000)
plt.plot(knots,JetEfficiency)
plt.grid(True)
plt.legend(['Thrust','JetPower - KW','Jet Efficiency'])
plt.show()
242/41: estimated_kN = np.interp(5.5,knots,ThrustkN)
242/42: print(estimated_kN)
242/43: estimated_MaxThrust = np.interp(5.5,knots,ThrustkN) * 1000
242/44: print(estimated_MaxThrust)
242/45: print("Estimated Maximum Thrust: %0.1f" % estimated_MaxThrust)
242/46: print("Estimated Maximum Thrust: %0.1f" % estimated_MaxThrust)
242/47:
print("Estimated Maximum Thrust: %0.1f N" % estimated_MaxThrust)
print("Estimated Maximum Jet Power: %0.1W" % JetPower)
242/48:
print("Estimated Maximum Thrust: %0.1f N" % estimated_MaxThrust)
print("Estimated Maximum Jet Power: %0.1f W" % JetPower)
242/49:
estimated_MaxThrust = np.interp(5.5,knots,ThrustkN) * 1000
estiamted_MaxPower = np.interp(5.5,knots,JetPower)
242/50:
print("Estimated Maximum Thrust: %0.1f N" % estimated_MaxThrust)
print("Estimated Maximum Jet Power: %0.1f W" % estiamted_MaxPower)
242/51:
Din = 13.0                # diameter, in
D = Din*2.54/100          # diameter, m
RPM = 3200.0              # rotations per minute 
N = RPM/60                # rotation rate, rev p sec
rho = 1025                # water density kg/m^3
T =  1                    # thrust
Q = 1                     # Torque
Vs_kts = 7                # Ship speed
Vs = Vs_kts*0.5           # Ship speed, m/s
Va = Vs                   # Mean inflow veloicty.
A = 2*np.pi*(D/2)**2      # Prop area
Rt = T                    # Total ship resistance (units??)

# Non-dimenstional Characterizatio of Prop Performance
J = Va/(N*D)              # Advancement Coefficient
Kt = T/(rho*N**2*D**4)    # Thrust Coef
Ct = 2*T/(rho*A*Va**2)    # Thrust Coef
Kq = Q/(rho*N**2*D**5)    # Torque Coef
eta_o = (T*Va) / (2*np.pi*N*Q)  # Prop Efficiency
eta_t = (Rt*Vs) / 2*np.pi*N*Q   # Propulsive Efficiency
242/52:
HP = 20                   # Shaft HP
Din = 13.0                # diameter, in
D = Din*2.54/100          # diameter, m
RPM = 3200.0              # rotations per minute 
N = RPM/60                # rotation rate, rev p sec
rho = 1025                # water density kg/m^3
T = estimated_MaxThrust   # thrust
Q = 5252.0 * HP / RPM     # Torque
Vs_kts = 7                # Ship speed
Vs = Vs_kts*0.5           # Ship speed, m/s
Va = Vs                   # Mean inflow veloicty.
A = 2*np.pi*(D/2)**2      # Prop area
Rt = T                    # Total ship resistance (units??)

# Non-dimenstional Characterizatio of Prop Performance
J = Va/(N*D)              # Advancement Coefficient
Kt = T/(rho*N**2*D**4)    # Thrust Coef
Ct = 2*T/(rho*A*Va**2)    # Thrust Coef
Kq = Q/(rho*N**2*D**5)    # Torque Coef
eta_o = (T*Va) / (2*np.pi*N*Q)  # Prop Efficiency
eta_t = (Rt*Vs) / 2*np.pi*N*Q   # Propulsive Efficiency
242/53: print(Ct)
242/54:
HP = 20                   # Shaft HP
Din = 13.0                # diameter, in
D = Din*2.54/100          # diameter, m
RPM = 3200.0              # rotations per minute 
N = RPM/60                # rotation rate, rev p sec
rho = 1025                # water density kg/m^3
T = estimated_MaxThrust   # thrust
Q = 5252.0 * HP / RPM     # Torque
Vs_kts = 7                # Ship speed
Vs = Vs_kts*0.5           # Ship speed, m/s
Va = Vs                   # Mean inflow veloicty.
A = 2*np.pi*(D/2)**2      # Prop area
Rt = T                    # Total ship resistance (units??)

# Non-dimenstional Characterizatio of Prop Performance
J = Va/(N*D)              # Advancement Coefficient
Kt = T/(rho*N**2*D**4)    # Thrust Coef
Ct = 2*T/(rho*A*Va**2)    # Thrust Coef
Kq = Q/(rho*N**2*D**5)    # Torque Coef
eta_o = (T*Va) / (2*np.pi*N*Q)  # Prop Efficiency
eta_t = (Rt*Vs) / 2*np.pi*N*Q   # Propulsive Efficiency
lambda = J/np.pi
242/55:
HP = 20                   # Shaft HP
Din = 13.0                # diameter, in
D = Din*2.54/100          # diameter, m
RPM = 3200.0              # rotations per minute 
N = RPM/60                # rotation rate, rev p sec
rho = 1025                # water density kg/m^3
T = estimated_MaxThrust   # thrust
Q = 5252.0 * HP / RPM     # Torque
Vs_kts = 7                # Ship speed
Vs = Vs_kts*0.5           # Ship speed, m/s
Va = Vs                   # Mean inflow veloicty.
A = 2*np.pi*(D/2)**2      # Prop area
Rt = T                    # Total ship resistance (units??)

# Non-dimenstional Characterizatio of Prop Performance
J = Va/(N*D)              # Advancement Coefficient
Kt = T/(rho*N**2*D**4)    # Thrust Coef
Ct = 2*T/(rho*A*Va**2)    # Thrust Coef
Kq = Q/(rho*N**2*D**5)    # Torque Coef
eta_o = (T*Va) / (2*np.pi*N*Q)  # Prop Efficiency
eta_t = (Rt*Vs) / 2*np.pi*N*Q   # Propulsive Efficiency
abs_lambda = J/np.pi
242/56:
print(abs_lambda)
print(Ct)
242/57:
HP = 20                   # Shaft HP
Din = 13.0                # diameter, in
D = Din*2.54/100          # diameter, m
RPM = 3200.0              # rotations per minute 
N = RPM/60                # rotation rate, rev p sec
rho = 1025                # water density kg/m^3
T = estimated_MaxThrust   # thrust
Q = 5252.0 * HP / RPM     # Torque
Vs_kts = 5.5                # Ship speed
Vs = Vs_kts*0.5           # Ship speed, m/s
Va = Vs                   # Mean inflow veloicty.
A = 2*np.pi*(D/2)**2      # Prop area
Rt = T                    # Total ship resistance (units??)

# Non-dimenstional Characterizatio of Prop Performance
J = Va/(N*D)              # Advancement Coefficient
Kt = T/(rho*N**2*D**4)    # Thrust Coef
Ct = 2*T/(rho*A*Va**2)    # Thrust Coef
Kq = Q/(rho*N**2*D**5)    # Torque Coef
eta_o = (T*Va) / (2*np.pi*N*Q)  # Prop Efficiency
eta_t = (Rt*Vs) / 2*np.pi*N*Q   # Propulsive Efficiency
abs_lambda = J/np.pi
242/58:
print(abs_lambda)
print(Ct)
242/59:
print(abs_lambda)
print(Ct)
print(J)
243/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
from mpl_toolkits.basemap import Basemap
import warnings
warnings.filterwarnings('ignore')

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook
243/2:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
243/3:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
243/4:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
243/5:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
243/6:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
243/7:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
243/8:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
243/9: rvgs_rssi.index
243/10:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
243/11:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
243/12: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
243/13: data.head()
243/14:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
243/15:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
243/16:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import matplotlib.pyplot as plt
from pyproj import *
import os
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')
import warnings
warnings.filterwarnings('ignore')

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook
243/17:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
243/18:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
243/19:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
243/20:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
243/21:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
243/22:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
243/23: rvgs_rssi.index
243/24:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
243/25:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
243/26: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
243/27: data.head()
243/28:
plt.figure(figsize=(10,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
243/29:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
243/30:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
243/31:
plt.figure(figsize=(5,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
243/32:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
243/33:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
243/34:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
243/35:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.show()
243/36:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.show()
243/37:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
243/38:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
243/39:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
243/40:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
243/41: #dgb_stats['rvgs_SNR_db']
243/42:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
243/43:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
243/44:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
243/45:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
243/46:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
243/47:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
243/48:
%%html 
<div class=image>
<img style="width:1000px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png"" />

</div>
243/49:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png"" />

</div>
243/50:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
243/51:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
243/52:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 18
plt.rcParams['axes.titlesize'] = 20
plt.rcParams['font.size'] = 16
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 14

plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
243/53:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 18
plt.rcParams['axes.titlesize'] = 20
plt.rcParams['font.size'] = 16
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 14

plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
243/54:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
243/55:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
243/56:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
243/57:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
243/58:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
243/59:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
243/60: rvgs_rssi.index
243/61:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
243/62:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
243/63: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
243/64: data.head()
243/65:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
243/66:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
243/67:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
243/68:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
244/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 18
plt.rcParams['axes.titlesize'] = 20
plt.rcParams['font.size'] = 16
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 14

plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
244/2:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
244/3:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
244/4:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
244/5:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
244/6:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
244/7:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
244/8: rvgs_rssi.index
244/9:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
244/10:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
244/11: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
244/12: data.head()
244/13:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
244/14:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
244/15:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
244/16:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.show()
244/17:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.show()
244/18:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
244/19:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
244/20:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
244/21:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
244/22: #dgb_stats['rvgs_SNR_db']
244/23:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
244/24:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 18
plt.rcParams['axes.titlesize'] = 20
plt.rcParams['font.size'] = 16
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 14

#plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
244/25:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
244/26:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
244/27:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
244/28:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
244/29:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
244/30: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
245/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 18
plt.rcParams['axes.titlesize'] = 20
plt.rcParams['font.size'] = 16
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 14

#plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
245/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
245/3:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
245/4:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
245/5:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
245/6: rvgs_rssi.index
245/7:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
245/8:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
245/9: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
245/10: data.head()
245/11:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
245/12:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 18
plt.rcParams['axes.titlesize'] = 20
plt.rcParams['font.size'] = 16
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 14

#plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
245/13:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
245/14:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
245/15:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
245/16:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
245/17:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
245/18:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
245/19: rvgs_rssi.index
245/20:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
245/21:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
245/22: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
245/23: data.head()
245/24:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
245/25:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
245/26:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
245/27:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.show()
245/28:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.show()
245/29:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
245/30:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
245/31:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
245/32:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
245/33: #dgb_stats['rvgs_SNR_db']
245/34:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
245/35:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
245/36:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
245/37:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
245/38:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
245/39:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
245/40:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
245/41:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
247/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 18
plt.rcParams['axes.titlesize'] = 20
plt.rcParams['font.size'] = 16
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 14

#plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
247/2:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
247/3:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
247/4:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
247/5:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
247/6:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
247/7:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
247/8: rvgs_rssi.index
247/9:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
247/10:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
247/11: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
247/12: data.head()
247/13:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
247/14:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
247/15:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
247/16:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.show()
247/17:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.show()
247/18:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
247/19:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
247/20:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
247/21:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
247/22: #dgb_stats['rvgs_SNR_db']
247/23:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
247/24:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
247/25:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
247/26:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
247/27:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
247/28:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
247/29:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
247/30:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
247/31:
plt.figure()
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
247/32:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 18
plt.rcParams['axes.titlesize'] = 20
plt.rcParams['font.size'] = 16
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 14

#plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
247/33:
plt.figure()
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
247/34:
plt.figure()
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
247/35:
plt.figure()
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
247/36:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
247/37:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
plt.xlabel('Measurement Number'
plt.ylabel('Seconds of Gap')
247/38:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
247/39:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout
247/40:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 16
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 14

#plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
247/41:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
247/42:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
247/43:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
247/44:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
247/45:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
247/46:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
247/47: rvgs_rssi.index
247/48:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
247/49:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
247/50: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
247/51: data.head()
247/52:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout
247/53:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

#plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
247/54:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout
247/55:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

plt.rcParams['savefig.dpi'] = 75

plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

#plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
247/56:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
247/57:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
247/58:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
247/59:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
247/60:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
247/61:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
247/62: rvgs_rssi.index
247/63:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
247/64:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
247/65: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
247/66: data.head()
247/67:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout
247/68:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
247/69:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.show()
247/70:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.show()
247/71:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.show()
247/72:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
247/73:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
247/74:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
247/75:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
247/76: #dgb_stats['rvgs_SNR_db']
247/77:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
247/78:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
247/79:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
247/80:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
247/81:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
247/82:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
247/83:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
247/84:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
247/85:
# Time spans of data.
plt.figure(figsize=(7,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
247/86:
# Time spans of data.
plt.figure(figsize=(10,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
247/87:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
247/88:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.tight_layout()
plt.show()
247/89:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
248/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

params = {
    'axes.labelsize': 8,
    'axes.titlesize':12,
    'text.fontsize': 8,
    'legend.fontsize': 10,
    'xtick.labelsize': 10,
    'ytick.labelsize': 10,
    'text.usetex': False,
    'figure.figsize': [4.5, 4.5]
   }
rcParams.update(params)

plt.rcParams['savefig.dpi'] = 75

#plt.rcParams['figure.autolayout'] = False
#plt.rcParams['figure.figsize'] = 10, 6
#plt.rcParams['axes.labelsize'] = 16
#plt.rcParams['axes.titlesize'] = 18
#plt.rcParams['font.size'] = 14
#plt.rcParams['lines.linewidth'] = 2.0
#plt.rcParams['lines.markersize'] = 8
#plt.rcParams['legend.fontsize'] = 12

#plt.rcParams['text.usetex'] = True
#plt.rcParams['font.family'] = "serif"
#plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
248/2:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

params = {
    'axes.labelsize': 8,
    'axes.titlesize':12,
    'text.fontsize': 8,
    'legend.fontsize': 10,
    'xtick.labelsize': 10,
    'ytick.labelsize': 10,
    'text.usetex': False,
    'figure.figsize': [4.5, 4.5]
   }
plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 75

#plt.rcParams['figure.autolayout'] = False
#plt.rcParams['figure.figsize'] = 10, 6
#plt.rcParams['axes.labelsize'] = 16
#plt.rcParams['axes.titlesize'] = 18
#plt.rcParams['font.size'] = 14
#plt.rcParams['lines.linewidth'] = 2.0
#plt.rcParams['lines.markersize'] = 8
#plt.rcParams['legend.fontsize'] = 12

#plt.rcParams['text.usetex'] = True
#plt.rcParams['font.family'] = "serif"
#plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
248/3:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

params = {
    'axes.labelsize': 8,
    'axes.titlesize':12,
    'font.size': 8,
    'legend.fontsize': 10,
    'xtick.labelsize': 10,
    'ytick.labelsize': 10,
    'text.usetex': False,
    'figure.figsize': [4.5, 4.5]
   }
plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 75

#plt.rcParams['figure.autolayout'] = False
#plt.rcParams['figure.figsize'] = 10, 6
#plt.rcParams['axes.labelsize'] = 16
#plt.rcParams['axes.titlesize'] = 18
#plt.rcParams['font.size'] = 14
#plt.rcParams['lines.linewidth'] = 2.0
#plt.rcParams['lines.markersize'] = 8
#plt.rcParams['legend.fontsize'] = 12

#plt.rcParams['text.usetex'] = True
#plt.rcParams['font.family'] = "serif"
#plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
248/4:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
248/5:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
248/6:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
248/7:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
248/8:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
248/9:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
248/10: rvgs_rssi.index
248/11:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
248/12:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
248/13: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
248/14: data.head()
248/15:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout
248/16:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
248/17:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
248/18:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.tight_layout()
plt.show()
248/19:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
248/20:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
248/21:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
248/22:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
248/23:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
248/24: #dgb_stats['rvgs_SNR_db']
248/25:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
248/26:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
248/27:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
248/28:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
248/29:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
248/30:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
248/31:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
248/32:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
249/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 75

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

#plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
#plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
249/2:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
249/3:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:500px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
249/4:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
249/5:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
249/6:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
249/7:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
249/8: rvgs_rssi.index
249/9:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
249/10:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
249/11: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
249/12: data.head()
249/13:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.show()
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout
249/14:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
249/15:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
249/16:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.tight_layout()
plt.show()
249/17:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
249/18:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
249/19:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
249/20:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
249/21:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
249/22: #dgb_stats['rvgs_SNR_db']
249/23:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
249/24:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
249/25:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
249/26:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
249/27:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
249/28:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
249/29:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
249/30:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
249/31:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:300px" src="Silviustesting/IMG_0788.JPG" />
<div> <p>Radio installation aboard the RV Gulf Surveyory. 
Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
</div>
249/32:
%%html 
<div class=image>
<img style="float: left; transform: rotate(90deg); width:300px" src="Silviustesting/IMG_0781.JPG" />
<div><p>Radio installation aboard the RV Galen J. 
Height of antennas above the water line is approximately 1.5 m. 
A second installation on the back of the pilot house is not shown at 2.6 m</p>
</div>
</div>
249/33:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
249/34:
#%%html 
#<div class=image>
#<img style="float: left; transform: rotate(90deg); width:300px" src="Silviustesting/IMG_0788.JPG" />
#<div> <p>Radio installation aboard the RV Gulf Surveyory. 
#Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
#</div>

![Radio installation aboard the RV Gulf Surveyory. 
#Height of antennas above the water line is approximately 14 ft (4.3 m)](src="Silviustesting/IMG_0788.JPG")
249/35:
#%%html 
#<div class=image>
#<img style="float: left; transform: rotate(90deg); width:300px" src="Silviustesting/IMG_0788.JPG" />
#<div> <p>Radio installation aboard the RV Gulf Surveyory. 
#Height of antennas above the water line is approximately 14 ft (4.3 m).</p> </div>
#</div>

![Radio installation aboard the RV Gulf Surveyory. Height of antennas above the water line is approximately 14 ft (4.3 m)](src="Silviustesting/IMG_0788.JPG")
249/36: ![Radio installation aboard the RV Gulf Surveyory. Height of antennas above the water line is approximately 14 ft (4.3 m)]("Silviustesting/IMG_0788.JPG")
249/37:
#<img src="Silviustesting/IMG_0788.JPG"
#     alt=""
#     style="width:300px;" />
249/38:
#<img src="Silviustesting/IMG_0781.JPG"
#     alt=""
#     style="width:300px;" />
249/39:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 75

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
249/40:
#<img src="Silviustesting/IMG_0788.JPG"
#     alt=""
#     style="width:300px;" />
249/41:
#<img src="Silviustesting/IMG_0781.JPG"
#     alt=""
#     style="width:300px;" />
249/42:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
249/43:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
249/44:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
249/45:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
249/46:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
249/47:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
249/48: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
249/49: data.head()
249/50:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
249/51:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
#plt.tight_layout()
plt.show()
249/52:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
#plt.tight_layout()
plt.show()
249/53:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
249/54:
plt.figure(figsize=(7,5),tight_layout=True)
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
#plt.tight_layout()
plt.show()
249/55:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
#plt.tight_layout()
plt.show()
249/56:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')


WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
%matplotlib notebook

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 75

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"
249/57:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
#plt.tight_layout()
plt.show()
250/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 75

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
250/2:
#<img src="Silviustesting/IMG_0788.JPG"
#     alt=""
#     style="width:300px;" />
252/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 75

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
252/2:
#<img src="Silviustesting/IMG_0788.JPG"
#     alt=""
#     style="width:300px;" />
252/3:
#<img src="Silviustesting/IMG_0781.JPG"
#     alt=""
#     style="width:300px;" />
252/4:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
252/5:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
252/6:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
252/7:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
252/8:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
252/9:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
252/10: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
252/11: data.head()
252/12:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
#plt.tight_layout()
plt.show()
253/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 75

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
253/2:
#<img src="Silviustesting/IMG_0788.JPG"
#     alt=""
#     style="width:300px;" />
253/3:
#<img src="Silviustesting/IMG_0781.JPG"
#     alt=""
#     style="width:300px;" />
253/4:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
253/5:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
253/6:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
253/7:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
253/8:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
253/9:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
253/10: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
253/11: data.head()
253/12:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
#plt.tight_layout()
plt.show()
254/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 75

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
254/2:
#<img src="Silviustesting/IMG_0788.JPG"
#     alt=""
#     style="width:300px;" />
254/3:
#<img src="Silviustesting/IMG_0781.JPG"
#     alt=""
#     style="width:300px;" />
254/4:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
254/5:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
254/6:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
254/7:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
254/8:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
254/9:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
254/10: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
254/11: data.head()
254/12:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
#plt.tight_layout()
plt.show()
254/13:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
254/14:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
254/15:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
254/16:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.tight_layout()
plt.show()
254/17:
#T = data.index > "2018-02-22 23:26:00"
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
254/18:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
254/19:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
254/20:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
254/21:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
254/22: #dgb_stats['rvgs_SNR_db']
254/23:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
254/24:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
254/25:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
254/26:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
254/27:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
254/28:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
254/29:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
254/30:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
254/31:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.ylabel('Seconds')
plt.xlabel('Measurement Number')
plt.tight_layout()
plt.show()
254/32:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 150

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
254/33:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
254/34:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
254/35:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
254/36:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
254/37:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
254/38:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
254/39: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
254/40: data.head()
254/41:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
254/42:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
254/43:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
254/44:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.ylabel('Seconds')
plt.xlabel('Measurement Number')
plt.tight_layout()
plt.show()
254/45:
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
254/46:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
254/47:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
254/48:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
254/49:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
254/50: #dgb_stats['rvgs_SNR_db']
254/51:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
254/52:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
254/53:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
254/54:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
254/55:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
254/56:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
254/57:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
254/58:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
256/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 150

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
256/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
256/3:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
256/4:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
256/5:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
256/6:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
256/7:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
256/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
256/9: data.head()
256/10:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
256/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
256/12:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
256/13:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.ylabel('Seconds')
plt.xlabel('Measurement Number')
plt.tight_layout()
plt.show()
256/14:
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
256/15:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
256/16:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
256/17:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
256/18:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
256/19: #dgb_stats['rvgs_SNR_db']
256/20:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
256/21:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
256/22:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
256/23:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
256/24:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
256/25:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
256/26:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
257/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 150

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
257/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
257/3:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
257/4:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
257/5:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
257/6:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
257/7:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
257/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
257/9: data.head()
257/10:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
257/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
257/12:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
257/13:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.ylabel('Seconds')
plt.xlabel('Measurement Number')
plt.tight_layout()
plt.show()
257/14:
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
257/15:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
257/16:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
257/17:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
257/18:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
257/19: #dgb_stats['rvgs_SNR_db']
257/20:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
257/21:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
257/22:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
257/23:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
257/24:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
257/25:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
257/26:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
257/27:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
258/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 150

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
258/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

rvgsdf.head()
258/3:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

galendf.head()
258/4:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
bw.head()
258/5:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

rvgs_rssi.head()
258/6:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

galen_rssi.head()
258/7:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
258/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
258/9: data.head()
258/10:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
258/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
258/12:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
258/13:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.ylabel('Seconds')
plt.xlabel('Measurement Number')
plt.tight_layout()
plt.show()
258/14:
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
258/15:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
258/16:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent/and Received vs Distance')
plt.show()
258/17:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
258/18:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
258/19: #dgb_stats['rvgs_SNR_db']
258/20:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
258/21:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
258/22:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
258/23:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
258/24:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
258/25:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
258/26:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
258/27:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
258/28:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent and Received vs Distance')
plt.show()
258/29:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

print("Summary:")
rvgsdf.head()
258/30:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

print("Summary:")
galendf.head()
258/31:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
print("Summary:")
bw.head()
258/32:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
print("Summary:")
rvgs_rssi.head()
258/33:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)
print("Summary:")
galen_rssi.head()
258/34:
print("Summary:")
data.head()
259/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 300

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
259/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

print("Summary:")
rvgsdf.head()
259/3:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

print("Summary:")
galendf.head()
259/4:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
print("Summary:")
bw.head()
259/5:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
print("Summary:")
rvgs_rssi.head()
259/6:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)
print("Summary:")
galen_rssi.head()
259/7:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
259/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
259/9:
print("Summary:")
data.head()
259/10:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
259/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
259/12:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
259/13:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.ylabel('Seconds')
plt.xlabel('Measurement Number')
plt.tight_layout()
plt.show()
259/14:
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
259/15:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
259/16:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent and Received vs Distance')
plt.show()
259/17:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
259/18:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
259/19: #dgb_stats['rvgs_SNR_db']
259/20:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()

plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()

# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
259/21:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
259/22:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()

#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
259/23:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
259/24:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
259/25:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
259/26:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
259/27:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
259/28:
%%html 
<div class=image>
<img style="width:800px" 
src="MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png" />
</div>
259/29:
%%html 
<div class=image>
<img style="width:800px" 
src="MN-MIMO_Link_Budget_Calculator_CCOM_Trial_4W.png" />
</div>
259/30:
%%html 
<div class=image>
<img style="width:700px" 
src="MN-MIMO_Link_Budget_Calculator_CCOM_Trial_4W.png" />
</div>
259/31:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
import matplotlib
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 300

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
259/32:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

print("Summary:")
rvgsdf.head()
259/33:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
plt.savefig('Timespan.png',dpi=300,orientaiton='landscape',facecolor='w')
259/34:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.ylabel('Seconds')
plt.xlabel('Measurement Number')
plt.tight_layout()
plt.show()
plt.savefig('delta_timespan.png',dpi=300,orientaiton='landscape',facecolor='w')
259/35:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
plt.savefig('MBytes_vs_distance.png',dpi=300,orientaiton='landscape',facecolor='w')
259/36:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent and Received vs Distance')
plt.show()
plt.savefig('MBits_vs_distance.png',dpi=300,orientaiton='landscape',facecolor='w')
259/37:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
plt.savefig('SNR_vs_Time.png',dpi=300,orientaiton='landscape',facecolor='w')
259/38:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()
plt.savefig('SNR_vs_distance_pts.png',dpi=300,orientaiton='landscape',facecolor='w')



plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()
plt.savefig('SNR_vs_distance_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')



plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()
plt.savefig('SNR_vs_distance_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')


# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
plt.savefig('SNR_vs_distance_semilog.png',dpi=300,orientaiton='landscape',facecolor='w')
259/39:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
plt.savefig('MBytes_vs_distance_w_mean.png',dpi=300,orientaiton='landscape',facecolor='w')


plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
plt.savefig('Mbits_vs_distance_w_mean.png',dpi=300,orientaiton='landscape',facecolor='w')
259/40:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()
plt.savefig('Mbits_vs_distance_w_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()
plt.savefig('Mbits_vs_distance_w_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')


#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
259/41:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
plt.savefig('Distance_vs_time_by_MBytes.png',dpi=300,orientaiton='landscape',facecolor='w')
259/42:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
plt.savefig('Distance_vs_time_by_MBits.png',dpi=300,orientaiton='landscape',facecolor='w')
259/43:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
plt.savefig('SatMap_w_tracks.png',dpi=300,orientaiton='landscape',facecolor='w')
260/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
import matplotlib
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 300

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
260/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

print("Summary:")
rvgsdf.head()
260/3:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

print("Summary:")
galendf.head()
260/4:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
print("Summary:")
bw.head()
260/5:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
print("Summary:")
rvgs_rssi.head()
260/6:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)
print("Summary:")
galen_rssi.head()
260/7:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
260/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
260/9:
print("Summary:")
data.head()
260/10:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
260/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
260/12:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
plt.savefig('plots/Timespan.png',dpi=300,orientaiton='landscape',facecolor='w')
260/13:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.ylabel('Seconds')
plt.xlabel('Measurement Number')
plt.tight_layout()
plt.show()
plt.savefig('delta_timespan.png',dpi=300,orientaiton='landscape',facecolor='w')
260/14:
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
plt.savefig('plots/distance_vs_time.png',dpi=300,orientaiton='landscape',facecolor='w')
260/15:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('Mega Bytes Sent and Received vs Distance')
plt.show()
plt.savefig('plots/MBytes_vs_distance.png',dpi=300,orientaiton='landscape',facecolor='w')
260/16:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent and Received vs Distance')
plt.show()
plt.savefig('MBits_vs_distance.png',dpi=300,orientaiton='landscape',facecolor='w')
260/17:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
plt.savefig('plots/SNR_vs_Time.png',dpi=300,orientaiton='landscape',facecolor='w')
260/18:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
260/19: #dgb_stats['rvgs_SNR_db']
260/20:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()
plt.savefig('plots/SNR_vs_distance_pts.png',dpi=300,orientaiton='landscape',facecolor='w')



plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()
plt.savefig('plots/SNR_vs_distance_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')



plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()
plt.savefig('plots/SNR_vs_distance_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')


# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
plt.savefig('plots/SNR_vs_distance_semilog.png',dpi=300,orientaiton='landscape',facecolor='w')
260/21:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
plt.savefig('plots/MBytes_vs_distance_w_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')


plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
plt.savefig('plots/MBytes_vs_distance_w_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')
260/22:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()
plt.savefig('plots/Mbits_vs_distance_w_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()
plt.savefig('plots/Mbits_vs_distance_w_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')


#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
260/23:
%%html 
<div class=image>
<img style="width:700px" 
src="MN-MIMO_Link_Budget_Calculator_CCOM_Trial_4W.png" />
</div>
260/24:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
plt.savefig('plots/Distance_vs_time_by_MBytes.png',dpi=300,orientaiton='landscape',facecolor='w')
260/25:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
plt.savefig('plots/Distance_vs_time_by_MBits.png',dpi=300,orientaiton='landscape',facecolor='w')
260/26:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
plt.savefig('plots/SatMap_w_tracks.png',dpi=300,orientaiton='landscape',facecolor='w')
260/27:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
plt.savefig('plots/Directivity_gain_vs_Beamwidth.png',dpi=300,orientaiton='landscape',facecolor='w')
260/28:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
plt.savefig('plots/TimeGaps.png',dpi=300,orientaiton='landscape',facecolor='w')
260/29:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MBytes Sent and Received vs Distance')
plt.show()
plt.savefig('plots/MBytes_vs_distance.png',dpi=300,orientaiton='landscape',facecolor='w')
260/30:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent and Received vs Distance')
plt.show()
plt.savefig('plots/MBits_vs_distance.png',dpi=300,orientaiton='landscape',facecolor='w')
260/31:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
plt.savefig('plots/SatMap_w_tracks.png',dpi=300,orientaiton='landscape',facecolor='w')
260/32:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
plt.savefig('plots/TimeGaps.png',dpi=300,orientaiton='landscape',facecolor='w')
261/1:
from IPython.display import Image
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
import matplotlib
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

import warnings
warnings.filterwarnings('ignore')

#params = {
#    'axes.labelsize': 8,
#    'axes.titlesize':12,
#    'font.size': 8,
#    'legend.fontsize': 10,
#    'xtick.labelsize': 10,
#    'ytick.labelsize': 10,
#    'text.usetex': False,
#    'figure.figsize': [4.5, 4.5]
#   }
#plt.rcParams.update(params)

plt.rcParams['savefig.dpi'] = 300

#plt.rcParams['figure.autolayout'] = False
plt.rcParams['figure.figsize'] = 10, 6
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 18
plt.rcParams['font.size'] = 14
plt.rcParams['lines.linewidth'] = 2.0
plt.rcParams['lines.markersize'] = 8
plt.rcParams['legend.fontsize'] = 12

plt.rcParams['text.usetex'] = True
#plt.rcParams['text.usetex'] = False
plt.rcParams['font.family'] = "serif"
plt.rcParams['font.serif'] = "cm"
plt.rcParams['text.latex.preamble'] = "\usepackage{subdepth}, \usepackage{type1cm}"

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")

%matplotlib notebook
261/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

# Geopandas (abandoning this for now)
#rvgs_pts = [Point(xy) for xy in zip(rvgsdf["rvgs_lon"],rvgsdf["rvgs_lat"])]
#rvgs_gdf = gpd.GeoDataFrame(rvgsdf, geometry=rvgs_pts)
#rvgs_gdf.crs = {"init":"epsg:4326"}
#rvgs_gdf = rvgs_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")

# Checking the sample rate of the RVGS nav.
#dt = rvgsdf.index[1:] - rvgsdf.index[:-1]
#np.mean(dt.total_seconds())

print("Summary:")
rvgsdf.head()
261/3:
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

# Geopandas (abandoning this for now)
#galen_pts = [Point(xy) for xy in zip(galendf["galen_lon"],galendf["galen_lat"])]
#galen_gdf = gpd.GeoDataFrame(galendf, geometry=galen_pts)
#galen_gdf.crs = {"init":"epsg:4326"}
#galen_gdf = galen_gdf.to_crs("+proj=utm +zone=19 +ellps=WGS84 +datum=WGS84 +units=m +no_defs")
#galen_gdf.head()

print("Summary:")
galendf.head()
261/4:
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)
print("Summary:")
bw.head()
261/5:
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)
print("Summary:")
rvgs_rssi.head()
261/6:
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)
print("Summary:")
galen_rssi.head()
261/7:
# RVGS radio digital SNR
x = rvgs_rssi.rvgs_sync_signal_power
y = rvgs_rssi.rvgs_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
rvgs_SNR_db = 10*np.log10(SNRmw) 
rvgs_rssi['rvgs_SNR_digital'] = pd.Series(rvgs_SNR_db,index=rvgs_rssi.index)

# Galen radio digital SNR
x = galen_rssi.galen_sync_signal_power
y = galen_rssi.galen_sync_noise_power
z = (y-x) / 51
SNRmw = (x - 12 * z) / (64*z)
SNRmw[SNRmw <= 0] = 1
galen_SNR_db = 10*np.log10(SNRmw) 
galen_rssi['galen_SNR_digital'] = pd.Series(galen_SNR_db,index=galen_rssi.index)

# Calculate the raw SNR values as well. Average the results from each antenna.
snr = np.transpose(np.mean([[rvgs_rssi['rvgs_antenna_1_raw'].values - rvgs_rssi['rvgs_noise_raw'].values],
                                [rvgs_rssi['rvgs_antenna_2_raw'].values - rvgs_rssi['rvgs_noise_raw'].values]],
                           axis=0))

rvgs_rssi['rvgs_SNR_raw'] = pd.Series(np.squeeze(snr),index=rvgs_rssi.index)

snr = np.transpose(np.mean([[galen_rssi['galen_antenna_1_raw'].values - galen_rssi['galen_noise_raw'].values],
                                [galen_rssi['galen_antenna_2_raw'].values - galen_rssi['galen_noise_raw'].values]],axis=0))
galen_rssi['galen_SNR_raw'] = pd.Series(np.squeeze(snr),index=galen_rssi.index)
261/8: data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
261/9:
print("Summary:")
data.head()
261/10:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.show()
plt.savefig('plots/TimeGaps.png',dpi=300,orientaiton='landscape',facecolor='w')
261/11:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
261/12:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.show()
plt.savefig('plots/Timespan.png',dpi=300,orientaiton='landscape',facecolor='w')
261/13:
plt.figure(figsize=(7,5))
dt = galen_rssi.index[1:]-galen_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.')
dt = rvgs_rssi.index[1:] - rvgs_rssi.index[:-1]
plt.plot(dt.total_seconds(),'.m')
plt.grid(True)
plt.ylim(-1,1)
plt.ylabel('Seconds')
plt.xlabel('Measurement Number')
plt.tight_layout()
plt.show()
plt.savefig('delta_timespan.png',dpi=300,orientaiton='landscape',facecolor='w')
261/14:
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.show()
plt.savefig('plots/distance_vs_time.png',dpi=300,orientaiton='landscape',facecolor='w')
261/15:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MBytes Sent and Received vs Distance')
plt.show()
plt.savefig('plots/MBytes_vs_distance.png',dpi=300,orientaiton='landscape',facecolor='w')
261/16:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received']*1024*1024*8/1e6,'b.')
plt.plot(data.distance,data['MBytes/s Sent']*1024*1024*8/1e6,'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bits per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MegaBits Sent and Received vs Distance')
plt.show()
plt.savefig('plots/MBits_vs_distance.png',dpi=300,orientaiton='landscape',facecolor='w')
261/17:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.show()
plt.savefig('plots/SNR_vs_Time.png',dpi=300,orientaiton='landscape',facecolor='w')
261/18:
# Set up time span indices for range tests at two heights.
T1 = (data.index > '2018-02-22 18:30:00') & (data.index < '2018-02-22 19:31:30')
T2 = (data.index > '2018-02-22 19:31:30') & (data.index < '2018-02-22 19:55:00')

data2 = data[T1]
dgb = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
data2 = data[T2]
dgb2 = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).describe()
#dgb2_std = data2.groupby(data2.distance.map(lambda d: np.round(d,decimals=-3))).std()
261/19: #dgb_stats['rvgs_SNR_db']
261/20:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.show()
plt.savefig('plots/SNR_vs_distance_pts.png',dpi=300,orientaiton='landscape',facecolor='w')



plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.show()
plt.savefig('plots/SNR_vs_distance_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')



plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.show()
plt.savefig('plots/SNR_vs_distance_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')


# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.show()
plt.savefig('plots/SNR_vs_distance_semilog.png',dpi=300,orientaiton='landscape',facecolor='w')
261/21:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
plt.savefig('plots/MBytes_vs_distance_w_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')


plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.show()
plt.savefig('plots/MBytes_vs_distance_w_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')
261/22:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.show()
plt.savefig('plots/Mbits_vs_distance_w_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.show()
plt.savefig('plots/Mbits_vs_distance_w_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')


#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
261/23:
%%html 
<div class=image>
<img style="width:700px" 
src="MN-MIMO_Link_Budget_Calculator_CCOM_Trial_4W.png" />
</div>
261/24:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.show()
plt.savefig('plots/Distance_vs_time_by_MBytes.png',dpi=300,orientaiton='landscape',facecolor='w')
261/25:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,
            c=data['MBytes/s Received'][T1]*8*1024*1024/1e6)
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,
            c=data['MBytes/s Received'][T2]*8*1024*1024/1e6)


plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MB/s')
plt.title('MegaBits per Second vs Distance')
plt.grid(True)
plt.show()
plt.savefig('plots/Distance_vs_time_by_MBits.png',dpi=300,orientaiton='landscape',facecolor='w')
261/26:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.show()
plt.savefig('plots/SatMap_w_tracks.png',dpi=300,orientaiton='landscape',facecolor='w')
261/27:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.show()
plt.savefig('plots/Directivity_gain_vs_Beamwidth.png',dpi=300,orientaiton='landscape',facecolor='w')
261/28:
plt.figure(figsize=(7,5))
dt = bw.index[1:]-bw.index[:-1]
plt.plot(dt.total_seconds(),linewidth=2)
plt.xlabel('Measurement Number')
plt.ylabel('Seconds of Gap')
plt.tight_layout()
plt.draw()
plt.savefig('plots/TimeGaps.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/29:
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)

# Calculate the instantaneous distance between vessels. 
dist = np.sqrt( np.power(data["rvgs_e"]-data["galen_e"],2) + np.power(data["rvgs_n"]-data["galen_n"],2))
data['distance'] = pd.Series(dist,index=data.index)
261/30:
plt.figure(figsize=(7,5))
plt.plot(data.distance,'.')
plt.grid(True)
plt.xlabel('Time',fontsize=12)
plt.ylabel('Distance, m')
plt.tight_layout()
plt.draw()
plt.savefig('plots/distance_vs_time.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/31:
plt.figure(figsize=(7,5))
plt.plot(data.distance,data['MBytes/s Received'],'b.')
plt.plot(data.distance,data['MBytes/s Sent'],'g.')
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('Mega Bytes per second')
plt.legend(['Received from Galen','Sent from Galen'])
plt.title('MBytes Sent and Received vs Distance')
plt.draw()
plt.savefig('plots/MBytes_vs_distance.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/32:
plt.figure(figsize=(7,5))
plt.plot(data['rvgs_antenna_1_raw'] - data['rvgs_noise_raw'],'.b')
plt.plot(data['galen_antenna_1_raw'] - data['galen_noise_raw'],'.g')
plt.plot(data['rvgs_SNR_digital'],'.c')
plt.plot(data['galen_SNR_digital'],'.k')
plt.legend(['RVGS raw','Galen raw','RVGS digital','Galen digital'])
plt.grid(True)
plt.ylabel('SNR')
plt.draw()
plt.savefig('plots/SNR_vs_Time.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/33:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.draw()
plt.savefig('plots/MBytes_vs_distance_w_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()


plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1],'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2],'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean'],
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean'],
             yerr=dgb2['MBytes/s Received']['std'] / dgb2['MBytes/s Received']['count'],
             fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBytes per Second')
plt.title('MBytes per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBytes/s 2.6 m','MBytes/s 1.5 m','Avg MBytes/s 2.6 m','Avg MBytes/s 1.5 m'])
plt.draw()
plt.savefig('plots/MBytes_vs_distance_w_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/34:
plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6,fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Dev vs Distance at 2 Antenna Heights')
plt.legend(['MBit/s 2.6 m','MBit/s 1.5 m','Avg MBit/s 2.6 m','Avg MBit/s 1.5 m'])
plt.draw()
plt.savefig('plots/Mbits_vs_distance_w_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()

plt.figure(figsize=(7,5))
plt.plot(data.distance[T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.plot(data.distance[T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g')
plt.errorbar(dgb.distance['mean'],dgb['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb['MBytes/s Received']['std'] / dgb['MBytes/s Received']['count'],fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['MBytes/s Received']['mean']*8*1024*1024/1e6,
             yerr=dgb2['MBytes/s Received']['std']*8*1024*1024/1e6 / dgb2['MBytes/s Received']['count'],fmt='.-g',linewidth=2,capsize=10)
plt.grid(True)
plt.xlabel('Distance, m')
plt.ylabel('MBits per Second')
plt.title('MBits per Second +/- 1 Std Err vs Distance at 2 Antenna Heights')
plt.legend(['MBits/s 2.6 m','MBits/s 1.5 m','Avg MBits/s 2.6 m','Avg MBits/s 1.5 m'])
plt.draw()
plt.savefig('plots/Mbits_vs_distance_w_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()


#Image("MIMO_Link_Budget_Calculator_CCOM_Trial_4W_10db_linkbudget_scale.png")
261/35:
plt.figure(figsize=(7,5))

plt.scatter(data.index[T1].to_pydatetime(),data.distance[T1],s=50,c=data['MBytes/s Received'][T1])
plt.scatter(data.index[T2].to_pydatetime(),data.distance[T2],s=50,c=data['MBytes/s Received'][T2])
plt.xlim('2018-02-22 18:30:00', '2018-02-22 20:00:00')
plt.xlabel('Time')
plt.ylabel('Distance Between Vessels, m')
cbar = plt.colorbar()
cbar.set_label('MBytes/s')
plt.title('MegaBytes per Second vs Distance')
plt.grid(True)
plt.draw()
plt.savefig('plots/Distance_vs_time_by_MBytes.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/36:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean([data['rvgs_lat'],data['galen_lat']])
Lon_0 = np.nanmean([data['rvgs_lon'],data['galen_lon']])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([data['rvgs_lon'],data['galen_lon']]) - lonbuf
LLcrnrlat = np.nanmin([data['rvgs_lat'],data['galen_lat']]) - latbuf
URcrnrlon = np.nanmax([data['rvgs_lon'],data['galen_lon']]) + lonbuf
URcrnrlat = np.nanmax([data['rvgs_lat'],data['galen_lat']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=data['rvgs_lon'],y=data['rvgs_lat'],latlon=True,s=1,c='y')
map.scatter(x=data['galen_lon'],y=data['galen_lat'],latlon=True,s=.5,c='m')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.xlabel('Vertical Extent of Plot %0.1f km' % (vscale/1000.0) )
plt.title('Paths of Vessels')
plt.legend(['RVGS','GALEN'])
plt.draw()
plt.savefig('plots/SatMap_w_tracks.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/37:
# Time spans of data.
plt.figure(figsize=(8,5))
plt.plot(galendf.index,'bo')
plt.plot(rvgsdf.index,'go')
plt.plot(bw.index,'ro')
plt.plot(rvgs_rssi.index,'co')
plt.plot(galen_rssi.index,'ko')
plt.grid(True)
plt.title('Time Spans of Data Sets')
plt.legend(['Galen Nav','RVGS Nav','BW Montor','RVGS Radio','Galen Radio'])
plt.tight_layout()
plt.draw()
plt.savefig('plots/Timespan.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/38:
# 2.6 m
plt.figure(figsize=(7,5))
plt.subplot(211)
plt.scatter(x=data.distance[T1],y=data['galen_SNR_raw'][T1],
            c='b',s=2,alpha=.1)
plt.plot(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)
plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 2.6 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
# 1.5 m
plt.subplot(212)
plt.scatter(x=data.distance[T2],y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.plot(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
         '.-y',linewidth=2)

plt.grid(True)
plt.ylabel('SNR')
plt.title('SNR vs Range, 1.5 m Antenna Height')
plt.xlim(0,7000)
plt.ylim(0,75)
plt.tight_layout()
plt.draw()
plt.savefig('plots/SNR_vs_distance_pts.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()



plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'],
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'],
             fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Dev vs Distance at 2 Rover Antenna Heights')
plt.draw()
plt.savefig('plots/SNR_vs_distance_mean_std.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()



plt.figure(figsize=(7,5))
plt.errorbar(dgb.distance['mean'],dgb['galen_SNR_raw']['mean'],
             yerr=dgb['galen_SNR_raw']['std'] / np.sqrt(dgb['galen_SNR_raw']['count']),
             fmt='.-b',linewidth=2,capsize=10)
plt.errorbar(dgb2.distance['mean'],dgb2['galen_SNR_raw']['mean'],
             yerr=dgb2['galen_SNR_raw']['std'] / np.sqrt(dgb2['galen_SNR_raw']['count'])
             ,fmt='.-g',linewidth=2,capsize=10)
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.grid(True)
plt.xlim(0,7000)
plt.ylim(0,40)
plt.title('Average SNR +/- 1 Std Err vs Distance at 2 Rover Antenna Heights')
plt.draw()
plt.savefig('plots/SNR_vs_distance_mean_stderr.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()


# Log plot.
plt.figure(figsize=(7,5))
plt.scatter(x=np.log10(data.distance[T1]),
             y=data['galen_SNR_raw'][T1],
             c='b',s=2,alpha=.1)
plt.scatter(x=np.log10(data.distance[T2]),
            y=data['galen_SNR_raw'][T2],
            c='g',s=2,alpha=.1)
plt.grid(True)
#plt.xlim(0,7000)
plt.ylim(0,75)
plt.title('SNR vs LOG10(Distance)')
plt.xlabel('LOG10(Distance)')
plt.ylabel('SNR')
plt.legend(['2.6 m Antenna Height','1.5 m Antenna Height'])
plt.draw()
plt.savefig('plots/SNR_vs_distance_semilog.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/39:
plt.figure(figsize=(7,5))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.savefig()
261/40:
plt.figure(figsize=(7,5))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b')
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/41:
plt.figure(figsize=(7,5))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/42:
plt.figure(figsize=(7,5))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.b',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/43:
plt.figure(figsize=(7,5))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/44:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.grid(True)
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/45:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.grid(True,which=major)
plt.grid(True,which=minor)
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/46:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.grid(True,which='major')
plt.grid(True,which='minor')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/47:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on(True)
plt.grid(True,which='major')
plt.grid(True,which='minor')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/48:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on
plt.grid(True,which='major')
plt.grid(True,which='minor')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/49:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/50:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle=':')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/51:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/52:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.3)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.3)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/53:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.1)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.1)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/54:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.01)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.01)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/55:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.01)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.01)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.xlim(0,60)
plt.ylim(0,35)
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/56:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.01)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.01)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.xlim(0,50)
plt.ylim(0,35)
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/57:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.05)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.05)
plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.xlim(0,50)
plt.ylim(0,35)
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/58:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.05)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.05)

fit1 = np.polyfit(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,1)
fit2 = np.polyfit(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,1)
plt.plot(data['galen_SNR_raw'][T1],np.polyval(fit1,data['galen_SNR_raw'][T1]),'-b')


plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.xlim(0,50)
plt.ylim(0,35)
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/59:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.05)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.05)

x = data['galen_SNR_raw'][T1]
x=x[~np.isnan(x)]
y = data['MBytes/s Received'][T1]*8*1024*1024/1e6
y =[y[~ np.isnan(x)]]
#fit1 = np.polyfit(,data['MBytes/s Received'][T1]*8*1024*1024/1e6,1)
#fit2 = np.polyfit(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,1)
#plt.plot(data['galen_SNR_raw'][T1],np.polyval(fit1,data['galen_SNR_raw'][T1]),'-b')


plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.xlim(0,50)
plt.ylim(0,35)
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/60:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.05)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.05)

x = data['galen_SNR_raw'][T1]
x=x[~np.isnan(x)]
y = data['MBytes/s Received'][T1]*8*1024*1024/1e6
y =[y[~ np.isnan(x)]]
fit1 = np.polyfit(x,y,1)
#fit2 = np.polyfit(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,1)
#plt.plot(data['galen_SNR_raw'][T1],np.polyval(fit1,data['galen_SNR_raw'][T1]),'-b')


plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.xlim(0,50)
plt.ylim(0,35)
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/61:
plt.figure(figsize=(10,7))
plt.plot(data['galen_SNR_raw'][T1],data['MBytes/s Received'][T1]*8*1024*1024/1e6,'.b',alpha=.05)
plt.plot(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,'.g',alpha=.05)

x = data['galen_SNR_raw'][T1]
x=x[~np.isnan(x)]
y = data['MBytes/s Received'][T1]*8*1024*1024/1e6
y =y[~ np.isnan(x)]
fit1 = np.polyfit(x,y,1)
#fit2 = np.polyfit(data['galen_SNR_raw'][T2],data['MBytes/s Received'][T2]*8*1024*1024/1e6,1)
#plt.plot(data['galen_SNR_raw'][T1],np.polyval(fit1,data['galen_SNR_raw'][T1]),'-b')


plt.xlabel('SNR')
plt.ylabel('Mbits per Second')
plt.title('Throughput vs SNR')
plt.minorticks_on()
plt.grid(True,which='major')
plt.grid(True,which='minor',linestyle='--')
plt.xlim(0,50)
plt.ylim(0,35)
plt.draw()
plt.savefig('plots/MBits_vs_SNR.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
261/62:
#import numpy as np
#import matplotlib.pyplot as plt
#%matplotlib inline
Beam = np.array([1.0,2,4,6,8,10, 12, 14, 16, 18, 20, 30, 40, 45])
Llambda = 50/Beam
DI = 10*np.log10(2*Llambda)
plt.figure(figsize=(10,7))
plt.plot(Beam,DI,'-o')
plt.grid(True)
plt.xlim(0,50)
plt.xlabel('Beam Width, Deg')
plt.ylabel('Directivity Gain')
plt.title('Directivity Gain from a Uniform Line Array')
plt.draw()
plt.savefig('plots/Directivity_gain_vs_Beamwidth.png',dpi=300,orientaiton='landscape',facecolor='w')
plt.show()
263/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
263/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

##
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

##
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)

##
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

## 
data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
263/3:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
263/4:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
from pyproj import *
WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
263/5:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

##
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

##
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)

##
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

## 
data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
263/6:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

##
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

##
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)

##
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

##
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

## 
data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
263/7: store = pd.HDFStore('bandwidthdata.h5')
264/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
from pyproj import *
WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
264/2:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

##
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

##
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)

##
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

##
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

## 
data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
264/3: store = pd.HDFStore('')
264/4: store = pd.HDFStore('bandwidth_data.h5')
264/5: store['data'] = data
264/6: store
264/7: data.shape()
264/8: data.shape
264/9: store.close()
264/10: store2 = pd.HDFStore('bandwidth_data.h5')
264/11: ls -l
264/12: ls -lh
264/13: store2['data'].keys()
264/14: store2['data'].head()
264/15: ls -lh
264/16:
%%timeit
store2['data'].describe()
264/17:
%%timeit
pass
store2['data'].describe()
264/18:
%%timeit
pass
data.describe()
264/19:
# Try as appendable table rather than fixed...
pd.read_hdf('bandwidth_data.h5','data',where=index>pd.Timestamp('2018-02-22 12:00:00'))

#store2 = pd.HDFStore('bandwidth_data.h5')
264/20:
# Try as appendable table rather than fixed...
pd.read_hdf('bandwidth_data.h5','data',where='index>pd.Timestamp('2018-02-22 12:00:00')')

#store2 = pd.HDFStore('bandwidth_data.h5')
264/21:
# Try as appendable table rather than fixed...
pd.read_hdf('bandwidth_data.h5','data',where='index>pd.Timestamp('20180222 12:00:00')')

#store2 = pd.HDFStore('bandwidth_data.h5')
264/22:
# Try as appendable table rather than fixed...
pd.read_hdf('bandwidth_data.h5','data',where='index>pd.Timestamp('22-02-2018 12:00:00')')

#store2 = pd.HDFStore('bandwidth_data.h5')
264/23:
# Try as appendable table rather than fixed...
pd.read_hdf('bandwidth_data.h5','data',where='index>pd.Timestamp("22-02-2018 12:00:00")')

#store2 = pd.HDFStore('bandwidth_data.h5')
264/24:
# Try as appendable table rather than fixed...
store = pd.HDFStore('bandwidth_data.h5',format=table)
store['data'] = data
#store2 = pd.HDFStore('bandwidth_data.h5')
264/25:
# Try as appendable table rather than fixed...
store = pd.HDFStore('bandwidth_data.h5',format='table')
store['data'] = data
#store2 = pd.HDFStore('bandwidth_data.h5')
264/26: store.close()
264/27: store2.close()
264/28: store2=pd.HDFStore('bandwidth_data.h5')
264/29:
%%timeit
pass
store2['data'].describe()
264/30: store2.close()
264/31: store pd.HDFStore('bandwidth_data.h5',complevel=1,complib='bzip2')
264/32: store=pd.HDFStore('bandwidth_data.h5',complevel=1,complib='bzip2')
264/33: ls -lh
264/34:
store=pd.HDFStore('bandwidth_data.h5',complevel=1,complib='bzip2')
store['data']=data
store.close()
264/35: ls -lh
264/36:
store=pd.HDFStore('bandwidth_data.h5',complevel=1,complib='bzip2')
store['data']=data
store.close()
264/37: ls -lh
264/38:
store=pd.HDFStore('bandwidth_data_uncompressed.h5')
store['data'] = data
store.close()
ls -lh
264/39: ls -lh
264/40:
store = pd.HDFStore('bandwidth_data_uncompressed.h5')
udata = store['data']
udata.head()
264/41: store.close()
264/42:
store = pd.HDFStore('bandwidth_data.h5')
cdata = store['data']
cdata.head()
store.close()
264/43:
rvgs = np.loadtxt('../rvgs/POSMV/Silvius.002_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': rvgs[:,0], 
                'month': rvgs[:,1],
                'day': rvgs[:,2],
                'hour': rvgs[:,3],
                'minute': rvgs[:,4],
                'second': rvgs[:,5]})
rvgsdf = pd.DataFrame(rvgs[:,6:],index=dates)
rvgsdf.rename(columns={0:"rvgs_lat",1:"rvgs_lon"},inplace=True)
rvgs_e, rvgs_n = transform(WGS84,UTM19N,rvgsdf['rvgs_lon'].tolist(),
                           rvgsdf['rvgs_lat'].tolist())
rvgsdf['rvgs_e'] = pd.Series(rvgs_e,index=rvgsdf.index)
rvgsdf['rvgs_n'] = pd.Series(rvgs_n,index=rvgsdf.index)

##
galen = np.loadtxt('../galinJ/GalenJGPS_NoTime.txt_parsed_GGA_fixed.txt')
dates = pd.to_datetime({'year': galen[:,0], 
                'month': galen[:,1],
                'day': galen[:,2],
                'hour': galen[:,3],
                'minute': galen[:,4],
                'second': galen[:,5]})
galendf = pd.DataFrame(galen[:,6:],index=dates)
galendf.rename(columns={0:"galen_lat",1:"galen_lon"},inplace=True)
galen_e, galen_n = transform(WGS84,UTM19N,galendf['galen_lon'].tolist(),
                             galendf['galen_lat'].tolist())
galendf['galen_e'] = pd.Series(galen_e,index=galendf.index)
galendf['galen_n'] = pd.Series(galen_n,index=galendf.index)

##
bw=pd.read_csv('../rvgs/BWmonitor/ParsedBW.csv')
#import datetime
#dt = [datetime.datetime.fromtimestamp(x) for x in bw['Unixtime']]
#dates = pd.Timestamp(dt)
#dates = pd.to_datetime(pd.Series(dt[:]))

dates = pd.to_datetime(pd.Series(bw['Unixtime']),unit='s',origin='unix')
bw.set_index(dates,inplace=True)
# There was some testing the previous day captured in the log. Omit this.
bw = bw[bw.index > '2018-02-22 12:00:00']
# Adjust to GMT
bw.index = bw.index + pd.Timedelta(hours=-5)

##
rvgs_rssi = pd.read_csv('../rvgs/BWmonitor/' + \
                                  'udp_rssi_2018-02-22T15-22-31_RVGS.txt',
                        index_col='iso_timestamp',parse_dates=True,
                        infer_datetime_format=True)
rvgs_rssi.rename(columns={"unix_timestamp":"rvgs_unixtimestamp",
                          "antenna_1_raw":"rvgs_antenna_1_raw",
                          "antenna_2_raw":"rvgs_antenna_2_raw",
                          "noise_raw":"rvgs_noise_raw",
                          "sync_signal_power":"rvgs_sync_signal_power",
                         "sync_noise_power":"rvgs_sync_noise_power"},
                 inplace=True)

##
galen_rssi = pd.read_csv('../galinJ/' + \
                                   'udp_rssi_2018-02-22T15-33-50_GalenJ.txt',
                        index_col = 'iso_timestamp',parse_dates=True,
                         infer_datetime_format=True)
galen_rssi.rename(columns={"unix_timestamp":"galen_unixtimestamp",
                          "antenna_1_raw":"galen_antenna_1_raw",
                          "antenna_2_raw":"galen_antenna_2_raw",
                          "noise_raw":"galen_noise_raw",
                          "sync_signal_power":"galen_sync_signal_power",
                         "sync_noise_power":"galen_sync_noise_power"},
                  inplace=True)

## 
data = pd.concat([rvgsdf, galendf, bw, rvgs_rssi, galen_rssi])
data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)
264/44:
store
store.info()
264/45: store = pd.HDFStore('bandwidth_data.h5')
264/46:
store['data'] = data
store.info()
data.shape()
264/47:
store['data'] = data
store
data.shape()
264/48:
store['data'] = data
store
data.shape
264/49: store.close()
264/50: ls -lh | grep h5
264/51: Create another store object of the same name
264/52: store2 = pd.HDFStore('bandwidth_data.h5')
264/53: ls -lh | grep h5
264/54:
Original remains. Creating the store object doesn not create the actual file. 

Use this new store object to access the file we had already created.
264/55: store2['data'].keys()
264/56: store2['data'].head()
264/57:
%%timeit
pass
store2['data'].describe()
264/58:
%%timeit
pass
data.describe()
264/59: store2.close()
264/60:
# Try as appendable table rather than fixed..
store = pd.HDFStore('bandwidth_data_table.h5',format='table')
store['data'] = data
store.close()
264/61: store=pd.HDFStore('bandwidth_data_table.h5')
264/62:
%%timeit
pass
store['data'].describe()
store.close()
264/63:
%%timeit
pass
store['data'].describe()
264/64: store=pd.HDFStore('bandwidth_data_table.h5')
264/65:
%%timeit
pass
store['data'].describe()
264/66: store.close()
264/67: ls -lh | grep h5
264/68:
store=pd.HDFStore('bandwidth_data_bz2_c5.h5',complevel=5,complib='bzip2')
store['data']=data
store.close()
264/69: ls -lh | grep h5
264/70: store=pd.HDFStore('bandwidth_data_bz2_c5.h5')
264/71:
%%timeit
pass
store['data'].describe()
264/72: store.close()
264/73: whos
264/74: memoryview
264/75: memoryview()
264/76: memoryview(data)
264/77: mem_usage(data)
264/78:
def mem_usage(pandas_obj):
    if isinstance(pandas_obj,pd.DataFrame):
        usage_b = pandas_obj.memory_usage(deep=True).sum()
    else: # we assume if not a df it's a series
        usage_b = pandas_obj.memory_usage(deep=True)
    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes
    return "{:03.2f} MB".format(usage_mb)

mem_usage(data)
265/1: import PIL as p
266/1: import exifread
266/2: f = open('/Users/vschmidt/Downloads/img_20180404_212242_829.jpg','rb')
266/3: tags = exifread.process_file(f)
266/4: print(tags)
266/5:
for tag in tags.keys():
    if tag not in ('JPEGThumbnail'):
        print("%s:%s" % (tag,tags[tag]))
267/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
import matplotlib
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')
269/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
import matplotlib
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')
269/2: cd 2017-09-14T13-39-29/
269/3:
nav = pd.read_csv('GGA_3_.txt',sep = '\s+',header=None,names=
                  ['log_year',
                   'log_month',
                   'log_day',
                   'log_hour',
                   'log_minute',
                   'log_second',
                   'year',
                   'month',
                   'day',
                   'hour',
                   'minute',
                   'second',
                   'latitude',
                   'longitude',
                   'fix_type',
                   'Nsats',
                   'hdop',
                   'height_msl','height_ellipsoid'])
269/4:
dates = pd.to_datetime('year': nav['log_year'], 
                           nav[]
                'month': nav['log_month'],
                'day': nav['log_day'],
                'hour': nav['log_hour'],
                'minute': nav['log_minute'],
                'second': nav['log_second']})
269/5:
dates = pd.to_datetime('year': nav['log_year'], 
                'month': nav['log_month'],
                'day': nav['log_day'],
                'hour': nav['log_hour'],
                'minute': nav['log_minute'],
                'second': nav['log_second']})
269/6:
dates = pd.to_datetime({}'year': nav['log_year'], 
                'month': nav['log_month'],
                'day': nav['log_day'],
                'hour': nav['log_hour'],
                'minute': nav['log_minute'],
                'second': nav['log_second']})
269/7:
dates = pd.to_datetime({'year': nav['log_year'], 
                'month': nav['log_month'],
                'day': nav['log_day'],
                'hour': nav['log_hour'],
                'minute': nav['log_minute'],
                'second': nav['log_second']})
269/8:
dates = pd.to_datetime({'year': nav['log_year'], 
                'month': nav['log_month'],
                'day': nav['log_day'],
                'hour': nav['log_hour'],
                'minute': nav['log_minute'],
                'second': nav['log_second']})
nav.set_index(dates)
nav_e, nav_n = transform(WGS84,UTM19N,nav['longitude'].tolist(),
                           nav['latitude'].tolist())
nav['nav_e'] = pd.Series(nav_e,index=nav.index)
nav['nav_n'] = pd.Series(nav_n,index=nav.index)
269/9:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
import matplotlib
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
269/10: cd 2017-09-14T13-39-29/
269/11:
nav = pd.read_csv('GGA_3_.txt',sep = '\s+',header=None,names=
                  ['log_year',
                   'log_month',
                   'log_day',
                   'log_hour',
                   'log_minute',
                   'log_second',
                   'year',
                   'month',
                   'day',
                   'hour',
                   'minute',
                   'second',
                   'latitude',
                   'longitude',
                   'fix_type',
                   'Nsats',
                   'hdop',
                   'height_msl','height_ellipsoid'])
269/12:
dates = pd.to_datetime({'year': nav['log_year'], 
                'month': nav['log_month'],
                'day': nav['log_day'],
                'hour': nav['log_hour'],
                'minute': nav['log_minute'],
                'second': nav['log_second']})
nav.set_index(dates)
nav_e, nav_n = transform(WGS84,UTM19N,nav['longitude'].tolist(),
                           nav['latitude'].tolist())
nav['nav_e'] = pd.Series(nav_e,index=nav.index)
nav['nav_n'] = pd.Series(nav_n,index=nav.index)
269/13:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
#import geopandas as gpd
from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
import matplotlib
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
269/14:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
#import geopandas as gpd
#from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
import matplotlib
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
269/15:
nav = pd.read_csv('GGA_3_.txt',sep = '\s+',header=None,names=
                  ['log_year',
                   'log_month',
                   'log_day',
                   'log_hour',
                   'log_minute',
                   'log_second',
                   'year',
                   'month',
                   'day',
                   'hour',
                   'minute',
                   'second',
                   'latitude',
                   'longitude',
                   'fix_type',
                   'Nsats',
                   'hdop',
                   'height_msl','height_ellipsoid'])
269/16:
dates = pd.to_datetime({'year': nav['log_year'], 
                'month': nav['log_month'],
                'day': nav['log_day'],
                'hour': nav['log_hour'],
                'minute': nav['log_minute'],
                'second': nav['log_second']})
nav.set_index(dates)
nav_e, nav_n = transform(WGS84,UTM19N,nav['longitude'].tolist(),
                           nav['latitude'].tolist())
nav['nav_e'] = pd.Series(nav_e,index=nav.index)
nav['nav_n'] = pd.Series(nav_n,index=nav.index)
269/17:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean(nav['latitude'])
Lon_0 = np.nanmean(nav['longitude'])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin(nav['longitude']]) - lonbuf
LLcrnrlat = np.nanmin(nav['latitude']) - latbuf
URcrnrlon = np.nanmax(data['longitude']) + lonbuf
URcrnrlat = np.nanmax(data['latitude']) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
             lat_0 = Lat_0,
             lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=nav['longitude'],y=nav['latitude'],latlon=True,s=1,c='y')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.title('Paths of Vessel')
plt.draw()
plt.show()
269/18:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean(nav['latitude'])
Lon_0 = np.nanmean(nav['longitude'])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin(nav['longitude']) - lonbuf
LLcrnrlat = np.nanmin(nav['latitude']) - latbuf
URcrnrlon = np.nanmax(data['longitude']) + lonbuf
URcrnrlat = np.nanmax(data['latitude']) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
              lat_0 = Lat_0,
              lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=nav['longitude'],y=nav['latitude'],latlon=True,s=1,c='y')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.title('Paths of Vessel')
plt.draw()
plt.show()
269/19:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean(nav['latitude'])
Lon_0 = np.nanmean(nav['longitude'])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin(nav['longitude']) - lonbuf
LLcrnrlat = np.nanmin(nav['latitude']) - latbuf
URcrnrlon = np.nanmax(nav['longitude']) + lonbuf
URcrnrlat = np.nanmax(nav['latitude']) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
              lat_0 = Lat_0,
              lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=nav['longitude'],y=nav['latitude'],latlon=True,s=1,c='y')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.title('Paths of Vessel')
plt.draw()
plt.show()
269/20: whos
270/1:
import pandas as pd
import numpy as np
from pandas import Series, DataFrame, Panel
#import geopandas as gpd
#from shapely.geometry import Point,LineString
import os
from pyproj import *

import matplotlib.pyplot as plt
import matplotlib
#import PrettyTable as pt
from mpl_toolkits.basemap import Basemap
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('png', 'pdf')

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84" \
               + " +datum=WGS84 +units=m +no_defs")
270/2:
nav = pd.read_csv('GGA_3_.txt',sep = '\s+',header=None,names=
                  ['log_year',
                   'log_month',
                   'log_day',
                   'log_hour',
                   'log_minute',
                   'log_second',
                   'year',
                   'month',
                   'day',
                   'hour',
                   'minute',
                   'second',
                   'latitude',
                   'longitude',
                   'fix_type',
                   'Nsats',
                   'hdop',
                   'height_msl','height_ellipsoid'])
270/3: cd 2017-09-14T13-39-29/
270/4:
nav = pd.read_csv('GGA_3_.txt',sep = '\s+',header=None,names=
                  ['log_year',
                   'log_month',
                   'log_day',
                   'log_hour',
                   'log_minute',
                   'log_second',
                   'year',
                   'month',
                   'day',
                   'hour',
                   'minute',
                   'second',
                   'latitude',
                   'longitude',
                   'fix_type',
                   'Nsats',
                   'hdop',
                   'height_msl','height_ellipsoid'])
270/5:
dates = pd.to_datetime({'year': nav['log_year'], 
                'month': nav['log_month'],
                'day': nav['log_day'],
                'hour': nav['log_hour'],
                'minute': nav['log_minute'],
                'second': nav['log_second']})
nav.set_index(dates)
nav_e, nav_n = transform(WGS84,UTM19N,nav['longitude'].tolist(),
                           nav['latitude'].tolist())
nav['nav_e'] = pd.Series(nav_e,index=nav.index)
nav['nav_n'] = pd.Series(nav_n,index=nav.index)
270/6:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean(nav['latitude'])
Lon_0 = np.nanmean(nav['longitude'])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin(nav['longitude']) - lonbuf
LLcrnrlat = np.nanmin(nav['latitude']) - latbuf
URcrnrlon = np.nanmax(nav['longitude']) + lonbuf
URcrnrlat = np.nanmax(nav['latitude']) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc',
              lat_0 = Lat_0,
              lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=nav['longitude'],y=nav['latitude'],latlon=True,s=1,c='y')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.title('Paths of Vessel')
plt.draw()
plt.show()
270/7:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean(nav['latitude'])
Lon_0 = np.nanmean(nav['longitude'])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin(nav['longitude']) - lonbuf
LLcrnrlat = np.nanmin(nav['latitude']) - latbuf
URcrnrlon = np.nanmax(nav['longitude']) + lonbuf
URcrnrlat = np.nanmax(nav['latitude']) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc', lat_0 = Lat_0, lon_0 = Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=nav['longitude'],y=nav['latitude'],latlon=True,s=1,c='y')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.title('Paths of Vessel')
plt.draw()
plt.show()
270/8: print(Lat_0)
270/9: Basemap?
270/10:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean(nav['latitude'])
Lon_0 = np.nanmean(nav['longitude'])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin(nav['longitude']) - lonbuf
LLcrnrlat = np.nanmin(nav['latitude']) - latbuf
URcrnrlon = np.nanmax(nav['longitude']) + lonbuf
URcrnrlat = np.nanmax(nav['latitude']) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc', 
              lat_0=Lat_0, 
              lon_0=Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=nav['longitude'],y=nav['latitude'],latlon=True,s=1,c='y')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.title('Paths of Vessel')
plt.draw()
plt.show()
270/11: whos
270/12: whos LLcrnrlon
270/13: whos Series
270/14:
plt.figure(figsize=(8,10))

Lat_0 = np.nanmean(nav['latitude'])
Lon_0 = np.nanmean(nav['longitude'])


latbuf = 0.02
lonbuf = latbuf * np.cos(Lat_0*np.pi/180)

LLcrnrlon = np.nanmin([nav['longitude']]) - lonbuf
LLcrnrlat = np.nanmin([nav['latitude']]) - latbuf
URcrnrlon = np.nanmax([nav['longitude']]) + lonbuf
URcrnrlat = np.nanmax([nav['latitude']]) + latbuf

map = Basemap(llcrnrlon=LLcrnrlon,
              llcrnrlat=LLcrnrlat,
              urcrnrlon=URcrnrlon,
              urcrnrlat=URcrnrlat, 
              epsg=4326,
              projection='tmerc', 
              lat_0=Lat_0, 
              lon_0=Lon_0)

vscale = (URcrnrlat-LLcrnrlat)*60*1852.0

#http://server.arcgisonline.com/arcgis/rest/services
map.drawmapboundary(fill_color='black')
#map.drawmapscale(LLcrnrlat,LLcrnrlon,Lat_0,Lon_0,length=1)
map.scatter(x=nav['longitude'],y=nav['latitude'],latlon=True,s=1,c='y')

map.arcgisimage(service='ESRI_Imagery_World_2D', 
                xpixels = 2000, verbose= False)

plt.title('Paths of Vessel')
plt.draw()
plt.show()
270/15: eng = pd.read_csv('engine,csv')
270/16: eng = pd.read_csv('engine.csv')
270/17: eng.head()
270/18:
eng = pd.read_csv('engine.csv')
pilot = pd.read_csv('pilot.csv')
vehicle = pd.read_csv('vehicle.csv')
vp = pd.read_csv('vehicle_processor.csv')
payload = pd.read_csv('payload.csv')
270/19:
eng = pd.read_csv('engine.csv')
pilot = pd.read_csv('pilot.csv')
vehicle = pd.read_csv('vehicle.csv')
#vp = pd.read_csv('vehicle_processor.csv')
payload = pd.read_csv('payload.csv')
270/20: eng.set_index(pd.Timestamp(eng['Epoch Time (s)']))
270/21: eng.set_index(pd.DatetimeIndex(eng['Epoch Time (s)']))
270/22: eng.set_index(pd.DatetimeIndex(eng['Epoch Time (s)'],unit='s'))
270/23: eng.set_index(pd.to_datetime(eng['Epoch Time (s)'],unit='s'))
270/24:
eng.set_index(pd.to_datetime(eng['Epoch Time (s)'],unit='s'))
pilot.set_index(pd.to_datetime(pilot['Epoch Time (s)'],unit='s'))
vehicle.set_index(pd.to_datetime(vehicle['Epoch Time (s)'],unit='s'))
payload.set_index(pd.to_datetime(payload['Epoch Time (s)'],unit='s'))
270/25:
data = pd.concat([nav,eng,pilot,vehicle,payload])

data.sort_index(inplace=True)
data.interpolate(method='linear',inplace=True,limit=500)
273/1: import sounddevice as sd
273/2: r = sd.rec(int(5*48000),samplerate=48000,channels=2)
273/3: sd.wait()
273/4: whos r
273/5: whos
273/6: import matplotlib.pyplot as plt
273/7: plt.plot(r[:,0])
273/8: plt.show()
273/9: sd.play(r,48000)
273/10: sd.play(r,48000)
274/1:
import sounddevice as sd
import sys
275/1: r = ()
275/2: whos
275/3: import numpy as np
275/4: r = np.zeros((4,3),dtype=theano.confi.floatX)
275/5: import theano
275/6: import math
275/7: math.modf(11,10)
275/8: math.modf?
275/9: 10%11
275/10: 11%10
274/2:
fs = 8000
ch = 1
N = 100
data = np.zeros(N,fs)
for i=range(0,100):
    print(i%10)
    data[i:]=sd.record(8000,samplerate=fs,channels=ch)

print("Done.")
274/3:
fs = 8000
ch = 1
N = 100
data = np.zeros(N,fs)
for i in range(0,100):
    print(i%10)
    data[i:]=sd.record(8000,samplerate=fs,channels=ch)

print("Done.")
274/4:
import sounddevice as sd
import sys
import numpy as np
274/5:
fs = 8000
ch = 1
N = 100
data = np.zeros(N,fs)
for i in range(0,100):
    print(i%10)
    data[i:]=sd.record(8000,samplerate=fs,channels=ch)

print("Done.")
275/11: import np
275/12: import numpy as np
274/6:
fs = 8000
ch = 1
N = 100
data = np.zeros((N,fs))
for i in range(0,100):
    print(i%10)
    data[i:]=sd.record(8000,samplerate=fs,channels=ch)

print("Done.")
275/13: a = np.zeros(1)
275/14: a
275/15: a = np.zeros((100,1)))
275/16: a = np.zeros((100,1))
275/17: a
275/18: b[:1] = a
275/19: b = np.ones((100,2))
275/20: b
275/21: b[:1] = a
275/22: b[:,1] = a
275/23: a = np.zeros((100))
275/24: whos a
275/25: a
275/26: b[:1] = a
275/27: b[:,1] = a
275/28: b
274/7:
fs = 8000
ch = 1
N = 100
data = np.zeros((N,fs))
for i in range(0,100):
    print(i%10)
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch)

print("Done.")
274/8:
fs = 8000
ch = 1
N = 100
data = np.zeros((N,fs))
for i in range(0,100):
    print(i%10)
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()

print("Done.")
275/29: sleep(1)
275/30: import time
275/31: time.sleep(1)
274/9:
fs = 8000
ch = 1
N = 10
data = np.zeros((N,fs))
for i in range(0,100):
    print(i%10)
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    #time.sleep(1)
print("Done.")
274/10:
fs = 8000
ch = 1
N = 10
data = np.zeros((N,fs))
for i in range(0,N):
    print(i%10)
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    #time.sleep(1)
print("Done.")
274/11:
%matplotlib inline
import sounddevice as sd
import sys
import numpy as np
import time
import matplotlib.pyplot as plt
274/12:
fs = 8000
ch = 1
N = 10
data = np.zeros((N,fs))
for i in range(0,N):
    print(i%10)
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    plt.plot(data[i,:])
    plt.show()
    print(\b)
    #time.sleep(1)
print("Done.")
274/13:
fs = 8000
ch = 1
N = 10
data = np.zeros((N,fs))
for i in range(0,N):
    print(i%10)
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    plt.plot(data[i,:])
    plt.show()
    print("\b")
    #time.sleep(1)
print("Done.")
274/14:
fs = 8000
ch = 1
N = 5
data = np.zeros((N,fs))
for i in range(0,N):
    print(i%10)
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b")
    plt.plot(data[i,:])
    plt.show()
    #time.sleep(1)
print("Done.")
274/15:
fs = 8000
ch = 1
N = 5
data = np.zeros((N,fs))
for i in range(0,N):
    print(i%10)
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b")
    #ax = plt.subplot(1,1,1)
    if i==0:
        ax = plt.plot(data[i,:])
    else:
        ax.set_ydata(data[i,:])
    #time.sleep(1)
print("Done.")
274/16:
fs = 8000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
for i in range(0,N):
    print(i%10)
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b")
    #ax = plt.subplot(1,1,1)
    if i==0:
        ax, = plt.plot(data[i,:])
    else:
        ax.set_ydata(data[i,:])
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/17:
fs = 8000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
for i in range(0,N):
    print(i%10)
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b")
    #ax = plt.subplot(1,1,1)
    if i==0:
        ax, = plt.plot(data[i,:])
        plt.show()
    else:
        ax.set_ydata(data[i,:])
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/18:
print("1")
time.sleep(1)
print("\b")
274/19:
print("1");
time.sleep(1)
print("\b")
274/20:
print("%d" % 1);
time.sleep(1)
print("\b")
274/21:
print(1,end=="");
time.sleep(1)
print("\b")
274/22:
print("1",end=="");
time.sleep(1)
print("\b")
274/23:
print("1",end="");
time.sleep(1)
print("\b")
274/24:
print("1",end="");
time.sleep(1)
print("\b")
print("2")
274/25:
print("1",end="");
time.sleep(1)
print("\b",end="")
print("2")
274/26:
fs = 8000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
for i in range(0,N):
    print(i%10,end="")
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    #ax = plt.subplot(1,1,1)
    if i==0:
        ax, = plt.plot(data[i,:])
        plt.show()
    else:
        ax.set_ydata(data[i,:])
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/27:
fs = 8000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
for i in range(0,N):
    print(i%10,end="")
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    #ax = plt.subplot(1,1,1)
    if i==0:
        ax, = plt.plot(data[i,:])
        plt.show()
    else:
        ax.set_ydata(data[i,:])
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/28:
fs = 8000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
for i in range(0,N):
    print(i%10,end="")
    data[i,:]=sd.rec(8000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    #ax = plt.subplot(1,1,1)
    if i==0:
        ax, = plt.plot(data[i,:])
        plt.show()
    else:
        ax.set_ydata(data[i,:])
        plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/29:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
for i in range(0,N):
    print(i%10,end="")
    data[i,:]=sd.rec(48000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    #ax = plt.subplot(1,1,1)
    if i==0:
        ax, = plt.plot(data[i,:])
        plt.show()
    else:
        ax.set_ydata(data[i,:])
        plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/30:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax, = plt.plot(data[i,:])
plt.show()
for i in range(0,N):
    print(i%10,end="")
    data[i,:]=sd.rec(48000,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    #ax = plt.subplot(1,1,1)
    ax.set_ydata(data[i,:])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/31: pyt.plot(data[3,:])
274/32: plt.plot(data[3,:])
274/33: a = sd.rec(fs,samplerate=fs,channels=ch)
274/34: plt.plot(a)
274/35: a = sd.rec(fs,samplerate=fs,channels=ch)
274/36: plt.plot(a)
274/37: a.size()
274/38: size(a)
274/39: np.size(a)
274/40:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax = fig.add_subplot(111)
line = ax.plot(data[i,:])
plt.show()
for i in range(0,N):
    print(i%10,end="")
    data[i,:]=sd.rec(fs,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    line.set_ydata(data[i,:])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/41:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax = fig.add_subplot(111)
line, = ax.plot(data[i,:])
plt.show()
for i in range(0,N):
    print(i%10,end="")
    data[i,:]=sd.rec(fs,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    line.set_ydata(data[i,:])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/42:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line, = ax.plot(data[i,:])
plt.show()
for i in range(0,N):
    print(i%10,end="")
    data[i,:]=sd.rec(fs,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    line.set_ydata(data[i,:])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/43: plt.plot(data[1,:])
274/44: range(0,N)
274/45: a = range(0,N)
274/46: print(a)
274/47: a[0]
274/48: a[1]
274/49: whos a
274/50: whos
274/51:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:])
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[i,:]=sd.rec(fs,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[i,:])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/52: i
274/53: line1.set_ydata(data[i,:])
274/54:
line1.set_ydata(data[i,:])
plt.show()
274/55:
line1.set_ydata([1,2,3])
plt.show()
274/56:
line1.set_data([1,2,3])
plt.show()
274/57:
line1.set_ydata([1,2,3])
plt.show()
274/58:
line1.set_ydata([1,2,3])
line1.show()
plt.show()
274/59:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:])
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[i,:]=sd.rec(fs,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[i,:])
    line1.show()
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/60:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:])
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[i,:]=sd.rec(fs,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[i,:])
    plt.draw()
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/61:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:])
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[i,:]=sd.rec(fs,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[i-1,:])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/62:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[i,:]=sd.rec(fs,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[i-1,:])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/63: plt.plot(data[-1,:])
274/64: plt.plot(data[1,:])
274/65: plt.plot(data[2,:])
274/66:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[i,:]=sd.rec(fs,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[i+1,:])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/67: plt.pcolor(data)
274/68:
plt.pcolor(data)
plt.show()
274/69:
plt.pcolor(np.log10(data)
plt.show()
274/70:
plt.pcolor(np.log10(data))
plt.show()
274/71:
fs = 48000
ch = 1
N = 5
data = np.zeros((N,fs))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[i,:]=sd.rec(fs,samplerate=fs,channels=ch).transpose()
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[i,:])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/72:
plt.pcolor(np.log10(data))
plt.show()
274/73:
fs = 48000
ch = 1
N = 5
data = np.zeros(fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/74:
fs = 48000
ch = 1
N = 5
data = np.zeros(fs,N)
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/75:
fs = 48000
ch = 1
N = 5
data = np.zeros((fs,N)
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/76:
fs = 48000
ch = 1
N = 5
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/77:
fs = 48000
ch = 1
N = 5
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)[:]
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/78:
fs = 48000
ch = 1
N = 5
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)[:,1]
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/79:
fs = 48000
ch = 1
N = 5
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)[:,0]
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    fig.canvas.draw()
    fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/80:
fs = 48000
ch = 1
N = 5
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)[:,0]
    sd.wait()
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/81:
plt.pcolor(np.log10(data))
plt.show()
274/82:
fs = 48000
ch = 1
N = 5
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)[:,0]
    sd.wait()
    print("\b",end="")
    line1.set_ydata(np.random((fs,1)))
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/83: np.random?
274/84: np.rand?
274/85: np.rand()?
274/86: np.random(10)
274/87: np.random.normal?
274/88: np.random.normal(size=(10,1))
274/89:
fs = 48000
ch = 1
N = 5
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)[:,0]
    sd.wait()
    print("\b",end="")
    line1.set_ydata(np.random.normal(size=(fs,1)))
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/90:
plt.pcolor(np.log10(data))
plt.show()
274/91:
fs = 48000
ch = 1
N = 10
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    data[:,i]=sd.rec(fs,samplerate=fs,channels=ch)[:,0]
    sd.wait()
    print("\b",end="")
    line1.set_ydata(np.random.normal(size=(fs,1)))
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/92:
plt.pcolor(np.log10(data))
plt.show()
274/93:
fs = 48000
ch = 1
N = 10
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[i,:],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    tmp = sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    data[:,i]=tmp[:,0]
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/94:
plt.pcolor(np.log10(data))
plt.show()
274/95:
fs = 48000
ch = 1
N = 10
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[:,i],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    tmp = sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    data[:,i]=tmp[:,0]
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/96:
plt.pcolor(np.log10(data))
plt.show()
274/97:
fs = 8000
ch = 1
N = 10
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[:,i],'b')
plt.show()
for i in range(0,N):
    print(i%N,end="")
    tmp = sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    data[:,i]=tmp[:,0]
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/98:
plt.pcolor(np.log10(data))
plt.show()
274/99:
fs = 8000
ch = 1
N = 10
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[:,i],'b')
plt.show()
print("Ready?")
time.sleep(1)
print("Go!")
for i in range(0,N):
    print(i%N,end="")
    tmp = sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    data[:,i]=tmp[:,0]
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/100:
plt.pcolor(np.log10(data))
plt.show()
274/101:
fs = 8000
ch = 1
N = 10
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[:,i],'b')
plt.show()
print("Ready?")
time.sleep(1)
print("Go!")
time.sleep(1)
for i in range(0,N):
    print(i%N,end="")
    tmp = sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    data[:,i]=tmp[:,0]
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/102:
plt.pcolor(np.log10(data))
plt.show()
274/103: sd.play(data[:,0],samplerate=fs)
274/104: sd.play(data[:,0],samplerate=fs)
274/105: sd.play(data[:,9],samplerate=fs)
274/106:
fs = 8000
ch = 1
N = 100
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[:,i],'b')
plt.show()
print("Ready?")
time.sleep(1)
print("Go!")
time.sleep(1)
for i in range(0,N):
    print(i%N,end="")
    tmp = sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    data[:,i]=tmp[:,0]
    print("\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/107:
print("10")
time.sleep(1)
print("\b\b")
print("1")
time.sleep(1)
print("\b\b")
print("3")
274/108:
print("10",end="")
time.sleep(1)
print("\b\b",end="")
print("1",end="")
time.sleep(1)
print("\b\b",end="")
print("3")
274/109:
fs = 8000
ch = 1
N = 10
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[:,i],'b')
plt.show()
print("Ready?")
time.sleep(1)
print("Go!")
time.sleep(1)
for i in range(0,N):
    print(i%10,end="")
    tmp = sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    data[:,i]=tmp[:,0]
    print("\b\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/110:
fs = 8000
ch = 1
N = 100
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[:,i],'b')
plt.show()
print("Ready?")
time.sleep(1)
print("Go!")
time.sleep(1)
for i in range(0,N):
    print(i%10,end="")
    tmp = sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    data[:,i]=tmp[:,0]
    print("\b\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/111:
fs = 8000
ch = 1
N = 100
data = np.zeros((fs,N))
fig = plt.figure()
ax = fig.add_subplot(111)
i=0
line1, = ax.plot(data[:,i],'b')
plt.show()
print("Ready?")
time.sleep(1)
print("Set!")
time.sleep(1)
print("Go!")
time.sleep(1)
for i in range(0,N):
    print(i%10,end="")
    tmp = sd.rec(fs,samplerate=fs,channels=ch)
    sd.wait()
    data[:,i]=tmp[:,0]
    print("\b\b",end="")
    line1.set_ydata(data[:,i])
    plt.show()
    #fig.canvas.draw()
    #fig.canvas.flush_events()
    #time.sleep(1)
print("Done.")
274/112:
plt.pcolor(np.log10(data))
plt.show()
274/113: np.save?
274/114: np.save("data_val.npy",data)
274/115: sd.play(data[:,9],samplerate=fs)
274/116:
%matplotlib inline
import sounddevice as sd
import sys
import numpy as np
import time
import matplotlib.pyplot as plt
from scipy import signal
274/117:
ff,tt,Sxx = signal.spectrogram(data[:,1],fs)
plt.pcolormesh(t, f, Sxx)
plt.ylabel('Frequency [Hz]')
plt.xlabel('Time [sec]')
plt.show()
274/118:
ff,tt,Sxx = signal.spectrogram(data[:,1],fs)
plt.pcolormesh(tt, ff, Sxx)
plt.ylabel('Frequency [Hz]')
plt.xlabel('Time [sec]')
plt.show()
274/119:
ff,tt,Sxx = signal.spectrogram(data[:,1],fs)
plt.pcolormesh(tt, ff, np.log10(Sxx)
plt.ylabel('Frequency [Hz]')
plt.xlabel('Time [sec]')
plt.show()
274/120:
ff,tt,Sxx = signal.spectrogram(data[:,1],fs)
plt.pcolormesh(tt, ff, np.log10(Sxx))
plt.ylabel('Frequency [Hz]')
plt.xlabel('Time [sec]')
plt.show()
274/121:
ff,tt,Sxx = signal.spectrogram(data[:,0],fs)
plt.pcolormesh(tt, ff, np.log10(Sxx))
plt.ylabel('Frequency [Hz]')
plt.xlabel('Time [sec]')
plt.show()
274/122:
filler = data[:2000,40]
data_p100 = [data[50:,:] filler[0:49]]
274/123:
filler = data[:2000,40]
data_p100 = [data[100:,:] filler[0:99]]
274/124:
plt.plot(filler)
plt.show()
274/125:
filler = data[0:2000,40]
data_p100 = [data[100:,:] filler[0:99]]
274/126:
plt.plot(filler)
plt.show()
274/127:
filler = data[0:2000,40]
#data_p100 = [data[100:,:] filler[0:99]]
274/128:
plt.plot(filler)
plt.show()
274/129:
filler = data[0:2000,40]
np.size(filler)
#data_p100 = [data[100:,:] filler[0:99]]
274/130:
filler = data[0:2000,40]
data_p100 = [data[100:,:] filler[0:99]]
274/131:
filler = data[0:2000,40]
data_p100 = [data[100:,:], filler[0:99]]
274/132:
plt.plot(data_p100[:,0])
plt.hold = True
plt.plot(data[:,0])
plt.show()
274/133: whos
274/134:
filler = data[0:2000,40]
data_p100 = np.hstack(data[100:,:], filler[0:99])
274/135:
filler = data[0:2000,40]
data_p100 = np.hstack((data[100:,:], filler[0:99]))
274/136:
filler = data[0:2000,40]
data_p100 = np.hstack((data[100:,:], filler[0:100]))
274/137: a =np.array([1,2,3,4]).transpose()
274/138: a
274/139: a =np.array([1,2,3,4])
274/140: a
274/141: a =np.array([[1],[2],[3],[4]])
274/142: np.repeat(a,5)
274/143: np.repeat(a.transpose(),5)
274/144: np.repeat(a.transpose(),5,axis=2)
274/145: a =np.matrix([[1],[2],[3],[4]])
274/146: np.repeat(a.transpose(),5)
274/147: np.repeat(a,5)
274/148: a =np.matrix([1,2,3,4,5])
274/149: np.repeat(a,5)
274/150: a =np.matrix([[1],[2],[3],[4]])
274/151: np.tile(a,5)
274/152: np.tile(a[0:3],5)
274/153:
filler = data[0:2000,40]
data_p100 = np.hstack((data[100:,:], np.tile(filler[0:100],N))
274/154:
filler = data[0:2000,40]
data_p100 = np.hstack((data[100:,:], np.tile(filler[0:100],N)))
274/155:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100],N)
data_p100 = np.hstack((data[100:,:], np.tile(filler[0:100],N)))
274/156: np.size(filler)
274/157: np.size(fill_100)
274/158: np.shape(fill_100)
274/159:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100].tranpose(),N)
data_p100 = np.hstack((data[100:,:], np.tile(filler[0:100],N)))
274/160: np.shape(fill_100)
274/161: a =np.array([1,2,3,4])
274/162: np.tile(a[0:3][np.newaxis],5)
274/163: np.tile(a[0:3][np.newaxis].T,5)
274/164:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.hstack((data[100:,:], np.tile(filler[0:100],N)))
274/165: np.shape(fill_100)
274/166:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.hstack((data[100:,:], fill_100))
274/167:
np.shape(fill_100)
np.shape(data[100:,:])
274/168:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
274/169:
np.shape(fill_100)
np.shape(data[100:,:])
274/170:
plt.plot(data_p100[:,0])
plt.hold = True
plt.plot(data[:,0])
plt.show()
274/171:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((data(:100,:), fill_100))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack((data(:500,:], fill_500)))
274/172:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((data(:-100,:), fill_100))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack((data(:-500,:], fill_500)))
274/173: a[:-3]
274/174: a[-3:]
274/175:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((data(-100:,:), fill_100))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack((data(-500:,:], fill_500)))
274/176:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((data(-100:,:), fill_100))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack((data[-500:,:], fill_500))
274/177:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((data[-100:,:], fill_100))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack((data[-500:,:], fill_500))
274/178:
plt.plot(data_p100[:,0])
plt.hold = True
plt.plot(data[:,0])
plt.plot(data_m100[:,0])
plt.plot(data_p1000[:,0])
plt.plot(data_m1000[:,0])
plt.show()
274/179:
plt.plot(data_p100[:,0])
plt.hold = True
plt.plot(data[:,0])
plt.plot(data_m100[:,0])
plt.plot(data_p500[:,0])
plt.plot(data_m500[:,0])
plt.show()
274/180: %reset a
274/181: whos
274/182: %reset?
274/183:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((data[-100:,:], fill_100))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack((data[-500:,:], fill_500))
fill_1000 = np.tile(filler[0:1000][np.newaxis].T,N)
data_p1000 = np.vstack((data[1000:,:], fill_1000))
data_m1000 = np.vstack((data[-1000:,:], fill_1000))
del fill_100, fill_500
274/184: whos
274/185:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((data[-100:,:], fill_100))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack((data[-500:,:], fill_500))
fill_1000 = np.tile(filler[0:1000][np.newaxis].T,N)
data_p1000 = np.vstack((data[1000:,:], fill_1000))
data_m1000 = np.vstack((data[-1000:,:], fill_1000))
del fill_100, fill_500, fil_1000
data2 = np.stack((data,data_p100,data_m100,data_p500,data_m500,data_p1000,data_m1000),axis=2)
274/186:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((data[-100:,:], fill_100))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack((data[-500:,:], fill_500))
fill_1000 = np.tile(filler[0:1000][np.newaxis].T,N)
data_p1000 = np.vstack((data[1000:,:], fill_1000))
data_m1000 = np.vstack((data[-1000:,:], fill_1000))
del fill_100, fill_500, fill_1000
data2 = np.stack((data,data_p100,data_m100,data_p500,data_m500,data_p1000,data_m1000),axis=2)
274/187:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((fill_100, data[-100:,:]))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack(( fill_500, data[-500:,:]))
fill_1000 = np.tile(filler[0:1000][np.newaxis].T,N)
data_p1000 = np.vstack((data[1000:,:], fill_1000))
data_m1000 = np.vstack((fill_1000, data[-1000:,:]))
del fill_100, fill_500, fill_1000
data2 = np.stack((data,data_p100,data_m100,data_p500,data_m500,data_p1000,data_m1000),axis=2)
274/188: whos
274/189: np.shape(data_m100)
274/190:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((fill_100, data[:-100,:]))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack(( fill_500, data[-500:,:]))
fill_1000 = np.tile(filler[0:1000][np.newaxis].T,N)
data_p1000 = np.vstack((data[1000:,:], fill_1000))
data_m1000 = np.vstack((fill_1000, data[-1000:,:]))
del fill_100, fill_500, fill_1000
data2 = np.stack((data,data_p100,data_m100,data_p500,data_m500,data_p1000,data_m1000),axis=2)
274/191: np.shape(data_m100)
274/192:
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((fill_100, data[:-100,:]))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack(( fill_500, data[:-500,:]))
fill_1000 = np.tile(filler[0:1000][np.newaxis].T,N)
data_p1000 = np.vstack((data[1000:,:], fill_1000))
data_m1000 = np.vstack((fill_1000, data[:-1000,:]))
del fill_100, fill_500, fill_1000
data2 = np.stack((data,data_p100,data_m100,data_p500,data_m500,data_p1000,data_m1000),axis=2)
274/193: np.shape(data_m100)
274/194:
# Time-shift data.
filler = data[0:2000,40]
fill_100 = np.tile(filler[0:100][np.newaxis].T,N)
data_p100 = np.vstack((data[100:,:], fill_100))
data_m100 = np.vstack((fill_100, data[:-100,:]))
fill_500 = np.tile(filler[0:500][np.newaxis].T,N)
data_p500 = np.vstack((data[500:,:], fill_500))
data_m500 = np.vstack(( fill_500, data[:-500,:]))
fill_1000 = np.tile(filler[0:1000][np.newaxis].T,N)
data_p1000 = np.vstack((data[1000:,:], fill_1000))
data_m1000 = np.vstack((fill_1000, data[:-1000,:]))
del fill_100, fill_500, fill_1000
data2 = np.stack((data,data_p100,data_m100,data_p500,data_m500,data_p1000,data_m1000),axis=2)
del data_p100,data_m100,data_p500,data_m500,data_p1000,data_m1000
276/1: import pandas as pd
276/2: F = file('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx','r')
276/3: pd.read_excel?
276/4: data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',sheet=0)
276/5: data.keys()
276/6: pd.read_excel?
276/7: data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',sheet=0,header=11)
276/8: pd.read_excel?
276/9: data.keys()
276/10: data.set_index(data['Trans Date'])
276/11: import matplotlib as plt
277/1:
%matplotlib
import pandas as pd
import matplotlib.pyplot as plt
277/2:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
278/1:
%matplotlib
import pandas as pd
import matplotlib.pyplot as plt
278/2:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/1:
%matplotlib
import pandas as pd
import matplotlib.pyplot as plt
279/2:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/3: data.set_index(data['Trans Date'])
279/4: data.groupby(pd.TimeGrouper(freq='M')).sum()
279/5: data.groupby(pd.Grouper(freq='M')).sum()
279/6: data.set_index(pd.to_datetime(data['Trans Date'])
279/7: data.set_index(pd.to_datetime(data['Trans Date']))
279/8: data.set_index(data.to_datetime(data['Trans Date']))
279/9: pd.to_datetime?
279/10: pd.datetime?
279/11: pd.to_datetime(data['Trans Date'])
279/12: data.keys()
279/13: data
279/14: data.set_index(data['Trans Date']))
279/15: data.set_index(data['Trans Date'])
279/16: data.index.month
279/17: data['date']=pd.to_datetime(data['Trans Date'])
279/18: data.index[0]
279/19: data.index[3]
279/20: data.index[4]
279/21: data
279/22: data.set_index(data['Trans Date'])
279/23: data
279/24: data = data.set_index(data['Trans Date'])
279/25: data
279/26: data.index[3]
279/27: dg = data.groupby(pd.Grouper(freq='M'))
279/28: data.index.month
279/29: data
279/30: data.index
279/31: data.to_timestamp?
279/32: data.to_timestamp()
279/33: data = data.set_index(data['Trans Date'])
279/34: data
279/35: data.to_timestamp()
279/36: data[0]
279/37: data.to_timestamp(axis='index')
279/38: dt = pd.DatetimeIndex(data['Trans Date'])
279/39: data.keys()
279/40: data.set_index?
279/41:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/42: data.keys()
279/43: data.set_index(data['Trans Date'],inplace=True)
279/44: data
279/45:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/46: data.keys()
279/47: data.set_index('Trans Date',inplace=True)
279/48: data
279/49: data.set_index(['Activity','Trans Date'],inplace=True)
279/50:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/51: data.keys()
279/52: data.set_index(['Activity','Trans Date'],inplace=True)
279/53: data
279/54: data.index
279/55: data.index[2]
279/56: dg = data.groupby(by=data.index[2][1])
279/57: dg = data.groupby(by=data.index)
279/58: dg
279/59: dg.sum()
279/60: data.groupby?
279/61:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/62: da = pd.DataFrame([data['Activity'],data['Transaction Amount'],index=data['Trans Date'])
279/63: da = pd.DataFrame([data['Activity'],data['Transaction Amount']],index=data['Trans Date'])
279/64: da = pd.DataFrame({'activity': data['Activity'], 'amount': data['Transaction Amount']},index=data['Trans Date'])
279/65: da
279/66: data
279/67: da
279/68:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/69: da = pd.DataFrame({'activity': data['Activity'], 'amount': data['Transaction Amount']},index=data['Trans Date'])
279/70: da
279/71: data['Activity']
279/72: da = pd.DataFrame({'activity': pd.Categorical(data['Activity']), 'amount': data['Transaction Amount']},index=data['Trans Date'])
279/73: da
279/74: da = pd.DataFrame({'activity': pd.Categorical(data['Activity']), 'amount': pd.Series(data['Transaction Amount'])},index=data['Trans Date'])
279/75: da
279/76:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity']),
                   'amount': pd.Series(data['Transaction Amount'],index=data['Trans Date'])},
                  index=data['Trans Date'])
279/77:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity']),
                   'amount': pd.Series(data['Transaction Amount'],index=data['Trans Date'],type=float64)},
                  index=data['Trans Date'])
279/78:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity']),
                   'amount': pd.Series(data.loc['Transaction Amount'],index=data['Trans Date'])},
                  index=data['Trans Date'])
279/79:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity']),
                   'amount': pd.Series(data['Transaction Amount'],index=data['Trans Date'])},
                  index=data['Trans Date'])
279/80:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'],index=data['Trans Date']),
                   'amount': pd.Series(data['Transaction Amount'],index=data['Trans Date'])},
                  index=data['Trans Date'])
279/81:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity']),
                   'amount': pd.Series(data['Transaction Amount']},
                  index=data['Trans Date'])
279/82:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity']),
                   'amount': pd.Series(data['Transaction Amount']})
279/83:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity']),
                   'amount': pd.Series(data['Transaction Amount'])}
279/84:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity']),
                   'amount': pd.Series(data['Transaction Amount'])})
279/85: ta = data['Transaction Amount']
279/86: ta
279/87: da.merge?
279/88: dd = [da, ts]
279/89: dd = [da, ta]
279/90:
dd = [da, ta]
dd
279/91:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])})
ta = data['Transaction Amount']
data = [da, ta]
279/92: data
279/93:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/94:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])})
ta = data['Transaction Amount']
data = [da, ta]
279/95: data
279/96:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
ta = data['Transaction Amount']
data = [da, ta]
279/97:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/98:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
ta = data['Transaction Amount']
data = [da, ta]
279/99:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
ta = data['Transaction Amount']
dd = [da, ta]
279/100:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/101:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
ta = data['Transaction Amount']
dd = [da, ta]
279/102: dd
279/103: ta
279/104:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11)
279/105:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])})
ta = data['Transaction Amount']
dd = [da, ta]
279/106: ta
279/107: dd
279/108:
dd = [da, ta]
dd
279/109: ta
279/110: da
279/111:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])})
ta = pd.DataFrame(data['Transaction Amount'])
dd = [da, ta]
279/112: dd
279/113:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
ta = pd.DataFrame(data['Transaction Amount'],index=data['Trans Date'])
dd = [da, ta]
279/114: dd
279/115:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
da.join?

ta = pd.DataFrame(data['Transaction Amount'],index=data['Trans Date'])
dd = [da, ta]
279/116:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
ta = pd.DataFrame(data['Transaction Amount'],index=data['Trans Date'])
dd = da.join(ta)
279/117: dd
279/118:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
ta = pd.DataFrame(data['Transaction Amount'])
dd = da.join(ta)
279/119:
da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
ta = pd.DataFrame(data['Transaction Amount'])
dd = da.join(ta.set_index(data['Trans Date']))
279/120: dd
279/121: dd.sort()
279/122: dd.sort_index()
279/123: dd
279/124: date = pd.to_datetime(data['Trans Date'])
279/125: dd
279/126: dd.keys()
279/127: dd.index
279/128: da
279/129:

da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
ta = pd.DataFrame(data['Transaction Amount'],index=data['Trans Date'])
dd = da.join(ta.set_index(data['Trans Date']))
279/130: dd
279/131:

#da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
da = data['Activity']
ta = pd.DataFrame(data['Transaction Amount'],index=data['Trans Date'])
dd = da.join(ta.set_index(data['Trans Date']))
279/132: da
279/133:

#da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
da = data['Activity']
#ta = pd.DataFrame(data['Transaction Amount'],index=data['Trans Date'])
ta = data['Transaction Amount']
#dd = da.join(ta.set_index(data['Trans Date']))
279/134: da
279/135: ta.head()
279/136:

#da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
da = data['Activity']
ta = pd.DataFrame(data['Transaction Amount'],index=data['Trans Date'],type='float64')
#ta = data['Transaction Amount']
#dd = da.join(ta.set_index(data['Trans Date']))
279/137: pd.DataFrame?
279/138:

#da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
da = data['Activity']
ta = pd.DataFrame(data['Transaction Amount'],index=data['Trans Date'],dtype='float64')
#ta = data['Transaction Amount']
#dd = da.join(ta.set_index(data['Trans Date']))
279/139:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/140:
data.head()
#da = pd.DataFrame({'activity': pd.Categorical(data['Activity'])},index=data['Trans Date'])
#da = data['Activity']
#ta = pd.DataFrame(data['Transaction Amount'],index=data['Trans Date'],dtype='float64')
#ta = data['Transaction Amount']
#dd = da.join(ta.set_index(data['Trans Date']))
279/141:
data.set_index('Trans Date')
data.head()
279/142: data.set_index?
279/143:
data.set_index('Trans Date',inplace=True)
data.head()
279/144:
data.set_index(['Trans Date','Activity',inplace=True)
data.head()
279/145:
data.set_index(['Trans Date','Activity'],inplace=True)
data.head()
279/146:
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/147:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/148:
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/149: dg = data.groupby(by='Activity').sum()
279/150: dg
279/151: dg = data.groupby(by='Activity')['Transaction Amount'].sum()
279/152: dg
279/153:
data.set_index(['Activity','Trans Date'],inplace=True)
data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data.head()
279/154:
data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/155:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/156:
data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/157:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/158:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/159:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/160:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data.drop(['UDCALM'])
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/161:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Activity' ~= 'UDCALM']]
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/162:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Activity' != 'UDCALM']]
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/163:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/164:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Activity' != 'UDCALM']]
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/165:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Activity'] != 'UDCALM']
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/166:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Activity'] == 'UDOMSV']
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/167:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/168:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Activity'] == 'UDOMSV']
data.set_index(['Activity','Trans Date'],inplace=True)
data.head()
279/169:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/170:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/171: dg = data.groupby(by=data.index)
279/172: dg
279/173: cs = dg.cumsum()
279/174:
plt.figure()
plt.plot(cs,'.')
279/175:
plt.figure()
plt.plot(cs,'.')
plt.show()
279/176: dg = data.groupby(by=data.index.month)
279/177: cs = dg.cumsum()
279/178:
plt.figure()
plt.plot(cs,'.')
plt.show()
279/179:
%matplotlib inline

import pandas as pd
import matplotlib.pyplot as plt
279/180:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/181:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/182: dg = data.groupby(by='Activity')['Transaction Amount'].sum()
279/183: dg
279/184: dg = data.groupby(by=data.index.month)
279/185: cs = dg.cumsum()
279/186:
plt.figure()
plt.plot(cs,'.')
plt.show()
279/187: cs
279/188: dg = data.groupby(by=data.index.month)['Transation Amount']
279/189: dg = data.groupby(by=data.index.month)['Transaction Amount']
279/190: cs = dg.cumsum()
279/191: dg
279/192: dg = data.groupby(by=data.index.month)['Transaction Amount'].cumsum()
279/193: dg = data.groupby(by='Activity')['Transaction Amount'].cumsum()
279/194: dg = data.groupby(by='Activity')['Transaction Amount'].sum()
279/195: type(dg)
279/196: print(dg)
279/197: dg = data.groupby(by='Activity')['Transaction Amount']
279/198: print(dg)
279/199: dg = data.groupby(by=data.index.month)['Transaction Amount'].sum()
279/200: print(dg)
279/201: dg = data.groupby(by=[data.index.year,data.index.month)['Transaction Amount'].sum()
279/202: dg = data.groupby(by=[data.index.year,data.index.month])['Transaction Amount'].sum()
279/203:
data = pd.read_excel('2017-11-06-08-01-42FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/204:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/205: #dg = data.groupby(by='Activity')['Transaction Amount']
279/206: dg = data.groupby(by=[data.index.year,data.index.month])['Transaction Amount'].sum()
279/207: dg = data.groupby(by=[pd.Grouper(freq='M'))['Transaction Amount'].sum()
279/208: dg = data.groupby(by=[pd.Grouper(freq='M')['Transaction Amount'].sum()
279/209: dg = data.groupby(by=pd.Grouper(freq='M'))['Transaction Amount'].sum()
279/210: dg = data.groupby(by=pd.Grouper(freq=['Y','M']))['Transaction Amount'].sum()
279/211:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample?
279/212:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M",how=sum)
279/213:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M").sum()
279/214:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M")['Transaction Amount'].sum()
279/215:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M")['Transaction Amount'].sum().plot()
279/216:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/217:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/218:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M")['Transaction Amount'].sum().plot()
279/219:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M")['Transaction Amount'].sum().bar()
279/220:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/221:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M")['Transaction Amount'].sum().plot(kind='bar','b')
279/222:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/223:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].contains('HR Payroll')]

Grant - Indirect Cost Recovery  
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/224:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].contains('HR Payroll')]

Grant - Indirect Cost Recovery  
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/225:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].contains('HR Payroll')]

Grant - Indirect Cost Recovery  
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/226:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/227:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].contains('HR Payroll')]

Grant - Indirect Cost Recovery  
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/228:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].contains('HR Payroll')]

Grant - Indirect Cost Recovery  
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/229:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/230:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].contains('HR Payroll')]

Grant - Indirect Cost Recovery  
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/231:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/232:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/233:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
#data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].contains('HR Payroll')]

Grant - Indirect Cost Recovery  
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/234:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/235:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].contains('HR Payroll')]
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/236:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].str.contains('HR Payroll')]
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/237:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/238:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].str.contains('HR Payroll')]
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/239:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[data['Transaction Description'].str.contains('HR Payroll')]
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/240:
td = data['Transaction Description']
btd = td.str.contains('HR')
279/241:
td = data['Transaction Description']
btd = td.str.contains('HR')
btd.head()
279/242:
td = data['Transaction Description']
btd = td.str.contains('HR')
btd.fillna(False)
btd.head()
279/243:
td = data['Transaction Description']
btd = td.str.contains('HR')
btd.fillna(False)
btd.fillna?
279/244:
td = data['Transaction Description']
btd = td.str.contains('HR')
btd.fillna(False,inplace=True)
btd.head()
279/245:
td = data['Transaction Description']
btd = td.str.contains('HR')
btd.fillna(False,inplace=True)
~btd.head()
279/246:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].str.contains('HR Payroll').fillna(False,inplace=True)]
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/247:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/248:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
data = data[~data['Transaction Description'].str.contains('HR Payroll').fillna(False,inplace=True)]
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/249:
a = data['Transaction Description'].str.contains('HR Payroll').fillna(False,inplace=True)
#td = data['Transaction Description']
#btd = td.str.contains('HR')
#btd.fillna(False,inplace=True)
#~btd.head()
a.head()
279/250:
a = data['Transaction Description'].str.contains('HR Payroll')
#td = data['Transaction Description']
#btd = td.str.contains('HR')
#btd.fillna(False,inplace=True)
#~btd.head()
a.head()
279/251:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/252:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
tmp = data['Transaction Description'].str.contains('HR Payroll').fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/253:
a = data['Transaction Description'].str.contains('HR Payroll')
#td = data['Transaction Description']
#btd = td.str.contains('HR')
#btd.fillna(False,inplace=True)
#~btd.head()
tmp.head()
279/254:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
tmp = data['Transaction Description'].str.contains('HR Payroll')
tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
data.set_index('Trans Date',inplace=True)
data.head()
279/255:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/256:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
data.set_index(['Account','Trans Date',inplace=True)
data.head()
279/257:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
data.set_index(['Account','Trans Date'],inplace=True)
data.head()
279/258:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/259:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
data.set_index(['Account','Trans Date'],inplace=True)
data.head()
279/260:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/261:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby(by='Account')

#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/262:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby(by='Account')
print(dg)
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/263:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby(by='Account')
dg.resample('M')['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/264:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby(by='Account')
dg.head()
#dg.resample('M')['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/265:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby(by='Account')
dg.head()
dg.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/266:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby(by='Account')
dg.head()
data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/267:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby(by='Account')
dg.level
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/268:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby(by='Account')
print(dg.level)
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/269:
#dg = data.groupby(by='Activity')['Transaction Amount']
data['account'].groupby('Transaction Amount').sum().plot()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/270:
#dg = data.groupby(by='Activity')['Transaction Amount']
data['Account'].groupby('Transaction Amount').sum().plot()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/271:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.groupby('Account')['Transaction Amount'].resample('M').sum().plot()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/272:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/273:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()
279/274:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.groupby('Account')['Transaction Amount'].resample('M').sum().plot()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/275:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.groupby('Account').resample("M")['Transaction Amount'].sum().plot()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/276:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/277:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()
279/278:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.groupby('Account').resample("M")['Transaction Amount'].sum().plot()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/279:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.groupby('Account')["Transaction Amount"].resample("M").sum().plot()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/280:
#dg = data.groupby(by='Activity')['Transaction Amount']
data.groupby('Account')["Transaction Amount"].resample("M").sum()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/281:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()


#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/282:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()
dg

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/283:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()
dg.groupby['Account'].sum()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/284:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()
dg.sum()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/285:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()
dg.groupby('Account').sum()

#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/286:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = dg.groupby('Account').sum()

act = dg['Account'][0]
act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/287:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = dg.groupby('Account').sum()

#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/288:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
dg.plot()
279/289:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = dg.groupby('Account').sum()

#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/290:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
dg
279/291:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = dg.groupby('Account').sum()

data.groupby('Account')["Transaction Amount"].resample("M").sum().plot()
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/292:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = dg.groupby('Account').sum()

data.groupby('Account')["Transaction Amount"].resample("M").plot()
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/293:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/294:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()
279/295:
#dg = data.groupby(by='Activity')['Transaction Amount']
dg = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = dg.groupby('Account').sum()

data.groupby('Account')["Transaction Amount"].resample("M").plot()
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/296:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = dg.groupby('Account').sum()

dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/297:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
dg
279/298:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
dg.plot()
279/299:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
dg
279/300:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
data.groupby('Account')["Transaction Amount"].plot(legend=True)
279/301:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
plt.figure(size=(8,5))
data.groupby('Account')["Transaction Amount"].plot(legend=True)
279/302:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
plt.figure(figsize=(8,5))
data.groupby('Account')["Transaction Amount"].plot(legend=True)
279/303:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
plt.figure(figsize=(12,7))
data.groupby('Account')["Transaction Amount"].plot(legend=True)
279/304:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
#plt.figure(figsize=(12,7))
#data.groupby('Account')["Transaction Amount"].plot(legend=True)
account_by_date
279/305:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
#plt.figure(figsize=(12,7))
#data.groupby('Account')["Transaction Amount"].plot(legend=True)
type(account_by_date)
279/306:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
#plt.figure(figsize=(12,7))
#data.groupby('Account')["Transaction Amount"].plot(legend=True)
account_by_date.plot()
279/307:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
#plt.figure(figsize=(12,7))
#data.groupby('Account')["Transaction Amount"].plot(legend=True)
account_by_date['Account']
279/308:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
#plt.figure(figsize=(12,7))
#data.groupby('Account')["Transaction Amount"].plot(legend=True)
pd.DataFrame(account_by_date).plot()
279/309:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
#plt.figure(figsize=(12,7))
#data.groupby('Account')["Transaction Amount"].plot(legend=True)
account_by_date
279/310:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
#plt.figure(figsize=(12,7))
#data.groupby('Account')["Transaction Amount"].plot(legend=True)
account_by_date.keys()
279/311:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
#plt.figure(figsize=(12,7))
#data.groupby('Account')["Transaction Amount"].plot(legend=True)
account_by_date['71000']
279/312:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
#plt.figure(figsize=(12,7))
#data.groupby('Account')["Transaction Amount"].plot(legend=True)
account_by_date['710000']
279/313:
# 740005: FAC for Mobile Lab
# 740004: FAC for Velodyne Lidar
#plt.figure(figsize=(12,7))
#data.groupby('Account')["Transaction Amount"].plot(legend=True)
accountnames = {}
account_by_date['710000']
account_by_date
279/314: totals
279/315: data[data['Account']==710000]
279/316: data[data['Account']==710000].head()
279/317: data[data['Account']=='710000'].head()
279/318: data[data['Account']=='710000']
279/319:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = dg.groupby('Account')['Transaction Amount'].resample("A").sum()

dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/320:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/321:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()
279/322:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = dg.groupby('Account')["Transaction Amount"].resample("A").sum()

dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/323:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = data.groupby('Account')["Transaction Amount"].resample("A").sum()
totals

#totals = dg.groupby('Account')["Transaction Amount"].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/324:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = data.groupby('Account')["Transaction Amount"].resample("Y").sum()
totals

#totals = dg.groupby('Account')["Transaction Amount"].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/325:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = data.groupby('Account')["Transaction Amount"].resample("Y")
totals

#totals = dg.groupby('Account')["Transaction Amount"].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/326:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = data.groupby('Account')["Transaction Amount"].resample("Y")
totals.head()

#totals = dg.groupby('Account')["Transaction Amount"].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/327:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = data.groupby('Account')["Transaction Amount"].resample("Y").sum()

#totals = dg.groupby('Account')["Transaction Amount"].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/328:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = data.groupby('Account')["Transaction Amount"].resample("A").sum()

#totals = dg.groupby('Account')["Transaction Amount"].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/329:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

#totals = dg.groupby('Account')["Transaction Amount"].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/330:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals = acount_by_date.groupby('Account')["Transaction Amount"].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/331:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals = account_by_date.groupby('Account')["Transaction Amount"].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/332: account_by_date
279/333: account_by_date.groupby('Account').resample("A").sum()
279/334: account_by_date
279/335: account_by_date.groupby('Account').sum()
279/336:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_date.groupby('Account').sum()
totalsbydate = data.resample("A").groupby('Account')

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/337:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_date.groupby('Account').sum()
totalsbydate = data['TransationAmount'].resample("A").groupby('Account')

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/338:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_date.groupby('Account').sum()
totalsbydate = data['Transation Amount'].resample("A").groupby('Account')

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/339:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_date.groupby('Account').sum()
totalsbydate = data['Transation Amount'].resample("A")

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/340:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_date.groupby('Account').sum()
totalsbydate = data['Transaction Amount'].resample("A")

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/341: totalsbydate
279/342:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_date.groupby('Account').sum()
totalsbydate = data['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/343: totalsbydate
279/344:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_date = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_date.groupby('Account').sum()
totalsbydate = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/345: totalsbydate
279/346:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_month = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')["Transaction Amount"].resample("M")
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/347: totalsbydate
279/348: account_by_month.describe()
279/349: account_by_month.mean()
279/350: account_by_month
279/351: data['Account'].describe()
279/352: data.Account.unique()
279/353: account_by_month
279/354: data.Account.unique()
279/355: data[data.Account=='715000'].count()
279/356: data[data.Account=='715000'].sum()
279/357:
#dg = data.groupby(by='Activity')['Transaction Amount']
account_by_month = data.groupby('Account')["Transaction Amount"].resample("M").sum()
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/358: dg
279/359: dg.Account
279/360: dg
279/361: dg.groups.keys()
279/362: account_by_month = data.groupby('Account')["Transaction Amount"].resample("M").sum?
279/363:
%matplotlib inline

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
279/364:
#dg = data.groupby(by='Activity')['Transaction Amount']
def custom_nansum(val):
    return np.nansum(val)

account_by_month = data.groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/365: account_by_month
279/366: account_by_month.groups.keys()
279/367: data.groupby('Account')['Transaction Amount'].resample("M")
279/368:
a = data.groupby('Account')['Transaction Amount']
a.groups.keys()
279/369:
a = data.groupby('Account')['Transaction Amount']
a.groups.resample("M").keys()
279/370:
a = data.groupby('Account')['Transaction Amount']
a.resample("M").keys()
279/371:
a = data.groupby('Account')['Transaction Amount']
a.resample("M")
279/372: account_by_month = data.groupby('Account')["Account"].resample("M")
279/373: account_by_month = data.groupby('Account')["Account"].resample("M").sum()
279/374:
account_by_month = data.groupby('Account')["Account"].resample("M").sum()
account_by_month
279/375: account_by_month = data.groupby('Account')["Account"]
279/376:
account_by_month = data.groupby('Account')["Account"]
account_by_month
279/377:
account_by_month = data.groupby('Account')["Account"]
account_by_month.resample("M")
279/378:
account_by_month = data.groupby('Account')["Account"]
account_by_month.resample("M").apply(np.unique)
279/379:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof. Services', "76O170"}
279/380:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services', "76O170"}
279/381:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
279/382:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/383:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
279/384:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
accountnames.values()
279/385:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
for val in accountnames.values:
    s.val = data[data.Account == val]["Transaction Amount"].sum()
279/386:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
for val in accountnames.values():
    s.val = data[data.Account == val]["Transaction Amount"].sum()
279/387:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
for val in accountnames.values():
    s[val]= data[data.Account == val]["Transaction Amount"].sum()
279/388:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
for val in accountnames.values():
    s[val]= data[data.Account == val]["Transaction Amount"].sum()
279/389:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
for val in accountnames.values():
    s[val]= data[data.Account == val]["Transaction Amount"].sum()

print(s)
279/390:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
    s[val,year]= data[data.Account == val and data.index.year == year]["Transaction Amount"].sum()

print(s)
279/391:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        s[val,year]= data[data.Account == val and data.index.year == year]["Transaction Amount"].sum()

print(s)
279/392:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        s[val + '_' + year]= data[data.Account == val and data.index.year == year]["Transaction Amount"].sum()

print(s)
279/393:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()

print(s)
279/394:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year.values== year]["Transaction Amount"].sum()


print(s)
279/395:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year== year]["Transaction Amount"].sum()


print(s)
279/396:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year=='year']["Transaction Amount"].sum()


print(s)
279/397:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
dg = data.groupby('Y')
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year]["Transaction Amount"].sum()


print(s)
279/398:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
dg = data.groupby(freq='Y')
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year]["Transaction Amount"].sum()


print(s)
279/399:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
dg = data.groupby(by='Y')
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year]["Transaction Amount"].sum()


print(s)
279/400:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
dg = data.groupby(by='year')
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year]["Transaction Amount"].sum()


print(s)
279/401:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
dg = data.groupby(by=year)
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year]["Transaction Amount"].sum()


print(s)
279/402:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
del year
dg = data.groupby(by=year)
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year]["Transaction Amount"].sum()


print(s)
279/403:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
del year
dg = data.groupby(by="A")
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year]["Transaction Amount"].sum()


print(s)
279/404:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
dg = data.groupby(by="A")
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year]["Transaction Amount"].sum()


print(s)
279/405:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
dg = data.groupby(by=index)
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year]["Transaction Amount"].sum()


print(s)
279/406: data.index.year
279/407:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        #s[val + '_' + year]= data[data.Account == val and data.index.year.values== year]["Transaction Amount"].sum()
        s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()


print(s)
279/408: data.index.year==2016
279/409: data[data.index.year==2016]['Transaction Amount']
279/410: data[data.index.year==2016 and data.Account == 71500]['Transaction Amount']
279/411: data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
279/412: data[[data.index.year==2016] and [data.Account == '71500']]['Transaction Amount']
279/413: data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
279/414:
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
t1 = data.index.year == 2016
t2 = data.Account=='715000'
t3 = t1 and t2
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
279/415:
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
t1 = data.index.year == 2016
t2 = data.Account=='715000'
t3 = t1 AND t2
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
279/416:
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
t1 = data.index.year == 2016
t2 = data.Account=='715000'
t3 = t1 & t2
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
279/417:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        s[val + '_' + year]= data[data.Account == val & data.index.year.values== year]["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()


print(s)
279/418:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        s[val + '_' + year]= data[data.Account == val & data.index.year== year]["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()


print(s)
279/419:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    for year in years:
        s[val + '_' + year]= data[data.index.year== year][data.Account=='715000']["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()


print(s)
279/420:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = ['2016', '2017','2018']
for val in accountnames.values():
    d = data[data.Account==val]
    for year in years:
        s[val + '_' + year]= d[data.index.year== year]["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()


print(s)
279/421:
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
d
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
279/422:
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
d[d.index.year == 2017]
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
279/423:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = [2016, 2017,2018]
for val in accountnames.values():
    d = data[data.Account==val]
    for year in years:
        s[val + '_' + year]= d[data.index.year== year]["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()


print(s)
279/424:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = [2016, 2017,2018]
for val in accountnames.values():
    d = data[data.Account==val]
    for year in years:
        s[val + '_' + str(year)]= d[data.index.year== year]["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()


print(s)
279/425:
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
d[d.index.year == 2017]['Transaction Amount'].sum()
#data[data.index.year==2016 and data.Account == '71500']['Transaction Amount']
279/426:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = [2016, 2017,2018]
for val in accountnames.values():
    d = data[data.Account==val]
    for year in years:
        s= d[data.index.year== year]["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        print(s)

print(s)
279/427:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = [2016, 2017,2018]
for val in accountnames.values():
    d = data[data.Account==val]
    for year in years:
        s= d[d.index.year== year]["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        print(s)

print(s)
279/428:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = [2016, 2017,2018]
for val in accountnames.values():
    d = data[data.Account==val]
    for year in years:
        s[val + '_' + year]= d[d.index.year== year]["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/429:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = [2016, 2017,2018]
for val in accountnames.values():
    d = data[data.Account==val]
    for year in years:
        s[val + '_' + str(year)]= d[d.index.year== year]["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/430:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = [2016, 2017,2018]
for val in accountnames.values():
    d = data[data.Account==val]
    for year in years:
        s[val][[str(year)]= d[d.index.year== year]["Transaction Amount"].sum()
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/431:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
years = [2016, 2017,2018]
for val in accountnames.values():
    d = data[data.Account==val]
    for year in years:
        y[str(year)] = d[d.index.year== year]["Transaction Amount"].sum()
        s[val] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/432:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
y={}
years = [2016, 2017,2018]
for val in accountnames.values():
    d = data[data.Account==val]
    for year in years:
        y[str(year)] = d[d.index.year== year]["Transaction Amount"].sum()
        s[val] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/433: s.710100
279/434:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
y={}
years = [2016, 2017,2018]
for key in accountnames.keys():
    d = data[data.Account==accountnames(key)]
    for year in years:
        y[str(year)] = d[d.index.year== year]["Transaction Amount"].sum()
        s[key] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/435:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
y={}
years = [2016, 2017,2018]
for key in accountnames.keys():
    d = data[data.Account==accountnames[key]]
    for year in years:
        y[str(year)] = d[d.index.year== year]["Transaction Amount"].sum()
        s[key] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/436: accountnames(key)
279/437: accountnames[key]
279/438: d
279/439: del d
279/440:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
y={}
years = [2016, 2017,2018]
for key in accountnames.keys():
    d = data[data.Account==accountnames[key]]
    for year in years:
        y[str(year)] = d[d.index.year== year]["Transaction Amount"].sum()
        s[key] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
279/441: print(s)
279/442: accountnames[key]
279/443: d[d.index.year==2016]
279/444: d[d.index.year==2017]
279/445: d[d.index.year==2017]['Transaction Amount']
279/446: d[d.index.year==2017]['Transaction Amount'].sum()
279/447:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
y={}
years = [2016, 2017,2018]
for key in accountnames.keys():
    d = data[data.Account==accountnames[key]]
    for year in years:
        y[str(year)] = d[d.index.year== year]["Transaction Amount"].sum()
        s[key] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/448:
a = data.groupby('Account')['Transaction Amount']
a.resample("M")
279/449:
a = data.groupby('Account')['Transaction Amount']
a.resample("M").sum()
279/450:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
y={}
years = [2016, 2017,2018]
for key in accountnames.keys():
    d = data[data.Account==accountnames[key]]['Transaction Amount']
    for year in years:
        y[str(year)] = d[d.index.year== year]["Transaction Amount"].sum()
        s[key] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/451:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
y={}
years = [2016, 2017,2018]
for key in accountnames.keys():
    d = data[data.Account==accountnames[key]]
    for year in years:
        y[str(year)] = d[d.index.year== year]["Transaction Amount"].sum()
        s[key] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/452: d[d.index.year==2017]
279/453:
%matplotlib inline

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
279/454:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/455:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
279/456:
#dg = data.groupby(by='Activity')['Transaction Amount']
def custom_nansum(val):
    return np.nansum(val)

account_by_month = data.groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/457:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
y={}
years = [2016, 2017,2018]
for key in accountnames.keys():
    d = data[data.Account==accountnames[key]]
    for year in years:
        y[str(year)] = d[d.index.year== year]["Transaction Amount"].sum()
        s[key] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/458:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
y={}
years = [2016, 2017,2018]
for key in accountnames.keys():
    d = data[data.Account==accountnames[key]]
    for thisyear in years:
        y[str(thisyear)] = d[d.index.year== thisyear]["Transaction Amount"].sum()
        s[key] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/459: d=data[data.Account == 'General Capital Equip']
279/460:
d=data[data.Account == 'General Capital Equip']
d
279/461:
d=data[data.Account == accountnames['General Capital Equip']]
d
279/462:
d=data[data.Account == accountnames['General Capital Equip']]
key
279/463:
d=data[data.Account == accountnames['General Capital Equip']]
thisyear
279/464:
d=data[data.Account == accountnames['General Capital Equip']]
d[d.index.year== thisyear]["Transaction Amount"].sum()
279/465:
d=data[data.Account == accountnames['General Capital Equip']]
d["Transaction Amount"].sum()
279/466:
d=data[data.Account == accountnames['General Capital Equip']]
d
279/467:
#account_by_month = data.groupby('Account')["Account"]
#account_by_month.resample("M").apply(np.unique)
s = {}
y={}
years = [2016, 2017,2018]
for key in accountnames.keys():
    d = data[data.Account==accountnames[key]]
    for thisyear in years:
        y[str(thisyear)] = np.sum(d[d.index.year== thisyear]["Transaction Amount"])
        s[key] = y
        #s[val + '_' + year]= data[data.index.year==year]["Transaction Amount"].sum()
        

print(s)
279/468: account_by_month.groups.keys()
279/469:
#dg = data.groupby(by='Activity')['Transaction Amount']
def custom_nansum(val):
    return np.nansum(val)

account_by_month = data.groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/470: account_by_month.groups.keys()
279/471: data.groupby('Account').groups.keys()
279/472: data.groupby('Account')['Transaction Amount'].groups.keys()
279/473: data.groupby('Account')['Transaction Amount'].resample("M").groups.keys()
279/474: data.groupby('Account')['Transaction Amount'].resample("M").sum()
279/475: data.groupby('Account')['Transaction Amount'].resample("M")
279/476: data.groupby('Account')['Transaction Amount'].resample("M").groups.keys()
279/477: data.groupby('Account')['Transaction Amount'].groups.keys()
279/478: print(data.groupby('Account')['Transaction Amount'].groups.keys())
279/479:
print(data.groupby('Account')['Transaction Amount'].groups.keys())
d=data.groupby('Account')['Transaction Amount']
d.resample?
279/480:
print(data.groupby('Account')['Transaction Amount'].groups.keys())
d=data.groupby('Account')['Transaction Amount']
d.resample("M").sum()
279/481:
print(data.groupby('Account')['Transaction Amount'].groups.keys())
d=data.groupby('Account')['Transaction Amount']
d
279/482:
print(data.groupby('Account')['Transaction Amount'].groups.keys())
d=data.groupby('Account')['Transaction Amount']
print(d)
279/483:
print(data.groupby('Account')['Transaction Amount'].groups.keys())
d=data.groupby('Account')['Transaction Amount']
d.describe()
279/484:
print(data.groupby('Account')['Transaction Amount'].groups.keys())
d=data.groupby('Account')['Transaction Amount']
d.get_group('715000')
279/485:
print(data.groupby('Account')['Transaction Amount'].groups.keys())
d=data.groupby('Account')['Transaction Amount']
d.get_group('715000').sum()
279/486:
#dg = data.groupby(by='Activity')['Transaction Amount']
def custom_nansum(val):
    return np.nansum(val)

dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    
account_by_month = data.groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
279/487:
for g,grp in account_by_month:
    print(g)
    print(grp)
279/488:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")


for g,grp in account_by_month_grp:
    print(g)
    print(grp)
279/489:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
279/490:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
279/491:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
279/492:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")


for g,grp in account_by_month_grp:
    print(g)
    print(grp)
279/493:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

print(account_by_month_grp)
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
279/494:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

account_by_month_grp.groups.keys()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
279/495:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
279/496:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
print(dd)
279/497:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
for a,b in dd:
    print(a b)
279/498:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
for a,b in dd:
    print(a, b)
279/499:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
type(dd)
279/500:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
dd.get_values?
279/501:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
dd.index
279/502:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.labels
279/503:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.labels
print(a)
279/504:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.levels
print(a)
279/505:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.levels
print(a[0])
279/506:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.levels
for a,b in dd.index.levels
print(a)
print(b)
279/507:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.levels
for a,b in dd.index.levels:
    print(a)
    print(b)
279/508:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.levels
print(a)
279/509:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.levels
print(a[0].shape())
279/510:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.levels
print(a[0].shape)
279/511:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.levels
print(a[1].shape)
281/1: F = '/a/b/c'
281/2: F.basename()
281/3: basename.(F)
281/4: import os
281/5: os.walk?
281/6: os.path.basename('/a/b/c/')
281/7: os.path.basename('/a/b/c')
281/8: os.path.dirname('/a/b/c')
281/9: os.path.split('a/b/c')
281/10: os.path.split('a/b/c/d')
281/11: ls
281/12: os.path.realpath('Movies/')
281/13: a = int('1')
281/14: print('%d' % a)
281/15: print('%d' % a-3)
281/16: print('%d' % a - 3)
281/17: print('%d' % (a - 3))
282/1: import subprocess
282/2: a = subprocess.call?
282/3: import Popen
282/4: import Popen2
282/5: import popen2
282/6: popen2.sys?
282/7: os.system/
282/8: os.system?
282/9: import os
282/10: os.system?
283/1: import pandas as pd
283/2: ls
283/3: pilot = pd.read__csv('pilot.csv')
283/4: pd.read_csv?
283/5: pilot = pd.read_csv('pilot.csv')
283/6: pilot
283/7: pilot.head()
283/8: pilot.head()
283/9: ls
283/10: pilot.to_hdf?
283/11: pilot.to_hdf('pilot.h5',key='pilot',mode='w')
283/12: pilot.to_hdf('pilot.h5',key='pilot',mode='w',dropna=True)
283/13: pilot.to_hdf('pilot.h5',key='pilot',mode='w',dropna=True,'complevel',9)
283/14: pilot.to_hdf('pilot.h5',key='pilot',mode='w',dropna=True,complevel=9)
283/15: pilot2 = pd.read_hdf('pilot.h5')
283/16: pilot==pilot2
283/17: pilot2.info()
283/18: pilot.info()
284/1: import pandas as pd
285/1: import pandas as pd
285/2: pilot = pd.read_csv('pilot.csv')
285/3: pilot.to_hdf('pilot_compressed.h5',key='pilot',mode='w',dropna=True,complevel=9)
285/4: pilot.to_hdf('pilot_compressed.h5',key='/pilot',mode='w',dropna=True,complevel=9)
285/5: pilot.to_hdf('pilot.h5',key='/pilot',mode='w',dropna=True))
285/6: pilot.to_hdf('pilot.h5',key='/pilot',mode='w',dropna=True)
286/1: import pandas as pd
286/2: cd /Volumes/CI_01/extracted_logs/2018-07-25T14-35-10/
286/3: ls
286/4: pd.read_hdf('pilot_compressed.h5')
286/5: whos
286/6: pilot = pd.read_hdf('pilot_compressed.h5')
286/7: pilot.head()
286/8: pilot.info()
286/9: import matplotlib as plt
286/10: plt.plot(pilot['Heading Control | Desired Heading(deg)'])
286/11: import matplotlib.pyplot as plt
286/12: plt.plot(pilot['Heading Control | Desired Heading(deg)'])
286/13: plt.show()
286/14: plt.plot(pilot['Heading Control | Desired Heading(deg)'],'.')
286/15: plt.show()
286/16: clear pilot
286/17: del pilot
286/18: ls
286/19: hdt = pd.read_csv('nmea2000_vessel_heading_pgn127250.txt',delimiter=' ')
286/20: hdt
286/21: hdt.head()
286/22: hdt.to_hdf?
286/23: hdt.to_hdf('hdt.h5',key='/hdt',complevel=9)
286/24: hdt2 = pd.read_hdf('hdt.h5')
286/25: hdt==hdt2
286/26: hdt.heading_sensor_reference[1]
286/27: hdt.heading_sensor_reference[10]
286/28: hdt.heading_sensor_reference[1]==hdt2.heading_sensor_reference[1]
286/29: hdt2.heading_sensor_reference[1]
286/30: nan==nan
286/31: import numpy as np
286/32: np.nan == np.nan
286/33: hdt2.head()
286/34: hdt.head()
286/35: hdt2.head()
286/36: hdt2.dtypes
286/37: hdt.dtypes
286/38: hdt2.to_hdf?
286/39: hdt.to_hdf('hdt_table.h5',key='/hdt',complevel=9,format='table')
286/40: hdt.to_hdf('hdt_table.h5',key='/hdt',complevel=9,format='table')
286/41: hdt.to_hdf('hdt_table.h5',key='/hdt',format='table')
286/42: hdt.dtypes
286/43: hdt.astype?
286/44: hdt.log_timestamp?
286/45: hdt.log_timestamp.dtype
286/46: hdt.log_timestamp.dtype()
286/47: hdt.log_timestamp.dtype
286/48: dts = pd.Timestamp(hdt.log_timestamp)
286/49: hdt.log_timestamp(1)
286/50: hdt.log_timestamp[1]
286/51: hdt.log_timestamp[2]
286/52: hdt.log_timestamp[3]
286/53: hdt.log_time[1]
286/54: hdt.log_time[2]
286/55: hdt.log_time[3]
286/56: hdt.log_timestamp[1]
286/57: hdt.head()
286/58: hdt.head()
286/59: hdt.log_timestamp[1]
286/60: hdt.log_timestamp[0]]
286/61: hdt.log_timestamp[0]
286/62: hdt.info()
286/63: hdt = pd.read_csv('nmea2000_vessel_heading_pgn127250.txt',delimiter='\s+')
286/64: hdt.info()
286/65: hdt.head()
286/66: hdt.to_hdf('hdt.h5',key='/hdt',complevel=9)
287/1: cd /Volumes/CI_01/extracted_logs/2018-07-25T14-35-10/
287/2: hdt = pd.read_csv('nmea2000_vessel_heading_pgn127250.txt',delimiter='\s+')
287/3: import pandas as pd
287/4: hdt = pd.read_csv('nmea2000_vessel_heading_pgn127250.txt',delimiter='\s+')
287/5: hdt.to_hdf('hdt_table_h5',key='/hdt', format='table')
287/6: hdt.to_hdf('hdt_table.h5',key='/hdt', format='table')
287/7: hdt.to_hdf?
287/8: hdt.to_hdf('hdt_table.ph5',key='/hdt', format='table')
287/9: hdt.to_hdf('hdt_table.h5',key='/hdt', format='table')
287/10: mv hdt_table.h5 hdt_table.ph5
287/11: cp hdt_table.ph5 hdt_table.h5
287/12: import scipy.io as sio
287/13: sio.savemat?
288/1: import pandas as pd
288/2: ls
288/3: cd /Volumes/CI_01/extracted_logs/2018-07-25T14-35-10/
288/4: ls
288/5: hdt = pd.read_hdf('hdt_table.ph5')
288/6: hdt.head()
289/1: import cProfile
290/1: import gpsparser
290/2: cd ~/gitsrc/ASVG_tools/lib/
290/3: cd ~/gitsrc/ASVG_tools/pyasv/lib/gpsparser/
290/4: ls
290/5: from gpsparser import GPSString
290/6: gps = GPSString("1532541911.123 $GNGGA,180511.0,6429.71061,N,16526.24729,W,1,21,0.6,4.7,M,7.1,M,,*68")
290/7: gps.identify()
290/8: gps.parse()
290/9: gps
290/10: gps.fields
290/11: import Decimal
290/12: import decimal
291/1: a = 1.34
291/2: b = str(a)
291/3: whos
291/4: a = [1.34, 2.34]
291/5: b = str(a)
291/6: whos
291/7: b[1]
291/8: b = (a)
291/9: whos
291/10: b[1]
291/11: b = (str(a))
291/12: whos
291/13: b = map(str,a)
291/14: whos
291/15: b[1]
291/16: import numpy as np
291/17: c = np.rand?
291/18: c = np.random(2)
291/19: c = np.random.normal(2)
291/20: c
291/21: import timeit
291/22: timeit?
292/1: float('NaN')
293/1: import datetime
293/2: dt = datetime.datetime.time?
293/3: dt = datetime.datetime.time(1.3)
293/4: a = int('03')
293/5: a
293/6: dt = datetime.datetime.time(1,2,3.4))
293/7: dt = datetime.datetime.time(1,2,3.4)
293/8: import sys
293/9: a = sys.stdin
293/10: a.fileno?
293/11: a.isatty()
293/12: ls
293/13: b=file('~/test.txt')
293/14: b = file('~/scratch/test.txt')
293/15: ls /Users/vschmidt/scratch/test.txt
293/16: b = file('/Users/vschmidt/scratch/test.txt')
293/17: b.isatty()
293/18: b.name()
293/19: b.name
293/20: a.name
293/21: a = 0
293/22: a++
293/23: a+=1
293/24: a
293/25: a
293/26: a+=1
293/27: a
293/28: import pandas as pd
293/29: a = pd.DataFrame()
293/30: type(a)
293/31: b = [123,234.0,12.3]
293/32: a.append(b)
293/33: a.append(b')
293/34: a.append?
293/35: b
293/36: c = [b; b]
293/37: c = [b, b]
293/38: c
293/39: del a
293/40: a = pd.DataFrame()
293/41: a.append(c)
293/42: c = []
293/43: c.append(b)
293/44: c
293/45: import numpy as np
293/46: a = np.matrix()
293/47: a = np.matrix?
293/48: a = np.matrix(b)
293/49: a.put?
293/50: import Timer
293/51: def hello:
293/52:
def hello():
    print("Hello!")
293/53: t = Time(10,hello)
293/54: t = Timer(10,hello)
293/55: import threading
293/56: t = threading.Timer(10,hello)
293/57: t.start()
293/58: yeild?
293/59: yield?
294/1: pwd
294/2: cd gitsrc/ASVG_tools/pyasv/lib/gpsparser
294/3: import gpsparser
294/4: g = gpsparser.GPSString()
294/5: g = gpsparser.GPSString("")
294/6: g.id
294/7: a = ['1\t2\t', 2,3,'5\t6']
294/8: a.expandtabs()
294/9: a.expand_tabs()
294/10: a = [1,2,3]
294/11: b = [a[:],4,5]
294/12: b
294/13: b = [a,4,5]
294/14: b
294/15: b = [a(:),4,5]
294/16: b = a+[4,5]
294/17: b
294/18: import datetime
294/19: dts = datetime.datetime.now()
294/20: dts.timetuple()
294/21: dts.utctimetuple
294/22: dts.utctimetuple()
294/23: dts.year
295/1: import gpsparser
295/2: g = gpsparser.GPSString("")
296/1: import gpsparser
296/2: g = gpsparser.GPSString("")
296/3: import datetime
296/4: g.datetimevec_numeric(datetime.datetime.now())
296/5: a = [g.datetimevec_numeric(datetime.datetime.now()), 1, 2]
296/6: a
296/7: a = g.datetimevec_numeric(datetime.datetime.now()) + [1, 2]
297/1: import datetime
297/2: import gpsparser
297/3: g = gpsparser.GPSString("")
297/4: g.datetimevec_numeric(datetime.datetime.now())
297/5: g.datetimevec_numeric(datetime.datetime.now()) + [1,3]
297/6: import pandas
297/7: a = [[1, 2],[3,4]]
297/8: a
297/9: import pandas as pd
297/10: d = pd.DataFrame(a)
297/11: d.head()
297/12: import gpsparser
297/13: df.head?
297/14: d.head?
297/15: print(d.head())
297/16: a = [1,2,3]
297/17: a[2:]
297/18: dt
297/19: import datetime
297/20: dt = datetime.datetime.now()
297/21: print(dt)
297/22: a = ['a','b','c']
297/23: map(lambda(x) return pc+x,a)
297/24: map(lambda(x) pc+x,a)
297/25: map(lambda(x) 'pc'+x,a)
297/26: map(lambda x, 'pc'+x,a)
297/27: map(lambda x: 'pc'+x,a)
297/28: g
297/29: g.msg = "1532567110.897 $GNGGA,010510.7,6429.71385,N,16526.25461,W,1,20,0.6,6.8,M,7.1,M,,*6D"
297/30: g.identify()
297/31: g.id
297/32: pwd
297/33: d = pd.read_hdf('/Volumes/CI_01/data_parsed_GGA.h5')
297/34: d = pd.read_hdf('/Volumes/CI_01/data_parsed_GGA.h5')
298/1: import pandas
298/2: import pandas as pd
298/3: data = pd.read_pickle('data.pkl')
298/4: data.head()
298/5: data.info()
298/6: data.to_hdf('data_parsed_GGA.h5',key='/GGA',format='table')
298/7: ls
298/8: ls -l
298/9: data.to_hdf('dataparsedGGA.h5',key='/GGA',format='table')
298/10: import pytables as pt
298/11: pd.__version__
297/35: pd.__version__
298/12: ls
298/13: whos
298/14: data.to_hdf('dataparsedGGA.h5',key='/GGA',format='table')
298/15: data = pd.read_hdf('data_parsed_GGA.h5')
298/16: d = pd.read_hdf('dataparsedGGA.h5')
298/17: d
298/18: data.to_hdf('data-parsed-GGA.h5',key='/GGA',format='table')
298/19: d = pd.read_hdf('data-parsed-GGA.h5')
298/20: data.to_hdf('data_parsed_GGA.h5',key='/GGA',format='table')
293/60: hdt = pd.read_hdf('hdt_table.ph5')
299/1: import pandas as pd
299/2: gga = pd.read_csv('GGA_3_.txt',delimiter='\s+')
299/3: gga = pd.read_csv('GGA_3_.txt',delimiter='\s+')
299/4: cd /Volumes/CI_01/extracted_logs/2018-07-29T18-40-04
299/5: gga = pd.read_csv('GGA_3_.txt',delimiter='\s+')
299/6: import matplotlib.pyplot as plt
299/7: gga.head()
299/8: import proj
299/9: import pyproj
299/10: gga.plot?
299/11: plt.plot(gga[:,13],gga[:,12],'.')
299/12: gga[1]
299/13: gga.head()
301/1: import pandas as pd
301/2: vehicle = pd.read_csv('vehicle.csv',delimiter='\s+')
301/3: vehicle.head()
301/4: vehicle = pd.read_csv('vehicle.csv')
301/5: vehicle.head()
301/6: vehicle.to_hdf('vehcile.h5',format='table',complevel=9)
301/7: vehicle.to_hdf?
301/8: vehicle.to_hdf?
301/9: vehicle.to_hdf('vehcile.h5',mode='w',format='table',complevel=9)
301/10: vehicle.to_hdf?
301/11: vehicle.to_hdf('vehcile.h5',key='/vehicle',mode='w',format='table',complevel=9)
301/12: import matplotlib.pyplot as plt
301/13: vehicle.keys()
301/14: plt.plot(vehicle[''Power | Battery Voltage(V)'],'.')
301/15: plt.plot(vehicle['Power | Battery Voltage(V)'],'.')
301/16: plt.show()
301/17: history
301/18: cd ~/Desktop
301/19: d = pd.read_csv('data.csv')
301/20: data.to_hdf('~/Desktop/data.h5',key='/circuits',mode='w',format='table',complevel=9)
301/21: d.to_hdf('~/Desktop/data.h5',key='/circuits',mode='w',format='table',complevel=9)
301/22: d.to_hdf('/Users/vschmidt/Desktop/data.h5',key='/circuits',mode='w',format='table',complevel=9)
301/23: h.head()
301/24: d.head()
302/1: import pandas as pd
302/2: data = pd.read_csv('data.csv')
302/3: data.head()
303/1: import sys
303/2: import os
303/3: os.stat('0001_20180728_185538_UNH_CW4.all.zip')
303/4: a = os.stat('0001_20180728_185538_UNH_CW4.all.zip')
303/5: a.st_atime - a.st_mtime
303/6: os.stat?
303/7: a.st_ctime - a.st_mtime
304/1: import os
304/2: a = os.stat('0001_20180728_185538_UNH_CW4.all.zip')
304/3: a.ctime
304/4: a.st_ctime
304/5: import datetime
304/6: bb = datetime.datetime.fromtimestamp(a.st_ctime)
304/7: bb.isoformat()
304/8: bb = datetime.datetime.fromtimestamp(a.st_mtime)
304/9: bb.isoformat()
304/10: b = os.stat('')
304/11: os.path.samestat?
304/12: os.stat('0001_20180728_185538_UNH_CW4.all')
304/13: os.listdir('.')
304/14: f[1][:-3]
304/15: f = os.listdir('.')
304/16: f[1][:-3]
304/17: f[0][-3:]
304/18: f[0][-3:] == 'all'
304/19: f[0][-3:] != 'all'
304/20: import sys
306/1: pwd
306/2: run('/Users/vschmidt/gitsrc/kmall/kmall.py')
306/3: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-h', wdir='/Users/vschmidt/gitsrc/kmall')
306/4: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-h', wdir='/Users/vschmidt/gitsrc/kmall')
306/5: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-h', wdir='/Users/vschmidt/gitsrc/kmall')
306/6: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-h', wdir='/Users/vschmidt/gitsrc/kmall')
306/7: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-h', wdir='/Users/vschmidt/gitsrc/kmall')
306/8: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-h', wdir='/Users/vschmidt/gitsrc/kmall')
306/9: a.b = 3
306/10: a['b'] = 3
306/11: dict?
307/1: import EMdgm
307/2: a = EMdgm.EMdgmHeader_def
308/1: import EMdgm
308/2: a = EMdgm.header
309/1: a = EMdgm.EMdgmHeader_def
309/2: import EMdgm
309/3: a = EMdgm.EMdgmHeader_def
309/4: a
309/5: print(a)
310/1: import EMdgm as E
311/1: import EMdgm
312/1: import EMdgm
313/1:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots/2*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame()
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetEfficiency'] = JetEfficiency
power.set_index(knots,inplace=True)
313/2: print(power)
313/3:
plt.figure()
plt.plot(knots,ThrustkN)
plt.plot(knots,JetPower/1000)
plt.plot(knots,JetEfficiency)
plt.grid(True)
plt.legend(['Thrust','JetPower - KW','Jet Efficiency'])
plt.show()
313/4:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots/2*ThrustkN*1000
ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / ShaftPower * 100

power = pd.DataFrame()
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetPowerHP'] = JetPower / 745
power['JetEfficiency'] = JetEfficiency
power.set_index(knots,inplace=True)
313/5: print(power)
313/6:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import interpolate 
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots/2*ThrustkN*1000

# From engine performance curves.
EngRatePwr = np.array([11,17.5,22])
EngRateRPM = np.array([1400 2000 3200])
EngPwr = interpolate.interp1d(EngRateRPM,EngRatePwr,fill_value='extrapolate')
rpm = np.array(range(1,3200,100))


#ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / EngPwr(rpm) * 100


power = pd.DataFrame()
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetPowerHP'] = JetPower / 745
power['JetEfficiency'] = JetEfficiency
power.set_index(knots,inplace=True)
313/7:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import interpolate 
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots/2*ThrustkN*1000

# From engine performance curves.
EngRatePwr = np.array([11,17.5,22])
EngRateRPM = np.array([1400, 2000, 3200])
EngPwr = interpolate.interp1d(EngRateRPM,EngRatePwr,fill_value='extrapolate')
rpm = np.array(range(1,3200,100))


#ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / EngPwr(rpm) * 100


power = pd.DataFrame()
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetPowerHP'] = JetPower / 745
power['JetEfficiency'] = JetEfficiency
power.set_index(knots,inplace=True)
313/8: rpm
313/9: shape(rpm)
313/10: rpm.shape
313/11:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import interpolate 
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots/2*ThrustkN*1000

# From engine performance curves.
EngRatePwr = np.array([11,17.5,22])
EngRateRPM = np.array([1400, 2000, 3200])
EngPwr = interpolate.interp1d(EngRateRPM,EngRatePwr,fill_value='extrapolate')
rpm = np.array(range(1,3200,320))


#ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / EngPwr(rpm) * 100


power = pd.DataFrame()
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetPowerHP'] = JetPower / 745
power['JetEfficiency'] = JetEfficiency
power.set_index(knots,inplace=True)
313/12: print(power)
313/13: EngPwr
313/14: EngPwr(rpm)
313/15: JetPower
313/16: EngPwr(rpm)
313/17:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import interpolate 
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots/2*ThrustkN*1000

# From engine performance curves.
EngRatePwr = np.array([11,17.5,22])*100
EngRateRPM = np.array([1400, 2000, 3200])
EngPwr = interpolate.interp1d(EngRateRPM,EngRatePwr,fill_value='extrapolate')
rpm = np.array(range(1,3200,320))


#ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / EngPwr(rpm) * 100


power = pd.DataFrame()
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetPowerHP'] = JetPower / 745
power['JetEfficiency'] = JetEfficiency
power.set_index(knots,inplace=True)
313/18: print(power)
313/19: EngPwr(rpm)
313/20:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import interpolate 
%matplotlib notebook

# Thurst curve data:
knots = np.transpose(np.array(range(1,11)))
ThrustkN = np.array([1.8,1.78,1.7,1.65,1.61,1.58,1.52,1.49,1.45,1.4]) # From plot above.
JetPower = knots/2*ThrustkN*1000

# From engine performance curves.
EngRatePwr = np.array([11,17.5,22])*1000
EngRateRPM = np.array([1400, 2000, 3200])
EngPwr = interpolate.interp1d(EngRateRPM,EngRatePwr,fill_value='extrapolate')
rpm = np.array(range(1,3200,320))


#ShaftPower = 20000  # approx, 30HP is 22kW
JetEfficiency = JetPower / EngPwr(rpm) * 100


power = pd.DataFrame()
power['ThurstKN'] = ThrustkN
power['JetPower'] = JetPower
power['JetPowerHP'] = JetPower / 745
power['JetEfficiency'] = JetEfficiency
power.set_index(knots,inplace=True)
313/21: EngPwr(rpm)
313/22: print(power)
314/1: import pandas as pd
314/2: cd /Volumes/ENG2015ASV/data/cworker4/extracted_logs/2018-04-20T12-32-17
314/3: d = pd.read_csv('GGA_3_.txt',delimiter='\s+')
314/4: d.to_hdf('GGA_3_.hf',format='table')
314/5: d.to_hdf('GGA_3_.hf',key='/hav',format='table')
314/6: timenames = ['year','month','day','hour','minute','second']
314/7: import sys
314/8: sys.path
314/9: sys.path.append('/Users/vschmidt/gitsrc/ASVG_tools/pyasv/lib/gpsparser/')
314/10: import gpsparser as gp
314/11: G = gp.GPSString()
314/12: G = gp.GPSString('')
314/13:
Last login: Tue Sep 25 14:50:46 on ttys002
aha:~ vschmidt$ less ~/gitsrc/ASVG_tools/pyasv/lib/gpsparser/gpsparser.py






















                           'semimajor',
                           'semiminor',
                           'orientation',
                           'lat1sigma',
                           'lon1sigma',
                           'height1sigma'],
                    "GSV":['pctime',
                           'PRN',
                           'elevation',
                           'azimuth',
                           'snr'],
                    "VTG":['pctime',
                           'cog',
                           'knots',
                           'kmph'],
                    "HDT":['pctime',
                           'heading'],
                    "PASHR": ['pctime',
                              'gpstime',
                              'heading',
                              'roll',
                              'pitch',
                              'heave',
                              'rollaccuracy',
                              'headingaccuracy',
                              'headingalgorithm',
                              'imustatus'],
                    "GGK":['pctime',
                           'gpstime',
                           'latitude',
                           'longitude',
                           'quality',
                           'svs',
                           'dop',
                           'eht']
        }
314/14:
def assign_fieldnames(stringtype):
    ''' A function to assing fieldnames when writing MATLAB structures.'''
    
    switcher = {
                "GGA":['pctime',
                       'gpstime',
                       'latitude',
                       'longitude',
                       'quality',
                       'svs',
                       'hdop',
                       'antennaheight',
                       'geoid'],
                "ZDA":['pctime',
                       'gpstime'],
                "RMC":['pctime',
                       'gpstime',
                       'fixstatus',
                       'latitude',
                       'longitude',
                       'knots',
                       'cog',
                       'magneticvariation'],
                "GST":['pctime',
                       'gpstime',
                       'residualrms',
                       'semimajor',
                       'semiminor',
                       'orientation',
                       'lat1sigma',
                       'lon1sigma',
                       'height1sigma'],
                "GSV":['pctime',
                       'PRN',
                       'elevation',
                       'azimuth',
                       'snr'],
                "VTG":['pctime',
                       'cog',
                       'knots',
                       'kmph'],
                "HDT":['pctime',
                       'heading'],
                "PASHR": ['pctime',
                          'gpstime',
                          'heading',
                          'roll',
                          'pitch',
                          'heave',
                          'rollaccuracy',
                          'headingaccuracy',
                          'headingalgorithm',
                          'imustatus'],
                "GGK":['pctime',
                       'gpstime',
                       'latitude',
                       'longitude',
                       'quality',
                       'svs',
                       'dop',
                       'eht']
    }
314/15: fieldnames = assign_fieldnames('GGA')
314/16: fieldnames = fieldnames[2:]
314/17: fieldnames
314/18:
fieldnames = ['pctime',
                           'gpstime',
                           'latitude',
                           'longitude',
                           'quality',
                           'svs',
                           'hdop',
                           'antennaheight',
                           'geoid']
314/19: fieldnames
314/20: columnnames = timenames + fieldnames
314/21: columnnames
314/22: columnnames = map(lambda x: 'PC_'+ x,timenames) + columnnames
314/23: d.shape()
314/24: d.shape
314/25: columnames.shape
314/26: columnnames
314/27: columnnames.__len__
314/28: columnnames.__len__()
314/29: fieldnames
314/30: fieldnames = fieldnames[2:]
314/31: columnnames = timenames + fieldnames
314/32: columnnames = map(lambda x: 'PC_'+ x,timenames) + columnnames
314/33: columnnames.__len__()
314/34: d.columns = columnnames
314/35: d.head()
314/36: d.to_hdf('GGA_3_.h5',key='/hav',format='table')
314/37: cd /Volumes/ENG2015ASV/data/cworker4/extracted_logs/2018-04-19T15-30-49
314/38: d = pd.read_csv('GGA_3_.txt',delimiter='\s+',columns = columnnames)
314/39: d = pd.read_csv('GGA_3_.txt',delimiter='\s+')
314/40: d.columns = columnnames
314/41: d.head()
314/42: d.to_hdf('GGA_3_.h5',key='/hav',format='table')
314/43: pwd
314/44: cd /Volumes/ENG2015ASV/data/cworker4/extracted_logs/2018-04-18T13-01-04
314/45: d = pd.read_csv('GGA_3_.txt',delimiter='\s+')
314/46: d.columns = columnnames
314/47: d.to_hdf('GGA_3_.h5',key='/hav',format='table')
314/48: cd /Volumes/ENG2015ASV/data/cworker4/extracted_logs/2017-12-18T13-18-06
314/49: d = pd.read_csv('GGA_3_.txt',delimiter='\s+')
314/50: d.columns = columnnames
314/51: d.to_hdf('GGA_3_.h5',key='/hav',format='table')
314/52: cd /Volumes/ENG2015ASV/data/cworker4/extracted_logs/2017-12-15T14-37-21
314/53: d = pd.read_csv('GGA_3_.txt',delimiter='\s+')
314/54: d.columns = columnnames
314/55: d.to_hdf('GGA_3_.h5',key='/hav',format='table')
314/56: att = pd.read_csv('nmea2000_vessel_heading_pgn127250.txt')
314/57: att.head()
314/58: att = pd.read_csv('nmea2000_vessel_heading_pgn127250.txt',delimiter='\s+')
314/59: att.head()
314/60: att.to_hdf('nmea2000_vessel_heading_pgn127250.ph5',key='head',format='table')
314/61: vtg = pd.read_csv('VTG_3_.txt',delimiter='\s+')
314/62: vtg.head()
314/63: vtg.columns = ['year','month','day','hour','min','second','n','mps','knots']
314/64: vtg.head()
314/65: vtg.to_hdf('VTG_3_.h5',key='vtg',format='table')
314/66: cd /Volumes/MAP2018Fairweather_ASV/BEN/data/extracted_logs/2018-07-25T14-35-10
314/67: vtg.to_hdf('VTG_3_.h5',key='vtg',format='table')
314/68: vtg.head()
314/69: vtg = pd.read_csv('VTG_3_.txt',delimiter='\s+')
314/70: vtg.columns = ['year','month','day','hour','min','second','n','mps','knots']
314/71: vtg.to_hdf('VTG_3_.h5',key='vtg',format='table')
315/1: import keras
316/1: import keras
317/1: import keras
318/1: import numpy as np
318/2: zw = np.array([[1,2,3];[1,2,3];[1,2,3]])
318/3: zw = np.array([[1,2,3],[1,2,3],[1,2,3]])
318/4: print(zw)
318/5: ww = np.array([[2,2,2],[2,2,2],[3,3,3]])
318/6: zw/ww
318/7: ww[:]
318/8: ww.ravel?
318/9: ww.ravel()
318/10: ww
318/11: ww.ndim()
318/12: ww.ndim
318/13: a = [1]
318/14: a.ndim
318/15: a.array([1])
318/16: a = np.array([1])
318/17: a.ndim
318/18: a.size()
318/19: a.size
318/20: ww.size()
318/21: ww.size
318/22: ww
318/23: b = [1,3]
318/24: b = np.array([1,3])
318/25: b.size
318/26: sum(ww==2)
318/27: sum(ww.ravel()==2)
318/28:
if sum(ww.ravel()==2):
    print('true')
318/29:
if sum(ww.ravel()==6):
    print('true')
318/30: ww
318/31: ww(ww==3) = 1
318/32: w==0
318/33: ww=0
318/34: ww = np.array([[2,2,2],[2,2,2],[3,3,3]])
318/35: ww==0
318/36: a = ww==0
318/37: np.range?
318/38: import numpy as np
318/39: range?
318/40: a
318/41: b
318/42: [b b]
318/43: [b, b]
318/44: c = [b, b]
318/45: c
318/46: c = [b[:], b[:]]
318/47: c
318/48: whos
318/49: ww
318/50: ww[ ww==3 ] = 4
318/51: ww
318/52: whos
318/53: a
318/54: b
318/55: np.concatenate(b,b)
318/56: a
318/57: a = np.array([1,3])
318/58: b = np.array([4,5])
318/59: a
318/60: b
318/61: np.concatenate(a,b)
318/62: np.concatenate((a,b)))
318/63: np.concatenate((a,b))
318/64: np.nan((3,4))
318/65: np.zeros((2,3))
318/66: np.zeros((2,3))+nap.nan
318/67: np.zeros((2,3))+nap.nan
318/68: np.zeros((2,3))+np.nan
318/69: a
318/70: a[-1]
318/71: a = np.range(1,3,1)
318/72: a = range(1,3,1)
318/73: a
318/74: a = range(1,5,1)
318/75: a
318/76: a = range(1,5,5)
318/77: a
318/78: range?
318/79: a = range(1,10,2)
318/80: a
318/81: np.linspace?
318/82: np.arange(1,10,2)
318/83: cinf = 2.2
318/84: cinf**2
318/85: whos
318/86: ww
318/87: (ww - 3)**2
318/88: (ww - 1)**2
318/89: np.all(ww==2)
318/90: ww
318/91: a = np.where(ww>3)
318/92: a
318/93: ww[a]
318/94: a = np.where(ww>5)
318/95: a
318/96: a.count()
318/97: a.count
318/98: a.count()
318/99: a
318/100: whos a
318/101: whos
318/102: count(a)
318/103: a.__len__()
318/104: np.where?
318/105: v = np.arange(0,20,100)
318/106: print(v)
318/107: v = np.arange(0,100,.2)
318/108: print(v)
318/109: a = np.where(v>50)
318/110: print(a)
318/111: b = np.where(v[a]> 75)
318/112: print(b)
318/113: c = v[a[b]]
318/114: v[b]
318/115: a[b]
318/116: whos
318/117: a[0]
318/118: v[a[b[0]]]
318/119: b[0]
318/120: a[b[0]]
318/121: a[int(b[0])]]
318/122: a[int(b[0])]
318/123: v
318/124: a = np.flatnonzero(v>50)
318/125: b = np.flatnonzero(v[a]> 75)
318/126: v[a[b]]
318/127: a = {}
318/128: a{'abc':123}
318/129: a('abc':123)
318/130: a = {}
318/131: whos
318/132: a['abc'] = 3
318/133: print(a)
318/134: haskey?
318/135: a.keys
318/136:
with key == 'abc' in a: 
    print(a['abc'])
318/137:
for key,value in a: 
    print(a['abc'])
318/138: a = [1,2,3]
318/139: b = [3,4,5]
318/140: set(a).difference(set(b))
318/141: set.difference?
318/142: a.union(b)
318/143: set(a).union(b)
318/144: b
318/145: set(a).union(set(b))
318/146: import os
318/147: os.stat?
318/148: ls
318/149: os.stat(vgrid.py)
318/150: a = os.stat('vgrid.py')
318/151: a
318/152: a.st_mtime
318/153: os.stat(/'/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/154: os.stat('/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/155: os.stat('/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/156: os.stat('/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/157: os.stat('/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/158: os.stat('/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/159: os.stat('/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/160: os.stat('/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/161: os.stat('/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/162: os.stat('/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/163: import time
318/164: now = time.time()
318/165: now - os.stat('/Users/vschmidt/scratch/test/asv_gga_composite.txt.bz2').st_mtime
318/166: import datetime
318/167: n = datetime.datetime.now()
318/168: n.toordinal()
318/169: n.timestamp()
318/170: d = datetime.datetime(2018,11,10,12,0,0,0)
318/171: print(d)
318/172: d.timestamp()
318/173: d2 = datetime.datetime(2018,11,10,12,0,0,0)
319/1: import numpy as np
319/2: a = np.empty((3,3))
319/3: a[:] = np.nan
319/4: x = np.concatenate(a,zeros((3,3)))
319/5: x = np.concatenate(a,np.zeros((3,3)))
319/6: a
319/7: b = zeros((3,3))
319/8: b = np.zeros((3,3))
319/9: b
319/10: a
319/11: x1 = np.concatenate?
319/12: x1 = np.concatenate((a,b))
319/13: x1
319/14: x2 = np.concatenate((a,b))
319/15: x2
319/16: a
319/17: a[1,1] = 3
319/18: a
319/19: x1
319/20: x2
319/21: x1 = np.concatenate((a,b),dim=2)
319/22: np.concatenate?
319/23: x1 = np.concatenate((a,b),axis=2)
319/24: x1 = np.concatenate((a,b),axis=1)
319/25: x1
319/26: a = 1
319/27: a.size
319/28: a=1.0
319/29: a.size
319/30: np.isscalar(a)
319/31: np.nansum?
319/32: a = range(20)
319/33: b = np.flatnonzero(a > 10)
319/34: a
319/35: b = np.flatnonzero(a > 10)
319/36: whos
319/37: a = np.arange(20)
319/38: a
319/39: b = np.flatnonzero(a > 10)
319/40: c = np.flatnonzero(a[b] > 15)
319/41: c
319/42: b
319/43: a[b[c]]
319/44: cd ~/gitsrc/vgrid/
319/45: ls
319/46: import vgrid as v
319/47: G = v.vgrid(1,1,'mean')
319/48: x = arange(10)
319/49: x = np.arange(10)
319/50: y = np.arange(10)
319/51: z = x + y
319/52: z
319/53: G.add(x,y,z,1)
319/54: reload(vgrid)
319/55: ls
319/56: reload?
319/57: reload('vgrid')
319/58: reload(vgrid)
319/59: whos
319/60: reload(v)
319/61: G = v.vgrid(1,1,'mean')
319/62: G.add(x,y,z,1)
319/63: G
319/64: reload(v)
319/65: G = v.vgrid(1,1,'mean')
319/66: G.add(x,y,z,1)
319/67: reload(v)
319/68: reload(v)
319/69: G.add(x,y,z,1)
319/70: G.add(x,y,z,1)
319/71: reload(v)
319/72: G = v.vgrid(1,1,'mean')
319/73: G.add(x,y,z,1)
319/74: reload(v)
319/75: G = v.vgrid(1,1,'mean')
319/76: G.add(x,y,z,1)
319/77: reload(v)
319/78: G = v.vgrid(1,1,'mean')
319/79: G.add(x,y,z,1)
319/80: reload(v)
319/81: G = v.vgrid(1,1,'mean')
319/82: G.add(x,y,z,1)
319/83: np.arange?
319/84: range?
319/85: reload(v)
319/86: G = v.vgrid(1,1,'mean')
319/87: G.add(x,y,z,1)
319/88: reload(v)
319/89: G = v.vgrid(1,1,'mean')
319/90: G.add(x,y,z,1)
319/91: reload(v)
319/92: G = v.vgrid(1,1,'mean')
319/93: G.add(x,y,z,1)
319/94: w = np.array(1)
319/95: whos
319/96: w.size
319/97: reload(v)
319/98: G = v.vgrid(1,1,'mean')
319/99: G.add(x,y,z,1)
319/100: reload(v)
319/101: G = v.vgrid(1,1,'mean')
319/102: G.add(x,y,z,1)
319/103: reload(v)
319/104: G = v.vgrid(1,1,'mean')
319/105: G.add(x,y,z,1)
319/106: reload(v)
319/107: G = v.vgrid(1,1,'mean')
319/108: G.add(x,y,z,1)
319/109: reload(v)
319/110: G = v.vgrid(1,1,'mean')
319/111: G.add(x,y,z,1)
319/112: a = [1,2,3]
319/113: b = [4,5]
319/114: c = [a,b]
319/115: c
319/116: c = [a[:],b[:]]
319/117: c
319/118: reload(v)
319/119: reload(v)
319/120: G = v.vgrid(1,1,'mean')
319/121: G.add(x,y,z,1)
319/122: reload(v)
319/123: G = v.vgrid(1,1,'mean')
319/124: G.add(x,y,z,1)
319/125: reload(v)
319/126: G = v.vgrid(1,1,'mean')
319/127: G.add(x,y,z,1)
319/128: reload(v)
319/129: G = v.vgrid(1,1,'mean')
319/130: G.add(x,y,z,1)
319/131: reload(v)
319/132: G = v.vgrid(1,1,'mean')
319/133: G.add(x,y,z,1)
319/134: x
319/135: y
319/136: z
319/137: z[0]=3
319/138: G.add(x,y,z,1)
319/139: a
319/140: a.insert(3)
319/141: a.insert?
319/142: a.insert(0,3)
319/143: a
319/144: a = np.array(a)
319/145: a.put?
319/146: numpy.put?
319/147: np.put/
319/148: np.put?
319/149: a.tostring()
319/150: a
319/151: b
319/152: np.concatinate((a[0],b))
319/153: np.concatenate((a[0],b))
319/154: np.append(a[0],b)
319/155: reload(v)
319/156: G = v.vgrid(1,1,'mean')
319/157: G.add(x,y,z,1)
319/158: reload(v)
319/159: G.add(x,y,z,1)
319/160: G = v.vgrid(1,1,'mean')
319/161: G.add(x,y,z,1)
319/162: G
319/163: G.zz()
319/164: z
319/165: reload(v)
319/166: G = v.vgrid(1,1,'mean')
319/167: G.add(x,y,z,1)
319/168: G.zz()
319/169: G.zw
319/170: G.ww
319/171: reload(v)
319/172: G = v.vgrid(1,1,'mean')
319/173: G.add(x,y,z,1)
319/174: who
319/175: a = np.array([1,2 ,3])
319/176: b = a
319/177: c = a
319/178: a[0] = 3
319/179: a
319/180: b
319/181: c
319/182: b = deep_copy(a)
319/183: reload(v)
319/184: G = v.vgrid(1,1,'mean')
319/185: G.add(x,y,z,1)
319/186: G.zz()
319/187: x
319/188: y
319/189: z
319/190: G = v.vgrid(1,1,'mean')
319/191: G = v.vgrid(1,2,'mean')
319/192: G.add(x,y,z,1)
319/193: G.zz()
319/194: import bokeh as b
319/195: from matplotlib import pyplot as plt
319/196: plt.figure()
319/197: plt.pcolor?
319/198: plt.pcolor(G.xx,G.yy,G.zz())
319/199: plt.show()
319/200: plt.colorbar()
319/201: reload(v)
319/202: G = v.vgrid(1,2,'mean')
319/203: G.add(x,y,z,1)
319/204: G.pcolor()
319/205: G = v.vgrid(1,2,'mean')
319/206: reload(v)
319/207: G = v.vgrid(1,2,'mean')
319/208: G.add(x,y,z,1)
319/209: G.pcolor()
319/210: reload(v)
319/211: G = v.vgrid(1,2,'mean')
319/212: G.add(x,y,z,1)
319/213: G.pcolor()
319/214: G.add(x,y,z,1)
319/215: G.pcolor()
319/216: G.add(x.reverse(),y,z,1)
319/217: G.add(np.flip(x),y,z,1)
319/218: G.add(np.flip(x,0),y,z,1)
319/219: G.pcolor()
319/220: x
319/221: z
319/222: G.xx
319/223: G.yy
319/224: G.zz()
319/225: reload(v)
319/226: G = v.vgrid(1,1,'mean')
319/227: G.add(x,y,z,1)
319/228: G.xx
319/229: G.yy
319/230: G.zz
319/231: G.zz()
319/232: G.add(np.flip(x,0),y,z,1)
319/233: G.zz()
319/234: G.xx
319/235: G.yy
319/236: G.zz
319/237: G.zz()
319/238: G.ww
319/239: reload(v)
319/240: G = v.vgrid(1,1,'mean')
319/241: G.add(x,y,z,1)
319/242: reload(v)
319/243: G = v.vgrid(1,1,'mean')
319/244: G.add(x,y,z,1)
319/245: reload(v)
319/246: G = v.vgrid(1,1,'mean')
319/247: G.add(x,y,z,1)
319/248: reload(v)
319/249: G = v.vgrid(1,1,'mean')
319/250: G.add(x,y,z,1)
319/251: reload(v)
319/252: G = v.vgrid(1,1,'mean')
319/253: G.add(x,y,z,1)
319/254: G.zz()
319/255: x = np.arange(1e6)
319/256: y = np.arange(1e6)
319/257: z = x + y
319/258: G.add(x,y,z,1)
319/259: reload(v)
319/260: reload(v)
319/261: G = v.vgrid(1,1,'mean')
319/262: G.add(x,y,z,1)
319/263: x = np.arange(1e4)
319/264: y = np.arange(1e4)
319/265: z = x + y
319/266: G.add(x,y,z,1)
319/267: import line_profiler
320/1: %lprun?
321/1: %lprun?
321/2: ls
321/3: cd ~/gitsrc/vgrid/
321/4: ls
321/5: %lprun?
321/6: %lprun -m vgrid
321/7: import vgrid as v
321/8: G = v.vgrid(1,1,'mean')
321/9: x = arange(1000)
321/10: import numpy
321/11: x = arange(1000)
321/12: x = np.arange(1000)
321/13: import numpy as np
321/14: x = np.arange(1000)
321/15: y = np.arange(1000)
321/16: z = x+y
321/17: G
321/18: %lprun -f G.add G.add(x,y,z,1)
321/19: %lprun -f G.add G.add(x,y,z,1)
321/20: %lprun -f G.add G.add(x,y,z,1)
321/21: %lprun -f G.add G.add(x,y,z,1)
321/22: import vgrid as v
321/23: G = v.vgrid(1,1,'mean')
321/24: %lprun -s -f G.add G.add(x,y,z,1)
322/1: import numpy as np
322/2: a = np.arange(1)
322/3: a = np.arange(10)
322/4: a
322/5: a[a>20]
322/6: a[a>10]
322/7: a[a>8]
321/25: import vgrid as v
321/26: G = v.vgrid(1,1,'mean')
321/27: %lprun -s -f G.add G.add(x,y,z,1)
322/8: idx = np.nonzero(a>10)
322/9: idx
322/10: idx.__len__()
322/11: idx.count()
322/12: idx.count?
322/13: idx
322/14: idx.size
322/15: idx.__len__()
322/16: idx[:].__len__()
322/17: idx[:]
322/18: whos idx
322/19: whos
322/20: idx
322/21: a[idx]
322/22: idx = np.nonzero(a>5)
322/23: idx
322/24: a
322/25: a = np.arange(10)*3
322/26: a
322/27: idx = np.nonzero(a>5)
322/28: idx
322/29: whos
322/30: idx[0]
322/31: idx[0].__len__()
322/32: idx = np.nonzero(a>100)
322/33: idx
322/34: idx[0].__len__()
321/28: import vgrid as v
321/29: reload(v)
321/30: reload(v)
321/31: import importlib
321/32: importlib.reload(vgrid)
321/33: importlib.reload(v)
321/34: G = v.vgrid(1,1,'mean')
321/35: %lprun -s -f G.add G.add(x,y,z,1)
321/36: %lprun -s -f G.add G.add(x,y,z,1)
321/37: importlib.reload(v)
321/38: G = v.vgrid(1,1,'mean')
321/39: %lprun -s -f G.add G.add(x,y,z,1)
321/40: importlib.reload(v)
321/41: G = v.vgrid(1,1,'mean')
321/42: %lprun -s -f G.add G.add(x,y,z,1)
322/35: idx[0]
322/36: idx = np.flatnonzero(a>100)
322/37: idx[0].__len__()
322/38: idx[0]
322/39: idx
322/40: idx = np.flatnonzero(a>20)
322/41: idx
322/42: idx.__len__()
322/43: idx = np.flatnonzero(a>100)
322/44: idx
322/45: idx.__len__()
322/46: idx.size
322/47: idx = np.flatnonzero(a>20)
322/48: idx.size
321/43: importlib.reload(v)
321/44: G = v.vgrid(1,1,'mean')
321/45: %lprun -s -f G.add G.add(x,y,z,1)
321/46: importlib.reload(v)
321/47: G = v.vgrid(1,1,'mean')
321/48: %lprun -s -f G.add G.add(x,y,z,1)
321/49: importlib.reload(v)
321/50: G = v.vgrid(1,1,'mean')
321/51: %lprun -s -f G.add G.add(x,y,z,1)
322/49: b = np.arange(1e3)
322/50: %timeit b.size
322/51: %timeit b.__len__()
322/52: %timeit b[100]-a
322/53: c = b[100]
322/54: %timeit c-a
322/55: %timeit (b[100]-a)**2
322/56: %timeit np.pow(b[100]-a),2)
322/57: np.pow?
322/58: np.power?
322/59: %timeit np.power(b[100]-a,2)
321/52: reload(v)
321/53: G = v.vgrid(1,1,'mean')
321/54: %timeit G.add(x,y,z,1)
321/55: whos
321/56: %lprun -s -f G.add G.add(x,y,z,1)
321/57: importlib.reload(v)
321/58: G = v.vgrid(1,1,'mean')
321/59: G.add(x,y,z,1)
322/60: a
322/61: b = np.flatnonzero(a>10)
322/62: b.size
322/63: c = np.flatnonzero(a>100)
322/64: c.size
322/65: c.size==0
321/60: %lprun -s -f G.add G.add(x,y,z,1)
321/61: whos
321/62: importlib.reload(v)
321/63: G = v.vgrid(1,1,'mean')
321/64: import time
321/65: start=time.time(); G.add(x,y,z,1); time.time()-start
321/66: %lprun -s -f G.add G.add(x,y,z,1)
321/67: G
321/68: np.shape?
321/69: np.shape(G.xx)
321/70: np.shape(G.yy)
321/71: np.shape(G.zw)
321/72: np.shape(G.nn)
321/73: %lprun -s -f G.add G.add(x,y,z,1)
321/74: importlib.reload(v)
321/75: G = v.vgrid(1,1,'mean')
321/76: %lprun -s -f G.add G.add(x,y,z,1)
321/77: %lprun -s -f G.add -f G.mean G.add(x,y,z,1)
321/78: %lprun -s -f G.add -f G.mean G.add(x,y,z,1)
321/79: %lprun -s -f G.add -f G.mean -m np G.add(x,y,z,1)
321/80: %lprun -s -f G.add -f G.mean -m numpy G.add(x,y,z,1)
321/81: %lprun -s -f G.add -f G.mean -m numpy G.add(x,y,z,1)
322/66: a
322/67: b
322/68: np.concatenate((a,b))
321/82: importlib.reload(v)
321/83: G = v.vgrid(1,1,'mean')
321/84: %lprun -s -f G.add -f G.mean -m numpy G.add(x,y,z,1)
322/69: a = [1.3, 2.5, 4.4]
322/70: np.concatenate((a,b))
321/85: importlib.reload(v)
321/86: G = v.vgrid(1,1,'mean')
321/87: %lprun -s -f G.add -f G.mean -m numpy G.add(x,y,z,1)
321/88: G.zw[1,1]
321/89: G.zw[1,1].size
321/90: z[range(3)]
321/91: z[range(3)].size
321/92: np.concatenate(G.zw[1,1],z[range(3)])
321/93: np.concatenate(np.array(G.zw[1,1]),z[range(3)])
321/94: z[range(3)]
321/95: whos
321/96: np.concatenate((np.array(G.zw[1,1]),z[range(3)]))
321/97: np.concatenate?
321/98: np.concatenate((np.array(G.zw[1,1]),z[range(3)]),axis=0)
321/99: np.concatenate((G.zw[1,1],z[range(3)]),axis=0)
321/100: np.empty(3)
321/101: importlib.reload(v)
321/102: G = v.vgrid(1,1,'mean')
321/103: G.add(x,y,z,1)
322/71: whos
322/72: a = np.arange(1000)
322/73: b = np.arange(1000)
322/74: tmp=np.empty(2000); tmp[0:1000]=a; tmp[999:] = b
322/75: tmp=np.empty(2000); tmp[0:1000]=a;
322/76: tmp=np.empty(2000); tmp[0:1000]=a; tmp[1000:] = b
322/77: %timeit tmp=np.empty(2000); tmp[0:1000]=a; tmp[1000:] = b
322/78: %timeit np.concatenate((a,b))
322/79: b = np.array(3)
322/80: %timeit tmp=np.empty(1001); tmp[0:1000]=a; tmp[-1] = b
322/81: %timeit np.concatenate((a,b))
322/82: a.size
322/83: b.size
322/84: a.shape
322/85: b.shape
322/86: b.reshape(1)
322/87: b.shape
322/88: b.shape?
322/89: whos
322/90: %timeit np.concatenate((a,np.array(b)))
322/91: a
322/92: b
322/93: b = np.array([3])
322/94: b
322/95: %timeit np.concatenate((a,b))
321/104: importlib.reload(v)
321/105: G = v.vgrid(1,1,'mean')
321/106: %lprun -s -f G.add -f G.mean -m numpy G.add(x,y,z,1)
321/107: %lprun -s -f G.add  G.add(x,y,z,1)
321/108: %timeit G.add(x,y,z,1)
321/109: importlib.reload(v)
321/110: G = v.vgrid(1,1,'mean')
321/111: %timeit G.add(x,y,z,1)
321/112: importlib.reload(v)
321/113: G = v.vgrid(1,1,'mean')
321/114: %timeit G.add(x,y,z,1)
321/115: importlib.reload(v)
321/116: G = v.vgrid(1,1,'mean')
321/117: %timeit G.add(x,y,z,1)
321/118: importlib.reload(v)
321/119: G = v.vgrid(1,1,'mean')
321/120: %timeit G.add(x,y,z,1)
321/121: %lprun -s -f G.add  -f G.mean G.add(x,y,z,1)
324/1: ls
324/2: import json
324/3: a = json.loads('20181024_1600.SPSOL')
325/1: import pandas as pd
325/2: F = file('20181023_1700.SPSOL','r')
325/3: D = pd.read_json(F)
325/4: D = pd.read_json(F,orient='index'))
325/5: D = pd.read_json(F,orient='index')
325/6: D = pd.read_json(F,orient='split')
325/7: D = pd.read_json(F,orient='values')
325/8: whos
325/9: data = F.read()
325/10: whos
325/11: data[0:10]
325/12: F.read?
325/13: F.seek?
325/14: F.seek(0)
325/15: data = F.read()
325/16: data
325/17: dd = pd.read_json(data)
325/18: dd = pd.read_json(data,orient='split')
325/19: ls
325/20: import sys
325/21: sys.path
325/22: sys.path = sys.path.append('/Users/vschmidt/gitsrc/oet/oet')
325/23: import spsol
325/24: import oet.spsol
325/25: F.seek(0)
325/26: rawtime = []
325/27: rawdata = []
325/28: for line in F.readlines()
325/29:
for line in F.readlines():
    FF = line.split()
    rawtime.append(FF[1])
    rawdata.append(FF[3])
325/30: rawdata[0]
325/31: dd = pd.DataFrame.from_records(rawdata)
325/32: dd.head()
325/33: dd.head
325/34: dd.head()
326/1: F = file('20181023_1700.SPSOL','r')
326/2:
for line in F.readlines():
    FF = line.split()
    rawtime.append(FF[1])
    rawdata.append(FF[3])
326/3: rawtime = []
326/4: rawdata = []
326/5:
for line in F.readlines():
    FF = line.split()
    rawtime.append(FF[1])
    rawdata.append(FF[3])
326/6: dd = pd.DataFrame.from_records(rawdata)
326/7: import pandas as pd
326/8: dd = pd.DataFrame.from_records(rawdata)
326/9: dd.head()
326/10: dd = pd.DataFrame(rawdata)
326/11: dd.head()
326/12: rawdata
326/13: F.seek(0)
326/14:
for line in F.readlines():
    FF = line.split()
    rawtime.append(FF[1])
    rawdata.append(FF[3])
326/15: rawdata[0]
326/16: rawdata[1]
326/17: dd = pd.DataFrame(rawdata)
326/18: dd.head()
326/19: import json
326/20: pd.io.json.json_normalize?
326/21: dd = pd.DataFrame.from_records(rawdata)
326/22: dd.head()
326/23: dd = pd.DataFrame.from_records?
326/24: dd = pd.read_json(rawdata)
326/25: rawdata[0]
326/26: dd = pd.DataFrame.from_records(rawdata,orient='index')
326/27: dd = pd.DataFrame.from_dict(rawdata)
326/28: dd.head()
326/29: dd = pd.DataFrame.from_records(rawdata)
326/30: dd.head()
326/31: dd = pd.io.json.json_normalize(rawdata)
326/32: rawdata[0]
326/33: rawdata[0][0]
326/34:
for line in F.readlines():
    FF = line.split()
    rawtime.append(FF[1])
    rawdata.append(json.loads(FF[3]))
326/35: rawdata[0]
326/36: json.load?
326/37: json.loads?
326/38: a = rawdata[0]
326/39: whos
326/40: rawdata=[]
326/41:
for line in F.readlines():
    FF = line.split()
    rawtime.append(FF[1])
    rawdata.append(json.loads(FF[3]))
326/42: rawdata[0]
326/43: rawdata
326/44: F.seek(0)
326/45:
for line in F.readlines():
    FF = line.split()
    rawtime.append(FF[1])
    rawdata.append(json.loads(FF[3]))
326/46: rawdata[0]
326/47: dd = pd.DataFrame.from_records(rawdata)
326/48: dd.head()
326/49: dd.set_index?
326/50: tt = pd.to_datetime(rawtime)
326/51: tt[0]
327/1:

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/Users/vschmidt/gitsrc/oet'])
327/2: pwd
327/3: ls
327/4: import oet
327/5: import oet.spsol
326/52: pwd
327/6: run('oet/spsol.py /Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog')
327/7: run?
327/8: run('oet/spsol.py','/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog')
327/9: run oet/oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
327/10: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
327/11: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
327/12: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
326/53: ls
328/1:

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/Users/vschmidt/gitsrc/oet'])
328/2: ls
328/3: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
328/4: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
326/54: ls
326/55: less spsol.csv
326/56: import glob
326/57: glob.glob('.' + '/' + '*.SPSOL')
328/5: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
328/6: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
326/58: ls -l
329/1:
import pandas as pd

data = pd.from_csv('spsol.csv')
329/2:
import pandas as pd

data = pd.read_csv('spsol.csv')
329/3: data.head()
329/4:
import pandas as pd
%matplotlib inline
import matplotlib.pyplot as plt
329/5:
plt.plot(data.roll)
plt.show()
329/6:
plt.plot(data.heave)
plt.show()
330/1: import plotly
331/1: import plotly
332/1:
import pandas as pd
import plotly.plotly as py
332/2: data = pd.read_csv('spsol.csv')
332/3: data.head()
332/4:
import pandas as pd
import plotly.plotly as py
import numpy as np
import plotly.tools as tls
332/5:
fig = plt.figure()
ax1 = fig.add_subplot(111)
ax1.plot(data.roll)

plotlyfig = tls.mpl_to_plotly(fig)
py.iplot(plotlyfig,filename='nautilus_roll')
332/6:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
332/7:
fig = plt.figure()
ax1 = fig.add_subplot(111)
ax1.plot(data.roll)

plotlyfig = tls.mpl_to_plotly(fig)
py.iplot(plotlyfig,filename='nautilus_roll')
332/8:
fig = plt.figure()
ax1 = fig.add_subplot(111)
ax1.plot(data.roll)
ax1.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
332/9:
fig = plt.figure()
ax1 = fig.add_subplot(111)
ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
332/10:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
332/11: data = pd.read_csv('spsol.csv')
332/12: data.head()
332/13:
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
332/14: import scipy as sci
328/7: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
333/1:

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/Users/vschmidt/gitsrc/oet'])
333/2: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
334/1:

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/Users/vschmidt/gitsrc/oet'])
335/1:
print('PyDev console: using IPython 6.5.0\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/Users/vschmidt/gitsrc/oet'])
335/2: pwd
335/3: ls
335/4: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
335/5: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
335/6: pwd
335/7: ls
335/8: rm spsol.h5
335/9: ls
335/10: run oet/spsol.py '/Users/vschmidt/scratch/nautilus_attitude/external.oet.org/datasharing/2019/0104vschmidt/NA103-raw-datalog'
336/1:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
336/2: data = pd.read_hdf('spsol.h5')
336/3: data.head()
336/4:
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/5: import scipy as sci
336/6:
f,t,Sxx = sci.signal.spectrum(data,roll[0:1e4],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,Sxx)
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
336/7:
import scipy as sci
import scipy.signal as sig
336/8:
f,t,Sxx = sig.spectrum(data,roll[0:1e4],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,Sxx)
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
336/9:
import scipy as sci
from scipy import signal
336/10:
f,t,Sxx = signal.spectrogram(data,roll[0:1e4],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,Sxx)
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
336/11:
f,t,Sxx = signal.spectrogram(data.roll[0:1e4],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,Sxx)
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
336/12:
f,t,Sxx = signal.spectrogram(data.roll.loc[0:1e4],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,Sxx)
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
336/13:
f,t,Sxx = signal.spectrogram(data.roll.loc[0:1e4],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
336/14:
f,t,Sxx = signal.spectrogram(data.roll.loc[0:1e5],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
336/15:
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc([0:1e4]))
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/16:
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[0:1e4])
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/17:
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[9e4:1e5])
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/18:
plt.plot(data.index)
plt.show()
336/19:
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[9e4:1e5])
ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/20:
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(111)
#ax1.plot(data.roll.loc[9e4:1e5])
ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/21:
f,t,Sxx = signal.spectrogram(data.roll.loc[3.5e6:3.6e6],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
336/22:
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.6e6])
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/23:
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/24:
f,t,Sxx = signal.spectrogram(data.roll.loc[3.5e6:3.7e6],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
336/25:
plt.plot(data.heave.loc[3.5e6:3.7e6])
plt.show()
336/26:
fig = plt.figure(figsize=(10,10)
plt.plot(data.heave.loc[3.5e6:3.7e6])
plt.show()
336/27:
fig = plt.figure(figsize=(10,10))
plt.plot(data.heave.loc[3.5e6:3.7e6])
plt.show()
336/28:
fig = plt.figure(figsize=(10,20))
plt.plot(data.heave.loc[3.5e6:3.7e6])
plt.show()
336/29:
fig = plt.figure(figsize=(20,10))
plt.plot(data.heave.loc[3.5e6:3.7e6])
plt.show()
336/30:
fig = plt.figure(figsize=(10,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
plt.grid(True)
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/31:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
plt.grid(True)
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/32:
fig = plt.figure(figsize=(20,10))
plt.plot(data.heave.loc[3.5e6:3.7e6])
plt.grid(True)
plt.show()
336/33:
plt.plot(data.heading.loc[3.5e6:3.7e6])
plt.show()
336/34:
fig = plt.figure(figsize=(20,10))
plt.plot(data.heading.loc[3.5e6:3.7e6])
plt.show()
336/35:
fig = plt.figure(figsize=(20,10))
plt.plot(data.heading.loc[3.5e6:3.7e6])
plt.grid(True)
plt.show()
336/36:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/37:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
plt.legend('Roll','Pitch')
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/38:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
plt.legend(('Roll','Pitch')
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/39:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/40:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
%matplotlib inline
import mpld3
mpld3.enable_notebook()
336/41:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/42:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
%matplotlib inline
import mpld3
mpld3.enable_notebook()
336/43: data = pd.read_hdf('spsol.h5')
336/44: data.head()
336/45:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
336/46:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
matplotlib inline
import mpld3
mpld3.enable_notebook()
336/47: data = pd.read_hdf('spsol.h5')
336/48: data.head()
336/49:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
337/1:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
matplotlib inline
import mpld3
mpld3.enable_notebook()
337/2:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
#%matplotlib inline
import mpld3
mpld3.enable_notebook()
337/3: data = pd.read_hdf('spsol.h5')
337/4: data.head()
337/5:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
338/1:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
%matplotlib notebook 
#import mpld3
#mpld3.enable_notebook()
338/2: data = pd.read_hdf('spsol.h5')
338/3: data.head()
338/4:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
338/5:
import scipy as sci
from scipy import signal
338/6:
f,t,Sxx = signal.spectrogram(data.roll.loc[3.5e6:3.7e6],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
338/7:
fig = plt.figure(figsize=(20,10))
plt.plot(data.heave.loc[3.5e6:3.7e6])
plt.grid(True)
plt.show()
338/8:
fig = plt.figure(figsize=(20,10))
plt.plot(data.heading.loc[3.5e6:3.7e6])
plt.grid(True)
plt.show()
339/1:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
%matplotlib notebook 
#import mpld3
#mpld3.enable_notebook()
339/2: data = pd.read_hdf('spsol.h5')
339/3: data.head()
339/4:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
339/5:
import scipy as sci
from scipy import signal
339/6:
f,t,Sxx = signal.spectrogram(data.roll.loc[3.5e6:3.7e6],5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
339/7:
fig = plt.figure(figsize=(20,10))
plt.plot(data.heave.loc[3.5e6:3.7e6])
plt.grid(True)
plt.show()
339/8:
fig = plt.figure(figsize=(20,10))
plt.plot(data.heading.loc[3.5e6:3.7e6])
plt.grid(True)
plt.show()
339/9: rm = data.roll.rolling?
339/10: rm = (data.rolling('1h',center = True,'roll',win_type='hamming')**2).mean()**.5
339/11: rm = (data.rolling('1h',center = True,on='roll',win_type='hamming')**2).mean()**.5
339/12: rm = (data.rolling('1H',center = True,on='roll',win_type='hamming')**2).mean()**.5
339/13: rm = (data.rolling('60Min',center = True,on='roll',win_type='hamming')**2).mean()**.5
340/1:
print('PyDev console: using IPython 6.5.0\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/Users/vschmidt/gitsrc/oet'])
339/14:
data = pd.read_hdf('spsol.h5')
data.set_index('time')
339/15:
data = pd.read_hdf('spsol.h5')
data.set_index(pd.to_datetime('time'))
339/16:
data = pd.read_hdf('spsol.h5')
data.set_index(pd.to_datetime(data.time))
339/17: data.head()
339/18:
data = pd.read_hdf('spsol.h5')
data.set_index(pd.to_datetime(data.time),inplace=True)
339/19: data.head()
339/20: rm = (data.rolling('60Min',center = True,on='roll',win_type='hamming')**2).mean()**.5
339/21: rm = (data.rolling('60M',center = True,on='roll',win_type='hamming')**2).mean()**.5
339/22: rm = (data.rolling('3600s',center = True,on='roll',win_type='hamming')**2).mean()**.5
339/23: data.rolling?
339/24: pd.Timestamp('0')
339/25:
data = pd.read_hdf('spsol.h5')
data.set_index(pd.Timestamp(data.time),inplace=True)
339/26:
data = pd.read_hdf('spsol.h5')
data.set_index(pd.to_datetime(data.time,units='s'),inplace=True)
339/27:
data = pd.read_hdf('spsol.h5')
data.set_index(pd.to_datetime(data.time,unit='s'),inplace=True)
339/28: data.head()
339/29: rm = (data.rolling('3600s',center = True,on='roll',win_type='hamming')**2).mean()**.5
339/30: rm = (data.rolling(5*3600,center = True,on='roll',win_type='hamming')**2).mean()**.5
339/31: rm = data.rolling(5*3600,center = True,on='roll',win_type='hamming').apply(lambda x: np.mean(x**2)**.5)
339/32: rm = data.rolling(5*3600,center = True,on='roll',win_type='hamming')
339/33: rm.head()
341/1: imports pandas as pd
341/2: import pandas as pd
341/3: pd?
341/4: pd.__version__
341/5: a = pd.Dataframe([1,2,3,4,5,6,7])
341/6: a = pd.DataFrame([1,2,3,4,5,6,7])
341/7: b = a.rolling(2)
341/8: whos
339/34: whos
342/1: import pandas
342/2: pandas.__version__
342/3: a = pandas.DataFrame([1,2,3,4,6,6])
342/4: b = a.rolling(2)
342/5: whos
342/6: a.index = pandas.to_datetime(['1990','1991','1992','1993','1994','1995'])
342/7: a.head()
342/8: b = a.rolling(2)
342/9: whos
342/10: b = a.rolling('2y')
342/11: b = a.rolling('2Y')
342/12: a.index = pandas.to_datetime(['1','2','3','4','5','7'],unit='s'))
342/13: a.index = pandas.to_datetime(['1','2','3','4','5','7'],unit='s')
342/14: a.head()
342/15: b = a.rolling('2s')
342/16: whos
343/1:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
%matplotlib notebook 
#import mpld3
#mpld3.enable_notebook()
343/2:
data = pd.read_hdf('spsol.h5')
data.set_index(pd.to_datetime(data.time,unit='s'),inplace=True)
343/3: data.head()
343/4: 5*3600
343/5: rm = data.rolling('3600s',center = True,on='roll',win_type='hamming')
343/6: rm = data.rolling(5*3600,center = True,on='roll',win_type='hamming')
343/7: whos
343/8: data.rolling?
343/9: rm = data.rolling('3600s',center = True,win_type='hamming')
343/10: data.rolling?
343/11: rm = data.rolling('3600s',center = True)
343/12: data.index.head()
343/13:
data = pd.read_hdf('spsol.h5')
data.set_index(pd.to_datetime(data.time,unit='s'),inplace=True)
data.sort_index(inplace=True)
343/14: data.head()
343/15:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.loc[3.5e6:3.7e6])
ax1.plot(data.pitch.loc[3.5e6:3.7e6])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/16: data.roll.loc?
343/17:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.iloc[3.5e6:3.7e6])
ax1.plot(data.pitch.iloc[3.5e6:3.7e6])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/18: data.roll.iloc[:3]
343/19: data.roll.iloc[:1e1]
343/20: data.roll.iloc[:int(1e1)]
343/21:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.iloc[int(3.5e6:3.7e6)])
ax1.plot(data.pitch.iloc[int(3.5e6:3.7e6)])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/22:
fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data.roll.iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data.pitch.iloc[int(3.5e6):int(3.7e6)])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/23:
fig = plt.figure(figsize=(20,10))
plt.plot(data.roll)
343/24:
fig = plt.figure(figsize=(20,10))
plt.plot(data.roll)
plt.show()
343/25:
fig = plt.figure(figsize=(20,10))
plt.plot(data.roll)
plt.grid(True)
plt.show()
343/26:


fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
ax1.plot(data['2018-10-30':'2018-11-01'].roll.iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data.pitch['2018-10-30':'2018-11-01'].iloc[int(3.5e6):int(3.7e6)])
plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/27:


fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
#ax1.plot(data['2018-10-30':'2018-11-01'].roll.iloc[int(3.5e6):int(3.7e6)])
#ax1.plot(data.pitch['2018-10-30':'2018-11-01'].iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data['2018-10-30':'2018-11-01'].roll)
ax1.plot(data.pitch['2018-10-30':'2018-11-01'])

plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/28:


fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
#ax1.plot(data['2018-10-30':'2018-11-01'].roll.iloc[int(3.5e6):int(3.7e6)])
#ax1.plot(data.pitch['2018-10-30':'2018-11-01'].iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data['2018-10-30-18':'2018-10-31-06'].roll)
ax1.plot(data.pitch['2018-10-30':'2018-11-01'])

plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/29:


fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
#ax1.plot(data['2018-10-30':'2018-11-01'].roll.iloc[int(3.5e6):int(3.7e6)])
#ax1.plot(data.pitch['2018-10-30':'2018-11-01'].iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data['2018-10-30-18':'2018-10-31-06'].roll)
ax1.plot(data.pitch['2018-10-30-18':'2018-10-31-06'])

plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/30:


fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
#ax1.plot(data['2018-10-30':'2018-11-01'].roll.iloc[int(3.5e6):int(3.7e6)])
#ax1.plot(data.pitch['2018-10-30':'2018-11-01'].iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data['2018-10-30-12':'2018-10-31-06'].roll)
ax1.plot(data.pitch['2018-10-30-12':'2018-10-31-06'])

plt.grid(True)
plt.legend(('Roll','Pitch'))
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/31:


fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
#ax1.plot(data['2018-10-30':'2018-11-01'].roll.iloc[int(3.5e6):int(3.7e6)])
#ax1.plot(data.pitch['2018-10-30':'2018-11-01'].iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data['2018-10-30-12':'2018-10-31-06'].roll)
ax1.plot(data.pitch['2018-10-30-12':'2018-10-31-06'])

plt.grid(True)
plt.legend(('Roll','Pitch'))
plt.ylabel('Degrees')
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/32:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
343/33:
import scipy as sci
from scipy import signal
343/34:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5)
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
341/9: from scipy import signal
341/10: signal.spectrogram?
341/11: signal.get_window?
343/35:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',1024))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
343/36:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',4096))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
343/37:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
2048/5.0
343/38:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

maxSxx = np.max(Sxx)
plt.plot(t,maxSxx,'xr')
341/12: import numpy as np
341/13: np.max?
343/39:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

maxSxx = np.max(Sxx,axis=0)
plt.plot(t,maxSxx,'xr')
343/40:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

maxii = np.argmax(Sxx,axis=0)
plt.plot(t,f[maxii],'xr')
343/41:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

fig = plt.figure(figsize=(20,10))
maxii = np.argmax(Sxx,axis=0)
plt.plot(t,1./f[maxii],'xr')
plt.grid(True)
341/14: import matplotlib.pyplot as plt
341/15: plt.axis?
343/42:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

fig = plt.figure(figsize=(20,10))
maxii = np.argmax(Sxx,axis=0)
plt.plot(t,1./f[maxii],'xr')
plt.grid(True)
aa = plt.axis()
plt.axis([aa[0],aa[1],0,50])
343/43:
f,t,Sxx = signal.spectrogram(data['2018-10-30-12':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

fig = plt.figure(figsize=(20,10))
maxii = np.argmax(Sxx,axis=0)
plt.plot(t,1./f[maxii],'xr')
plt.grid(True)
aa = plt.axis();
plt.axis([aa[0],aa[1],0,20])
343/44:
fig = plt.figure(figsize=(20,10))
plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.grid(True)
plt.show()
343/45:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data.heave)
plt.grid(True)
plt.show()
343/46:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.grid(True)
plt.show()
343/47:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-29-12':'2018-10-11-01'].heave)
plt.grid(True)
plt.show()
343/48:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-29-12':'2018-11-01'].heave)
plt.grid(True)
plt.show()
343/49:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-29-12':'2018-10-30-12'].heave)
plt.grid(True)
plt.show()
343/50:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-29-18':'2018-10-30-12'].heave)
plt.grid(True)
plt.show()
343/51:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

fig = plt.figure(figsize=(20,10))
maxii = np.argmax(Sxx,axis=0)
plt.plot(t,1./f[maxii],'xr')
plt.grid(True)
aa = plt.axis();
plt.axis([aa[0],aa[1],0,20])
343/52:


fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
#ax1.plot(data['2018-10-30':'2018-11-01'].roll.iloc[int(3.5e6):int(3.7e6)])
#ax1.plot(data.pitch['2018-10-30':'2018-11-01'].iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data['2018-10-29-18':'2018-10-31-06'].roll)
ax1.plot(data.pitch['2018-10-29-18':'2018-10-31-06'])

plt.grid(True)
plt.legend(('Roll','Pitch'))
plt.ylabel('Degrees')
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
343/53:
fig = plt.figure(figsize=(20,10))
plt.plot(data['2018-10-29-18':'2018-10-31-06'].heading)
plt.grid(True)
plt.show()
343/54: rm = data.rolling('3600s',center = True)
343/55: rm = data.rolling('3600s')
343/56: whos
343/57: rm = data.rolling('3600s').apply(lambda x: (x**2).mean()**.5)
343/58: rm = data.roll.rolling('3600s').apply(lambda x: (x**2).mean()**.5,raw=True)
341/16: whos
341/17: a.rolling?
341/18: a.resample?
343/59: whos
343/60: rm.head()
343/61: plt.plot(rm)
343/62:
plt.plot(rm)
plt.show()
343/63:
fig = plt.figure(figsize=(20,10))
plt.plot(rm)
plt.show()
343/64:
fig = plt.figure(figsize=(20,10))
plt.plot(rm)
plt.ylabel('Roll, Deg')
plt.title('Hourly RMS Roll Value')
plt.show()
343/65:
fig = plt.figure(figsize=(20,10))
plt.plot(rm)
plt.ylabel('Roll, Deg')
plt.title('Hourly RMS Roll Value')
plt.grid(True)
plt.show()
343/66:
fig = plt.figure(figsize=(20,10))
plt.plot(data.rate_roll)
plt.show()
343/67:
fig = plt.figure(figsize=(20,10))
#plt.plot(data.rate_roll)
rm = data.rate_roll.rolling('3600s').max()
plt.plot(rm)
plt.show()
343/68:
fig = plt.figure(figsize=(20,10))
#plt.plot(data.rate_roll)
rm = data.rate_roll.rolling('3600s').max()
plt.plot(rm)
plt.grid(True)
plt.show()
343/69:
fig = plt.figure(figsize=(20,10))
#plt.plot(data.rate_roll)
rm = data.rate_roll.rolling('3600s').max()
plt.plot(rm)
plt.grid(True)
plt.title('Roll Rate')
plt.ylabel('Degrees Per Second')
plt.show()
343/70:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

fig = plt.figure(figsize=(20,10))
maxii = np.argmax(Sxx,axis=0)
plt.plot(t,1./f[maxii],'xr')
plt.grid(True)
plt.title('Mean Roll Period')
plt.ylabel('Seconds')
aa = plt.axis();
plt.axis([aa[0],aa[1],0,20])
343/71:


fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
#ax1.plot(data['2018-10-30':'2018-11-01'].roll.iloc[int(3.5e6):int(3.7e6)])
#ax1.plot(data.pitch['2018-10-30':'2018-11-01'].iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data['2018-10-29-18':'2018-10-31-06'].roll)
ax1.plot(data.pitch['2018-10-29-18':'2018-10-31-06'])

plt.grid(True)
plt.legend(('Roll','Pitch'))
plt.ylabel('Degrees')
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
data.roll.max()
data.pitch.max()
343/72:


fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
#ax1.plot(data['2018-10-30':'2018-11-01'].roll.iloc[int(3.5e6):int(3.7e6)])
#ax1.plot(data.pitch['2018-10-30':'2018-11-01'].iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data['2018-10-29-18':'2018-10-31-06'].roll)
ax1.plot(data.pitch['2018-10-29-18':'2018-10-31-06'])

plt.grid(True)
plt.legend(('Roll','Pitch'))
plt.ylabel('Degrees')
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
print('Max Roll %0.2f' % data.roll.max())
print('Max Pitch %0.2f' % data.pitch.max())
343/73:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()
341/19: plt.clim?
343/74:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

maxH = np.max(Sxx,axis=0)
plt.plot(maxH)
343/75:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

maxH = np.max(np.sqrt(Sxx),axis=0)
plt.plot(maxH)
343/76:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,20*np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

maxH = np.max(np.sqrt(Sxx),axis=0)
plt.plot(t,maxH)
341/20: signal.spectrogram?
343/77:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

fig = plt.figure(figsize=(20,10))
maxii = np.argmax(Sxx,axis=0)
plt.plot(t,1./f[maxii],'xr')
plt.grid(True)
plt.title('Mean Roll Period')
plt.ylabel('Seconds')
aa = plt.axis();
plt.axis([aa[0],aa[1],0,20])
343/78:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

maxH = np.max(np.sqrt(Sxx),axis=0)
plt.plot(t,maxH)
343/79:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

fig = plt.figure(figsize=(20,10))
maxH = np.max(np.sqrt(Sxx),axis=0)
plt.plot(t,maxH)
343/80:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
maxHii = np.argmax(np.sqrt(Sxx),axis=0)
plt.plot(t,f[maxHii],'rx')

plt.show()

fig = plt.figure(figsize=(20,10))
maxH = np.max(np.sqrt(Sxx),axis=0)


plt.plot(t,maxH)
343/81:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
maxHii = np.argmax(np.sqrt(Sxx),axis=0)
plt.plot(t,f[maxHii],'rx')

plt.show()

fig = plt.figure(figsize=(20,10))
maxH = np.max(np.sqrt(Sxx),axis=0)


plt.plot(t,maxH)
plt.plot(t,1./f[maxHii],'rx')
plt.grid(True)
plt.show()
343/82:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
maxHii = np.argmax(np.sqrt(Sxx),axis=0)
plt.plot(t,f[maxHii],'rx')

plt.show()

fig = plt.figure(figsize=(20,10))
maxH = np.max(np.sqrt(Sxx),axis=0)


plt.plot(t,maxH)
plt.plot(t,1./f[maxHii],'rx')
plt.grid(True)
plt.show()
legend(['Heave Amplitude, M','Heave Period, S'])
343/83:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
maxHii = np.argmax(np.sqrt(Sxx),axis=0)
plt.plot(t,f[maxHii],'rx')

plt.show()

fig = plt.figure(figsize=(20,10))
maxH = np.max(np.sqrt(Sxx),axis=0)


plt.plot(t,maxH)
plt.plot(t,1./f[maxHii],'rx')
plt.grid(True)
plt.show()
plt.legend(['Heave Amplitude, M','Heave Period, S'])
343/84:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
maxHii = np.argmax(np.sqrt(Sxx),axis=0)
plt.plot(t,f[maxHii],'rx')

plt.show()

fig = plt.figure(figsize=(20,10))
maxH = np.max(np.sqrt(Sxx),axis=0)


plt.plot(t,maxH)
plt.plot(t,1./f[maxHii],'rx')
plt.grid(True)
plt.legend(['Heave Amplitude, M','Heave Period, S'])
plt.show()
343/85:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
maxHii = np.argmax(np.sqrt(Sxx),axis=0)
plt.plot(t,f[maxHii],'rx')

plt.show()

fig = plt.figure(figsize=(20,10))
maxH = np.max(np.sqrt(Sxx),axis=0)


plt.plot(t,maxH)
plt.plot(t,1./f[maxHii],'rx')
plt.grid(True)
plt.legend(['Heave Amplitude, M','Heave Period, S'])
xlabel('Time, S')
plt.show()
343/86:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-29-18':'2018-10-30-12'].heave)
Hr = datadata['2018-10-29-18':'2018-10-30-12'].heave.rolling('60s').max()
plt.plot(Hr,'..')
plt.grid(True)
plt.show()
343/87:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-29-18':'2018-10-30-12'].heave)
Hr = data['2018-10-29-18':'2018-10-30-12'].heave.rolling('60s').max()
plt.plot(Hr,'..')
plt.grid(True)
plt.show()
343/88:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-29-18':'2018-10-30-12'].heave)
Hr = data['2018-10-29-18':'2018-10-30-12'].heave.rolling('60s').max()
plt.plot(Hr,'.')
plt.grid(True)
plt.show()
343/89:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-29-18':'2018-10-30-12'].heave)
HMax = data['2018-10-29-18':'2018-10-30-12'].heave.rolling('60s').max()
Hmin = data['2018-10-29-18':'2018-10-30-12'].heave.rolling('60s').min()
plt.plot(Hmax,'.')
plt.plot(Hmin,'.')
plt.grid(True)
plt.show()
343/90:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-29-18':'2018-10-30-12'].heave)
Hmax = data['2018-10-29-18':'2018-10-30-12'].heave.rolling('60s').max()
Hmin = data['2018-10-29-18':'2018-10-30-12'].heave.rolling('60s').min()
plt.plot(Hmax,'.')
plt.plot(Hmin,'.')
plt.grid(True)
plt.show()
343/91:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
maxHii = np.argmax(np.sqrt(Sxx),axis=0)
plt.plot(t,f[maxHii],'rx')

plt.show()

fig = plt.figure(figsize=(20,10))
maxH = np.max(np.sqrt(Sxx)/2,axis=0)


plt.plot(t,maxH)
plt.plot(t,1./f[maxHii],'rx')
plt.grid(True)
plt.legend(['Heave Amplitude, M','Heave Period, S'])
xlabel('Time, S')
plt.show()
343/92:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',2048))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
maxHii = np.argmax(np.sqrt(Sxx),axis=0)
plt.plot(t,f[maxHii],'rx')

plt.show()

fig = plt.figure(figsize=(20,10))
maxH = np.max(np.sqrt(Sxx)/2,axis=0)


plt.plot(t,maxH)
plt.plot(t,1./f[maxHii],'rx')
plt.grid(True)
plt.legend(['Heave Amplitude, M','Heave Period, S'])
xlabel('Time, S')
plt.show()
343/93:
fig = plt.figure(figsize=(20,10))
plt.plot(np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)./np.diff(data['2018-10-29-18':'2018-10-31-06'].time))
343/94:
fig = plt.figure(figsize=((20,10))
plt.plot(np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)./np.diff(data['2018-10-29-18':'2018-10-31-06'].time))
plt.show()
343/95:
fig = plt.figure(figsize=((20,10))
plt.plot(np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)./np.diff(data['2018-10-29-18':'2018-10-31-06'].index))
plt.show()
343/96: np.diff?
343/97:
fig = plt.figure(figsize=(20,10))

plt.plot(np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)./np.diff(data['2018-10-29-18':'2018-10-31-06'].time))
plt.show()
343/98:
fig = plt.figure(figsize=(20,10))
dHdt = np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)./np.diff(data['2018-10-29-18':'2018-10-31-06'].time)

plt.plot(dHdt)
plt.show()
343/99:
fig = plt.figure(figsize=(20,10))
dH = np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)
dt = np.diff(data['2018-10-29-18':'2018-10-31-06'].time)

plt.plot(dHdt)
plt.show()
343/100:
fig = plt.figure(figsize=(20,10))
dH = np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)
dt = np.diff(data['2018-10-29-18':'2018-10-31-06'].time)

plt.plot(dH./dt)
plt.show()
343/101: whos
343/102:
fig = plt.figure(figsize=(20,10))
dH = np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)
dt = np.diff(data['2018-10-29-18':'2018-10-31-06'].time)

plt.plot(dH/dt)
plt.show()
343/103:
fig = plt.figure(figsize=(20,10))
dH = np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)
dt = np.diff(data['2018-10-29-18':'2018-10-31-06'].time)

plt.hist(dH/dt)
plt.show()
343/104:
fig = plt.figure(figsize=(20,10))
dH = np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)
dt = np.diff(data['2018-10-29-18':'2018-10-31-06'].time)

plt.hist(dH/dt,100)
plt.show()
343/105:
fig = plt.figure(figsize=(20,10))
dH = np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)
dt = np.diff(data['2018-10-29-18':'2018-10-31-06'].time)
dHdt = dH/dt

plt.hist(dHdt[dHdt < 10,100)
plt.show()
343/106:
fig = plt.figure(figsize=(20,10))
dH = np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)
dt = np.diff(data['2018-10-29-18':'2018-10-31-06'].time)
dHdt = dH/dt

plt.hist(dHdt[dHdt < 10],100)
plt.show()
343/107:
fig = plt.figure(figsize=(20,10))
dH = np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)
dt = np.diff(data['2018-10-29-18':'2018-10-31-06'].time)
dHdt = dH/dt

plt.hist(dHdt[abs(dHdt) < 10],100)
plt.show()
343/108:
fig = plt.figure(figsize=(20,10))
dH = np.diff(data['2018-10-29-18':'2018-10-31-06'].heading)
dt = np.diff(data['2018-10-29-18':'2018-10-31-06'].time)
dHdt = dH/dt

#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt[abs(dHdt)<10])
plt.show()
343/109:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt

#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt[abs(dHdt)<10])
plt.show()
343/110: whos
343/111:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()

#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.show()
343/112:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.show()
343/113: plt.plot(data.vel_down)
343/114:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
343/115:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').max())
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
343/116:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').max())
plt.legend('Max Heave Rate','Max Vertical Velocity')
plt.ylabel('Meters Per Second')
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
343/117:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').max())
plt.legend([]'Max Heave Rate','Max Vertical Velocity'])
plt.ylabel('Meters Per Second')
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
343/118:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').max())
plt.legend(['Max Heave Rate','Max Vertical Velocity'])
plt.ylabel('Meters Per Second')
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
343/119:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').max())
plt.legend(['Max Heave Rate','Max Vertical Velocity'])
plt.ylabel('Meters Per Second')
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
print('Max Vertical Velocity: %0.3f' % data['2018-10-29-18':'2018-10-31-06'].vel_down.max())
343/120:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').max())
plt.legend(['Max Heave Rate','Max Vertical Velocity'])
plt.ylabel('Meters Per Second')
plt.grid(True)
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
print('Max Vertical Velocity: %0.3f' % data['2018-10-29-18':'2018-10-31-06'].vel_down.max())
343/121:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').abs().max())
plt.legend(['Max Heave Rate','Max Vertical Velocity'])
plt.ylabel('Meters Per Second')
plt.grid(True)
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
print('Max Vertical Velocity: %0.3f' % data['2018-10-29-18':'2018-10-31-06'].vel_down.max())
343/122:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').absmax())
plt.legend(['Max Heave Rate','Max Vertical Velocity'])
plt.ylabel('Meters Per Second')
plt.grid(True)
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
print('Max Vertical Velocity: %0.3f' % data['2018-10-29-18':'2018-10-31-06'].vel_down.max())
343/123:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').max())
plt.legend(['Max Heave Rate','Max Vertical Velocity'])
plt.ylabel('Meters Per Second')
plt.grid(True)
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
print('Max Vertical Velocity: %0.3f' % data['2018-10-29-18':'2018-10-31-06'].vel_down.max())
343/124: dHdt.head()
343/125: dHdt.diff()
343/126: dHdt.diff()./dHdt.time.diff()
343/127: dHdt.diff()/dHdt.time.diff()
343/128: dHdt
343/129: dHdt.diff()/dHdt.index.diff()
343/130: dHdt.diff()/np.diff(dHdt.index)
343/131: dHdt.diff()/np.diff(dHdt.index.to_native_types?)
343/132:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
ddHddt = dHdt.diff()
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(dHdt.rolling('60s').min())

plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').min())


plt.legend(['Max Heave Rate','Max Vertical Velocity'])
plt.ylabel('Meters Per Second')
plt.grid(True)
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
print('Max Vertical Velocity: %0.3f' % data['2018-10-29-18':'2018-10-31-06'].vel_down.max())
343/133:
fig = plt.figure(figsize=(20,10))
dH = data['2018-10-29-18':'2018-10-31-06'].heading.diff()
dt = data['2018-10-29-18':'2018-10-31-06'].time.diff()
dHdt = dH/dt
dHdt = dHdt[abs(dHdt) < 10]
ddHddt = dHdt.diff()
#plt.hist(dHdt[abs(dHdt) < 10],100)
plt.plot(dHdt.rolling('60s').max())
plt.plot(dHdt.rolling('60s').min())

plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').max())
plt.plot(data['2018-10-29-18':'2018-10-31-06'].vel_down.rolling('60s').min())


plt.legend(['Max Heave Rate UP','Max Heave Rate Down''Max Vertical Velocity UP','Max Vertical Velocity Down'])
plt.ylabel('Meters Per Second')
plt.grid(True)
plt.show()
print('Max Heave Rate: %0.3f' % dHdt.max())
print('Max Vertical Velocity: %0.3f' % data['2018-10-29-18':'2018-10-31-06'].vel_down.max())
343/134: dHdt.index.to_native_types?
343/135: dHdtdf = pd.DataFrame(dHdt)
343/136: dHdtdf.head()
343/137: dHdtdf = pd.DataFrame(dHdt,columns=['HeaveVel'])
343/138: dHdtdf.head()
343/139: dHdtdf.index.difference?
343/140: tt = dHdtdf.index.to_pydatetime()
343/141: tt[0]
343/142: np.diff(tt)
343/143: dt = np.diff(tt)
343/144: a = dt[0]
343/145: a.seconds()
343/146: a.seconds
343/147: a.total_seconds
343/148: a.total_seconds()
343/149:
dHdtdf = pd.DataFrame(dHdt,columns=['HeaveVel'])
ddHddt = dHdtdf.diff()/.2
343/150:
dHdtdf = pd.DataFrame(dHdt,columns=['HeaveVel'])
ddHddt = dHdtdf.diff()/.2
fig = plt.figure(figsize=(20,10))
plt.plot(ddHddt)
343/151: whos
343/152:
dHdtdf = pd.DataFrame(dHdt,columns=['HeaveVel'])
ddHddt = dHdtdf.diff()/.2
fig = plt.figure(figsize=(20,10))
plt.plot(ddHddt.roll('60s').max())
343/153:
dHdtdf = pd.DataFrame(dHdt,columns=['HeaveVel'])
ddHddt = dHdtdf.diff()/.2
fig = plt.figure(figsize=(20,10))
plt.plot(ddHddt.rolling('60s').max())
343/154:
dHdtdf = pd.DataFrame(dHdt,columns=['HeaveVel'])
ddHddt = dHdtdf.diff()/.2
fig = plt.figure(figsize=(20,10))
plt.plot(ddHddt.rolling('60s').max()/9.82)
plt.grid(True)
plt.ylabel('Vertical Gs)
plt.show()
343/155:
dHdtdf = pd.DataFrame(dHdt,columns=['HeaveVel'])
ddHddt = dHdtdf.diff()/.2
fig = plt.figure(figsize=(20,10))
plt.plot(ddHddt.rolling('60s').max()/9.82)
plt.grid(True)
plt.ylabel('Vertical Gs')
plt.show()
341/21: 15**2
341/22: 17**2
341/23: 225/289
344/1:
import pandas as pd
import plotly.plotly as py
import numpy as np
import matplotlib.pyplot as plt
import plotly.tools as tls
%matplotlib notebook 
#import mpld3
#mpld3.enable_notebook()
344/2:
data = pd.read_hdf('spsol.h5')
data.set_index(pd.to_datetime(data.time,unit='s'),inplace=True)
data.sort_index(inplace=True)
344/3: data.head()
344/4:
fig = plt.figure(figsize=(20,10))
plt.plot(data.roll)
plt.grid(True)
plt.show()
344/5:


fig = plt.figure(figsize=(20,10))
ax1 = fig.add_subplot(111)
#ax1.plot(data['2018-10-30':'2018-11-01'].roll.iloc[int(3.5e6):int(3.7e6)])
#ax1.plot(data.pitch['2018-10-30':'2018-11-01'].iloc[int(3.5e6):int(3.7e6)])
ax1.plot(data['2018-10-29-18':'2018-10-31-06'].roll)
ax1.plot(data.pitch['2018-10-29-18':'2018-10-31-06'])

plt.grid(True)
plt.legend(('Roll','Pitch'))
plt.ylabel('Degrees')
#ax1.plot(data.roll)
plt.show()
#plotlyfig = tls.mpl_to_plotly(fig)
#py.iplot(plotlyfig,filename='nautilus_roll')
print('Max Roll %0.2f' % data.roll.max())
print('Max Pitch %0.2f' % data.pitch.max())
344/6:
import scipy as sci
from scipy import signal
344/7:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].roll,5,window=signal.get_window('hamming',512))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
plt.show()

fig = plt.figure(figsize=(20,10))
maxii = np.argmax(Sxx,axis=0)
plt.plot(t,1./f[maxii],'xr')
plt.grid(True)
plt.title('Mean Roll Period')
plt.ylabel('Seconds')
aa = plt.axis();
plt.axis([aa[0],aa[1],0,20])
344/8:
fig = plt.figure(figsize=(20,10))
#plt.plot(data['2018-10-30-12':'2018-10-31-06'].heave)
plt.plot(data['2018-10-29-18':'2018-10-30-12'].heave)
Hmax = data['2018-10-29-18':'2018-10-30-12'].heave.rolling('60s').max()
Hmin = data['2018-10-29-18':'2018-10-30-12'].heave.rolling('60s').min()
plt.plot(Hmax,'.')
plt.plot(Hmin,'.')
plt.grid(True)
plt.show()
344/9:
f,t,Sxx = signal.spectrogram(data['2018-10-29-18':'2018-10-31-06'].heave,5,window=signal.get_window('hamming',512))
fig=plt.figure(figsize = (20,10))
plt.pcolormesh(t,f,np.log10(Sxx))
plt.ylabel('Frquency Hz')
plt.xlabel('Time, s')
maxHii = np.argmax(np.sqrt(Sxx),axis=0)
plt.plot(t,f[maxHii],'rx')

plt.show()

fig = plt.figure(figsize=(20,10))
maxH = np.max(np.sqrt(Sxx)/2,axis=0)


plt.plot(t,maxH)
plt.plot(t,1./f[maxHii],'rx')
plt.grid(True)
plt.legend(['Heave Amplitude, M','Heave Period, S'])
xlabel('Time, S')
plt.show()
344/10:
fig = plt.figure(figsize=(20,10))
plt.plot(data['2018-10-29-18':'2018-10-31-06'].heading)
plt.grid(True)
plt.show()
345/1: import pandas as pd
345/2: d = pd.read_csv('GGA_3_.txt',delimiter=' ')
345/3: d = pd.read_csv('GGA_3_.txt',delimiter='\t')
345/4: d.head()
345/5: tt = pd.Timestamp(d[0:6])
345/6: tt = pd.Timestamp(d[:0:6])
345/7: d.head()
345/8: tt = pd.Timestamp(d[:,0:6])
345/9: d.head()
345/10: d.to_hdf('~/scratch/GGA.h5','gga',format='table')
345/11: d.to_hdf('~/scratch/GGA.h5','w','gga',format='table')
345/12: d.to_hdf('/Users/vschmidt/scratch/GGA.h5',,'gga',format='table')
345/13: d.to_hdf('/Users/vschmidt/scratch/GGA.h5','gga',format='table')
345/14: pwd
345/15: cd ..
345/16: ls
345/17: cd /Volumes/MAP2018ChannelIslands/cw4/extracted_logs/2018-11-03T13-30-58
345/18: d = pd.read_csv('payload.csv')
345/19: d.head()
345/20: d.to_hdf('payload.h5','payload',format='table',complevel=9)
346/1:
%matplotlib inline

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
346/2:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
346/3:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
data = data[data['Activity'] == 'UDOMSV']
#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index('Trans Date',inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
346/4: data.head()
346/5:
#dg = data.groupby(by='Activity')['Transaction Amount']
def custom_nansum(val):
    return np.nansum(val)

dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    
account_by_month = data.groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/6: account_by_month.head()
346/7: account_by_month.plot()
346/8: account_by_month.plot(kind='bar')
346/9:
#dg = data.groupby(by='Activity')['Transaction Amount']
def custom_nansum(val):
    return np.nansum(val)

dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    
account_by_month = data.groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
account_by_year = data.groupby('Account')["Transaction Amount"].resample("Y").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/10: account_by_year.plot(kind='bar')
346/11:
account_by_year.head()
#account_by_year.plot(kind='bar')
346/12:
#dg = data.groupby(by='Activity')['Transaction Amount']
def custom_nansum(val):
    return np.nansum(val)

dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    
account_by_month = data.groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/13:
account_by_year.head()
#account_by_year.plot(kind='bar')
346/14:
#dg = data.groupby(by='Activity')['Transaction Amount']
def custom_nansum(val):
    return np.nansum(val)

dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    

account_by_month = data['2018'].groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
#account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/15:
account_by_month.head()
#account_by_year.plot(kind='bar')
346/16:
account_by_month.head()
account_by_month.plot(kind='bar')
346/17:
account_by_month.head()
fig = plt.figure(figsize=(20,10))
account_by_month.plot(kind='bar')
346/18:
account_by_month.head()
fig = plt.figure(figsize=(20,10))
account_by_month.unstack().plot(kind='bar')
346/19:
account_by_month.head()
fig = plt.figure(figsize=(20,10))
account_by_month.unstack().plot(kind='bar')
346/20:
account_by_month.head()
fig = plt.figure(figsize=(20,10))
account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/21:
account_by_month.head()
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/22:
#dg = data.groupby(by='Activity')['Transaction Amount']
def custom_nansum(val):
    return np.nansum(val)

dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    

account_by_month = data['2018'].groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
data_by_month = data['2018']["Transaction Amount"].resample("M").apply(custom_nansum)


#account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/23:
data_by_month.head()
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/24:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index(['Account''Trans Date'],inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
346/25:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
346/26:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index(['Account''Trans Date'],inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
346/27:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')
346/28:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index(['Account','Trans Date'],inplace=True)
data.set_index(['Account','Trans Date'],inplace=True)
data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
346/29: data.head()
346/30:
#dg = data.groupby(by='Activity')['Transaction Amount']
def custom_nansum(val):
    return np.nansum(val)

dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    

account_by_month = data['2018'].groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
data_by_month = data['2018'].resample("M").apply(custom_nansum)


#account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/31: data['2018'].resample('M').apply(custom_nansum)
346/32: data.index
346/33: data.index[1]
346/34: data.head()
346/35: data[[:,'2018']].resample('M').apply(custom_nansum)
346/36:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index(['Account','Trans Date'],inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
346/37:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
346/38:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index(['Account','Trans Date'],inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
346/39: data.head()
346/40:
bymonth = data['2018'].resample('M').apply(custom_nansum)
bymonth.head()
346/41:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
346/42:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index('Trans Date',inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
346/43: data.head()
346/44:
bymonth = data['2018'].resample('M').apply(custom_nansum)
bymonth.head()
346/45:
bymonth = data['2018']['Transation Amount'].resample('M').apply(custom_nansum)
bymonth.head()
346/46:
bymonth = data['2018'].resample('M')['Transation Amount'].apply(custom_nansum)
bymonth.head()
346/47:
bymonth = data['2018'].resample('M').apply(custom_nansum)
bymonth.head()
346/48:
#dg = data.groupby(by='Activity')['Transaction Amount']


dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    

account_by_month = data['2018'].groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
data_by_month = data['2018'].resample("M").apply(custom_nansum)


#account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/49:
data_by_month.head()
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/50:
#dg = data.groupby(by='Activity')['Transaction Amount']


dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    

account_by_month = data['2018'].groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
data_by_month = data['2018']["Transaction Amount"].resample("M").apply(custom_nansum)


#account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/51:
data_by_month.head()
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/52:
data_by_month.head()
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/53:
account_by_month.head()
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/54:
print(account_by_month)
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/55:
#dg = data.groupby(by='Activity')['Transaction Amount']


dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    

#account_by_month = data['2018'].groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
account_by_month = data['2018'].resample("M"),groupby('Account')["Transaction Amount"].apply(custom_nansum)


data_by_month = data['2018']["Transaction Amount"].resample("M").apply(custom_nansum)


#account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/56:
#dg = data.groupby(by='Activity')['Transaction Amount']


dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    

#account_by_month = data['2018'].groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)
account_by_month = data['2018'].resample("M").groupby('Account')["Transaction Amount"].apply(custom_nansum)


data_by_month = data['2018']["Transaction Amount"].resample("M").apply(custom_nansum)


#account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/57:
#dg = data.groupby(by='Activity')['Transaction Amount']


dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    

account_by_month = data['2018'].groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)



data_by_month = data['2018']["Transaction Amount"].resample("M").apply(custom_nansum)


#account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
346/58:
print(account_by_month)
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/59:
print(account_by_month)
print(account_by_month.groupby('Trans Date'))
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/60:
#print(account_by_month)
print(account_by_month.groupby('Trans Date'))
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
346/61:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
346/62:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index('Trans Date',inplace=True)
data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
346/63: data.head()
346/64:
data = pd.read_excel('2018-06-04-02-53-15FIN2075 - Revenue and Expenditure Schmidt UDOMSV UDOMCI.xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
346/65:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index('Trans Date',inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
346/66: data.head()
346/67: grouper = data.groupby([pd.Grouper('1M'),'Account'])
346/68: grouper = data.groupby([pd.Grouper('M'),'Account'])
346/69: grouper = data.groupby([pd.Grouper('Trans Date',freq='M'),'Account'])
346/70: grouper = data.groupby([pd.Grouper('Trans Date',freq='1M'),'Account'])
346/71: grouper = data.groupby([pd.Grouper(key='Trans Date',freq='1M'),'Account'])
346/72: grouper = data.groupby([pd.Grouper(key='Trans Date',freq='1M'),'Account'])
346/73: grouper = data.groupby([pd.Grouper('1M'),'Account'])
346/74: grouper = data.groupby([pd.Grouper('M'),'Account'])
346/75: grouper = data.groupby([pd.Grouper(freq='1M'),'Account'])
346/76:
grouper = data.groupby([pd.Grouper(freq='1M'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
346/77:
grouper = data.groupby([pd.Grouper(freq='1M'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()
346/78:
grouper = data.groupby([pd.Grouper(freq='1M'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.plot(kind='bar')
346/79:
grouper = data.groupby([pd.Grouper(freq='1M'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.unstacked().plot(kind='bar')
346/80:
grouper = data.groupby([pd.Grouper(freq='1M'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()
346/81:
grouper = data.groupby([pd.Grouper(freq='1M'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.plot(kind-'bar',figsize=(20,10))
346/82:
grouper = data.groupby([pd.Grouper(freq='1M'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.plot(kind='bar',figsize=(20,10))
347/1: from math import *
347/2: 10%3
347/3: 10%3 is 1
347/4: range?
348/1: import numba
348/2: numba.__version__
349/1: a = [][]
349/2: a = []
349/3: a[0] = [1,2,3]
350/1: import numpy as np
350/2: import vgrid as v
350/3: G = v.grid?
350/4: G = v.grid()?
350/5: G = v.vgrid?
350/6: G = v.vgrid(1,1,'mean')
350/7: x = np.random.randint?
350/8: x = np.random.randint(-100,100,1e4)
350/9: x = np.random.randint?
350/10: x = np.random.randint(-100,100,int(1e4))
350/11: whos
350/12: y = np.random.randint(-100,100,int(1e4))
350/13: z = x+y
350/14: G
350/15: G?
350/16: reload(v)
350/17: G = v.vgrid(1,1,'mean')
350/18: G.calc_membership(x,y)
350/19: reload(v)
350/20: G = v.vgrid(1,1,'mean')
350/21: G.calc_membership(x,y)
350/22: G
350/23: reload(v)
350/24: G = v.vgrid(1,1,'mean')
350/25: G.calc_membership(x,y)
350/26: reload(v)
350/27: G = v.vgrid(1,1,'mean')
350/28: G.calc_membership(x,y)
350/29: reload(v)
350/30: G = v.vgrid(1,1,'mean')
350/31: G.calc_membership(x,y)
350/32: reload(v)
350/33: G = v.vgrid(1,1,'mean')
350/34: G.calc_membership(x,y)
350/35: reload(v)
350/36: G = v.vgrid(1,1,'mean')
350/37: G.calc_membership(x,y)
350/38: reload(v)
350/39: G = v.vgrid(1,1,'mean')
350/40: G.calc_membership(x,y)
350/41: reload(v)
350/42: G = v.vgrid(1,1,'mean')
350/43: G.calc_membership(x,y)
350/44: G.membership[0][0]
350/45: G.membership[1][0]
350/46: G.membership[2][0]
350/47: G.membership[3][0]
350/48: rows = len(G.membership)
350/49: cols = len(G.membership[0])
350/50: rows
350/51: cols
350/52:
for row in range(rows):
    for col in range(cols):
        print(G.membership[row,col])
350/53:
for row in range(rows):
    for col in range(cols):
        print(G.membership[row][col])
350/54: x = range(10)
350/55: y = range(10)
350/56: z = x+y
350/57: G = v.vgrid(1,1,'mean')
350/58: G.calc_membership(x,y)
350/59: x
350/60: y
350/61: x = np.range(10)
350/62: x = np.arange?
350/63: x = np.arange(10)
350/64: y = np.arange(10)
350/65: x
350/66: y
350/67: G = v.vgrid(1,1,'mean')
350/68: G.calc_membership(x,y)
350/69: G.membership
350/70: G.xx
350/71: G.yy
350/72: G.membership[0][0]
350/73: G.calc_membership(x,y)
350/74: reload(v)
350/75: G = v.vgrid(1,1,'mean')
350/76: G.calc_membership(x,y)
350/77: reload(v)
350/78: G = v.vgrid(1,1,'mean')
350/79: G.calc_membership(x,y)
350/80: G.membership
350/81: %timeit?
350/82: x = np.random.randint(-100,100,int(1e4))
350/83: y = np.random.randint(-100,100,int(1e4))
350/84: G = v.vgrid(1,1,'mean')
350/85: %timeit G.calc_membership(x,y)
350/86: G.membership
350/87: whos
350/88: reload(v)
350/89: G = v.vgrid(1,1,'mean')
350/90: G.calc_membership(x,y)
351/1: import time
351/2: time.mktime()
351/3: time.gmtime()
351/4: time.mktime(time.gmtime)
351/5: time.mktime(time.gmtime())
351/6: time.mktime(time.gmtime())
351/7: time.mktime(time.gmtime())
351/8: time.mktime(time.gmtime())
351/9: time.mktime?
351/10: time.gmtime()
351/11: import datetime
351/12: print(datetime.datetime.now().totimestamp())
351/13: time.time()
352/1: import datetime.datetime as dt
352/2: import datetime as dt
352/3: t1 = dt.datetime('6/2/2019')
352/4: import dateutil
352/5: d1 = dateutil.parser.parse('6/2/2019')
352/6: from dateutil import parser
352/7: from dateutil.parser import *
352/8: d1 = parse('6/2/2019')
352/9: d2 = parse('7/15/2019')
352/10: shipping = d2-d1
352/11: shipping.days()
352/12: shipping.days
352/13: d3 = parse('8/28/2019')
352/14: d4 = parse('10/11/2019')
352/15: returning = d4-d3
352/16: returning.days()
352/17: returning.days
352/18: import numpy as np
352/19: d = np.load('/Volumes/ENG2015ASV/data/cworker4/vp/ccscm/scm-vp/2016-09-14T13-54-55/2016-09-14T18-39-56.Forward\ Camera/160914-1939/1473878398.507_disp.npy')
352/20: pwd
352/21: d = np.load('/Users/vschmidt/Desktop/1473878398.507_disp.npy')
352/22: d.shape
352/23: import matplotlib.pyplot as plt
352/24:
plt.figure(figsize=(10,10)
)
352/25: plt.plot_surface(d,linewidth=0)
352/26: plt.hist(d)
352/27: plt.show()
352/28: plt.imshow(d)
352/29: plt.show()
352/30: plt.imshow(d)
352/31: plt.colorbar()
352/32: plt.show()
352/33: plt.imshow(d*255)
352/34: plt.colorbar()
352/35: plt.show()
352/36: plt.imshow(1/d)
352/37: plt.colorbar()
352/38: plt.show()
352/39: plt.colorbar?
352/40: plt.clim?
352/41: plt.imshow(1/d)
352/42: plt.colorbar()
352/43: plt.clim(0,1000)
352/44: plt.show()
352/45: plt.imshow(1/d)
352/46: plt.colorbar()
352/47: plt.clim(0,200)
352/48: plt.show()
353/1:
print('PyDev console: using IPython 6.5.0\n')

import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['/Users/vschmidt/gitsrc/oet'])
354/1: import vgrid as v
355/1: import vgrid as v
355/2: import numba
355/3: import vgrid as v
355/4: import vgrid as v
355/5: import vgrid as v
355/6: v.__version__
355/7: numba.__version__
356/1: ls
356/2: import vgrid as v
356/3: import vgrid as v
356/4: import vgrid as v
356/5: import numpy as np
356/6: x = np.nprange(10)
356/7: x = np.range(10)
356/8: x = np.arange(10)
356/9: y = np.arange(10)
356/10: z = x+y
356/11: from importlib import reload
356/12: reload(v)
356/13: v
356/14: v = reload(v)
356/15: G = v.vgrid()
356/16: G = v.vgrid(1,1,1)
356/17: v = reload(v)
356/18: V = v.vgrid(1,1,1)
356/19: reload(v)
356/20: v = reload(v)
356/21: V = v.vgrid(1,1,1)
357/1: import vgrid as v
357/2: V = v.vgrid(1,1,1)
357/3: v = reload(v)
357/4: V = v.vgrid(1,1,1)
358/1: import vgrid as v
358/2: V = v.vgrid(1,1,1)
359/1: import vgrid as v
359/2: V = v.vgrid(1,1,1)
360/1: import vgrid as v
360/2: V = v.vgrid(1,1,1)
360/3: import numpy as np
360/4: a = np.array(np.nan)
360/5: a
361/1: V = v.vgrid(1,1,1)
361/2: import numpy as np
361/3: import vgrid as v
361/4: V = v.vgrid(1,1,1)
362/1: import numbatest as n
362/2: import numbatest as n
362/3: N = n.test(1,1,1)
362/4: from importlib import reload
363/1: import numbatest as n
363/2: N = n.test(1,1,1)
363/3: N.print_test()
364/1: import numbatest as n
364/2: import numbatest as n
364/3: import numbatest as n
364/4: import numbatest as n
364/5: import numbatest as n
364/6: import numbatest as n
364/7: import numbatest as n
365/1: import numbatest as n
365/2: import numbatest as n
365/3: import numbatest as n
366/1: import numbatest as n
366/2: import numbatest as n
366/3: import numbatest as n
367/1: import numbatest as n
367/2: import numbatest as n
367/3: import numbatest as n
367/4: import numbatest as n
368/1: import numbatest as n
368/2: import numbatest as n
368/3: N = n.test()
368/4: N = n.Test()
368/5: N.makerandomdata(10)
368/6: import numpy as np
368/7: np.random.normal(10)
368/8: np.random.normal((1,10))
368/9: np.random(10)
368/10: np.random.normal?
368/11: np.random.uniform?
368/12: np.random(10)
369/1: import numbatest as n
369/2: N = n.Test()
369/3: N.makerandomdata(10)
369/4: N.print_test()
369/5: N.makegrid()
370/1: import numbatest as n
370/2: N = n.Test()
370/3: N.makerandomdata(10)
370/4: N.makegrid()
370/5: N.xx
370/6: N.yy
370/7: N._membership()
370/8: N._membership()
371/1: import numbatest as n
371/2: N = n.Test()
371/3: N.makerandomdata(10)
371/4: N.makegrid()
371/5: N._membership()
371/6: m = N._membership()
371/7: size(m)
371/8: m.__len__()
372/1: ls
372/2: run('numbatest.py')
372/3: run('./numbatest.py')
372/4: run?
372/5: run 'numbatest.py'
372/6: run 'numbatest.py'
372/7: run 'numbatest.py'
372/8: run 'numbatest.py'
373/1: import numbatest as n
373/2: N = n.Test()
373/3: N.makerandomdata(10)
373/4: N.makegrid()
373/5: import timeit
373/6: timeit.timeit('N.membership()')
374/1: import scipy
374/2: scipy.interp?
374/3: scipy.trapz?
375/1: import numpy
375/2: from keras.models import Sequential
376/1:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM.xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
376/2:
%matplotlib inline

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
376/3:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM.xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
376/4:
%matplotlib inline

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
376/5:
%matplotlib inline

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
print(os.path.curdir)
376/6:
%matplotlib inline

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
print(os.path.abspath(os.path.curdir))
376/7:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM.xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
376/8:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
376/9:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index('Trans Date',inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170"}
376/10: data.head()
376/11:
grouper = data.groupby([pd.Grouper(freq='1M'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
376/12:
#dg = data.groupby(by='Activity')['Transaction Amount']


dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    

account_by_month = data['2018'].groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)



data_by_month = data['2018']["Transaction Amount"].resample("M").apply(custom_nansum)


#account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
376/13:
#print(account_by_month)
#print(account_by_month.groupby('Trans Date'))
#account_by_month.unstack().plot(kind='bar',figsize=(20,10))
376/14:
account_by_month_grp = data.groupby('Account')["Transaction Amount"].resample("M")

dd = account_by_month_grp.sum()
#for g,grp in account_by_month_grp:
#    print(g)
#    print(grp)
a = dd.index.levels
print(a[1].shape)
376/15:
grouper = data.groupby([pd.Grouper(freq='1Y'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
376/16:
grouper = data.groupby([pd.Grouper(freq='1Y'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth.plot()
376/17:
grouper = data.groupby([pd.Grouper(freq='1Y'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

plt.figure(figsize(7,7))
bymonth.plot()
376/18:
grouper = data.groupby([pd.Grouper(freq='1Y'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

plt.figure(figsize=(7,7))
bymonth.plot()
376/19:
grouper = data.groupby([pd.Grouper(freq='1Y'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymont.head()

plt.figure(figsize=(10,10))
bymonth.plot()
376/20:
grouper = data.groupby([pd.Grouper(freq='1Y'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

plt.figure(figsize=(10,10))
bymonth.plot()
376/21:
grouper = data.groupby([pd.Grouper(freq='1Y'),'Account'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/22:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index('Trans Date',inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames:
    accountnumbers(v)=k
376/23:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index('Trans Date',inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames:
    accountnumbers[v]=k
376/24:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index('Trans Date',inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames:
    print(k + ',' + v)
    #accountnumbers[v]=k
376/25:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index('Trans Date',inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()

accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
#for k,v in accountnames:
#    print(k + ',' + v)
    #accountnumbers[v]=k
print(accountnames)
376/26:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
#for k,v in accountnames:
#    print(k + ',' + v)
    #accountnumbers[v]=k
print(accountnames)
376/27:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames:
    #print(k + ',' + v)
    accountnumbers[v]=k
376/28:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
376/29:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
376/30:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index('Trans Date',inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()
376/31:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
376/32:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k

data['AccountNames]'] = map(accountnumbers.get,data['Account'])
376/33: data.head()
376/34:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
 print(accountnumbers[data['Account'][1]])

#data['AccountNames]'] = map(accountnumbers.get,data['Account'])
376/35:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
print(accountnumbers[data['Account'][1]])

#data['AccountNames]'] = map(accountnumbers.get,data['Account'])
376/36:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
print(map(accountnumbers.get,data['Account']))

#data['AccountNames]'] = map(accountnumbers.get,data['Account'])
376/37:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['AccountNames]'] = list(map(accountnumbers.get,data['Account']))
376/38: data.head()
376/39:
grouper = data.groupby([pd.Grouper(freq='1Y'),'AccountName',])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/40:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
376/41:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index('Trans Date',inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()
376/42:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['AccountName]'] = list(map(accountnumbers.get,data['Account']))
376/43: data.head()
376/44:
grouper = data.groupby([pd.Grouper(freq='1Y'),'AccountName',])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/45:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
376/46:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

data.set_index('Trans Date',inplace=True)
#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()
376/47:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['AccountName'] = list(map(accountnumbers.get,data['Account']))
376/48: data.head()
376/49:
grouper = data.groupby([pd.Grouper(freq='1Y'),'AccountName',])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/50:
grouper = data.groupby([pd.Grouper(freq='1M'),'AccountName',])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/51:
#dg = data.groupby(by='Activity')['Transaction Amount']


dg = data.groupby('Account')["Transaction Amount"]
#for val in accountnames.values():
#    account_by_month[val] = dg.get_group(val).sum()
    

account_by_month = data['2018'].groupby('Account')["Transaction Amount"].resample("M").apply(custom_nansum)



data_by_month = data['2018']["Transaction Amount"].resample("M").apply(custom_nansum)


#account_by_year = data.groupby('Account')["Transaction Amount"].resample("A").apply(custom_nansum)


#account_by_month = data.groupby('Account')["Transaction Amount"].resample("M")

#totals = data.groupby('Account')["Transaction Amount"].resample("A").sum().plot()

totals_by_account = account_by_month.groupby('Account').sum()
totals_by_account_by_year = data.groupby('Account')['Transaction Amount'].resample("A").sum()

#dg = data.groupby('Account')
#act = dg['Account'][0]
#act.plot()
#data.resample('M',level=1)['Transaction Amount'].sum().plot()
#data.resample("M")['Transaction Amount'].sum().plot(kind='bar')
376/52:
grouper = data.groupby([pd.Grouper(key='Trans Date',freq='1M'),'AccountName',])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/53:
grouper = data.groupby([pd.Grouper(freq='M'),'AccountName',])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/54:
grouper = data.groupby([pd.Grouper(key='index',freq='M'),'AccountName',])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/55:
grouper = data.groupby([pd.Grouper(key='Trans Date',freq='M'),'AccountName',])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/56:
grouper = data.groupby([pd.Grouper(freq='M'),'AccountName',])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/57:
grouper = data.groupby([pd.Grouper(freq='M'),'AccountName',]).apply(custom_nansum)
#bymonth = grouper['Transaction Amount'].apply(custom_nansum)
#bymonth.head()
grouper.head()
#plt.figure(figsize=(10,10))
#bymonth.plot()
376/58:
grouper = data.groupby([pd.Grouper(freq='M'),'AccountName',])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/59:
grouper = data.groupby([pd.Grouper(freq='M'),'AccountName'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

bymonth2 = data.rsample('M').groupby('AccountName')['Transaction Amount'].apply(custom_nansum)
bymonth2.head()
#plt.figure(figsize=(10,10))
#bymonth.plot()
376/60:
grouper = data.groupby([pd.Grouper(freq='M'),'AccountName'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()

bymonth2 = data.resample('M').groupby('AccountName')['Transaction Amount'].apply(custom_nansum)
bymonth2.head()
#plt.figure(figsize=(10,10))
#bymonth.plot()
376/61:
grouper = data.groupby([pd.Grouper(freq='M'),'AccountName'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()


#plt.figure(figsize=(10,10))
#bymonth.plot()
376/62:
grouper = data.groupby([pd.Grouper(freq='M'),'AccountName'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()
grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/63:
grouper = data.groupby([pd.Grouper(freq='M'),'AccountName'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
#bymonth.head()
grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/64:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['Account Name]'] = list(map(accountnumbers.get,data['Account']))

data.set_index(['Trans Date','Account Name'],inplace=True)
376/65:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
376/66:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index('Trans Date',inplace=True)

#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()
376/67:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['Account Name]'] = list(map(accountnumbers.get,data['Account']))

data.set_index(['Trans Date','Account Name'],inplace=True)
376/68:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')

def custom_nansum(val):
    return np.nansum(val)
376/69:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index('Trans Date',inplace=True)

#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()
376/70:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['Account Name'] = list(map(accountnumbers.get,data['Account']))

data.set_index(['Trans Date','Account Name'],inplace=True)
376/71: data.head()
376/72:
grouper = data.groupby(pd.Grouper(freq='M')
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/73:
grouper = data.groupby(pd.Grouper(freq='M').apply(custom_nansum)
#bymonth = grouper('Transaction Amount').apply(custom_nansum)
#bymonth.head()
grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/74:
grouper = data.groupby(pd.Grouper(freq='M')
bymonth = grouper('Transaction Amount').apply(custom_nansum)
bymonth.head()
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/75:
grouper = data.groupby(pd.Grouper(freq='M')
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/76:
grouper = data.groupby(pd.Grouper(level=0,freq='M',)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/77:
grouper = data.groupby(pd.Grouper(level=0,freq='M'))
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/78:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.head()
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/79:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
print(bymonth)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/80:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum).cumsum()
print(bymonth)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/81:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = grouper['Transaction Amount'].apply(custom_nansum).cumsum()


print(bymonth)
print(bymonth_cumulative)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/82:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = grouper['Transaction Amount'].apply(custom_nansum).groupby('Account Name'].cumsum()


print(bymonth)
print(bymonth_cumulative)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/83:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = grouper['Transaction Amount'].apply(custom_nansum).groupby('Account Name').cumsum()


print(bymonth)
print(bymonth_cumulative)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/84:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = grouper['Transaction Amount'].apply(custom_nansum).groupby('Account Name').cumsum()


print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.plot()
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/85:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = grouper['Transaction Amount'].apply(custom_nansum).groupby('Account Name').cumsum()


print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot()
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/86:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = grouper['Transaction Amount'].apply(custom_nansum).groupby('Account Name').cumsum()


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot()
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/87:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = grouper['Transaction Amount'].apply(custom_nansum).groupby('Account Name').cumsum()


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(figsize=(10,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/88:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'])
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = grouper['Transaction Amount'].apply(custom_nansum).groupby('Account Name').cumsum()


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/89:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = grouper['Transaction Amount'].apply(custom_nansum).groupby('Account Name').cumsum()


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
377/1: import pandas as pd
377/2: a = ['Jack','Jack','Jack','jack','Jill','Jill']
377/3: b = ['Monday','Tuesday','Tuesday','Wednesday','Monday','Wednesday']
377/4: c = [10, 20, 10,50,40,110]
377/5: d = [a,b,c]
377/6: d
377/7: d.T
377/8: a[:]
377/9: a'
377/10: a.T
377/11: d = [a;b;c]
377/12: df = pd.DataFrame()
377/13: df['name'] = a
377/14: df['day'] = b
377/15: df['no'] = c
377/16: df.print()
377/17: print(df)
376/90:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
for month in bymonth
    print(month)




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/91:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
for month in bymonth:
    print(month)




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/92:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
for month, value in bymonth:
    print(month)
    print(value)




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/93:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth)
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/94:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sortlevel(0))
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/95:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sortlevel(1))
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/96:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sortlevel(1).cumsum())
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/97:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sortlevel(1).groupby(level=0).cumsum())
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/98:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sortlevel(1).cumsum())
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/99:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sortlevel(1).cumsum().groupby(level0))
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/100:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sortlevel(1).cumsum().groupby(level=0))
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/101:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sort_index(1).cumsum().groupby(level=0))
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/102:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sortlevel(1).cumsum().groupby(level=0))
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/103:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sort_index(level=1).cumsum().groupby(level=0))
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/104:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sort_index(level=1).cumsum().groupby(level=0).sum())
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/105:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sort_index(level=1).cumsum()
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/106:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sort_index(level=1).cumsum())
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/107:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sort_index(level=1).groupby(level=1).cumsum())
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/108:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

print(bymonth.sort_index(level=1).groupby(level=0).cumsum())
    




#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/109:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1).groupby(level=0).cumsum()
    



#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/110:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1).groupby(level=0).cumsum()
    



#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/111:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1).groupby(level=0).cumsum()
    
print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/112:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1).groupby(level=0).cumsum()
    
print(bymonth_cumulative.groupby('Account Name'))


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/113:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1).groupby(level=0).cumsum()
    
print(bymonth_cumulative


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/114:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1).groupby(level=0).cumsum()
    
print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True)
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/115:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1).groupby(level=0).cumsum()
    
print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True,legend=True)
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/116:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1).groupby(level=0).cumsum()
    
print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True)
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/117:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')
data['Trans Date'] = data.to_datetime(data['Trans Date'])

def custom_nansum(val):
    return np.nansum(val)
376/118:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')
data['Trans Date'] = pd.to_datetime(data['Trans Date'])

def custom_nansum(val):
    return np.nansum(val)
376/119:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')
#data['Trans Date'] = pd.to_datetime(data['Trans Date'])

def custom_nansum(val):
    return np.nansum(val)
376/120:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index('Trans Date',inplace=True)

#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
#data.head()
376/121:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index('Trans Date',inplace=True)

#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
data.head()
376/122:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['Account Name'] = list(map(accountnumbers.get,data['Account']))

data.set_index(['Trans Date','Account Name'],inplace=True)
376/123: data.head()
376/124:
data['Trans Date']=pd.to_datetime(data['Trans Date'])
data.head()
376/125:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')
#data['Trans Date'] = pd.to_datetime(data['Trans Date'])

def custom_nansum(val):
    return np.nansum(val)
376/126:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index('Trans Date',inplace=True)

#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
data.head()
376/127:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['Account Name'] = list(map(accountnumbers.get,data['Account']))

data.set_index(['Trans Date','Account Name'],inplace=True)
376/128:
data['Trans Date']=pd.to_datetime(data['Trans Date'])
data.head()
376/129:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')
#data['Trans Date'] = pd.to_datetime(data['Trans Date'])

def custom_nansum(val):
    return np.nansum(val)
376/130:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index('Trans Date',inplace=True)

#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
data.head()
376/131:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['Account Name'] = list(map(accountnumbers.get,data['Account']))
data['Trans Date']=pd.to_datetime(data['Trans Date'])


#data.set_index(['Trans Date','Account Name'],inplace=True)
376/132: data.head()
376/133:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['Account Name'] = list(map(accountnumbers.get,data['Account']))
data['Trans Date']=pd.to_datetime(data['Trans Date'])


data.set_index(['Trans Date','Account Name'],inplace=True)
376/134: data.head()
376/135:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1).groupby(level=0).cumsum()
    
print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').pivot(index='Trans Date',plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/136:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1).groupby(level=0).cumsum()
    
print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/137:
data.head()
data.dtypes
376/138:
data.head()
data.index.dtype
376/139:
data.head()
data.index.dtype()
376/140: data.head()
376/141:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1)
    
print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/142:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1)
for a = bymonth_cumulative['Account Name']:
    print(a)
print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/143:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1)
for a in bymonth_cumulative['Account Name']:
    print(a)
#print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/144:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.sort_index(level=1)

#print(bymonth_cumulative)


print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/145:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

for x, y in bymonth(level=0)
    print(x)
    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

#print(bymonth_cumulative)


print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/146:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

for x, y in bymonth(level=0):
    print(x)
    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

#print(bymonth_cumulative)


print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/147:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

for x, y in bymonth.groupby(level=0):
    print(x)
    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

#print(bymonth_cumulative)


print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/148:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

for x, y in bymonth.groupby(level=1):
    print(x)
    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

#print(bymonth_cumulative)


print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/149:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymont.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

print(bymonth_cumulative)


print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/150:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
#bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/151:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(x='Trans Date',figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/152:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(,figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/153:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bymonth_cumulative.groupby('Account Name').plot(figsize=(15,10),grid=True,legend=True,marker='o')
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/154:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bb = bymonth_cumulative.groupby('Account Name')
bb.head()
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/155:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
bb = bymonth_cumulative.groupby(level=1)
bb.head()
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/156:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
plt.figure(figsize=(10,15))
for x, y in bymonth_cumulative.groupby(level=1):
    plt.plot(y['Trans Date'],y['Transaction Amount'])
plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/157:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
plt.figure(figsize=(10,15))
for x, y in bymonth_cumulative.groupby(level=1):
    print(y)
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/158:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
plt.figure(figsize=(10,15))
for x, y in bymonth_cumulative.groupby(level=1):
    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/159:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative,columns=['Amount'])

print(bymonth_cumulative)


#print(bymonth)
#print(bymonth_cumulative)
plt.figure(figsize=(10,15))
for x, y in bymonth_cumulative.groupby(level=1):
    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/160:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative,columns=['Amount'])

print(bymonthdf)


#print(bymonth)
#print(bymonth_cumulative)
plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/161:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)

print(bymonthdf)


#print(bymonth)
#print(bymonth_cumulative)
plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/162:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)

print(bymonthdf.groupby(level=1))


#print(bymonth)
#print(bymonth_cumulative)
plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/163:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)

print(bymonthdf.groupby(level=1).cumsum())


#print(bymonth)
#print(bymonth_cumulative)
plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
#bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/164:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)

bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()


#print(bymonth)
#print(bymonth_cumulative)
plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
bymonth_cumulative.plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/165:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)

bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()


#print(bymonth)
#print(bymonth_cumulative)
plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/166:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)

bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()


#print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/167:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)

bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()


#print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()
bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/168:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)

bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()


#print(bymonth)
print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/169:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)

bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()


#print(bymonth)
print(bymonth_cumulative.index)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/170:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative).sort(level=0)

bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()


#print(bymonth)
print(bymonth_cumulative.index)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)


#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/171:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

#print(bymonth)
print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

bymonth_cumulative.loc[bymonth_cumulative.]
#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/172:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

#print(bymonth)
print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/173:
grouper = data.loc['>=2019'].groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

#print(bymonth)
print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/174:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/175:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)

bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.loc[">2018"])
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/176:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth.sort_index()
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.loc[">2018"])
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/177:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')
#data['Trans Date'] = pd.to_datetime(data['Trans Date'])

def custom_nansum(val):
    return np.nansum(val)
376/178:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index('Trans Date',inplace=True)

#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
data.head()
376/179:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['Account Name'] = list(map(accountnumbers.get,data['Account']))
data['Trans Date']=pd.to_datetime(data['Trans Date'])


data.sort_values(['Trans Date','Account Name']).set_index(['Trans Date','Account Name'],inplace=True)
376/180: data.head()
376/181:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.loc[">2018"])
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/182:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['Account Name'] = list(map(accountnumbers.get,data['Account']))
data['Trans Date']=pd.to_datetime(data['Trans Date'])


data.sort_values(['Trans Date','Account Name'],inplace=True)
data.set_index(['Trans Date','Account Name'],inplace=True)
376/183:
data = pd.read_excel('2019-03-04-02-53-25FIN2075 - Revenue and Expenditure Schmidt UDOMSV,UDOMNP,UDOMTM .xlsx',
                    sheet=0,header=11,index='Trans Date')
#data['Trans Date'] = pd.to_datetime(data['Trans Date'])

def custom_nansum(val):
    return np.nansum(val)
376/184:
data = data[data['Transaction Description'] != 'Grant - Accrued Revenue']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Charge']
data = data[data['Transaction Description'] != 'Grant - Indirect Cost Recovery']
#tmp = data['Transaction Description'].str.contains('HR Payroll')
#tmp.fillna(False,inplace=True)
#data = data[~tmp]
# Gets rid of RVGS Activity code:
data = data[data['Activity'] == 'UDOMSV']

#data.set_index('Trans Date',inplace=True)

#data.set_index(['Account','Trans Date'],inplace=True)
#data.index[1]
data.head()
376/185:
accountnames = {'In State Travel': "710000",
                'Out of State Travel': "710100",
                'Foreign Travel':"710200",
                'Conf Registration': "710300",
                'Supplies General Gov': "711100",
                'Supplies Chem Lab':"711142",
                'Postage': "714010",
                'Non Cap Equip General': "715000",
                'Maint and Repairs': "716000",
                'Rentals': "716125",
                'Professional Services': "717200",
                'Telecom':"718000",
                'MembershipDues':"719100",
                'General Capital Equip': "740000",
                'Fab. Captial Equip': "740005",
                'Insurance': "71C600",
                'Internal Gen Supplies': "76O110",
                'Internal Rental': "76O16B",
                'Internal Prof Services': "76O170",
                'Student Labor': "61SNSH",
               'Work Study': "61SNWS"}

accountnumbers = {}
for k,v in accountnames.items():
    #print(k + ',' + v)
    accountnumbers[v]=k
    
#print(map(accountnumbers.get,data['Account']))

data['Account Name'] = list(map(accountnumbers.get,data['Account']))
data['Trans Date']=pd.to_datetime(data['Trans Date'])


data.sort_values(['Trans Date','Account Name'],inplace=True)
data.set_index(['Trans Date','Account Name'],inplace=True)
376/186: data.head()
376/187:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.loc[">2018"])
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/188:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.loc["2019":"2019"])
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/189:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("2019","2019",level=0)))
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/190:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("2019","2019"),level=0)))
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/191:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("2019","2019"),level=0))
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/192:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("2019","2019"),level=0).groupby(level=0).cumsum())
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/193:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("2019","2019"),level=0).groupby(level=1).cumsum())
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/194:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("2019","2019"),level=0).groupby('Account Name').cumsum())
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/195:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("2019","2019"),level=0))
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/196:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs("2019",level=0))
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/197:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs("2019",level=0))
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/198:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(">=2019",level=0))
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/199:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019",level=0))
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/200:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0))
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/201:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/202:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').cumsum())
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/203:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/204:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name')
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/205:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name'))
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/206:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0))
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/207:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0)groupby('Account Name').sum())
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/208:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/209:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0))
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/210:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())
print(bymonth)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/211:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

print(data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General '))

#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/212:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

print(data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General ')))

#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/213:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

print(data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General '),level=(0,'Account Name')))

#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/214:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

print(data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name')))

#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/215:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

print(data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))['Transation Amount'])

#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/216:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

print(data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))['Transaction Amount'])

#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/217:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

print(data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))['Transaction Amount','Transaction Description'])

#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/218:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

print(data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))['Transaction Amount','Transaction Description'])

#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/219:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

genequip = data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))['Transaction Amount','Transaction Description']


#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/220:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

genequip = data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))

#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/221:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

genequip = data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))
print(genequip)
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/222:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

genequip = data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))
print(genequip[['Transaction Amount','Transaction Description'])
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/223:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

genequip = data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))
print(genequip[['Transaction Amount','Transaction Description']]
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/224:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

genequip = data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))
print(genequip[['Transaction Amount','Transaction Description']])
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/225:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

genequip = data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name')genequip[['Transaction Amount','Transaction Description']].print()
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/226:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

genequip = data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name')
genequip[['Transaction Amount','Transaction Description']].print()
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/227:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

genequip = data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name')

print(genequip[['Transaction Amount','Transaction Description']])
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
376/228:
grouper = data.groupby([pd.Grouper(level=0,freq='M'),'Account Name'],sort=False)
bymonth = grouper['Transaction Amount'].apply(custom_nansum)
bymonth_cumulative = bymonth.groupby(level=1).cumsum()

#for x, y in bymonth.groupby(level=1):
#    print(x)
#    print(y)
#bymonth_cumulative = bymonth.sort_index(level=1)

bymonthdf = pd.DataFrame(bymonth_cumulative)


bymonth_cumulative=bymonthdf.groupby(level=1).cumsum()

print(bymonth.xs(slice("1-1-2019","4-1-2019"),level=0).groupby('Account Name').sum())

genequip = data.xs((slice("1-1-2019","4-1-2019"),'Non Cap Equip General'),level=(0,'Account Name'))

print(genequip[['Transaction Amount','Transaction Description']])
#print(bymonth_cumulative)
#plt.figure(figsize=(10,15))
#for x, y in bymonth_cumulative.groupby(level=1):
#    print(y['Trans Date'])
    #plt.plot(y['Trans Date'],y['Transaction Amount'])
#plt.show()
#bb = bymonth_cumulative.groupby(level=1)
#bb.head()

#bymonth_cumulative.groupby(level=1).plot(figsize=(15,10),grid=True,legend=True)

#grouper.head()

#plt.figure(figsize=(10,10))
#bymonth.plot()
378/1:
import geopandas
import geoplot
379/1:
import geopandas
import geoplot


aisfile = './AIS_ASCII_by_UTM_Month/2017/AIS_2017_05_Zone17.csv'
379/2: ais = geopandas.read_file(aisfile)
380/1:
import geopandas
import geoplot
import pandas

aisfile = './AIS_ASCII_by_UTM_Month/2017/AIS_2017_05_Zone17.csv'
380/2: ais = pandas.read_csv(aisfile)
380/3: ais.head()
380/4:
gdf = geopandas.GeoDataFrame(
    ais, geometry=geopandas.points_from_xy(ais.LON, ais.LAT))
380/5:
import geopandas
import geoplot
import pandas
import shapely

aisfile = './AIS_ASCII_by_UTM_Month/2017/AIS_2017_05_Zone17.csv'
382/1: ls
382/2: cd ~/gitsrc/kmall/
382/3: ls
382/4: run('./kmall.py','-f 0007_20190513_154724_ASVBEN.kmall')
382/5: run('kmall.py','-f 0007_20190513_154724_ASVBEN.kmall')
382/6: run?
382/7: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/8: import pandas as pd
382/9: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/10: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/11: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/12: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/13: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/14: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/15: import numpy as np
382/16: np.nan?
382/17: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/18: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/19: pktcnt = 0
382/20: msgsize = np.zeros((1,1000))+np.nan
382/21: print(msgsize[0:100])
382/22: msgsize[0] = 3
382/23: msgsize[pktcnt]
382/24: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/25: msgsize = np.empty((1000,1))
382/26: print(msgsize[0:100])
382/27: msgsize[0] = 3
382/28: print(msgsize[0:100])
382/29: print(msgsize[0:10])
382/30: msgsize[pktcnt]
382/31: msgoffset = np.full((1000,1),np.nan)
382/32: msgoffset[0:10]
382/33: msgoffset = np.full(1000,np.nan)
382/34: msgoffset[0:10]
382/35: msgoffset[0]=3
382/36: msgoffset[0:10]
382/37: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/38: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/39: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/40: np.full(1000,np.nan,dtype = np.int32)
382/41: msgoffset[0] = 3
382/42: msgsize[msgoffset[0]]
382/43: msgoffset[0]
382/44: msgsize[0]
382/45: msgsize[0:10]
382/46: msgoffset[0]
382/47:
msgoffset[0].dtype
()
382/48: int(msgoffset[0])
382/49: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/50: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/51: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/52: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/53: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/54: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/55: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/56: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/57: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/58: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/59: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/60: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/61: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/62: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/63: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/64: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/65: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/66: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/67: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/68: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/69: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/70: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/71: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/72: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/73: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/74: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/75: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/76: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/77: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/78: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/79: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/80: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/81: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/82: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/83: [np.array(np.nan),np.array(np.nan),np.array(np.nan),np.array(np.nan)]
382/84: a = [np.array(np.nan),np.array(np.nan),np.array(np.nan),np.array(np.nan)]
382/85: a.size
382/86: a.size()
382/87: a
382/88: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/89:
pd.DataFrame([[np.nan],[np.nan],[np.nan],[np.nan]],
                                  columns=["Time","ByteOffset","MessageSize","MessageType"])
382/90:
pd.DataFrame([[np.nan], [np.nan], [np.nan], [np.nan]],
                                  columns=["Time","ByteOffset","MessageSize","MessageType"])
382/91:
pd.DataFrame([[np.nan]; [np.nan]; [np.nan]; [np.nan]],
                                  columns=["Time","ByteOffset","MessageSize","MessageType"])
382/92:
pd.DataFrame([[np.nan],[np.nan],[np.nan],[np.nan]],
                                  columns=["Time","ByteOffset","MessageSize","MessageType"])
382/93: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/94: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/95: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/96: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/97: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/98: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/99: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/100: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/101: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/102: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/103: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/104: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/105: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -v
382/106: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/107: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/108: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/109: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/110: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/111: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/112: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/113: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/114: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/115: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
382/116: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall
383/1: a = {'a':3,'b':4}
383/2: print(a)
383/3:
for key, value in a.items():
    print(key value)
383/4:
for key, value in a.items():
    print(key)
383/5: import argparse
383/6: parser = argparse.ArgumentParser()
383/7: parser.add_argument?
383/8: crop = '0,10|100,101'
383/9: a = crop.split('|')
383/10: print(a)
383/11: LL,UR = crop.split('|')
383/12: LL
383/13: UR
383/14: import imageio
383/15: ls
383/16: cd admin/ccom/ccom-progressreports
383/17: ls
383/18: cd 2019
383/19: cd scratch
383/20: ls
383/21: tmp = imageio.imread('2019-05-07T19-14-08_screenshot.png')
383/22: tmp
383/23: tmp.size
383/24: tmp2 = tmp[10:100,11:101]
383/25: tmp2.shape
383/26: tmp.shape
383/27: import pil
383/28: import matplotlib as plt
383/29: import matplotlib.pyplot as plt
383/30: imgplot = plt.imshow(tmp2)
383/31: plt.show()
383/32: tmp2 = tmp[3010:30100,11:101]
383/33: imgplot = plt.imshow(tmp2)
383/34: plt.show()
384/1: a = 1:3
384/2: a=range(1,3)
384/3: a
384/4: print(a)
384/5: b = [1,2,3,4,5]
384/6: b[a]
384/7: import numpy
384/8: import numpy as np
384/9: a = np.arange(1,3)
384/10: a
384/11: b[a]
384/12: np.arange(1,2,type=int)
384/13: np.arange(1,2,dtype=int)
384/14: np.arange(1,3,dtype=int)
384/15: b[a]
384/16: a = np.array(np.arange(3))
384/17: a
384/18: b
384/19: b[a]
384/20: a
384/21: b
384/22: b[[0,1,2]]
384/23: b[np.array([0,1,2])]
384/24: b[np.array(int([0,1,2]))]
384/25: a
384/26: b
384/27: whos
384/28: import imageio
384/29: tmp = imageio.imread('2019-05-07T19-14-08_screenshot.png')
384/30: pwd
384/31: cd admin/ccom/ccom-progressreports/2019/scratch
384/32: tmp = imageio.imread('2019-05-07T19-14-08_screenshot.png')
384/33: tmp.shape
384/34: rows,cols,colors = tmp.shape
384/35: rows
384/36: a.len()
384/37: a.len
384/38: a
384/39: b
384/40: b.append(6)
384/41: b
384/42: b.len
384/43: b.len()
384/44: b.length()
384/45: b.length
384/46: b.length()
384/47: b.__len__()
384/48: tmp
384/49: tmp2 = tmp[3010:30100,11:101]
384/50: tmp2.shape
384/51: tmp.shape
384/52: nrows,ncols,ncolors = tmp2.shape
384/53: nrow
384/54: nrows
385/1: runfile('/Users/vschmidt/Box Sync/2019_OET_AE/data/NA113/scripts/handheldGPS_processor.py', wdir='/Users/vschmidt/Box Sync/2019_OET_AE/data/NA113/scripts')
385/2: runfile('/Users/vschmidt/Box Sync/2019_OET_AE/data/NA113/scripts/handheldGPS_processor.py', wdir='/Users/vschmidt/Box Sync/2019_OET_AE/data/NA113/scripts')
385/3: ls
385/4: import os
385/5: os.system('ls')
385/6: import exifread
385/7: from PIL import Image
385/8: from PIL.EXIFTags import TAGS
385/9: from PIL.ExifTags import TAGS
385/10:
for (k,v) in Image.open('../20190719/handheldGPS_GoPro/rover03/rawgopro/images/GOPR0379.JPG')._getexif().iteritems():
    print("%s = %s" % (TAGS.get(k), v))
385/11:
for (k,v) in Image.open('../20190719/handheldGPS_GoPro/rover03/rawgopro/images/GOPR0379.JPG')._getexif():
    print("%s = %s" % (TAGS.get(k), v))
385/12: a = Image.open('../20190719/handheldGPS_GoPro/rover03/rawgopro/images/GOPR0379.JPG')._getexif()
385/13: print(a)
385/14:
for (k,v) in a:
    print("%s = %s", % (k,v))
385/15:
for (k,v) in a:
    print("%s = %s" % (k,v))
385/16:
DATETOPROCESS="20190719"
ROVERTOPROCESS="rover03"  # One of rover01-rover06                              

HOMEDIR="/Users/vschmidt/BoxSync/2019_OET_AE/data/NA113"
RAWGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro/" 
               + ROVERTOPROCESS + "/rawgopro")
ROVER_DIR = HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro/" + ROVERTOPROCESS
BASE_DIR = HOMEDIR + "/" + DATETOPROCESS + "/GPSbasestation/"
RTKLIBCONFIG = HOMEDIR + "/scripts/ppk.conf"

EXIFTOOL = "/usr/local/bin/exiftool"
RNX2RTKP = "/usr/local/bin/rnx2rtkp"
385/17:
YYYYMMDD = os.system("`" + EXIFTOOL + "-CreateDate " + RAWGOPRO_DIR + "/images | sed 's/^.*2019/201\
9/' | sed 's/://g' | sed 's/ .*//' | head -2 | tail -1`")
385/18:
YYYYMMDD = os.system("`" + EXIFTOOL + " -CreateDate " + RAWGOPRO_DIR + "/images | sed 's/^.*2019/201\
9/' | sed 's/://g' | sed 's/ .*//' | head -2 | tail -1`")
385/19:
YYYYMMDD = os.system("" + EXIFTOOL + " -CreateDate " + RAWGOPRO_DIR + "/images | sed 's/^.*2019/201\
9/' | sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
385/20: YYYYMMDD
385/21: os.system?
385/22:
YYYYMMDD, status = os.system("" + EXIFTOOL + " -CreateDate " + RAWGOPRO_DIR + "/images | sed 's/^.*2019/201\
9/' | sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
385/23:
YYYYMMDD = subprocess.check_output(EXIFTOOL + " -CreateDate " + RAWGOPRO_DIR + "/images | sed 's/^.*2019/201\
9/' | sed 's/://g' | sed 's/ .*//' | head -2 | tail -1", shell=True)
385/24: import subprocess
385/25:
YYYYMMDD = subprocess.check_output(EXIFTOOL + " -CreateDate " + RAWGOPRO_DIR + "/images | sed 's/^.*2019/201\
9/' | sed 's/://g' | sed 's/ .*//' | head -2 | tail -1", shell=True)
385/26: YYYYMMDD
385/27: YYYYMMDD.chomp()
385/28:
process = subprocess.Popen(EXIFTOOL + " -CreateDate " + RAWGOPRO_DIR + "/images | sed 's/^.*2019/201\
9/' | sed 's/://g' | sed 's/ .*//' | head -2 | tail -1",stdout=PIPE, stderr=PIPE)
385/29: from subprocess import Popen, PIPE
385/30:
process = subprocess.Popen(EXIFTOOL + " -CreateDate " + RAWGOPRO_DIR + "/images | sed 's/^.*2019/201\
9/' | sed 's/://g' | sed 's/ .*//' | head -2 | tail -1",stdout=PIPE, stderr=PIPE)
385/31:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
385/32: print(cmd)
385/33: process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE)
385/34: os.system(RAWGOPRO_DIR)
385/35: os.system("ls " + RAWGOPRO_DIR)
385/36:
process = subprocess.Popen([EXIFTOOL, 
                            "-CreateDate", 
                            RAWGOPRO_DIR + "/images",
                            "| sed 's/^.*2019/2019/' ",
                            "| sed 's/://g' ",
                            "| sed 's/ .*//' ",
                            "| head -2 | tail -1"],stdout=PIPE, stderr=PIPE)
385/37: YYYYMMDD = process.communicate()
385/38: YYYYMMDD
385/39:
process = subprocess.Popen([EXIFTOOL, 
                            "-CreateDate", 
                            RAWGOPRO_DIR + "/images",
                            "| sed 's/^.*2019/2019/' ",
                            "| sed 's/://g' ",
                            "| sed 's/ .*//' ",
                            "| head -2 | tail -1"],stdout=PIPE, stderr=PIPE)
385/40:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
YYYYMMDD = os.system("`" + cmd + "`")
385/41:
process = subprocess.Popen([EXIFTOOL, 
                            "-CreateDate", 
                            RAWGOPRO_DIR + "/images",
                            "| sed 's/^.*2019/2019/' ",
                            "| sed 's/://g' ",
                            "| sed 's/ .*//' ",
                            "| head -2 | tail -1",stdout=PIPE, stderr=PIPE, shell=True)
                            
                            ]
385/42:
process = subprocess.Popen([EXIFTOOL, 
                            "-CreateDate", 
                            RAWGOPRO_DIR + "/images",
                            "| sed 's/^.*2019/2019/' ",
                            "| sed 's/://g' ",
                            "| sed 's/ .*//' ",
                            "| head -2 | tail -1"],stdout=PIPE, stderr=PIPE, shell=True)
385/43: YYYYMMDD = process.communicate()
385/44: YYYYMMDD
385/45:
process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD = processs.communicate()
385/46: cmd
385/47: process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
385/48: YYYYMMDD = process.communicate()
385/49: YYYYMMDD
385/50: (YYYYMMDD, err) = processs.communicate()
385/51: process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
385/52: (YYYYMMDD, err) = processs.communicate()
385/53: whos
385/54:
process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = processs.communicate()
385/55: process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)YYYYMMDD_result = processs.communicate()
385/56: process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
385/57: YYYYMMDD = process.communicate()
385/58: YYYYMMDD[0]
385/59: YYYYMMDD[0].decode('UTF-8')
385/60: YYYYMMDD[0].decode('UTF-8').chomp()
385/61: a = YYYYMMDD[0].decode('UTF-8')
385/62: a.rstrip()
385/63:
cmd = (EXIFTOOL + 
       " -T -c +0.8f -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images > " + IMAGE_METADATA)
385/64:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = processs.communicate()
YYYYMMDD = YYYYMMDD_result[0].decode('UTF-8').rstrip()

# Create file name for EXIF data.                                               
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.txt"

'''
Use exif tool to extract metadata from the images. [Image file name, and tim\
e, minimum.]                                                                    
'''
cmd = (EXIFTOOL + 
       " -T -c +0.8f -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images > " + IMAGE_METADATA)
385/65:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = processs.communicate()[0].decode('UTF-8').rstrip()

# Create file name for EXIF data.                                               
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.txt"

'''
Use exif tool to extract metadata from the images. [Image file name, and tim\
e, minimum.]                                                                    
'''
cmd = (EXIFTOOL + 
       " -T -c +0.8f -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images > " + IMAGE_METADATA)
385/66: whos
385/67: process.communicate()
385/68:
process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = process.communicate()[0].decode('UTF-8').rstrip()

# Create file name for EXIF data.                                               
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.txt"

'''
Use exif tool to extract metadata from the images. [Image file name, and tim\
e, minimum.]                                                                    
'''
cmd = (EXIFTOOL + 
       " -T -c +0.8f -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images > " + IMAGE_METADATA)
385/69:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = process.communicate()
YYYYMMDD = YYYYMMDD_result.decode('UTF-8').rstrip()

# Create file name for EXIF data.                                               
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.txt"

'''
Use exif tool to extract metadata from the images. [Image file name, and tim\
e, minimum.]                                                                    
'''
cmd = (EXIFTOOL + 
       " -T -c +0.8f -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images > " + IMAGE_METADATA)
385/70:
YYYYMMDD = YYYYMMDD_result[0].decode('UTF-8').rstrip()

# Create file name for EXIF data.                                               
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.txt"

'''
Use exif tool to extract metadata from the images. [Image file name, and tim\
e, minimum.]                                                                    
'''
cmd = (EXIFTOOL + 
       " -T -c +0.8f -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images > " + IMAGE_METADATA)
385/71: cmd
385/72: process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stout=PIPE)
385/73: process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
385/74: process.communicate()
385/75: pwd
385/76: ls
385/77: v = os.listdir('.')
385/78: v
385/79: v[0][-3:]
385/80:
ROVERFILE = None
ROVERNAVFILE = None
BASESTATIONFILE = None

# Get the file names for Rover, Base and output.   
for f in os.listdir(ROVER_DIR + "/rawgps/"):
    if f[-3:] == "obs":
        ROVERFILE = ROVER_DIR + "/rawgps/" + f
    if f[-3:] == "nav":
        ROVERNAVFILE = ROVER_DIR + "/rawgps/" + f

# Look for CORS .o or .obs file           
for f in os.listdir(BASE_DIR):
    if f[-1:] == "o" or f[-3:] == "obs":
        BASESTATIONFILE = BASE_DIR + '/' + f

OUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" ROVERTOPROCESS + "_ppk.txt")

if ROVERFILE is None or ROVERNAVFILE is None or BASESTATIONFILE is None:
    print("ERROR: Missing data files.")
    sys.exit(1)

cmd= (RNX2RTKP + " -x 3 -k " + RTKLIBCONFIG +
      " " + ROVERFILE + 
      " " + BASESTATIONFILE + 
      " " + ROVERNAVFILE + 
      "-o" OUTPUTFILE)

print("Processing: %s" % cmd)
385/81:
OUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" + ROVERTOPROCESS + "_ppk.txt")
385/82: whos
385/83:
if ROVERFILE is None or ROVERNAVFILE is None or BASESTATIONFILE is None:
    print("ERROR: Missing data files.")
    sys.exit(1)

cmd= (RNX2RTKP + " -x 3 -k " + RTKLIBCONFIG +
      " " + ROVERFILE + 
      " " + BASESTATIONFILE + 
      " " + ROVERNAVFILE + 
      "-o" OUTPUTFILE)
385/84:
cmd= (RNX2RTKP + " -x 3 -k " + RTKLIBCONFIG +
      " " + ROVERFILE + 
      " " + BASESTATIONFILE + 
      " " + ROVERNAVFILE + 
      "-o" + OUTPUTFILE)
385/85: ROVERFILE
385/86:
ROVERFILE = None
ROVERNAVFILE = None
BASESTATIONFILE = None

# Get the file names for Rover, Base and output.   
for f in os.listdir(ROVER_DIR + "/rawgps/"):
    if f[-3:] == "obs":
        ROVERFILE = ROVER_DIR + "/rawgps/" + f
    if f[-3:] == "nav":
        ROVERNAVFILE = ROVER_DIR + "/rawgps/" + f

# Look for CORS .o or .obs file           
for f in os.listdir(BASE_DIR):
    if f[-1:] == "o" or f[-3:] == "obs":
        BASESTATIONFILE = BASE_DIR + '/' + f

OUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" + ROVERTOPROCESS + "_ppk.txt")
385/87: ROVERFILE
385/88: ROVERNAVFILE
385/89: BASESTATIONFILE
385/90:
if ROVERFILE is None or ROVERNAVFILE is None or BASESTATIONFILE is None:
    print("ERROR: Missing data files.")
    sys.exit(1)
385/91:
cmd= (RNX2RTKP + " -x 3 -k " + RTKLIBCONFIG +
      " " + ROVERFILE + 
      " " + BASESTATIONFILE + 
      " " + ROVERNAVFILE + 
      "-o" + OUTPUTFILE)
385/92: print(cmd)
385/93:
print("Processing: %s" % cmd)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
process.wait()
385/94: process.communicate()
385/95: BASE_DIR = HOMEDIR + "/" + DATETOPROCESS + "/GPSbasestation"
385/96:
# Look for CORS .o or .obs file           
for f in os.listdir(BASE_DIR):
    if f[-1:] == "o" or f[-3:] == "obs":
        BASESTATIONFILE = BASE_DIR + '/' + f
385/97:
cmd= (RNX2RTKP + " -x 3 -k " + RTKLIBCONFIG +
      " " + ROVERFILE + 
      " " + BASESTATIONFILE + 
      " " + ROVERNAVFILE + 
      " -o" + OUTPUTFILE)
385/98: print(cmd)
385/99:
cmd= (RNX2RTKP + " -x 3 -k " + RTKLIBCONFIG +
      " " + ROVERFILE + 
      " " + BASESTATIONFILE + 
      " " + ROVERNAVFILE + 
      " -o " + OUTPUTFILE)
385/100: print(cmd)
385/101:
print("Processing: %s" % cmd)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
while True:
    output = process.stdout.readline().decode('UTF-8')
    if output == ' ' and process.poll is not None:
        break
    if output:
        print output.strip()
rc = process.poll()
385/102:
print("Processing: %s" % cmd)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
while True:
    output = process.stdout.readline().decode('UTF-8')
    if output == ' ' and process.poll is not None:
        break
    if output:
        print(output.strip())
rc = process.poll()
385/103:
print("Processing: %s" % cmd)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
while True:
    output = process.stdout.readline().decode('UTF-8')
    if output == ' ' and process.poll() is not None:
        break
    if output:
        print(output.strip())
rc = process.poll()
385/104:
print("Processing: %s" % cmd)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
while True:
    output = process.stdout.readline().decode('UTF-8')
    if output == '' and process.poll() is not None:
        break
    if output:
        print(output.strip())
rc = process.poll()
385/105: process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
385/106: process.wait()
385/107: cmd
385/108: process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
385/109: print(process.communicate())
385/110:

process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE,
                           universal_newlines=True)
while True:
    output = process.stdout.readline().decode('UTF-8')
    if output == '' and process.poll() is not None:
        break
    if output:
        print(output.strip())
rc = process.poll()
385/111: process.stdout.newlines?
385/112:
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE,
                           universal_newlines=True,
                           text=True)
while True:
    output = process.stdout.readline()
    if output == '' and process.poll() is not None:
        break
    if output:
        print(output.strip())
rc = process.poll()
385/113:
print("Processing: %s" % cmd)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE,
                           universal_newlines=True,
                           encode='UTF-8')
while True:
    output = process.stdout.read(1024)
    if output == '' and process.poll() is not None:
        break
    if output:
        print(output.strip())
rc = process.poll()
385/114:
print("Processing: %s" % cmd)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE,
                           universal_newlines=True)
while True:
    output = process.stdout.read(1024)
    if output == '' and process.poll() is not None:
        break
    if output:
        print(output.strip())
rc = process.poll()
385/115:
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE,
                           universal_newlines=True)
while True:
    print("Here")
    output = process.stdout.read(1024)
    if output == '' and process.poll() is not None:
        break
    if output:
        print(output.strip())
rc = process.poll()
385/116:
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE,
                           universal_newlines=True)
385/117: process.stdout.encoding
385/118: process.stdout.readable()
385/119: process.stdout.read(1)
385/120: process.stderr.read(1)
385/121: process.stderr.readline(1)
385/122: process.stderr.readline(1)
385/123: process.stderr.readline(1)
385/124: process.stderr.read(1)
385/125: process.stderr.read(1)
385/126: process.stderr.readline()
385/127: process.poll()
385/128: process.wait()
385/129:
EXIFOUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" + ROVERTOPROCESS + "_ppk.txt")
385/130: import pandas as pd
385/131: data = pd.read?
385/132: data = pd.read_csv(EXIFOUTPUTFILE)
385/133:
DATETOPROCESS="20190721"
ROVERTOPROCESS="rover03"  # One of rover01-rover06                              

HOMEDIR="/Users/vschmidt/BoxSync/2019_OET_AE/data/NA113"
RAWGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + ROVERTOPROCESS + "/rawgopro")
ROVER_DIR = HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro/" + ROVERTOPROCESS
BASE_DIR = HOMEDIR + "/" + DATETOPROCESS + "/GPSbasestation"
RTKLIBCONFIG = HOMEDIR + "/scripts/ppk.conf"

EXIFTOOL = "/usr/local/bin/exiftool"
RNX2RTKP = "/usr/local/bin/rnx2rtkp"
385/134:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = process.communicate()
YYYYMMDD = YYYYMMDD_result[0].decode('UTF-8').rstrip()

# Create file name for EXIF data.                                               
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.txt"

'''
Use exif tool to extract metadata from the images. [Image file name, and tim\
e, minimum.]                                                                    
'''
cmd = (EXIFTOOL + 
       " -T -c %0.8f -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images > " + IMAGE_METADATA)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
385/135: process.communicate()
385/136: cmd
385/137:
HOMEDIR="/Users/vschmidt/BoxSync/2019_OET_AE/data/NA113"
RAWGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/rawgopro")
ROVER_DIR = HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro/" + ROVERTOPROCESS
BASE_DIR = HOMEDIR + "/" + DATETOPROCESS + "/GPSbasestation"
RTKLIBCONFIG = HOMEDIR + "/scripts/ppk.conf"

EXIFTOOL = "/usr/local/bin/exiftool"
RNX2RTKP = "/usr/local/bin/rnx2rtkp"
385/138:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = process.communicate()
YYYYMMDD = YYYYMMDD_result[0].decode('UTF-8').rstrip()

# Create file name for EXIF data.                                               
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.txt"
385/139: IMAGE_METADATA
385/140:
cmd = (EXIFTOOL + 
       " -T -c %0.8f -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images > " + IMAGE_METADATA)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
385/141:
ROVERFILE = None
ROVERNAVFILE = None
BASESTATIONFILE = None

# Get the file names for Rover, Base and output.   
for f in os.listdir(ROVER_DIR + "/rawgps/"):
    if f[-3:] == "obs":
        ROVERFILE = ROVER_DIR + "/rawgps/" + f
    if f[-3:] == "nav":
        ROVERNAVFILE = ROVER_DIR + "/rawgps/" + f

# Look for CORS .o or .obs file           
for f in os.listdir(BASE_DIR):
    if f[-1:] == "o" or f[-3:] == "obs":
        BASESTATIONFILE = BASE_DIR + '/' + f

EXIFOUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" + ROVERTOPROCESS + "_ppk.txt")

if ROVERFILE is None or ROVERNAVFILE is None or BASESTATIONFILE is None:
    print("ERROR: Missing data files.")
    sys.exit(1)

cmd= (RNX2RTKP + " -x 3 -k " + RTKLIBCONFIG +
      " " + ROVERFILE + 
      " " + BASESTATIONFILE + 
      " " + ROVERNAVFILE + 
      " -o " + EXIFOUTPUTFILE)
385/142: cmd
385/143:
print("Processing: %s" % cmd)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE,
                           universal_newlines=True)
while True:
    output = process.stderr.readline()
    if output == '' and process.poll() is not None:
        break
    if output:
        print(output.strip())
385/144:
cmd = (EXIFTOOL + 
       " -T -c %0.8f -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort > " + IMAGE_METADATA)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
385/145: pwd
385/146:     d = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/rawgopro/NA113_20190721_RAW_IMAGE_METADATA.txt',delimter='\s+')
385/147:     d = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/rawgopro/NA113_20190721_RAW_IMAGE_METADATA.txt',delimiter='\s+')
385/148:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort > " + IMAGE_METADATA)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
385/149:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort > " + IMAGE_METADATA)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
385/150: data = pd.read_csv(EXIFOUTPUTFILE)
385/151:     d = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/rawgopro/NA113_20190721_RAW_IMAGE_METADATA.txt',delimiter='\s+')
385/152: d.head()
385/153: d
385/154:     d = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/rawgopro/NA113_20190721_RAW_IMAGE_METADATA.txt',delimiter='\s+',parsedates=True,index_col=1)
385/155:     d = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/rawgopro/NA113_20190721_RAW_IMAGE_METADATA.txt',delimiter='\s+',parse_dates=True,index_col=1)
385/156: d
385/157: d.head()
385/158:     d = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/rawgopro/NA113_20190721_RAW_IMAGE_METADATA.txt',delimiter='\s+',parse_dates=True,index_col=1,header=None)
385/159: d.head()
385/160: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt')
385/161: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+')
385/162: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+',comment='%')
385/163: rovernav
385/164: rovernav.head()
385/165: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+',comment='%',parse_dates=True,index_col=[0 1])
385/166: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+',comment='%',parse_dates=True)
385/167: rovernav.head()
385/168: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+',comment='%',parse_dates=[0 1])
385/169: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+',comment='%',parse_dates=[0,1])
385/170: rovernav.head()
385/171: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+',comment='%',parse_dates=[0,1],header=None)
385/172: rovernav.head()
385/173: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+',comment='%',parse_dates=[0,1],header=None,index_col=0)
385/174: rovernav.head()
385/175: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+',comment='%',parse_dates=[0,1],header=None)
385/176: rovernav.head()
385/177: rovernav.index = 0
385/178: rovernav.index(0)
385/179: rovernav.set_index=0
385/180: rovernav.head()
385/181: rovernav.set_index?
385/182: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+',comment='%',parse_dates=[0,1],header=None)
385/183: rovernav.head()
385/184: rovernav.set_index?
385/185: rovernav.head()
385/186: rovernav.set_index('0')
385/187: rovernav.set_index(0,inplace=True)
385/188: rovernav.head()
385/189: rovernav[1]
385/190: rovernav[2]
385/191: rovernav[1]
385/192: rovernav = pd.read_csv('../20190721/handheldGPS_GoPro/rover03/processedgps/NA113_20190721_rover03_ppk.txt',delimiter='\s+',comment='%',parse_dates=[0,1],header=None)
385/193: rovernav.head()
385/194: rovernav[0]
385/195: rovernav[1]
385/196: rovernav.set_index(1,inplace=True)
385/197: rovernav.head()
385/198: rovernav[2]
385/199: d
385/200: d.columns?
385/201: d
385/202: d.columns=['Filename','Lat','Lon']
385/203: d.head()
385/204: rovernav.head()
385/205:
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']
rovernav.head()
385/206: import numpy as np
385/207: np.interpolate?
385/208: np.interp?
385/209: whos
385/210: d
385/211: d.index.to_flat_index
385/212: d.index.to_numpy()
385/213: d.index.to_julian_date()
385/214: np.interp?
385/215: d
385/216: newd = d
385/217: d.head()
385/218: rovernav
385/219: rovernav.head()
385/220: rovernav['sde(m)']
385/221: rovernav['height']
385/222: rovernav['sdu(m)']
385/223: d
385/224: exifdata = d
385/225: import scipy as sci
385/226:
newexifdata = exifdata
newexifdata.PPKLat = sci.interp1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav.lat,
                                  kind='linear')
newexifdata.PPKLon = sci.interp1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav.lon,
                                  kind='linear')
newexifdata.PPKheight_m = sci.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['height'],
                                  kind='linear')
newexifdata.PPKsde_m = sci.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['sde(m)'],
                                  kind='linear')
newexifdata.PPKsdn_m = sci.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['sdn(m)'],
                                  kind='linear')
newexifdata.PPKsdheight_m = sci.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['sdu(m)'],
                                  kind='linear')
385/227:
newexifdata = exifdata
newexifdata.PPKLat = sci.interpolate.interp1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav.lat,
                                  kind='linear')
newexifdata.PPKLon = sci.interpolate.interp1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav.lon,
                                  kind='linear')
newexifdata.PPKheight_m = sci.interpolate.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['height'],
                                  kind='linear')
newexifdata.PPKsde_m = sci.interpolate.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['sde(m)'],
                                  kind='linear')
newexifdata.PPKsdn_m = sci.interpolate.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['sdn(m)'],
                                  kind='linear')
newexifdata.PPKsdheight_m = sci.interpolate.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['sdu(m)'],
                                  kind='linear')
385/228: sci.interp?
385/229: import scipy.interpolate as I
385/230:
newexifdata = exifdata
newexifdata.PPKLat = I.interp1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav.lat,
                                  kind='linear')
newexifdata.PPKLon = I.interp1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav.lon,
                                  kind='linear')
newexifdata.PPKheight_m = I.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['height'],
                                  kind='linear')
newexifdata.PPKsde_m = I.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['sde(m)'],
                                  kind='linear')
newexifdata.PPKsdn_m = I.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['sdn(m)'],
                                  kind='linear')
newexifdata.PPKsdheight_m = I.inter1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav['sdu(m)'],
                                  kind='linear')
385/231:
newexifdata.PPKLat = I.interp1d(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav.lat,
                                  kind='linear')
385/232:
newexifdata.PPKLat = np.interp(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav.lat)
385/233:
newexifdata.PPKLat = np.interp(exifdata.index.to_numpy,
                                  rovernav.index.to_numpy,
                                  rovernav.lat)
385/234:
newexifdata.PPKLat = np.interp(exifdata.index.to_julian_date,
                                  rovernav.index.to_julian_date,
                                  rovernav.lat)
385/235: exifdata.index.to_julian_date
385/236: exifdata.index.to_julian_date()
385/237:
newexifdata.PPKLat = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
385/238: newexifdata
385/239:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_numpy()),
                                  rovernav.index.to_numpy(),
                                  rovernav.lat)



(
385/240:

newexifdata['PPKLat'] = np.interp(exifdata.index.to_numpy(),
                                  rovernav.index.to_numpy(),
                                  rovernav.lat)
385/241: exifdata.index.to_julian_date
385/242:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
385/243: newexifdata.plot(y=['Lat','PPKLat'])
385/244: newexifdata.plot(y=['Lat'])
385/245: import matplotlib.pyplot as plt
385/246: plt.figure()
385/247: plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
385/248: plt.plot(exifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
385/249: p = plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
385/250: plt.hold()
385/251: plt.plot(exifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
385/252: newexifdata.plot()
385/253: newexifdata.head()
385/254: plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
385/255: hold on
385/256: hold(True)
386/1:
import os
import sys
import datetime
import numpy as np
import pandas as pd
import subprocess import Popen, PIPE
import scipy.interpolate as I
386/2:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
386/3:
DATETOPROCESS="20190721"
ROVERTOPROCESS="rover03"  # One of rover01-rover06                              

HOMEDIR="/Users/vschmidt/BoxSync/2019_OET_AE/data/NA113"
RAWGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/rawgopro")
ROVER_DIR = HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro/" + ROVERTOPROCESS
BASE_DIR = HOMEDIR + "/" + DATETOPROCESS + "/GPSbasestation"
RTKLIBCONFIG = HOMEDIR + "/scripts/ppk.conf"

EXIFTOOL = "/usr/local/bin/exiftool"
RNX2RTKP = "/usr/local/bin/rnx2rtkp"
386/4:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = subprocess.Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = process.communicate()
YYYYMMDD = YYYYMMDD_result[0].decode('UTF-8').rstrip()
386/5:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = process.communicate()
YYYYMMDD = YYYYMMDD_result[0].decode('UTF-8').rstrip()
386/6: IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.txt"
386/7:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort > " + IMAGE_METADATA)
process = subprocess.Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/8:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -CreateDate -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort > " + IMAGE_METADATA)
process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/9:
ROVERFILE = None
ROVERNAVFILE = None
BASESTATIONFILE = None

# Get the file names for Rover obs, nav, Base and output.   
for f in os.listdir(ROVER_DIR + "/rawgps/"):
    if f[-3:] == "obs":
        ROVERFILE = ROVER_DIR + "/rawgps/" + f
    if f[-3:] == "nav":
        ROVERNAVFILE = ROVER_DIR + "/rawgps/" + f
        
# Look for CORS .o or .obs file           
for f in os.listdir(BASE_DIR):
    if f[-1:] == "o" or f[-3:] == "obs":
        BASESTATIONFILE = BASE_DIR + '/' + f

ROVERPPKOUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" + ROVERTOPROCESS + "_ppk.txt")
386/10:
exifdata = pd.read_csv(EXIFOUTPUTFILE,delimiter='\s+',
                       parse_dates=True,index_col=1,header=None)
exifdata.columns=['Filename','Lat','Lon']

# Load new navigagtion
rovernav = pd.read_csv(ROVERPPKOUTPUTFILE,delimiter='\s+',
                       comment='%',parse_dates=[0,1],header=None)
rovernav.set_index(1,inplace=True)
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']

newexifdata = exifdata
386/11:
# Load exif data and parse timestamps (use pandas)
exifdata = pd.read_csv(IMAGE_METADATA,delimiter='\s+',
                       parse_dates=True,index_col=1,header=None)
exifdata.columns=['Filename','Lat','Lon']

# Load new navigagtion
rovernav = pd.read_csv(ROVERPPKOUTPUTFILE,delimiter='\s+',
                       comment='%',parse_dates=[0,1],header=None)
rovernav.set_index(1,inplace=True)
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']

newexifdata = exifdata
386/12:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
386/13:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
import matplotlib.pyplot as plt
386/14:
plt.figure(7,5)
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
386/15:
plt.figure(size=(7,5)
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
386/16:
plt.figure(size=(7,5))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
386/17: plt.figure?
386/18:
plt.figure(figsize=(7,5))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
386/19:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort > " + IMAGE_METADATA)
process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/20:
# Load exif data and parse timestamps (use pandas)
exifdata = pd.read_csv(IMAGE_METADATA,delimiter='\s+',
                       parse_dates=True,index_col=1,header=None)
exifdata.columns=['Filename','Lat','Lon']

# Load new navigagtion
rovernav = pd.read_csv(ROVERPPKOUTPUTFILE,delimiter='\s+',
                       comment='%',parse_dates=[0,1],header=None)
rovernav.set_index(1,inplace=True)
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']

newexifdata = exifdata
386/21:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
386/22:
plt.figure(figsize=(7,5))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
386/23:
# Load exif data and parse timestamps (use pandas)
exifdata = pd.read_csv(IMAGE_METADATA,delimiter='\s+',
                       parse_dates=True,index_col=1,header=None)
exifdata.columns=['Filename','Lat','Lon']

# Load new navigagtion
rovernav = pd.read_csv(ROVERPPKOUTPUTFILE,delimiter='\s+',
                       comment='%',parse_dates=[0,1],header=None)
rovernav.set_index(1,inplace=True)
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']

newexifdata = exifdata
386/24:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
386/25: exifdata.head()
386/26:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + IMAGE_METADATA)
process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/27:
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA_WITHGPS.txt"
BADIMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.WITHOUTGPS.txt"
386/28:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/29:
ROVERFILE = None
ROVERNAVFILE = None
BASESTATIONFILE = None

# Get the file names for Rover obs, nav, Base and output.   
for f in os.listdir(ROVER_DIR + "/rawgps/"):
    if f[-3:] == "obs":
        ROVERFILE = ROVER_DIR + "/rawgps/" + f
    if f[-3:] == "nav":
        ROVERNAVFILE = ROVER_DIR + "/rawgps/" + f
        
# Look for CORS .o or .obs file           
for f in os.listdir(BASE_DIR):
    if f[-1:] == "o" or f[-3:] == "obs":
        BASESTATIONFILE = BASE_DIR + '/' + f

ROVERPPKOUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" + ROVERTOPROCESS + "_ppk.txt")
386/30:
# Load exif data and parse timestamps (use pandas)
exifdata = pd.read_csv(IMAGE_METADATA,delimiter='\s+',
                       parse_dates=True,index_col=1,header=None)
exifdata.columns=['Filename','Lat','Lon']

# Load new navigagtion
rovernav = pd.read_csv(ROVERPPKOUTPUTFILE,delimiter='\s+',
                       comment='%',parse_dates=[0,1],header=None)
rovernav.set_index(1,inplace=True)
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']

newexifdata = exifdata
386/31: exifdata.head()
386/32:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
386/33:
plt.figure(figsize=(7,5))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
386/34:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
newexifdata['PPKLon'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lon)
newexifdata['PPKheight'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['height'])
newexifdata['PPKsde_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sde(m)'])
newexifdata['PPKsdn_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sdn(m)'])
newexifdata['PPKsdu_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sdu(m)'])
386/35:
plt.figure(figsize=(9,5))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
386/36:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
import matplotlib.pyplot as plt
%matplotlib notebook
386/37:
DATETOPROCESS="20190721"
ROVERTOPROCESS="rover03"  # One of rover01-rover06                              

HOMEDIR="/Users/vschmidt/BoxSync/2019_OET_AE/data/NA113"
RAWGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/rawgopro")
ROVER_DIR = HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro/" + ROVERTOPROCESS
BASE_DIR = HOMEDIR + "/" + DATETOPROCESS + "/GPSbasestation"
RTKLIBCONFIG = HOMEDIR + "/scripts/ppk.conf"

EXIFTOOL = "/usr/local/bin/exiftool"
RNX2RTKP = "/usr/local/bin/rnx2rtkp"
386/38:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = process.communicate()
YYYYMMDD = YYYYMMDD_result[0].decode('UTF-8').rstrip()
386/39:
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA_WITHGPS.txt"
BADIMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.WITHOUTGPS.txt"
386/40:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/41:
ROVERFILE = None
ROVERNAVFILE = None
BASESTATIONFILE = None

# Get the file names for Rover obs, nav, Base and output.   
for f in os.listdir(ROVER_DIR + "/rawgps/"):
    if f[-3:] == "obs":
        ROVERFILE = ROVER_DIR + "/rawgps/" + f
    if f[-3:] == "nav":
        ROVERNAVFILE = ROVER_DIR + "/rawgps/" + f
        
# Look for CORS .o or .obs file           
for f in os.listdir(BASE_DIR):
    if f[-1:] == "o" or f[-3:] == "obs":
        BASESTATIONFILE = BASE_DIR + '/' + f

ROVERPPKOUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" + ROVERTOPROCESS + "_ppk.txt")
386/42:
# Load exif data and parse timestamps (use pandas)
exifdata = pd.read_csv(IMAGE_METADATA,delimiter='\s+',
                       parse_dates=True,index_col=1,header=None)
exifdata.columns=['Filename','Lat','Lon']

# Load new navigagtion
rovernav = pd.read_csv(ROVERPPKOUTPUTFILE,delimiter='\s+',
                       comment='%',parse_dates=[0,1],header=None)
rovernav.set_index(1,inplace=True)
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']

newexifdata = exifdata
386/43: exifdata.head()
386/44:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
newexifdata['PPKLon'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lon)
newexifdata['PPKheight'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['height'])
newexifdata['PPKsde_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sde(m)'])
newexifdata['PPKsdn_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sdn(m)'])
newexifdata['PPKsdu_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sdu(m)'])
386/45:
plt.figure(figsize=(9,5))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
386/46:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
386/47:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
386/48:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
386/49:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
plt.ylabel('Latitude')

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
386/50:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
plt.ylabel('Latitude')

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')

plt.figure(figsize=(9,9))
plt.plot(rovernav.lon,rovernav.lat)
plt.plot(newexifdata.PPKLon,newexifdata.PPKLat,'o')
plt.grid(True)
386/51:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
plt.ylabel('Latitude')

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
386/52:
plt.figure(figsize=(7,7))
plt.plot(rovernav.lon,rovernav.lat)
plt.plot(newexifdata.PPKLon,newexifdata.PPKLat,'o')
plt.grid(True)
386/53:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
import matplotlib.pyplot as plt
%matplotlib notebook

from pyproj import *
from mpl_toolkits import Basemap

WGS84 = Proj(init='EPSG:4326')\n",
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84"
               + " +datum=WGS84 +units=m +no_defs")
386/54:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
import matplotlib.pyplot as plt
%matplotlib notebook

from pyproj import *
from mpl_toolkits import Basemap

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84"
               + " +datum=WGS84 +units=m +no_defs")
386/55:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
import matplotlib.pyplot as plt
%matplotlib notebook

from pyproj import *
from mpl_toolkits.basemap import Basemap

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84"
               + " +datum=WGS84 +units=m +no_defs")
386/56:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
import matplotlib.pyplot as plt
%matplotlib notebook

from pyproj import *
from mpl_toolkits.basemap import Basemap

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84"
               + " +datum=WGS84 +units=m +no_defs")
386/57:
DATETOPROCESS="20190721"
ROVERTOPROCESS="rover03"  # One of rover01-rover06                              

HOMEDIR="/Users/vschmidt/BoxSync/2019_OET_AE/data/NA113"
RAWGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/rawgopro")
PPKGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/processedgopro")


ROVER_DIR = HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro/" + ROVERTOPROCESS
BASE_DIR = HOMEDIR + "/" + DATETOPROCESS + "/GPSbasestation"
RTKLIBCONFIG = HOMEDIR + "/scripts/ppk.conf"

EXIFTOOL = "/usr/local/bin/exiftool"
RNX2RTKP = "/usr/local/bin/rnx2rtkp"
386/58:
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA_WITHGPS.txt"
BADIMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.WITHOUTGPS.txt"
IMAGE_METADATA_W_PPK = PPKGOPRO_DIR + "/NA113_" + YYYYMMDD + "_PPK_IMAGE_METADATA.txt"
386/59: newexifdata.to_csv(IMAGE_METADATA_W_PPK)
386/60: newexifdata.to_csv?
386/61: newexifdata.to_csv(IMAGE_METADATA_W_PPK,sep='\t',float_format='%0.9f')
386/62: newexifdata.head()
386/63:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude" + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/64:
cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude" + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)

cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/65:
cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude" + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
print(process.communicate[0])

cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/66:
cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude" + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
print(process.communicate()[0])

cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/67:
cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude" + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
print(process.communicate()[1])

cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/68:
cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
print(process.communicate()[1])

cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/69:
cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort  > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
print(process.communicate()[1])

cmd = (EXIFTOOL + 
       " -n -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/70:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort  > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
print(process.communicate()[1])

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/71:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
print(process.communicate()[1])

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/72:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | /grep T | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
print(process.communicate()[1])

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/73:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
print(process.communicate()[1])

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/74:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
err = process.communicate()[1]
if err is not '':
    print(err)

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
err = process.communicate()[1]
if err is not '':
    print(err)
386/75:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
err = process.communicate()[1].decode()
if err is not '':
    print(err)

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
err = process.communicate()[1].deocde()
if err is not '':
    print(err)
386/76:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
err = process.communicate()[1].decode('UTF-8')
if err is not '':
    print(err)

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
err = process.communicate()[1].deocde()
if err is not '':
    print(err)
386/77:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
err = process.communicate()[1].decode('UTF-8')
if err is not '':
    print(err)

cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
err = process.communicate()[1].deocde('UTF-8')
if err is not '':
    print(err)
386/78:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)


cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
386/79:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
plt.ylabel('Latitude')
plt.grid(True)

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')
plt.grid(True)


plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
plt.grid(True)
386/80:
plt.figure(figsize=(8, 8))
m = Basemap(projection='ortho', resolution=None, 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution='f')
m.bluemarble(scale=0.5);
386/81:
plt.figure(figsize=(8, 8))
m = Basemap(projection='ortho', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution='f')
m.bluemarble(scale=0.5);
386/82:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
import matplotlib.pyplot as plt
%matplotlib notebook

from pyproj import *
from mpl_toolkits.basemap import Basemap

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84"
               + " +datum=WGS84 +units=m +no_defs")
386/83:
plt.figure(figsize=(8, 8))
m = Basemap(projection='ortho', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution='f')
m.bluemarble(scale=0.5);
386/84:
plt.figure(figsize=(8, 8))
m = Basemap(projection='ortho', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution=None)
m.bluemarble(scale=0.5);
386/85:
plt.figure(figsize=(8, 8))
m = Basemap(projection='merc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution=None)
m.bluemarble(scale=0.5);
386/86:
plt.figure(figsize=(8, 8))
m = Basemap(projection='cyl', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution=None)
m.bluemarble(scale=0.5);
386/87:
plt.figure(figsize=(8, 8))
m = Basemap(projection='lcc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution=None)
m.bluemarble(scale=0.5);
386/88:
plt.figure(figsize=(8, 8))
m = Basemap(projection='lcc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution=None)
m.etopo(scale=20);
386/89:
plt.figure(figsize=(8, 8))
m = Basemap(projection='lcc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution=None)
#m.etopo(scale=0)
m.bluemarble(scale=10)
386/90: newexifdata.to_csv(IMAGE_METADATA_W_PPK,sep='\t',float_format='%0.9f')
386/91:
plt.figure(figsize=(8, 8))
m = Basemap(projection='lcc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution=None)
#m.etopo(scale=0)
m.bluemarble(scale=1)
386/92:
plt.figure(figsize=(8, 8))
m = Basemap(projection='ortho', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution=None)
#m.etopo(scale=0)
m.bluemarble(scale=1)
386/93:
plt.figure(figsize=(8, 8))
m = Basemap(projection='ortho', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
           width=200,
           height=200,
           resolution=None)
#m.etopo(scale=0)
m.bluemarble(scale=10)
386/94:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
m = Basemap(projection='tmerc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            width=200,
            height=200,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble(scale=.5)
386/95:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
m = Basemap(projection='tmerc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            width=200,
            height=200,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble()
386/96:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
m = Basemap(projection='tmerc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble()
386/97:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)

m = Basemap(projection='tmerc', 
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble()
386/98:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)

m = Basemap(projection='tmerc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            width=200,
            height=200,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble()
386/99: np.mean(newexifdata.PPKLat)
386/100:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)

m = Basemap(projection='tmerc', 
            lat_o=np.mean(newexifdata.PPKLat), 
            lon_o=np.mean(newexifdata.PPKLon),
            width=200,
            height=200,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble()
386/101:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)

m = Basemap(projection='tmerc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            width=200,
            height=200,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble()
386/102:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)

m = Basemap(projection='tmerc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            width=2000,
            height=2000,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble()
386/103:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)

m = Basemap(projection='tmerc', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble()
386/104:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)

m = Basemap(projection='ortho', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble()
386/105:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)

m = Basemap(projection='ortho', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat)
#m.etopo(scale=0)
m.bluemarble()
386/106:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)

m = Basemap(projection='ortho', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble(scale=0.5)
386/107:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)

m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
#m.etopo(scale=0)
m.bluemarble(scale=0.5)
386/108:
map = Basemap(llcrnrlon=-10.5,llcrnrlat=33,urcrnrlon=10.,urcrnrlat=46.,
             resolution='i', projection='cass', lat_0 = 39.5, lon_0 = 0.)

map.bluemarble()
386/109:
map = Basemap(llcrnrlon=-10.5,llcrnrlat=33,urcrnrlon=10.,urcrnrlat=46.,
             resolution='i', projection='cass', lat_0 = 39.5, lon_0 = 0.)

map.bluemarble()
plt.show()
386/110:
map = Basemap(llcrnrlon=-10.5,llcrnrlat=33,urcrnrlon=10.,urcrnrlat=46.,
             resolution='i', projection='cass', lat_0 = 39.5, lon_0 = 0.)

map.bluemarble()
map.drawcoastlines()
plt.show()
386/111:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)
'''
m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
            '''

m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None,
           epsg=4326)

#m.etopo(scale=0)
#m.bluemarble(scale=0.5)

m.arcgisimage(service='ESRI_Imagery_World_2D',xpixels = 2000, verbose= False)
386/112:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)
'''
m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
            '''

m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None,
           epsg=4326)

#m.etopo(scale=0)
#m.bluemarble(scale=0.5)

m.arcgisimage(service='ESRI_Imagery_World_2D',xpixels = 3000, verbose= False)
386/113:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)
'''
m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
            '''

m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None,
           epsg=4326)

#m.etopo(scale=0)
#m.bluemarble(scale=0.5)

m.arcgisimage(service='ESRI_Imagery_World_2D',xpixels = 5000, verbose= False)
386/114:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)

latbuf = 100/1852/60
lonbuf = 100/1852/60*np.cos(llcrnrlat)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)
'''
m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
            '''

m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon-lonbuf,
            llcrnrlat = llcrnrlat-latbuf,
            urcrnrlon = urcrnrlon+lonbuf,
            urcrnrlat = urcrnrlat+latbuf,
            resolution=None,
           epsg=4326)

#m.etopo(scale=0)
#m.bluemarble(scale=0.5)

m.arcgisimage(service='ESRI_Imagery_World_2D',xpixels = 5000, verbose= False)
386/115:
plt.figure(figsize=(8, 8))
llcrnrlon = np.min(newexifdata.PPKLon)
llcrnrlat = np.min(newexifdata.PPKLat)
urcrnrlon = np.max(newexifdata.PPKLon)
urcrnrlat = np.max(newexifdata.PPKLat)

latbuf = 100/1852/60
lonbuf = 100/1852/60*np.cos(llcrnrlat*np.pi/180.0)
#m = Basemap(projection='tmerc', 
#            lat_0=np.mean(newexifdata.PPKLat), 
#            lon_0=np.mean(newexifdata.PPKLon),
#           llcrnrlat = llcrnrlat,
#            urcrnrlon = urcrnrlon,
#            urcrnrlat = urcrnrlat,
#            width=200,
#            height=200,
#            resolution=None)
'''
m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon,
            llcrnrlat = llcrnrlat,
            urcrnrlon = urcrnrlon,
            urcrnrlat = urcrnrlat,
            resolution=None)
            '''

m = Basemap(projection='cass', 
            lat_0=np.mean(newexifdata.PPKLat), 
            lon_0=np.mean(newexifdata.PPKLon),
            llcrnrlon = llcrnrlon-lonbuf,
            llcrnrlat = llcrnrlat-latbuf,
            urcrnrlon = urcrnrlon+lonbuf,
            urcrnrlat = urcrnrlat+latbuf,
            resolution=None,
           epsg=4326)

#m.etopo(scale=0)
#m.bluemarble(scale=0.5)

m.arcgisimage(service='ESRI_Imagery_World_2D',xpixels = 5000, verbose= False)
388/1: import sys
388/2: import os
388/3: os.environ('GOOGLE_API_KEY')
388/4: os.environ?
388/5: os.environ['GOOGLE_API_KEY']
387/1:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
import matplotlib.pyplot as plt
%matplotlib notebook

from pyproj import *
from mpl_toolkits.basemap import Basemap

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84"
               + " +datum=WGS84 +units=m +no_defs")
import gmaps

os.environ['GOOGLE_API_KEY']
gmaps.configure(api_key=os.environ['GOOGLE_API_KEY'])
387/2:
DATETOPROCESS="20190721"
ROVERTOPROCESS="rover03"  # One of rover01-rover06                              

HOMEDIR="/Users/vschmidt/BoxSync/2019_OET_AE/data/NA113"
RAWGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/rawgopro")
PPKGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/processedgopro")


ROVER_DIR = HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro/" + ROVERTOPROCESS
BASE_DIR = HOMEDIR + "/" + DATETOPROCESS + "/GPSbasestation"
RTKLIBCONFIG = HOMEDIR + "/scripts/ppk.conf"

EXIFTOOL = "/usr/local/bin/exiftool"
RNX2RTKP = "/usr/local/bin/rnx2rtkp"
387/3:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = process.communicate()
YYYYMMDD = YYYYMMDD_result[0].decode('UTF-8').rstrip()
387/4:
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA_WITHGPS.txt"
BADIMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.WITHOUTGPS.txt"
IMAGE_METADATA_W_PPK = PPKGOPRO_DIR + "/NA113_" + YYYYMMDD + "_PPK_IMAGE_METADATA.txt"
387/5:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)


cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
387/6:
ROVERFILE = None
ROVERNAVFILE = None
BASESTATIONFILE = None

# Get the file names for Rover obs, nav, Base and output.   
for f in os.listdir(ROVER_DIR + "/rawgps/"):
    if f[-3:] == "obs":
        ROVERFILE = ROVER_DIR + "/rawgps/" + f
    if f[-3:] == "nav":
        ROVERNAVFILE = ROVER_DIR + "/rawgps/" + f
        
# Look for CORS .o or .obs file           
for f in os.listdir(BASE_DIR):
    if f[-1:] == "o" or f[-3:] == "obs":
        BASESTATIONFILE = BASE_DIR + '/' + f

ROVERPPKOUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" + ROVERTOPROCESS + "_ppk.txt")
387/7:
# Load exif data and parse timestamps (use pandas)
exifdata = pd.read_csv(IMAGE_METADATA,delimiter='\s+',
                       parse_dates=True,index_col=1,header=None)
exifdata.columns=['Filename','Lat','Lon']

# Load new navigagtion
rovernav = pd.read_csv(ROVERPPKOUTPUTFILE,delimiter='\s+',
                       comment='%',parse_dates=[0,1],header=None)
rovernav.set_index(1,inplace=True)
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']

newexifdata = exifdata
387/8: exifdata.head()
387/9:
# Load exif data and parse timestamps (use pandas)
exifdata = pd.read_csv(IMAGE_METADATA,delimiter='\s+',
                       parse_dates=True,index_col=1,header=None)
exifdata.columns=['Filename','Lat','Lon','Height']

# Load new navigagtion
rovernav = pd.read_csv(ROVERPPKOUTPUTFILE,delimiter='\s+',
                       comment='%',parse_dates=[0,1],header=None)
rovernav.set_index(1,inplace=True)
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']

newexifdata = exifdata
387/10: exifdata.head()
387/11:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
newexifdata['PPKLon'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lon)
newexifdata['PPKheight'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['height'])
newexifdata['PPKsde_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sde(m)'])
newexifdata['PPKsdn_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sdn(m)'])
newexifdata['PPKsdu_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sdu(m)'])
newexifdata.head()
387/12:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
plt.ylabel('Latitude')
plt.grid(True)

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')
plt.grid(True)


plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
plt.grid(True)
387/13:
plt.figure(figsize=(7,7))
plt.plot(rovernav.lon,rovernav.lat)
plt.plot(newexifdata.PPKLon,newexifdata.PPKLat,'o')
plt.grid(True)
387/14: gmaps.figure((np.mean(newexifdata.PPKLat),np.mean(newexifdata.PPKLon)),zoom_level=15)
387/15: gmaps.figure(center=(np.mean(newexifdata.PPKLat),np.mean(newexifdata.PPKLon)),zoom_level=15)
387/16: gmaps.figure(map_type='SATELLITE',center=(np.mean(newexifdata.PPKLat),np.mean(newexifdata.PPKLon)),zoom_level=15)
387/17:
gmaps.figure(map_type='SATELLITE',center=(np.mean(newexifdata.PPKLat),np.mean(newexifdata.PPKLon)),zoom_level=15)
fig
387/18:
fig = gmaps.figure(map_type='SATELLITE',center=(np.mean(newexifdata.PPKLat),np.mean(newexifdata.PPKLon)),zoom_level=15)
fig
389/1:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
import matplotlib.pyplot as plt
%matplotlib notebook

from pyproj import *
from mpl_toolkits.basemap import Basemap

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84"
               + " +datum=WGS84 +units=m +no_defs")
import gmaps

os.environ['GOOGLE_API_KEY']
gmaps.configure(api_key=os.environ['GOOGLE_API_KEY'])
389/2:
DATETOPROCESS="20190721"
ROVERTOPROCESS="rover03"  # One of rover01-rover06                              

HOMEDIR="/Users/vschmidt/BoxSync/2019_OET_AE/data/NA113"
RAWGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/rawgopro")
PPKGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/processedgopro")


ROVER_DIR = HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro/" + ROVERTOPROCESS
BASE_DIR = HOMEDIR + "/" + DATETOPROCESS + "/GPSbasestation"
RTKLIBCONFIG = HOMEDIR + "/scripts/ppk.conf"

EXIFTOOL = "/usr/local/bin/exiftool"
RNX2RTKP = "/usr/local/bin/rnx2rtkp"
389/3:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = process.communicate()
YYYYMMDD = YYYYMMDD_result[0].decode('UTF-8').rstrip()
389/4:
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA_WITHGPS.txt"
BADIMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.WITHOUTGPS.txt"
IMAGE_METADATA_W_PPK = PPKGOPRO_DIR + "/NA113_" + YYYYMMDD + "_PPK_IMAGE_METADATA.txt"
389/5:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)


cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
389/6:
ROVERFILE = None
ROVERNAVFILE = None
BASESTATIONFILE = None

# Get the file names for Rover obs, nav, Base and output.   
for f in os.listdir(ROVER_DIR + "/rawgps/"):
    if f[-3:] == "obs":
        ROVERFILE = ROVER_DIR + "/rawgps/" + f
    if f[-3:] == "nav":
        ROVERNAVFILE = ROVER_DIR + "/rawgps/" + f
        
# Look for CORS .o or .obs file           
for f in os.listdir(BASE_DIR):
    if f[-1:] == "o" or f[-3:] == "obs":
        BASESTATIONFILE = BASE_DIR + '/' + f

ROVERPPKOUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" + ROVERTOPROCESS + "_ppk.txt")
389/7:
# Load exif data and parse timestamps (use pandas)
exifdata = pd.read_csv(IMAGE_METADATA,delimiter='\s+',
                       parse_dates=True,index_col=1,header=None)
exifdata.columns=['Filename','Lat','Lon','Height']

# Load new navigagtion
rovernav = pd.read_csv(ROVERPPKOUTPUTFILE,delimiter='\s+',
                       comment='%',parse_dates=[0,1],header=None)
rovernav.set_index(1,inplace=True)
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']

newexifdata = exifdata
389/8: exifdata.head()
389/9:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
newexifdata['PPKLon'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lon)
newexifdata['PPKheight'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['height'])
newexifdata['PPKsde_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sde(m)'])
newexifdata['PPKsdn_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sdn(m)'])
newexifdata['PPKsdu_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sdu(m)'])
newexifdata.head()
389/10:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
plt.ylabel('Latitude')
plt.grid(True)

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')
plt.grid(True)


plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
plt.grid(True)
389/11:
fig = gmaps.figure(map_type='SATELLITE',center=(np.mean(newexifdata.PPKLat),np.mean(newexifdata.PPKLon)),zoom_level=15)
fig
389/12:
fig = gmaps.figure(map_type='SATELLITE',center=(np.mean(newexifdata.PPKLat),np.mean(newexifdata.PPKLon)),
                   zoom_level=12)
fig
389/13: jupyter nbextension list
390/1:
import os
import sys
import datetime
import numpy as np
import pandas as pd
from subprocess import Popen, PIPE
import scipy.interpolate as I
import matplotlib.pyplot as plt
%matplotlib notebook

from pyproj import *
from mpl_toolkits.basemap import Basemap

WGS84 = Proj(init='EPSG:4326')
UTM19N = Proj("+proj=utm +zone=19 +ellps=WGS84"
               + " +datum=WGS84 +units=m +no_defs")
import gmaps

os.environ['GOOGLE_API_KEY']
gmaps.configure(api_key=os.environ['GOOGLE_API_KEY'])
390/2:
DATETOPROCESS="20190721"
ROVERTOPROCESS="rover03"  # One of rover01-rover06                              

HOMEDIR="/Users/vschmidt/BoxSync/2019_OET_AE/data/NA113"
RAWGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/rawgopro")
PPKGOPRO_DIR = (HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro" 
               + "/"+ ROVERTOPROCESS + "/processedgopro")


ROVER_DIR = HOMEDIR + "/" + DATETOPROCESS + "/handheldGPS_GoPro/" + ROVERTOPROCESS
BASE_DIR = HOMEDIR + "/" + DATETOPROCESS + "/GPSbasestation"
RTKLIBCONFIG = HOMEDIR + "/scripts/ppk.conf"

EXIFTOOL = "/usr/local/bin/exiftool"
RNX2RTKP = "/usr/local/bin/rnx2rtkp"
390/3:
cmd = (EXIFTOOL + " -CreateDate " + 
       RAWGOPRO_DIR + "/images | sed 's/^.*2019/2019/' " + 
       "| sed 's/://g' | sed 's/ .*//' | head -2 | tail -1")
process = Popen(cmd,stdout=PIPE, stderr=PIPE, shell=True)
YYYYMMDD_result = process.communicate()
YYYYMMDD = YYYYMMDD_result[0].decode('UTF-8').rstrip()
390/4:
IMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA_WITHGPS.txt"
BADIMAGE_METADATA = RAWGOPRO_DIR + "/NA113_" + YYYYMMDD + "_RAW_IMAGE_METADATA.WITHOUTGPS.txt"
IMAGE_METADATA_W_PPK = PPKGOPRO_DIR + "/NA113_" + YYYYMMDD + "_PPK_IMAGE_METADATA.txt"
390/5:
cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + IMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)


cmd = (EXIFTOOL + 
       " -T -c %+0.8f -d '%Y-%m-%dT%H:%M:%S' -FileName -GpsDateTime -GpsLatitude -GpsLongitude -GpsAltitude " + 
       RAWGOPRO_DIR + "/images | /usr/bin/sort | grep T | sed 's/ m Above.*//' > " + BADIMAGE_METADATA)

process = Popen(cmd,shell=True,stderr=PIPE,stdout=PIPE)
390/6:
ROVERFILE = None
ROVERNAVFILE = None
BASESTATIONFILE = None

# Get the file names for Rover obs, nav, Base and output.   
for f in os.listdir(ROVER_DIR + "/rawgps/"):
    if f[-3:] == "obs":
        ROVERFILE = ROVER_DIR + "/rawgps/" + f
    if f[-3:] == "nav":
        ROVERNAVFILE = ROVER_DIR + "/rawgps/" + f
        
# Look for CORS .o or .obs file           
for f in os.listdir(BASE_DIR):
    if f[-1:] == "o" or f[-3:] == "obs":
        BASESTATIONFILE = BASE_DIR + '/' + f

ROVERPPKOUTPUTFILE= (ROVER_DIR + "/processedgps/" + 
             "NA113_" + YYYYMMDD + "_" + ROVERTOPROCESS + "_ppk.txt")
390/7:
# Load exif data and parse timestamps (use pandas)
exifdata = pd.read_csv(IMAGE_METADATA,delimiter='\s+',
                       parse_dates=True,index_col=1,header=None)
exifdata.columns=['Filename','Lat','Lon','Height']

# Load new navigagtion
rovernav = pd.read_csv(ROVERPPKOUTPUTFILE,delimiter='\s+',
                       comment='%',parse_dates=[0,1],header=None)
rovernav.set_index(1,inplace=True)
rovernav.columns = ['GPST','lat','lon','height','Q','ns', 'sdn(m)',
                    'sde(m)','sdu(m)','sdne(m)','sdeu(m)','sdun(m)',
                    'age(s)','ratA']

newexifdata = exifdata
390/8: exifdata.head()
390/9:
newexifdata['PPKLat'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lat)
newexifdata['PPKLon'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav.lon)
newexifdata['PPKheight'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['height'])
newexifdata['PPKsde_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sde(m)'])
newexifdata['PPKsdn_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sdn(m)'])
newexifdata['PPKsdu_m'] = np.interp(exifdata.index.to_julian_date(),
                                  rovernav.index.to_julian_date(),
                                  rovernav['sdu(m)'])
newexifdata.head()
390/10:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLat,'o')
plt.ylabel('Latitude')
plt.grid(True)

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')
plt.grid(True)


plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
plt.grid(True)
390/11:
plt.figure(figsize=(7,7))
plt.plot(rovernav.lon,rovernav.lat)
plt.plot(newexifdata.PPKLon,newexifdata.PPKLat,'o')
plt.grid(True)
390/12:
fig = gmaps.figure(map_type='SATELLITE',center=(np.mean(newexifdata.PPKLat),np.mean(newexifdata.PPKLon)),
                   zoom_level=12)
fig
390/13:
fig = gmaps.figure(map_type='SATELLITE',center=(np.mean(newexifdata.PPKLat),np.mean(newexifdata.PPKLon)),
                   zoom_level=12)
fig
391/1: cd ~/scratch/
391/2: import pandas
391/3: import pandas as pd
391/4: d = pd.read_csv('hwbias.csv')
391/5: d.head()
391/6: d.plot('0.0250')
391/7: d.plot('0.0250')
390/14:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date()+23/24/60,newexifdata.PPKLat,'o')
plt.ylabel('Latitude')
plt.grid(True)

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')
plt.grid(True)


plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
plt.grid(True)
390/15:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date()+23/60,newexifdata.PPKLat,'o')
plt.ylabel('Latitude')
plt.grid(True)

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')
plt.grid(True)


plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
plt.grid(True)
390/16:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date()+23/60/24,newexifdata.PPKLat,'o')
plt.ylabel('Latitude')
plt.grid(True)

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')
plt.grid(True)


plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
plt.grid(True)
390/17:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date()+23/60/24/365,newexifdata.PPKLat,'o')
plt.ylabel('Latitude')
plt.grid(True)

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')
plt.grid(True)


plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
plt.grid(True)
390/18:
plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lat)
plt.plot(newexifdata.index.to_julian_date()+23/60/24/365,newexifdata.PPKLat,'o')
plt.plot(newexifdata.index.to_julian_date()+23/60/24/365,newexifdata.PPKLat,'om')
plt.ylabel('Latitude')
plt.grid(True)

plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav.lon)
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKLon,'o')
plt.ylabel('Longitude')
plt.grid(True)


plt.figure(figsize=(9,3))
plt.plot(rovernav.index.to_julian_date(),rovernav['height'])
plt.plot(newexifdata.index.to_julian_date(),newexifdata.PPKheight,'o')
plt.ylabel('Height')
plt.grid(True)
392/1: import socket as S
392/2: SS = S.socket?
393/1:
%matplotlib inline
import regexp
import pandas
import datetime
import numpy as np
import matplotlib.pyplot as plt
393/2:
%matplotlib inline
import re
import pandas
import datetime
import numpy as np
import matplotlib.pyplot as plt
393/3: ls
393/4: pwd
393/5: BIST_file = '20190724-235330-EM2040P_40-combined.txt'
393/6:
BF = file(BIST_FILE,'r')

while(not eof(BF)):
    line = BF.readline()
    
    if re.match(r"Software-date-and-versions",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r"RX-CPU-link",line):
        print("Found Rx-CPU-link Test")
        
BF.close()
393/7:
BF = open(BIST_FILE,'r')

while(not eof(BF)):
    line = BF.readline()
    
    if re.match(r"Software-date-and-versions",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r"RX-CPU-link",line):
        print("Found Rx-CPU-link Test")
        
BF.close()
393/8: BIST_file = '20190724-235330-EM2040P_40-combined.txt'
393/9:
BF = open(BIST_FILE,'r')

while(not eof(BF)):
    line = BF.readline()
    
    if re.match(r"Software-date-and-versions",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r"RX-CPU-link",line):
        print("Found Rx-CPU-link Test")
        
BF.close()
393/10: BIST_file = '20190724-235330-EM2040P_40-combined.txt'
393/11:
BF = open(BIST_FILE,'r')

while(not eof(BF)):
    line = BF.readline()
    
    if re.match(r"Software-date-and-versions",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r"RX-CPU-link",line):
        print("Found Rx-CPU-link Test")
        
BF.close()
393/12:

for line in file(BST_file):
    
    if re.match(r"Software-date-and-versions",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r"RX-CPU-link",line):
        print("Found Rx-CPU-link Test")
        
BF.close()
393/13:
BF = open(file,,"r")
for line in BF:
    
    if re.match(r"Software-date-and-versions",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r"RX-CPU-link",line):
        print("Found Rx-CPU-link Test")
        
BF.close()
393/14:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r"Software-date-and-versions",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r"RX-CPU-link",line):
        print("Found Rx-CPU-link Test")
        
BF.close()
393/15:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r"RX-CPU-link",line):
        print("Found Rx-CPU-link Test")
        
BF.close()
393/16:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
BF.close()
393/17:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
    if re.match(r".*RX-noise-spectrum.*"):
        print("Found Rx Noise Spectrum Test")
BF.close()
393/18:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
    if re.match(r".*RX-noise-spectrum.*".line):
        print("Found Rx Noise Spectrum Test")

        
BF.close()
393/19:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        print("Found Rx Noise Spectrum Test")

        
BF.close()
393/20:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        print("Found Rx Noise Spectrum Test")

    if re.match(r"RX-noise-level",line):
        print("Found RX Noise Level Test")
        
        
BF.close()
393/21:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        print("Found Rx Noise Spectrum Test")

    if re.match(r".*RX-noise-level.*",line):
        print("Found RX Noise Level Test")
        
        
BF.close()
393/22:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        print("Found Rx Noise Spectrum Test")

    if re.match(r".*RX-noise-level.*",line):
        print("Found RX Noise Level Test")
        
    if re.match(r".*TX-channels-via-RX.*",line):
        print("Found TX Channels via RX Test")
        
BF.close()
393/23:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        print("Found Software Date and Versions Test")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        print("Found Rx Noise Spectrum Test")

    if re.match(r".*RX-noise-level.*",line):
        print("Found RX Noise Level Test")
        
    if re.match(r".*TX-channels-via-RX.*",line):
        print("Found TX Channels via RX Test")
        
    if re.match(r".*RX-channels.*",line):
        print("Found RX Channels Test")
        
BF.close()
393/24:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if re.match(r".*-Passed-.*",line):
            print("Found Software Date and Versions Test: Passed")
        else
            print("Found Software Date and Versions Test: Failed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        print("Found Rx Noise Spectrum Test")

    if re.match(r".*RX-noise-level.*",line):
        print("Found RX Noise Level Test")
        
    if re.match(r".*TX-channels-via-RX.*",line):
        print("Found TX Channels via RX Test")
        
    if re.match(r".*RX-channels.*",line):
        print("Found RX Channels Test")
        
BF.close()
393/25:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if re.match(r".*-Passed-.*",line):
            print("Found Software Date and Versions Test: Passed")
        else:
            print("Found Software Date and Versions Test: Failed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        print("Found Rx Noise Spectrum Test")

    if re.match(r".*RX-noise-level.*",line):
        print("Found RX Noise Level Test")
        
    if re.match(r".*TX-channels-via-RX.*",line):
        print("Found TX Channels via RX Test")
        
    if re.match(r".*RX-channels.*",line):
        print("Found RX Channels Test")
        
BF.close()
393/26:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if re.match(r".*-Passed-.*",line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: Failed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        print("Found Rx-CPU-link Test")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        print("Found Rx Noise Spectrum Test")

    if re.match(r".*RX-noise-level.*",line):
        print("Found RX Noise Level Test")
        
    if re.match(r".*TX-channels-via-RX.*",line):
        print("Found TX Channels via RX Test")
        
    if re.match(r".*RX-channels.*",line):
        print("Found RX Channels Test")
        
BF.close()
393/27:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if re.match(r".*-Passed-.*",line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if re.match(r".*-Passed-.*",line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        print("Found Rx Noise Spectrum Test")

    if re.match(r".*RX-noise-level.*",line):
        print("Found RX Noise Level Test")
        
    if re.match(r".*TX-channels-via-RX.*",line):
        print("Found TX Channels via RX Test")
        
    if re.match(r".*RX-channels.*",line):
        print("Found RX Channels Test")
        
BF.close()
393/28:
BF = open(BIST_file,"r")
for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if re.match(r".*-Passed-.*",line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if re.match(r".*-Passed-.*",line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        print("Found Rx Noise Spectrum Test")

    if re.match(r".*RX-noise-level.*",line):
        print("Found RX Noise Level Test")
        
    if re.match(r".*TX-channels-via-RX.*",line):
        print("Found TX Channels via RX Test")
        
    if re.match(r".*RX-channels.*",line):
        print("Found RX Channels Test")
        
BF.close()
393/29:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if re.match(r".*-Passed-.*",line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if re.match(r".*-Passed-.*",line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
    if re.match(r".*RX-noise-level.*",line):
        print("Found RX Noise Level Test")
        
    if re.match(r".*TX-channels-via-RX.*",line):
        print("Found TX Channels via RX Test")
        
    if re.match(r".*RX-channels.*",line):
        print("Found RX Channels Test")
        
BF.close()
393/30:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
    if re.match(r".*RX-noise-level.*",line):
        print("Found RX Noise Level Test")
        
    if re.match(r".*TX-channels-via-RX.*",line):
        print("Found TX Channels via RX Test")
        
    if re.match(r".*RX-channels.*",line):
        print("Found RX Channels Test")
        
BF.close()
393/31:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\tFailed")
        
BF.close()
393/32:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
        
BF.close()
393/33:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r"-RX-CBMF-link-",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
        
BF.close()
393/34:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
        
BF.close()
393/35:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")


            
BF.close()
393/36:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")



            
BF.close()
393/37:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else
            print("Found RX Unit Test:\t\t\t\tFailed")




            
BF.close()
393/38:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")




            
BF.close()
393/39:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.math(r"./-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")



            
BF.close()
393/40:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r"./-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")



            
BF.close()
393/41:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")



            
BF.close()
393/42:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*".line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\tFailed")



            
BF.close()
393/43:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\tFailed")



            
BF.close()
393/44:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/45:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/46:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*"BF.readline()):
        pass
    
    pattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe ".*"
    match = re.search(pattern).group()
    if match is not None:
        print(match.group)
393/47:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/48:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    pattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe ".*"
    match = re.search(pattern).group()
    if match is not None:
        print(match.group)
393/49:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    pattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*"
    match = re.search(pattern).group()
    if match is not None:
        print(match.group)
393/50:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/51:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*"
    z = 0
    while z < 95:
        match = re.search(datapattern).group()
        if match is not None:
            print(match.group)
            z = z + 1
393/52:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/53:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*"
    z = 0
    while z < 95:
        
        match = re.search(datapattern,BF.readline()).group()
        if match is not None:
            print(match.group)
            z = z + 1
393/54:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/55:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*"
    z = 0
    while z < 95:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            print(match.group)
            z = z + 1
393/56:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/57:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*"
    z = 0
    while z < 95:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            print(match.group())
            z = z + 1
393/58:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
394/1: import numpy as np
394/2: a = np.array((3,4))
394/3: a
394/4: a = np.array()
394/5: a = {}
394/6: a = []
394/7: a.append([1 3 4])
394/8: a.append([1,3,4])
394/9: a.append([2,3,4])
394/10: a
394/11: a.size()
394/12: b = np.array(a)
394/13: b
394/14: b.shape()
394/15: b.shape
393/59:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*"
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelAmplitude.append(match.group())
            
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    print(RXChannelsAmplitude)
393/60:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/61:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*"
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(match.group())
            
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    print(RXChannelsAmplitude)
393/62:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/63:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*"
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(match.group())
            print(match.group(2))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    print(RXChannelsAmplitude)
393/64:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
394/16: import re
394/17: line = '83           -0.8     -0.7       -2.3     -2.4        1.7     -0.4 '
394/18: datapattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*"
394/19: fe = '(-?\d+\.\d+)'
394/20: datapattern = ".*" + fe + "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*"
394/21: datapattern
394/22: print(r datapattern)
394/23: print(r'datapattern')
394/24: print(r"datapattern")
394/25: print(r\datapattern)
394/26: print(r/datapattern)
394/27: print(r\datapattern)
394/28: print(r\datapattern)
394/29: datapattern
394/30: line
394/31: match = re.search(datapattern,line)
394/32: match.group()
394/33: match.group(1)
394/34: match.group(0)
394/35: match.group(1)
394/36: match.group(2)
394/37: match.group(3)
394/38: match.group(4)
394/39: match.group(5)
394/40:
    datapattern = (".*" + "\d*" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + .*")
394/41:
    datapattern = (".*" + "\d*" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*")
394/42: datapattern
394/43: match = re.search(datapattern,line)
394/44: match.group()
394/45: match.group(0)
394/46: match.group(1)
394/47:
    datapattern = (".*" + "\d+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*")
394/48: match = re.search(datapattern,line)
394/49: match.group(1)
394/50:
    datapattern = ("\s+" + "\d+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s+")
394/51: match = re.search(datapattern,line)
394/52: match
394/53:
    datapattern = ("\s+" + "\d+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s+")
394/54: line
394/55:
    datapattern = ("\s?" + "\d+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s+")
394/56: match = re.search(datapattern,line)
394/57: match
394/58:
    datapattern = (".*" + "\d+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*")
394/59: match = re.search(datapattern,line)
394/60: match
394/61: match.group()
394/62:
    datapattern = (".*" + "\d+" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*")
394/63: match = re.search(datapattern,line)
394/64: match.group()
394/65: match.group(1)
394/66: match.group(0)
394/67:
    datapattern = (".*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + ".*")
394/68: match = re.search(datapattern,line)
394/69: match.group()
394/70: match.group(0)
394/71: match.group(1)
394/72: match.group(2)
394/73:
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
394/74: match = re.search(datapattern,line)
394/75: match.groupdict
394/76: match.group(1)
394/77: match.group(2)
394/78: match.group
394/79: match.group(0)
394/80: a = []
394/81: a.append(match.group(0))
394/82: a.append(match.group(0))
394/83: a
394/84: b = np.array(a)
394/85: b
394/86: b.shape
394/87: a = []
394/88: match.groupdict?
394/89: match.groupdict()
394/90: match.group?
394/91: match.group(1:6)
394/92: match.group(range(6))
394/93: match.group(2)
394/94: match.group(0).split()
393/65:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(match.group().split())
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    print(RXChannelsAmplitude)
393/66:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/67:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(float(match.group().split()))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    print(RXChannelsAmplitude)
393/68:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/69:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(map(float,match.group().split()))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    print(RXChannelsAmplitude)
393/70:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
394/95: a = map(float,match.group(0).split())
394/96: a
394/97: print(a)
394/98: map?
394/99: a []
394/100: a = []
394/101: a.append(map(float,match.group(0).split()))
394/102: a.append(map(float,match.group(0).split()))
394/103: a.append(map(float,match.group(0).split()))
394/104: b = np.array(a)
394/105: b
394/106: b.mean()
394/107: map?
394/108: max(a)
394/109: a = map(float,match.group(0).split())
394/110: max(a)
394/111: a
393/71:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    print(RXChannelsAmplitude)
393/72:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/73:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RxChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    print(RXChannelsPhase)
393/74:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/75:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    print(RXChannelsPhase)
393/76:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/77:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    plt.figure(figsize(7,7))
    plt.plot(RXChannelsAmplitude)
    plt.show()
393/78:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/79: plt.figure?
393/80:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    plt.figure(figsize=(7,7))
    plt.plot(RXChannelsAmplitude)
    plt.show()
393/81:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/82:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    plt.figure(figsize=(7,7))
    plt.plot(RXChannelsAmplitude[,1:])
    plt.show()
393/83:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/84:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    plt.figure(figsize=(7,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.show()
393/85:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/86:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    plt.figure(figsize=(7,10))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.show()
393/87:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/88:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.show()
393/89:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
394/112: import matplotlib.pyplot as plt
394/113: plt.grid?
393/90:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
393/91:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/92:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
 
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.grid(True)
    plt.show()
393/93:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/94:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/95:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.grid(True)
    plt.show()
393/96:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
394/114: a
394/115: a = [[1,2,3],[2,3,4]]
394/116: a
394/117: b
394/118: b = np.array(a)
394/119: b.shape()
394/120: b.shape
394/121: b
394/122: b.max()
394/123: max(b)
394/124: b.max?
394/125: np.amax?
394/126: b
394/127: np.max?
394/128: b.max(axis=1)
394/129: b
394/130: b.max(axis=0)
394/131: b.max(axis=0)==b
394/132: b[b.max(axis=0)==b]
393/97:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[0,MaxMask[:,0]]
    Max300kHzChannel = RXChannelsNoiseLevel[0,MaxMask[:,1]]
    Max400kHzChannel = RXChannelsNoiseLevel[0,MaxMask[:,2]]


    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/98:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[0,MaxMask[:,0]]
    Max300kHzChannel = RXChannelsNoiseLevel[0,MaxMask[:,1]]
    Max400kHzChannel = RXChannelsNoiseLevel[0,MaxMask[:,2]]

    
    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzChannel,MaxRxChannelNoiseLevel[0],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/99:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
394/133: bmask = b.max(axis=0)==b
394/134: bmask
394/135: b[0,bmask[:,0])
394/136: b[0,bmask[:,0]]
394/137: bmask[:,0]
394/138: np.find(bmask[:,0])
394/139: b.where?
394/140: b
394/141: np.where?
394/142: np.where(bmask)
394/143: bmask
394/144: b
394/145: ii = np.where(bmask)
394/146: b[0,ii[:,0])
394/147: ii
394/148: ii[:,0]
394/149: np.where(bmask,b)
394/150: bmask
394/151: b
394/152: np.where(bmask,b[:,0])
394/153: b[:,0]
394/154: np.where?
394/155: np.where(bmask[:,0],b[:,0])
394/156: np.where(bmask[:,0])
394/157: b[np.where(bmask[:,0])]
394/158: bmask
394/159: b[np.where(bmask[:,0]),0-]
394/160: b[np.where(bmask[:,0]),0]
393/100:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[0,np.where(MaxMask[:,0])]
    Max300kHzChannel = RXChannelsNoiseLevel[0,np.where(MaxMask[:,1])]
    Max400kHzChannel = RXChannelsNoiseLevel[0,np.where(MaxMask[:,2])]

    
    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzChannel,MaxRxChannelNoiseLevel[0],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/101:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/102:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,0]),0]
    Max300kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max400kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]

    
    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzChannel,MaxRxChannelNoiseLevel[0],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/103:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/104:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,0]),0]
    Max300kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max400kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]

    print("Max Channel Noise %f" % MaxRxChannelNoiseLevel)
    print("Max Channel %f" % Max200kHzChannel)
    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzChannel,MaxRxChannelNoiseLevel[0],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/105:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/106:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,0]),0]
    Max300kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max400kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]

    print("Max Channel Noise %f" % MaxRxChannelNoiseLevel[0])
    print("Max Channel %f" % Max200kHzChannel)
    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzChannel,MaxRxChannelNoiseLevel[0],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/107:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/108:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,0]),0]
    Max300kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max400kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]

    print("Max Channel Noise %f" % MaxRxChannelNoiseLevel[0])
    print("Max Channel %f" % Max200kHzChannel)
    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/109:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/110:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,0]),0]
    Max300kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max400kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]

    print(MaxRxChannelNoiseLevel)
    print("Max Channel Noise %f" % MaxRxChannelNoiseLevel[0])
    print("Max Channel %f" % Max200kHzChannel)
    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/111:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/112:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    print(MaxRxChannelNoiseLevel)
    print("Max Channel Noise %f" % MaxRxChannelNoiseLevel[0])
    print("Max Channel %f" % Max200kHzChannel)
    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/113:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/114:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    print(MaxRxChannelNoiseLevel)
    print("Max Channel Noise %f" % MaxRxChannelNoiseLevel[1])
    print("Max Channel %f" % Max200kHzChannel)
    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/115:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/116:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    print(MaxRxChannelNoiseLevel)
    print("Max Channel Noise %f" % MaxRxChannelNoiseLevel[1])
    print("Max Channel %f" % Max200kHzChannel)
    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/117:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/118:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %f\t%f" % (MaxRxChannelNoiseLevel[1],Max200kHzNoiseChannel)
    print("\tMax Channel:Noise %f\t%f" % (MaxRxChannelNoiseLevel[2],Max300kHzNoiseChannel)
    print("\tMax Channel:Noise %f\t%f" % (MaxRxChannelNoiseLevel[3],Max400kHzNoiseChannel)

    

    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/119:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/120:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %f\t%f" % (MaxRxChannelNoiseLevel[1],Max200kHzNoiseChannel))
    print("\tMax Channel:Noise %f\t%f" % (MaxRxChannelNoiseLevel[2],Max300kHzNoiseChannel))
    print("\tMax Channel:Noise %f\t%f" % (MaxRxChannelNoiseLevel[3],Max400kHzNoiseChannel))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/121:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/122:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %f\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %f\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %f\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/123:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/124:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/125:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/126:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %0d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %0d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %0d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
393/127:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/128:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXNoiseSpectrumList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/129:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/130:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/131:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+\|s+" + fe + "\s+\|s+" + fe + "\s+\|s+" + fe + 
                "\s+\|s+" + fe + "\s+\|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXNoiseSpectrumList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/132:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
394/161:
datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
394/162: datapattern
394/163: line = "   182.9 |    51.0 |    51.2 |    51.2 |    51.1 |"
394/164: match = re.search(datapattern,line)
394/165: match.group()
394/166:
datapattern = ("\s*" + fe + "\s+\|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
394/167: match = re.search(datapattern,line)
394/168: match.group()
394/169: fe
394/170: datapattern = ("\s*" + fe + "\s+\|s+")
394/171: match = re.search(datapattern,line)
394/172: match.group()
394/173: datapattern = ("\s*" + fe + "\s+\|s*")
394/174: datapattern = ("\s*" + fe + "\s+\|s.*")
394/175: re.match(datapattern,line)
394/176: datapattern = ("\s*" + fe + "\s+\\|s.*")
394/177: re.match(datapattern,line)
394/178: match = re.search(datapattern,line)
394/179: match.group()
394/180: line
394/181:
datapattern = ("\s*" + fe + "\s+\|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
394/182: datapattern
394/183:
datapattern = ("\s*" + fe + "\s+\|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + r"\s+|\s*")
394/184: datapattern
394/185:
datapattern = (r'\s*' + fe + r'\s+\|s+' + fe + r'\s+|s+' + fe + r'\s+|s+' + fe + 
                r'\s+|s+' + fe + r'\s+|\s*')
394/186: datapattern
394/187: match = re.search(datapattern,line)
394/188: match.group()
394/189: fe
394/190: fe = r'(-?\d+\.\d+)'
394/191: fe
394/192:
datapattern = (r'\s*' + fe + r'\s+\|s+' + fe + r'\s+|s+' + fe + r'\s+|s+' + fe + 
                r'\s+|s+' + fe + r'\s+|\s*')
394/193: datapattern
394/194: match = re.search(datapattern,line)
394/195: match.group()
394/196: line
394/197: data = line.split('|')
394/198: data
394/199: data.__len__()
394/200: whos data
394/201: whos
394/202: len(data)
393/133:
%matplotlib inline
import re
import pandas
import datetime
import numpy as np
import matplotlib.pyplot as plt
393/134: BIST_file = '20190724-235330-EM2040P_40-combined.txt'
393/135:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.split('|')
        if len(data) == 6:
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/136:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/137: plt.figure?
393/138:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.split('|')
        if len(data) == 6:
            print(data)
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/139:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/140:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            print(data)
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/141:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
394/203: data[0]
394/204: float(data[0])
394/205: map(float,data)
394/206: list(map)
394/207: list[map]
394/208: list[map(float,data)]
394/209: data
394/210: list(map(float,data))
394/211: float(data[5])
394/212: data.shift()
394/213: data.pop()
394/214: data
393/142:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            print(data)
            RXNoiseSpectrumList.append(list(map(float,data.pop())))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/143:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/144:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            RXNoiseSpectrumList.append(list(map(float,data.pop())))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/145:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/146:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/147:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/148:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            print(data)
            RXNoiseSpectrumList.append(list(map(float,data))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/149:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/150:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data))))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/151:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/152:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    print(RXNoiseSpectrum)
393/153:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/154:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    plt.imshow(RXNoiseSpectrum[:,1:])
    plt.show()
393/155:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/156:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/157:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
394/215: plt.imshow?
393/158:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    plt.pcolor(RXNoiseSpectrum[:,0],[15,45,80,100],RXNoiseSpectrum[:,1:].transpose())
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/159:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/160:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    plt.pcolor(RXNoiseSpectrum[:,0],[15,45,75,90],RXNoiseSpectrum[:,1:].transpose())
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/161:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/162:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'o')
    plt.xlabel('kHz')
    plt.ylabel('Band')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/163:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/164:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('Band')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/165:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/166:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG')
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/167:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/168:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major')
    plt.grid(True,which='minor')
    plt.minorticks_on()
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/169:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/170:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/171:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/172:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-)
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/173:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/174:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-'')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/175:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/176:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    
    plt.grid(True)
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/177:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/178:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/179:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/180:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/181:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/182:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/183:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/184:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=2.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/185:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/186:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:])
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:])
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o')
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o')
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o')
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/187:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/188:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o',linewidth=3.0)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o',linewidth=3.0)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o',linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/189:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/190:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'o',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'o',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'o',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/191:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/192:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/193:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/194:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    plt.savefig('RxNoiseLevels.pdf' bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/195:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/196:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    plt.savefig('RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/197:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/198:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.savefig('RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/199:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/200:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    global BIST_DateTime
    global BIST_Model

    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.title([BIST_DateTime + ' ' + BIST_Model + ' ' + 'RX Channel Amplitude'])
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
    global BIST_DateTime
    global BIST_Model

        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.savefig('RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    global BIST_DateTime
    global BIST_Model


    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/201:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/202:
BIST_file = '20190724-235330-EM2040P_40-combined.txt'

F = BIST_file.split('-')
BIST_DateTime = F[0]+'-'+F[1]
BIST_Model = F[2]
393/203:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    global BIST_DateTime
    global BIST_Model

    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.title([BIST_DateTime + ' ' + BIST_Model + ' ' + 'RX Channel Amplitude'])
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
    global BIST_DateTime
    global BIST_Model

        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title('RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.savefig('RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    global BIST_DateTime
    global BIST_Model


    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title('RX Noise Spectrum Test')
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/204:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/205:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    global BIST_DateTime
    global BIST_Model

    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Amplitude'])
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Phase'])
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
    global BIST_DateTime
    global BIST_Model

        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Noise Levels, dB'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.savefig('RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    global BIST_DateTime
    global BIST_Model


    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Noise Spectrum Test'])
    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    plt.show()
393/206:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/207:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    global BIST_DateTime
    global BIST_Model

    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Amplitude'])
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' +]'RxChannelAmplitude.pdf',bbox_inches='tight')
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Phase'])
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' +]'RxChannelPhase.pdf',bbox_inches='tight')
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
    global BIST_DateTime
    global BIST_Model

        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Noise Levels, dB'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' +]'RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    global BIST_DateTime
    global BIST_Model


    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Noise Spectrum Test'])
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' +]'RxNoiseSpectrum.pdf',bbox_inches='tight')    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    #plt.show()
393/208:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/209:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    global BIST_DateTime
    global BIST_Model

    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Amplitude'])
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' +]'RxChannelAmplitude.pdf',bbox_inches='tight')
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Phase'])
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' +]'RxChannelPhase.pdf',bbox_inches='tight')
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
    global BIST_DateTime
    global BIST_Model

        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Noise Levels, dB'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' +]'RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    global BIST_DateTime
    global BIST_Model


    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Noise Spectrum Test'])
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' +'RxNoiseSpectrum.pdf',bbox_inches='tight')    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    #plt.show()
393/210:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    global BIST_DateTime
    global BIST_Model

    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Amplitude'])
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' + 'RxChannelAmplitude.pdf',bbox_inches='tight')
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Phase'])
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' + 'RxChannelPhase.pdf',bbox_inches='tight')
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
    global BIST_DateTime
    global BIST_Model

        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Noise Levels, dB'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' + 'RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    global BIST_DateTime
    global BIST_Model


    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title([BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Noise Spectrum Test'])
    plt.savefig([[BIST_DateTime + '-' + BIST_Model + '-' +'RxNoiseSpectrum.pdf',bbox_inches='tight')    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    #plt.show()
393/211:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/212:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    global BIST_DateTime
    global BIST_Model

    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Amplitude')
    plt.savefig([BIST_DateTime + '-' + BIST_Model + '-' + 'RxChannelAmplitude.pdf',bbox_inches='tight')
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Phase')
    plt.savefig([BIST_DateTime + '-' + BIST_Model + '-' + 'RxChannelPhase.pdf',bbox_inches='tight')
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
    global BIST_DateTime
    global BIST_Model

        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.savefig(BIST_DateTime + '-' + BIST_Model + '-' + 'RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    global BIST_DateTime
    global BIST_Model


    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Noise Spectrum Test')
    plt.savefig(BIST_DateTime + '-' + BIST_Model + '-' +'RxNoiseSpectrum.pdf',bbox_inches='tight')    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    #plt.show()
393/213:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    global BIST_DateTime
    global BIST_Model

    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Amplitude')
    plt.savefig(BIST_DateTime + '-' + BIST_Model + '-' + 'RxChannelAmplitude.pdf',bbox_inches='tight')
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Phase')
    plt.savefig(BIST_DateTime + '-' + BIST_Model + '-' + 'RxChannelPhase.pdf',bbox_inches='tight')
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
    global BIST_DateTime
    global BIST_Model

        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.savefig(BIST_DateTime + '-' + BIST_Model + '-' + 'RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    global BIST_DateTime
    global BIST_Model


    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Noise Spectrum Test')
    plt.savefig(BIST_DateTime + '-' + BIST_Model + '-' +'RxNoiseSpectrum.pdf',bbox_inches='tight')    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    #plt.show()
393/214:
BF = open(BIST_file,"r")

def test_passed(line):
    return re.match(r".*-Passed-.*",line)

for line in BF:
    
    if re.match(r".*Software-date-and-versions.*",line):
        if test_passed(line):
            print("Found Software Date and Versions Test: \t\tPassed")
        else:
            print("Found Software Date and Versions Test: \t\tFailed.")
        
    if re.match(r".*RX-CPU-link.*",line):
        if test_passed(line):
            print("Found Rx-CPU-link Test: \t\t\tPassed")
        else:
            print("Found Rx-CPU-link Test: \t\t\tFailed")
        
    if re.match(r".*RX-noise-spectrum.*",line):
        if test_passed(line):
            print("Found Rx Noise Spectrum Test\t\t\tPassed")
        else:
            print("Found Rx Noise Spectrum Test\t\t\tFailed")
            
        process_RXNoiseSpectrum(BF)
            
    if re.match(r".*RX-noise-level.*",line):
        if test_passed(line):
            print("Found RX Noise Level Test\t\t\tPassed")
        else:
            print("Found RX Noise Level Test\t\t\tFailed")
            
        process_RXNoiseLevel(BF)

    if re.match(r".*TX-channels-via-RX.*",line):
        if test_passed(line):
            print("Found TX Channels via RX Test:\t\t\tPassed")
        else:
            print("Found TX Channels via RX Test:\t\t\tFailed")
            
    if re.match(r".*RX-channels.*",line):
        if test_passed(line):
            print("Found RX Channels Test:\t\t\t\tPassed")
        else:
            print("Found RX Channels Test:\t\t\t\tFailed")
            
        process_RXChannelsTest(BF)
            
    if re.match(r".*-RX-CBMF-link-.*",line):
        if test_passed(line):
            print("Found RX CBMF Link Test:\t\t\tPassed")
        else:
            print("Found RX CBMF Link Test:\t\t\tFailed")
            
    if re.match(r".*-CBMF-CPU-link-.*",line):
        if test_passed(line):
            print("Found CMBF CPU Link Test:\t\t\tPassed")
        else:
            print("Found CMBF CPU Link Test:\t\t\tFailed")
            
    if re.match(r".*-TX-unit-test-.*",line):
        if test_passed(line):
            print("Found TX Unit Test:\t\t\t\tPassed")
        else:
            print("Found TX Unit Test:\t\t\t\tFailed")
            
    if re.match(r".*-RX-unit-test-.*",line):
        if test_passed(line):
            print("Found RX Unit Test:\t\t\t\tPassed")
        else:
            print("Found RX Unit Test:\t\t\t\tFailed")

    if re.match(r".*-CBMF-test-.*",line):
        if test_passed(line):
            print("Found CMBF Test:\t\t\t\tPassed")
        else:
            print("Found CMBF Test:\t\t\t\tFailed")

    if re.match(r".*-CPU-test-.*",line):
        if test_passed(line):
            print("Found CPU Test:\t\t\t\t\tPassed")
        else:
            print("Found CPU Test:\t\t\t\t\tFailed")



            
BF.close()
393/215:
%matplotlib inline
import re
import pandas
import datetime
import numpy as np
import matplotlib.pyplot as plt
393/216:
BIST_file = '20190724-235330-EM2040P_40-combined.txt'

F = BIST_file.split('-')
BIST_DateTime = F[0]+'-'+F[1]
BIST_Model = F[2]
393/217:
def process_RXChannelsTest(BF):
    ''' Process the RX Channels Test
    
    Signal Amplitude in dB
    
    
    
                  200kHz              300kHz              380kHz
    
    Channel       Low      High       Low      High       Low      High
    
      0           -1.9     -1.0       -0.8     -1.5        3.5      0.2 
      ...
    '''
    global BIST_DateTime
    global BIST_Model

    fe = '(-?\d+\.\d+)'

    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass
    
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                   "\s+" + fe + "\s+" + fe + "\s+" + fe + "\s*")
    
    RXChannelsAmpList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsAmpList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsAmplitude = np.array(RXChannelsAmpList)
    
    #print(RXChannelsAmplitude)

    while not re.match(r".*Signal Phase.*",BF.readline()):
        pass


    RXChannelsPhaseList = []
    z = 0
    while z < 96:
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsPhaseList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
            
    RXChannelsPhase = np.array(RXChannelsPhaseList)

    #print(RXChannelsPhase)

    # Plot Amplitude
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsAmplitude[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Amplitude, dB')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True)
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Amplitude')
    plt.savefig(BIST_DateTime + '-' + BIST_Model + '-' + 'RxChannelAmplitude.pdf',bbox_inches='tight')
    plt.show()
    
    
    # Plot Phase
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsPhase[:,1:],linewidth=3.0)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Phase')
    plt.legend(['200 kHz Low','200 kHz High','300 kHz Low','300 kHz High','400 kHz Low','400 kHz High'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Phase')
    plt.savefig(BIST_DateTime + '-' + BIST_Model + '-' + 'RxChannelPhase.pdf',bbox_inches='tight')
    plt.show()
    
def process_RXNoiseLevel(BF):
    ''' Process the RX Noise Level Test'''
    
    global BIST_DateTime
    global BIST_Model

        
    # Jump to Amplitude table.
    while not re.match(r".*Signal Amplitude in dB.*",BF.readline()):
        pass

    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + "(\d+)" "\s+" + fe + "\s+" + fe + "\s+" + fe + 
                "\s*")
    
    RXChannelsNoiseLevelList = []
    z = 0
    while z < 96:
        
        match = re.search(datapattern,BF.readline())
        if match is not None:
            RXChannelsNoiseLevelList.append(list(map(float,match.group().split())))
            #print(match.group())
            z = z + 1
    
    RXChannelsNoiseLevel = np.array(RXChannelsNoiseLevelList)
    
    MaxRxChannelNoiseLevel = RXChannelsNoiseLevel.max(axis=0)
    MaxMask = MaxRxChannelNoiseLevel == RXChannelsNoiseLevel
    Max200kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,1]),0]
    Max300kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,2]),0]
    Max400kHzNoiseChannel = RXChannelsNoiseLevel[np.where(MaxMask[:,3]),0]

    #print(MaxRxChannelNoiseLevel)
    print("\tMax Channel:Noise %d\t%f" % (Max200kHzNoiseChannel, MaxRxChannelNoiseLevel[1]))
    print("\tMax Channel:Noise %d\t%f" % (Max300kHzNoiseChannel, MaxRxChannelNoiseLevel[2]))
    print("\tMax Channel:Noise %d\t%f" % (Max400kHzNoiseChannel, MaxRxChannelNoiseLevel[3]))

    
    # Plot Noise Levels
    plt.figure(figsize=(10,7))
    plt.plot(RXChannelsNoiseLevel[:,1:],linewidth=3.0)
    plt.plot(Max200kHzNoiseChannel,MaxRxChannelNoiseLevel[1],'ro',markersize=12)
    plt.plot(Max300kHzNoiseChannel,MaxRxChannelNoiseLevel[2],'ro',markersize=12)
    plt.plot(Max400kHzNoiseChannel,MaxRxChannelNoiseLevel[3],'ro',markersize=12)
    plt.xlabel('Channel Number')
    plt.ylabel('RX Noise Level, dB')
    plt.legend(['200 kHz','300 kHz','400 kHz','Max'])
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Channel Noise Levels, dB')
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.savefig(BIST_DateTime + '-' + BIST_Model + '-' + 'RxNoiseLevels.pdf',bbox_inches='tight')
    
def process_RXNoiseSpectrum(BF):

    global BIST_DateTime
    global BIST_Model


    while not re.match(r".*Spectral noise test:.*",BF.readline()):
        pass

    
    fe = '(-?\d+\.\d+)'
    datapattern = ("\s*" + fe + "\s+|s+" + fe + "\s+|s+" + fe + "\s+|s+" + fe + 
                "\s+|s+" + fe + "\s+|\s*")
    
    RXNoiseSpectrumList = []
    
    z = 0
    while z < 24:
        line = BF.readline()
        
        data = line.rstrip().split('|')
        if len(data) == 6:
            data.pop()
            RXNoiseSpectrumList.append(list(map(float,data)))
            #print(match.group())
            z = z + 1
        if re.match('Summary',line):
            break


    RXNoiseSpectrum = np.array(RXNoiseSpectrumList)
    #print(RXNoiseSpectrum)
    plt.figure(figsize=(10,7))
    #plt.pcolor(RXNoiseSpectrum[:,0],[1,2,3]],RXNoiseSpectrum[:,1:-1].transpose())
    plt.plot(RXNoiseSpectrum[:,0],RXNoiseSpectrum[:,1:],'-o')
    plt.xlabel('kHz')
    plt.ylabel('dB')
    plt.legend(['CH 0-31','CH 32-63','CH 64-95','AVG'])
    plt.grid(True,which='major',linestyle='-')
    plt.grid(True,which='minor',linestyle='--')
    plt.minorticks_on()
    plt.title(BIST_DateTime + ', ' + BIST_Model + ', ' + 'RX Noise Spectrum Test')
    plt.savefig(BIST_DateTime + '-' + BIST_Model + '-' +'RxNoiseSpectrum.pdf',bbox_inches='tight')    
    #plt.imshow(RXNoiseSpectrum[:,1:].transpose())
    #plt.show()
    

def test_passed(line):
    return re.match(r".*-Passed-.*",line)
393/218:
def process_BIST_file(filename)
    '''Parse and Plot data from a Kongsberg BIST data file'''


    BF = open(filename,"r")


    for line in BF:
        
        if re.match(r".*Software-date-and-versions.*",line):
            if test_passed(line):
                print("Found Software Date and Versions Test: \t\tPassed")
            else:
                print("Found Software Date and Versions Test: \t\tFailed.")

        if re.match(r".*RX-CPU-link.*",line):
            if test_passed(line):
                print("Found Rx-CPU-link Test: \t\t\tPassed")
            else:
                print("Found Rx-CPU-link Test: \t\t\tFailed")

        if re.match(r".*RX-noise-spectrum.*",line):
            if test_passed(line):
                print("Found Rx Noise Spectrum Test\t\t\tPassed")
            else:
                print("Found Rx Noise Spectrum Test\t\t\tFailed")

            process_RXNoiseSpectrum(BF)

        if re.match(r".*RX-noise-level.*",line):
            if test_passed(line):
                print("Found RX Noise Level Test\t\t\tPassed")
            else:
                print("Found RX Noise Level Test\t\t\tFailed")

            process_RXNoiseLevel(BF)

        if re.match(r".*TX-channels-via-RX.*",line):
            if test_passed(line):
                print("Found TX Channels via RX Test:\t\t\tPassed")
            else:
                print("Found TX Channels via RX Test:\t\t\tFailed")

        if re.match(r".*RX-channels.*",line):
            if test_passed(line):
                print("Found RX Channels Test:\t\t\t\tPassed")
            else:
                print("Found RX Channels Test:\t\t\t\tFailed")

            process_RXChannelsTest(BF)

        if re.match(r".*-RX-CBMF-link-.*",line):
            if test_passed(line):
                print("Found RX CBMF Link Test:\t\t\tPassed")
            else:
                print("Found RX CBMF Link Test:\t\t\tFailed")

        if re.match(r".*-CBMF-CPU-link-.*",line):
            if test_passed(line):
                print("Found CMBF CPU Link Test:\t\t\tPassed")
            else:
                print("Found CMBF CPU Link Test:\t\t\tFailed")

        if re.match(r".*-TX-unit-test-.*",line):
            if test_passed(line):
                print("Found TX Unit Test:\t\t\t\tPassed")
            else:
                print("Found TX Unit Test:\t\t\t\tFailed")

        if re.match(r".*-RX-unit-test-.*",line):
            if test_passed(line):
                print("Found RX Unit Test:\t\t\t\tPassed")
            else:
                print("Found RX Unit Test:\t\t\t\tFailed")

        if re.match(r".*-CBMF-test-.*",line):
            if test_passed(line):
                print("Found CMBF Test:\t\t\t\tPassed")
            else:
                print("Found CMBF Test:\t\t\t\tFailed")

        if re.match(r".*-CPU-test-.*",line):
            if test_passed(line):
                print("Found CPU Test:\t\t\t\t\tPassed")
            else:
                print("Found CPU Test:\t\t\t\t\tFailed")




    BF.close()
393/219:
def process_BIST_file(filename):
    '''Parse and Plot data from a Kongsberg BIST data file'''


    BF = open(filename,"r")


    for line in BF:
        
        if re.match(r".*Software-date-and-versions.*",line):
            if test_passed(line):
                print("Found Software Date and Versions Test: \t\tPassed")
            else:
                print("Found Software Date and Versions Test: \t\tFailed.")

        if re.match(r".*RX-CPU-link.*",line):
            if test_passed(line):
                print("Found Rx-CPU-link Test: \t\t\tPassed")
            else:
                print("Found Rx-CPU-link Test: \t\t\tFailed")

        if re.match(r".*RX-noise-spectrum.*",line):
            if test_passed(line):
                print("Found Rx Noise Spectrum Test\t\t\tPassed")
            else:
                print("Found Rx Noise Spectrum Test\t\t\tFailed")

            process_RXNoiseSpectrum(BF)

        if re.match(r".*RX-noise-level.*",line):
            if test_passed(line):
                print("Found RX Noise Level Test\t\t\tPassed")
            else:
                print("Found RX Noise Level Test\t\t\tFailed")

            process_RXNoiseLevel(BF)

        if re.match(r".*TX-channels-via-RX.*",line):
            if test_passed(line):
                print("Found TX Channels via RX Test:\t\t\tPassed")
            else:
                print("Found TX Channels via RX Test:\t\t\tFailed")

        if re.match(r".*RX-channels.*",line):
            if test_passed(line):
                print("Found RX Channels Test:\t\t\t\tPassed")
            else:
                print("Found RX Channels Test:\t\t\t\tFailed")

            process_RXChannelsTest(BF)

        if re.match(r".*-RX-CBMF-link-.*",line):
            if test_passed(line):
                print("Found RX CBMF Link Test:\t\t\tPassed")
            else:
                print("Found RX CBMF Link Test:\t\t\tFailed")

        if re.match(r".*-CBMF-CPU-link-.*",line):
            if test_passed(line):
                print("Found CMBF CPU Link Test:\t\t\tPassed")
            else:
                print("Found CMBF CPU Link Test:\t\t\tFailed")

        if re.match(r".*-TX-unit-test-.*",line):
            if test_passed(line):
                print("Found TX Unit Test:\t\t\t\tPassed")
            else:
                print("Found TX Unit Test:\t\t\t\tFailed")

        if re.match(r".*-RX-unit-test-.*",line):
            if test_passed(line):
                print("Found RX Unit Test:\t\t\t\tPassed")
            else:
                print("Found RX Unit Test:\t\t\t\tFailed")

        if re.match(r".*-CBMF-test-.*",line):
            if test_passed(line):
                print("Found CMBF Test:\t\t\t\tPassed")
            else:
                print("Found CMBF Test:\t\t\t\tFailed")

        if re.match(r".*-CPU-test-.*",line):
            if test_passed(line):
                print("Found CPU Test:\t\t\t\t\tPassed")
            else:
                print("Found CPU Test:\t\t\t\t\tFailed")




    BF.close()
393/220: process_BIST_file(BIST_file)
396/1: import datetime as dt
396/2: t1 = dt.datetime.now()
396/3: t1 = dt.datetime.now()
396/4: t2 = dt.datetime.now()
396/5: ddt = t2-t1
396/6: ddt.days()
396/7: ddt.days
396/8: ddt.seconds
396/9: ddt.totaseconds
396/10: ddt.total_seconds
396/11: ddt.total_seconds()
396/12: ddt.resolution
396/13: print(ddt)
398/1:
import pandas as pd
import numpy as np
398/2: nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt')
398/3: nav.head()
398/4: nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None)
398/5: nav.head()
398/6: nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+')
398/7: nav.head()
398/8: nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+',index=0)
398/9:
nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+',
                  columns={'Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS'})
398/10: nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+')
398/11:
nav.columns = {'Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS'}
nav.head()
398/12:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.head()
398/13:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.timetuple?
nav.head()
398/14:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.set_index('Time',inplace=True)
nav.head()
398/15:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.set_index('Time',inplace=True)
nav.to_timestamp?
nav.head()
398/16:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.set_index('Time',inplace=True)
nav.to_timestamp(columns('Time'),inplace=True)
nav.head()
398/17:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.set_index('Time',inplace=True)
nav.to_timestamp(columns='Time',inplace=True)
nav.head()
398/18: nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+')
398/19:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.set_index('Time',inplace=True)
nav.to_timestamp(columns='Time',inplace=True)
nav.head()
398/20:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.set_index('Time',inplace=True)
pd.datetime?
nav.head()
398/21:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.set_index=pd.DatetimeIndex(nav.Time,inplace=True)
nav.head()
398/22: nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+')
398/23:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.set_index=pd.DatetimeIndex(nav.Time,inplace=True)
nav.head()
398/24:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
nav.set_index=pd.DatetimeIndex(nav.Time)
nav.head()
398/25: nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+')
398/26:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
dates = pd.to_datetime(nav['Time'])
nav.set_index(dates,inplace=True)
398/27:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
dates = pd.to_datetime(nav["Time"])
nav.set_index(dates,inplace=True)
398/28: nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+')
398/29:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
dates = pd.to_datetime(nav["Time"])
nav.set_index(dates,inplace=True)
398/30:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
dates = pd.to_datetime(nav["EpochTime"])
nav.set_index(dates,inplace=True)
398/31:
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
dates = pd.to_datetime(nav["EpochTime"])
nav.set_index(dates,inplace=True)
nav.head()
398/32:
nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+')
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
dates = pd.to_datetime(nav["EpochTime"])
nav.set_index(dates,inplace=True)
nav.head()
398/33: gp = pd.read_csv('ASV_UW_STILLS/20190810145243.csv')
398/34: gp.head()
398/35:
dates = pd.to_datetime(gp["CreateDate"])
gp.set_index(dates,inplace=True)
398/36:
gp["CreateDate"].head()
#dates = pd.to_datetime(gp["CreateDate"])
#gp.set_index(dates,inplace=True)
398/37:
gp["CreateDate"].head()
dates = pd.to_datetime(gp["CreateDate"],yearfirst=True)
#gp.set_index(dates,inplace=True)
398/38:
gp["CreateDate"].head()
dates = pd.to_datetime(gp["CreateDate"],yearfirst=True,format="%Y:%m:%d %H:%M:%S")
#gp.set_index(dates,inplace=True)
398/39:
gp["CreateDate"].head()
#dates = pd.to_datetime(gp["CreateDate"],yearfirst=True,format="%Y:%m:%d %H:%M:%S")
#gp.set_index(dates,inplace=True)
398/40:
gp["CreateDate"].head()
dates = pd.to_datetime(gp["CreateDate"],yearfirst=True,format="%Y:%m:%d %H:%M:%S")
#gp.set_index(dates,inplace=True)
398/41:
gp = pd.read_csv('ASV_UW_STILLS/20190810145243.csv')
M = gp["CreateDate"] ~= "-"
gp = gp[M]
398/42:
gp = pd.read_csv('ASV_UW_STILLS/20190810145243.csv')
M = gp["CreateDate"] != "-"
gp = gp[M]
398/43:
gp.head()
#gp["CreateDate"].head()
#dates = pd.to_datetime(gp["CreateDate"],yearfirst=True,format="%Y:%m:%d %H:%M:%S")
#gp.set_index(dates,inplace=True)
398/44:
gp.head()
#gp["CreateDate"].head()
dates = pd.to_datetime(gp["CreateDate"],yearfirst=True,format="%Y:%m:%d %H:%M:%S")
#gp.set_index(dates,inplace=True)
398/45:
gp.head()
#gp["CreateDate"].head()
dates = pd.to_datetime(gp["CreateDate"],yearfirst=True,format="%Y:%m:%d %H:%M:%S")
gp.set_index(dates,inplace=True)
398/46:
gp.head()
#gp["CreateDate"].head()
dates = pd.to_datetime(gp["CreateDate"],yearfirst=True,format="%Y:%m:%d %H:%M:%S")
gp.set_index(dates,inplace=True)
gp.head()
398/47:
# pd.concat([data, ts]).sort_index().interpolate()[ts.index]
gp2 = pd.concat([gp, nav]).sort_index().interpolate()[gp.index)]
398/48:
# pd.concat([data, ts]).sort_index().interpolate()[ts.index]
gp2 = pd.concat([gp, nav]).sort_index().interpolate()[gp.index]
398/49:
# pd.concat([data, ts]).sort_index().interpolate()[ts.index]
gp2 = pd.concat([gp, nav])
398/50: gp2.sort_index(inplace=True)
398/51: gp2.interpolate(inplace=True)
398/52: gp2 = gp[gp.index]
398/53: gp2 = gp2[gp.index]
398/54:
gp2.head()
#gp2 = gp2[gp.index]
398/55:
nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+')
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
dates = pd.to_datetime(nav["EpochTime"],unit=s)
nav.set_index(dates,inplace=True)
nav.head()
398/56:
nav = pd.read_csv('NA113_20190809_to_20190815_NadirExtraction.txt',header = None,delimiter = '\s+')
nav.columns = ['Time','EpochTime','Longitude','Latitude','Eastings','Northings','NadirDepth','BS']
dates = pd.to_datetime(nav["EpochTime"],unit="s")
nav.set_index(dates,inplace=True)
nav.head()
398/57:
# pd.concat([data, ts]).sort_index().interpolate()[ts.index]
gp2 = pd.concat([gp, nav])
398/58: gp2.sort_index(inplace=True)
398/59: gp2.interpolate(inplace=True)
398/60:
gp2.head()
#gp2 = gp2[gp.index]
398/61:
#gp2.head()
gp2 = gp2[gp.index]
gp2.head()
398/62:
# pd.concat([data, ts]).sort_index().interpolate()[ts.index]
gp2 = pd.concat([gp, nav])
398/63: gp2.sort_index(inplace=True)
398/64: gp2.interpolate(inplace=True)
398/65:
#gp2.head()
gp2 = gp2[gp.index]
gp2.head()
400/1: import os
400/2: import sys
400/3: ls
400/4: dir?
401/1: ls
401/2: cd gitsrc/kmall/
401/3: ls
401/4: ./kmall.py -h
401/5: run('kmall.py' '-h')
401/6: run('./kmall.py' '-h')
401/7: ls
401/8: import kmall
401/9: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/10: K.index_file()
401/11: reimport('kmall')
401/12: import importlib
401/13: importlib.reload(kmall)
401/14: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/15: importlib.reload(kmall)
401/16: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/17: K.index_file()
401/18: import pandas as pd
401/19: K.Index['MessageType'] = K.Index.MessageType.astype('category')
401/20: print(K.dtypes)
401/21: print(K.Index.dtypes)
401/22: K.Index.groupby('Category')['MessageType'].describe().reset_index()
401/23: K.Index.groupby("Category")["MessageType"].describe().reset_index()
401/24: print(K.Index.dtypes)
401/25: K.Index.groupby("MessageType").describe().reset_index()
401/26: K.Index.groupby("MessageType").describe().reset_index()
401/27: K.Index.groupby("MessageType").describe().reset_index()
401/28: K.Index.groupby("MessageType").describe().reset_index().head()
401/29: print(K.Index.groupby("MessageType").describe().reset_index())
401/30: print(K.Index.groupby("MessageType").describe())
401/31: pd.describe_option?
401/32: K.Index.groupby("MessageType").count()
401/33: K.Index.groupby("MessageType")['MessageType'].count()
401/34: K.Index.groupby("MessageType")['MessageSize'].count()
401/35: K.Index.groupby("MessageType")['MessageSize'].sum()
401/36: importlib.reload(kmall)
401/37: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/38: K.index_file()
401/39: K.report_packet_types()
401/40: importlib.reload(kmall)
401/41: importlib.reload(kmall)
401/42: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/43: K.index_file()
401/44: K.report_packet_types()
401/45: importlib.reload(kmall)
401/46: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/47: K.index_file()
401/48: K.report_packet_types()
401/49: msg_type_group = K.Index.groupby("MessageType")
401/50: msg_type_group.MessageType
401/51: print(msg_type_group.MessageType)
401/52: msg_type_group
401/53: print(msg_type_group)
401/54: msg_type_group.groups()
401/55: msg_type_group.groups
401/56: msg_type_group.groups.keys()
401/57: msg_type_group.count()
401/58: msg_type_group['MessageType'].count()
401/59:
summary = {"Count":     msg_type_group["MessageType"].count(),
                   "Size":      msg_type_group["MessageSize"].sum(),
                   "Min Size":  msg_type_group["MessageSize"].min(),    
                   "Max Size":  msg_type_group["MessageSize"].max()}
401/60: IndexSummary = pd.DataFrame(summary)
401/61: print(IndexSummary)
401/62: K
401/63: K.msgsize
401/64: K.msgtype[0]
401/65: ku = K.msgtype.unique()
401/66: set(K.msgtype)
401/67: a = set(K.msgtype)
401/68: K.msgtype == a[0]
401/69: a = list(set(K.msgtype))
401/70: M = K.msgtype == a[0]
401/71: M
401/72: a[0]
401/73: K.msgtype
401/74: map?
401/75: map( landa(x): x==a[0],K.msgtype)
401/76: map( landa(x) x==a[0],K.msgtype)
401/77: map( lamba(x) x==a[0],K.msgtype)
401/78: map( lamba(x): x==a[0],K.msgtype)
401/79: lambda?
401/80: map( lambda(x): x==a[0],K.msgtype)
401/81: map( lambda(x) x==a[0],K.msgtype)
401/82: map( lambda x: x==a[0],K.msgtype)
401/83: M = map( lambda x: x==a[0],K.msgtype)
401/84: sum(M)
401/85: a[0]
401/86: K.report_packet_types()
401/87: K.Index.groupby("MessageType")['MessageSize'].count()
401/88: a = {'a':12}
401/89: a{'b': 23}
401/90: a['b'] = 23
401/91: a
401/92: M = map( lambda x: x==a[0],K.msgtype)
401/93: a
401/94: a = list(set(K.msgtype))
401/95: a
401/96: a[3]
401/97: a[3] == "b'#MRZ'"
401/98: ls
401/99: FID = fopen('0007_20190513_154724_ASVBEN.kmall','r')
401/100: FID = open('0007_20190513_154724_ASVBEN.kmall','r')
401/101: import struct
401/102: fields = struct.unpack_from?
401/103: fields = struct.unpack?
401/104: fields = struct.unpack("Ic4BBHII",FID.read(20))
401/105: fields = struct.unpack("IccccBBHII",FID.read(20))
401/106: FID.seek(0)
401/107: fields = struct.unpack_from("Ic4BBHII",FID.read(20))
401/108: FID.seek(0)
401/109: fields = struct.unpack_from("IccccBBHII",FID.read(20))
401/110: FID.seek(0)
401/111: fields = struct.unpack_from("I",FID.read(4))
401/112: struct.unpack_from?
401/113: FID.seek(0)
401/114: fields = struct.unpack_from("I",FID.read(4),0)
401/115: FID.seek(0)
401/116: FID.tell()
401/117: FID
401/118: fields = struct.unpack("I",FID.read(4))
401/119: import struct
401/120: FID.seek(0)
401/121: F = struct.unpack("i",FID.read(4))
401/122: FID.close()
401/123: FID = open('0007_20190513_154724_ASVBEN.kmall','rb')
401/124: fields = struct.unpack_from("IccccBBHII",FID.read(20))
401/125: fields
401/126: fields
401/127: fields[0]
401/128: fields[1:4]
401/129: fields[1:5]
401/130: "'.join(fields[1:5])
401/131: ''.join(fields[1:5])
401/132: ''.join(str(fields[1:5]))
401/133: "".join(str(fields[1:5]))
401/134: FID.seek(0)
401/135: fields = struct.unpack_from("I4cBBHII",FID.read(20))
401/136: fields
401/137: fields[1:5]
401/138: str(fields[1:5])
401/139: map(str,fields[1:5])
401/140: a = [map(str,fields[1:5])]
401/141: a
401/142: print(a)
401/143: map(str,fields[1:5]).join()
401/144: "".join(map(str,fields[1:5]))
401/145: str(fields[1])
401/146: a = str(fields[1])
401/147: a[0]
401/148: a[1]
401/149: a[2]
401/150: fields
401/151: FID.seek(0)
401/152: fields = struct.unpack_from("I4sBBHII",FID.read(20))
401/153: fields
401/154: str(fields[1])
401/155: FID.seek?
401/156: dg.test = 'abc'
401/157: dg{'numbytes':32}
401/158: dg['numbytes']=32
401/159: dg= {}
401/160: dg['numbytes'] = 32
401/161: dg
401/162: import datetime
401/163: d = datetime.datetime.fromordinal(0)
401/164: d = datetime.datetime.fromtimestamp(0)
401/165: d
401/166: d = datetime.datetime.fromtimestamp(1)
401/167: d
401/168: d = datetime.datetime.fromtimestamp?
401/169: d = datetime.datetime(0)
401/170: d = datetime.datetime(0,0,0,0,0,1)
401/171: d = datetime.datetime(1970,1,1,0,0,1)
401/172: d
401/173: a
401/174: a
401/175: a = list(set(K.msgtype))
401/176: a
401/177: b = {}
401/178: b['abc',13]
401/179: b['abc'] = 33
401/180: b['cde'] = 33
401/181: b['cde'] = 44
401/182: b
401/183:
for k,v in b.items():
    print(k)
401/184:
for k,v in b.items():
    print(k)
    print(v)
401/185:
def print_datagram(dg):
    for k,v in dg.items():
        print("%s: %s" % k,str(v))
401/186: a
401/187: b
401/188: print_datagram(b)
401/189:
def print_datagram(dg):
    for k,v in dg.items():
        print("%s: %s" % (k,str(v)))
401/190: print_datagram(b)
401/191: d
401/192: str(d)
401/193: importlib.reload(kmall)
401/194: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/195: K.index_file()
401/196: K.check_ping_count()
401/197: importlib.reload(kmall)
401/198: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/199: K.index_file()
401/200: K.check_ping_count()
401/201: importlib.reload(kmall)
401/202: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/203: K.index_file()
401/204: K.check_ping_count()
401/205: importlib.reload(kmall)
401/206: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/207: K.index_file()
401/208: K.check_ping_count()
401/209: FID.tell?
401/210: importlib.reload(kmall)
401/211: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/212: K.index_file()
401/213: K.Index.dtypes
401/214: K.check_ping_count()
401/215: importlib.reload(kmall)
401/216: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/217: K.index_file()
401/218: K.check_ping_count()
401/219: importlib.reload(kmall)
401/220: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/221: K.index_file()
401/222: K.check_ping_count()
401/223: importlib.reload(kmall)
401/224: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/225: K.index_file()
401/226: K.check_ping_count()
401/227: dt
401/228: d
401/229: d = datetime.datetime(1970,1,1,0,0,1,.1223456)
401/230: d = datetime.datetime(1970,1,1,0,0,1,1223456)
401/231: floor(1.2345)
401/232: np.foor(1.2345)
401/233: import numpy as np
401/234: np.foor(1.2345)
401/235: np.floor(1.2345)
401/236: np.int(1.2345)
401/237: importlib.reload(kmall)
401/238: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/239: K.index_file()
401/240: K.check_ping_count()
401/241: import time
401/242: time.gmtime(1234567.89)
401/243: datetime.datetime(time.gmtime(1234567.89))
401/244: datetime.datetime.fromtimestamp(time.gmtime(1234567.89))
401/245: datetime.datetime.fromtimestamp(1234567.89)
401/246: importlib.reload(kmall)
401/247: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/248: K.check_ping_count()
401/249: importlib.reload(kmall)
401/250: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/251: K.check_ping_count()
401/252: importlib.reload(kmall)
401/253: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/254: K.check_ping_count()
401/255: importlib.reload(kmall)
401/256: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/257: K.check_ping_count()
401/258: importlib.reload(kmall)
401/259: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/260: K.check_ping_count()
401/261: importlib.reload(kmall)
401/262: importlib.reload(kmall)
401/263: importlib.reload(kmall)
401/264: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/265: K.check_ping_count()
401/266: importlib.reload(kmall)
401/267: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/268: K.check_ping_count()
401/269: importlib.reload(kmall)
401/270: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/271: K.check_ping_count()
401/272: importlib.reload(kmall)
401/273: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/274: a = K.check_ping_count()
401/275: a
401/276: K.Index
401/277: sum([x=="b'#MRZ'" for x in K.msgtype])
401/278: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-h', wdir='/Users/vschmidt/gitsrc/kmall')
401/279:

ls
401/280: ls
401/281: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/282: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/283: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/284: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/285: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/286: a = [1 ,2 3]
401/287: a = [1, 2, 3]
401/288: b = [4, 5, 6]
401/289: [x for x in a if 5 in b]
401/290: [x for x in a if b in 5]
401/291: [x for x in a if b in [5]]
401/292: [x for x,y in zip(a,b) if y==5]
401/293: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/294: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/295: importlib.reload(kmall)
401/296: ls
401/297: importlib.reload(kmall)
401/298: ls
401/299: importlib.reload(kmall)
401/300: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/301: import kmall
401/302: K = kmall.kmall('0007_20190513_154724_ASVBEN.kmall')
401/303: a = K.check_ping_count()
401/304: a
401/305: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
402/1:
for x in range(10):
    print(x)
402/2: a = [True, False, False]
402/3: b = [1 ,2 3]
402/4: b = [1 ,2, 3]
402/5: b[a]
402/6: b[int(a)]
401/306: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/307: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/308: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/309: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/310: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/311: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/312: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/313: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
403/1: import struct
403/2: struct.calcsize("4B2H3I2d11f")
403/3: struct.calcsize("4B2H3I2d21f")
403/4: int('0000006')
403/5: int(0000006)
403/6: bin(123)
403/7: int('0b100000')
403/8: int('100000')
403/9: int('100000',2)
403/10: a = {'a': 1, 'b':2}
403/11: a.a
403/12: a
403/13: a['a']
403/14:
if 'a' in a:
    print('yes')
403/15:
if 'b' in a:
    print('yes')
403/16:
if 'c' in a:
    print('yes')
401/314: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/315: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/316: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/317: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/318: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/319: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/320: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
403/17: bin(7)
403/18: bin(31)
401/321: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
403/19: bin(96)
403/20: import datetime
403/21: datetime.datetime.fromtimestamp(1557762443)
401/322: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/323: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
403/22: a
403/23: d[0] = {'a':1,'b':2}
403/24: d = {}
403/25: d = []
403/26: d[0] = {'a':1,'b':2}
403/27: d.append({'a':1,'b':2})
403/28: d.append({'a':4,'b':3})
403/29: d
403/30:
for k,v in d[0]:
    dg[k] = [x[k] for x in d]
403/31: d
403/32:
for k,v in d[0].items():
    dg[k] = [x[k] for x in d]
403/33: dg = {}
403/34:
for k,v in d[0].items():
    dg[k] = [x[k] for x in d]
403/35: dg
403/36: print(d)
401/324: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/325: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/326: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/327: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-vvv -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/328: dt
401/329: d
401/330: D = list()
401/331: D.append(d)
401/332: D.append(datetime.datetime.now())
401/333: D.append(datetime.datetime.now())
401/334: D.append(datetime.datetime.now())
401/335: D.append(datetime.datetime.now())
401/336: D.append(datetime.datetime.now())
401/337: D
401/338: np.diff(D)
401/339: np.diff(D).seconds
401/340: np.diff(x.totalseconds for x in D]
401/341: np.diff([x.totalseconds for x in D])
401/342: d
401/343: d.second
401/344: d.microsecond = 1234
401/345: d = datetime.datetime.now()
401/346: d.microseconds
401/347: d.seconds
401/348: d
401/349: d.second
401/350: d.timestamp
401/351: d.timestamp()
401/352: np.diff([x.timestamp() for x in D])
401/353: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/354: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/355: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/356: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
403/37: d
403/38: d['a'] = [1, 2]
403/39: d[0].a = [1,2]
403/40: d[0]['a]
403/41: d[0]
403/42: d[0]['a']
403/43: d[0]['a'] = [1, 2]
403/44: d[0]['b'] = [11, 22]
403/45: d[1]['a'] = [3, 4]
403/46: d[1]['b'] = [33, 44]
403/47: print(d)
403/48: dg = {}
403/49:
for k,v in d[0].items():
    dg[k] = [x[k][:] for x in d]
403/50: dg
403/51:
for k,v in d[0].items():
    dg[k] = [y for x in d for y in x]
403/52: dg
403/53: d
403/54:
for k,v in d[0].items():
    dg[k] = [item for sublist in d for item in sublist]
403/55: dg
403/56:
for k,v in d[0].items():
    dg[k] = [item for sublist in d for item in sublist[k]]
403/57: dg
401/357: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/358: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/359: dg.append(self.read_EMdgmSKM_def(FID))
403/58: D
403/59: d
403/60: dg
403/61:
for k,v in d[0].items():
    dg[k] = [item for sublist in d for item in sublist[k]]
403/62: dg
403/63:
for k,v in d[0].items():
    dg[k] = [item for sublist in d for item in sublist[k]]
403/64: dg
403/65:
for k,v in d[0].items():
    dg[k] = [item for sublist in d if isinstance(item,list) for item in sublist[k]]
403/66:
for k,v in d[0].items():
    dg[k] = [item for sublist in d if isinstance(sublist[k],list) for item in sublist[k]]
403/67: dg
403/68: d
403/69: d[0]['c'] = 55
403/70: d[1]['c'] = 66
403/71: d
403/72:
for k,v in d[0].items():
    dg[k] = [item for sublist in d if isinstance(sublist[k],list) for item in sublist[k] else for item in [sublist[k]]]
403/73:
for k,v in d[0].items():
    dg[k] = [item for sublist in d if isinstance(sublist[k],list) for item in sublist[k] else for item in list(sublist[k])]
403/74:
for k,v in d[0].items():
    dg[k] = [item for sublist in d if isinstance(sublist[k],list) for item in sublist[k]]
403/75: dg
403/76:
for k,v in d[0].items():
    dg[k] = [item[k] for sublist in d if isinstance(sublist[k],scalar)]
403/77: isinstance?
403/78: q = 3
403/79: isinstance(q)
403/80: type(q)
403/81: q = 3.0
403/82: type(q)
403/83:
for k,v in d[0].items():
    dg[k] = [item[k] for sublist in d if isinstance(sublist[k],int) or isinstance(sublist[k],float)]
403/84:
for k,v in d[0].items():
    dg[k] = [sublist[k] for sublist in d if isinstance(sublist[k],int) or isinstance(sublist[k],float)]
403/85: dg
403/86:
for k,v in d[0].items():
    dg[k] = [sublist[k] for sublist in d if isinstance(sublist[k],int) or isinstance(sublist[k],float) else item for item in sublist[k]]
403/87:
for k,v in d[0].items():
    dg[k] = [sublist[k] for sublist in d if isinstance(sublist[k],int) or isinstance(sublist[k],float) else item for sublist in d for item in sublist[k]]
403/88:
for k,v in d[0].items():
    dg[k] = [(sublist[k] for sublist in d) if isinstance(sublist[k],int) or isinstance(sublist[k],float) else (item for sublist in d for item in sublist[k])]
403/89:
for k,v in d[0].items():
    dg[k] = [sublist[k] for sublist in d if isinstance(sublist[k],int) or isinstance(sublist[k],float) else (item for sublist in d for item in sublist[k])]
403/90:
for k,v in d[0].items():
    dg[k] = [sublist[k] for sublist in d if (isinstance(sublist[k],int) or isinstance(sublist[k],float)) else (item for sublist in d for item in sublist[k])]
403/91:
for k,v in d[0].items():
    dg[k] = [sublist[k] if (isinstance(sublist[k],int) or isinstance(sublist[k],float)) else item for item in sublist[k] for sublist in d]
403/92:
for k,v in d[0].items():
    dg[k] = [sublist[k] if (isinstance(sublist[k],int) or isinstance(sublist[k],float)) else (item for item in sublist[k]) for sublist in d]
403/93: dg
403/94: dg['a]
403/95: dg['a']
403/96: print(dg['a'])
403/97:
for k,v in d[0].items():
    dg[k] = [sublist[k] if (isinstance(sublist[k],int) or isinstance(sublist[k],float)) else item for item in sublist[k] for sublist in d]
403/98:
for k,v in d[0].items():
    dg[k] = [sublist[k] if (isinstance(sublist[k],int) or isinstance(sublist[k],float)) else (item for item in sublist[k]) for sublist in d]
403/99: dg
403/100:
for k,v in d[0].items():
    dg[k] = [sublist[k] if (isinstance(sublist[k],int) or isinstance(sublist[k],float)) else (item for item in sublist[k]).items() for sublist in d]
403/101: d
403/102:
for k,v in d[0].items():
    dg[k] = [sublist[k] if (isinstance(sublist[k],int) or isinstance(sublist[k],float)) else (item. for item in sublist[k]) for sublist in d]
403/103: dg
403/104: dg['a']
403/105: dg['a'][0]
403/106: aa = dg['a'][0]
403/107: aa.gi_yieldfrom?
403/108: aa.send?
403/109: aa.send()
403/110: aa.send(1)
403/111:
for k,v in d[0].items():
    dg[k] = [sublist[k] if (isinstance(sublist[k],int) or isinstance(sublist[k],float)) else ([item for item in sublist[k]]) for sublist in d]
403/112: dg
403/113:
for k,v in d[0].items():
    dg[k] = [sublist[k] if (isinstance(sublist[k],int) or isinstance(sublist[k],float)) else (value for value in [item for item in sublist[k]]) for sublist in d]
403/114: dg
403/115:
for k,v in d[0].items():
    dg[k] = [item for itme in sublist[k] if (isinstance(sublist[k],list)) else sublist[k] for sublist in d]
403/116:
for k,v in d[0].items():
    dg[k] = [item for item in sublist[k] if (isinstance(sublist[k],list)) else (sublist[k]) for sublist in d]
403/117:
for k,v in d[0].items():
    dg[k] = [item for itme in sublist[k] if isinstance(sublist[k],list) else sublist[k] (for sublist in d)]
403/118:
for k,v in d[0].items():
    dg[k] = [(item for itme in sublist[k]) if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/119: dg
403/120:
for k,v in d[0].items():
    dg[k] = [(item for item in sublist[k]) if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/121: dg
403/122:
for k,v in d[0].items():
    dg[k] = [[(item for item in sublist[k])] if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/123: dg
403/124:
for k,v in d[0].items():
    dg[k] = [(item for item in sublist[k]) if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/125: dg
403/126:
for k,v in d[0].items():
    dg[k] = [item for item in sublist[k] if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/127:
for k,v in d[0].items():
    dg[k] = [[(item for item in sublist[k])] if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/128: flatten = lambda l: [item for sublist in l for item in sublist]
403/129:
for k,v in d[0].items():
    dg[k] = [flatten(sublist[k]) if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/130: flatten = lambda l: [item for item in l]
403/131:
for k,v in d[0].items():
    dg[k] = [flatten(sublist[k]) if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/132: dg
403/133: flatten = lambda l: [item for item in sublist for sublist in l]
403/134:
for k,v in d[0].items():
    dg[k] = [flatten(sublist[k]) if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/135:
for k,v in d[0].items():
    dg[k] = [flatten(sublist[k]) if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/136: flatten = lambda l: [item for sublist in l for item in sublist]
403/137:
for k,v in d[0].items():
    dg[k] = [flatten(sublist[k]) if isinstance(sublist[k],list) else sublist[k] for sublist in d]
403/138: flatten = lambda l: [item for item in l]
403/139:
for k,v in d[0].items():
    dg[k] = [sublist[k] if (isinstance(sublist[k],int) or isinstance(sublist[k],float)) else ([item for item in sublist[k]]) for sublist in d]
403/140: dg
403/141:
for k,v in d[0].items():
    dg[k] = [item[k] for sublist in d if isinstance(sublist[k],int) or isinstance(sublist[k],float)]
403/142:
for k,v in d[0].items():
    dg[k] = [item for item in sublist[k] if (isinstance(sublist[k],list)) else (sublist[k]) for sublist in d]
403/143:
for k,v in d[0].items():
    dg[k] = [sublist[k] for sublist in d if isinstance(sublist[k],int) or isinstance(sublist[k],float)]
403/144: dg
403/145:
for k,v in d[0].items():
    dg[k] = [item for item in sublist[k] for sublist in d if isinstance(sublist[k],list) ]
403/146:
for k,v in d[0].items():
    dg[k] = [item for item in sublist[k] if isinstance(sublist[k],list) for sublist in d]
403/147:
for k,v in d[0].items():
    dg[k] = [(item for item in sublist[k]) if isinstance(sublist[k],list) for sublist in d]
403/148:
for k,v in d[0].items():
    dg[k] = [(item for item in sublist[k]) if isinstance(sublist[k],list) (for sublist in d)]
403/149:
for k,v in d[0].items():
    dg[k] = [sublist[k] for sublist in d if isinstance(sublist[k],int) or isinstance(sublist[k],float)]
403/150:
for k,v in d[0].items(): 
    dg[k] = [item for sublist in d if isinstance(sublist[k],list) for item in sublist[k]]
403/151: dg
403/152:
for k,v in d[0].items():
    dg[k] = [item for sublist in d if (isinstance(sublist[k],list)) for sublist in d else sublist[k] for sublist in d]
403/153:
for k,v in d[0].items(): 
    dg[k] = [item for sublist in d if isinstance(sublist[k],list) for item in sublist[k]]
403/154: dg
403/155:
for k,v in d[0].items(): 
    dg[k] = [item for sublist in d if isinstance(sublist[k],list) else sublist[k] for item in sublist[k]]
403/156:
for k,v in d[0].items(): 
    dg[k] = [item for sublist in d if isinstance(sublist[k],list) for item in sublist[k] else sublist[k]]
403/157:
for k,v in d[0].items(): 
    dg[k] = [item for sublist in d if isinstance(sublist[k],list) (for item in sublist[k]) else sublist[k]]
403/158:
for k,v in d[0].items(): 
    dg[k] = [item for dictitem in d if isinstance(sublist[k],list) for item in dictitem[k]]
403/159:
for k,v in d[0].items(): 
    dg[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
403/160: dg
403/161:
for k,v in d[0].items(): 
    dg[k] = [item for dictitem in d if isinstance(dictitem[k],list) else dictitem[k] for item in dictitem[k]]
403/162:
for k,v in d[0].items(): 
    dg[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
403/163: dg
403/164:
for k,v in d[0].items():
    dg[k] = [dictitem[k] for dictitem in d if not isinstance(dictitem[k],list) for item in dictitem[k]]
403/165:
for k,v in d[0].items():
    dg[k] = [dictitem[k] for dictitem in d if not isinstance(dictitem[k],list)]
403/166: dg
403/167:
for k,v in d[0].items():
    dg[k] = [dictitem[k] for dictitem in d if not isinstance(dictitem[k],list) else dg[k]]]
403/168:
for k,v in d[0].items():
    dg[k] = [dictitem[k] if not isinstance(dictitem[k],list) else dg[k] for dictitem in d]
403/169: dg
403/170:
for k,v in d[0].items():
    dg[k] = [dictitem[k] for dictitem in d if not isinstance(dictitem[k],list)]
403/171: dg
403/172:
for k,v in d[0].items(): 
    dg[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
403/173: dg
403/174:
for k,v in d[0].items():
    dg[k] = [dictitem[k] if not isinstance(dictitem[k],list) else dg[k] for dictitem in d]
403/175: dg
403/176:
for k,v in d[0].items(): 
    dg[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
403/177: dg
403/178:
for k,v in d[0].items():
    dg[k] = [dictitem[k] if not isinstance(dictitem[k],list) for dictitem in d]
403/179:
for k,v in d[0].items():
    dg[k] = [dictitem[k] if not isinstance(dictitem[k],list) for dictitem in d]
403/180: dg
403/181:
for k,v in d[0].items():
    dg[k] = [dictitem[k] if not isinstance(dictitem[k],list) for dictitem in d]
403/182:
for k,v in d[0].items(): 
    dg[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
403/183: dg
403/184:
for k,v in d[0].items():
    dg[k] = [dictitem[k] for dictitem in d if not isinstance(dictitem[k],list)]
403/185: dg
403/186:
for k,v in d[0].items(): 
    dg[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
403/187: dg
403/188:
for k,v in d[0].items():
    dg[k] = [dictitem[k] for dictitem in d if not isinstance(dictitem[k],list) else item for item in dictitem[k]]
403/189:
for k,v in d[0].items():
    dg[k] = [dictitem[k] for dictitem in d if not isinstance(dictitem[k],list) else (item for item in dictitem[k])]
403/190:
for k,v in d[0].items():
    dg[k] = [dictitem[k] for dictitem in d if not isinstance(dictitem[k],list) else dg[k]]
403/191:
for k,v in d[0].items(): 
    dg[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
403/192: dg
403/193:
for k,v in d[0].items(): 
    dg[k] = [item (for dictitem in d if isinstance(dictitem[k],list)) for item in dictitem[k]]
403/194:
for k,v in d[0].items(): 
    dg[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
403/195: dg
403/196: dg1 = {}
403/197:
for k,v in d[0].items(): 
    dg1[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
403/198: dg1
403/199: dg2 = {}
403/200:
for k,v in d[0].items(): 
    dg1[k] = [dictitem[k] for dictitem in d if not isinstance(dictitem[k],list)]
403/201: dg1
403/202: dg = {**dg1,**dg2}
403/203: dg
403/204: dg1
403/205: dg2
403/206: dg1 = {}
403/207:
for k,v in d[0].items(): 
    dg1[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
403/208: dg1
403/209: dg2 = {}
403/210:
for k,v in d[0].items(): 
    dg2[k] = [dictitem[k] for dictitem in d if not isinstance(dictitem[k],list)]
403/211: dg2
403/212: dg = [x for x,y in zip(dg1,dg2) if len(y) == 0 else y]
403/213: dg = [x if len(y) == 0 else y for x,y in zip(dg1,dg2)]
403/214: dg
403/215: dg1
403/216: dg2
403/217:
for k,v in dg[0].items():
    dg[k] = [x[k] if len(y[k])==0 else y[k] for x,y in zip(dg1,dg2)]
403/218: dg[0]
403/219:
for k,v in dg1[0].items():
    dg[k] = [x[k] if len(y[k])==0 else y[k] for x,y in zip(dg1,dg2)]
403/220: dg1[0]
403/221: dg1
403/222:
for k,v in d[0].items():
    dg[k] = [x[k] if len(y[k])==0 else y[k] for x,y in zip(dg1,dg2)]
403/223:
for k,v in dg1:
    dg[k] = [x[k] if len(y[k])==0 else y[k] for x,y in zip(dg1,dg2)]
403/224: dg1
403/225:
for k,v in d[0].items():
    dg[k] = [x[k] if len(y[k])==0 else y[k] for x,y in zip(dg1,dg2)]
403/226: dg
403/227: dg = {}
403/228:
for k,v in d[0].items():
    dg[k] = [x[k] if len(y[k])==0 else y[k] for x,y in zip(dg1,dg2)]
403/229: dg
403/230:
for k,v in d[0].items():
    dg[k] = [x if len(y)==0 else y for x,y in zip(dg1,dg2)]
403/231: dg
403/232:
for k,v in d[0].items():
    dg[k] = [x if len(y)==0 else y for x,y in zip(dg1[k],dg2[k])]
403/233: dg
403/234: k
403/235: dg1[k]
403/236: dg2[k]
403/237: dg[k]
403/238: len(dg2[k])
403/239:
for k,v in d[0].items():
    dg[k] = [x if not len(y)==0 else y for x,y in zip(dg1[k],dg2[k])]
403/240: dg
403/241: len(dg2[k])
403/242: len(dg2[k]) == 0
403/243:
for k,v in d[0].items():
    dg[k] = [1 if len(y)==0 else y for x,y in zip(dg1[k],dg2[k])]
403/244: dg
403/245:
for k,v in d[0].items():
    dg[k] = [x if len(y)==0 else 1 for x,y in zip(dg1[k],dg2[k])]
403/246: dg
403/247:
for k,v in d[0].items():
    dg[k] = [x if len(y)==0 else y for x,y in zip(dg1[k],dg2[k])]
403/248: aa = zip(dg1[k],dg2[k])
403/249: aa
403/250: print(aa)
403/251: print(x) for x,y in aa
403/252: [x+y for x,y in aa]
403/253: aa
403/254: list(aa)
403/255:
for k,v in d[0].items():
    dg[k] = [x for x,y in zip(dg1[k],dg2[k]) if len(y)==0 else y]
403/256:
for k,v in d[0].items():
    dg[k] = [x if len(y)==0 else y for x,y in zip(dg1[k],dg2[k])]
403/257: dg
403/258:
for k,v in d[0].items():
    dg[k] = [x if len(y)==0 else y for x,y in map(None,dg1[k],dg2[k])]
403/259: dg
403/260:
for k,v in d[0].items():
    dg[k] = [x if len(y)==0 else y for x,y in zip(dg1[k],dg2[k])]
403/261: dg
403/262:
for k,v in d[0].items():
    dg[k] = [(x,y) for x,y in zip(dg1[k],dg2[k])]
403/263: dg
403/264: dg1['a']
403/265:
for k,v in d[0].items():
    if len(dg1[k]) == 0:
        dg[k] = dg2[k]
    else
403/266:
for k,v in d[0].items():
    if len(dg1[k]) == 0:
        dg[k] = dg2[k]
    else:
        dg[k] = dg1[k]
403/267: dg
401/360: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/361: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/362: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/363: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/364: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/365: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/366: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/367: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/368: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/369: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/370: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/371: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/372: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/373: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/374: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/375: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-v -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/376: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args=' -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/377: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args=' -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
401/378: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args=' -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
403/268:
for k,v in d[0].items(): 
    dg1[k] = [item for dictitem in d if isinstance(dictitem[k],list) for item in dictitem[k]]
    
    
    
a
403/269: a = [1,2,3]
403/270: a.shift()
403/271: a.remove(-1)
404/1: import kmall
404/2: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
404/3: pct = K.check_ping_count()
405/1: import kmall
405/2: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
405/3: pct = K.check_ping_count()
406/1: import kmall
406/2: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
406/3: pct = K.check_ping_count()
406/4: pct
406/5: import matplotlib.pyplot as plt
406/6: plt.plot(pct,'.')
406/7: plt.show()
406/8: max(pct)
406/9: min(pct)
406/10: max(pct)-min(pct)
406/11: len(pct)
406/12: import numpy as np
406/13: dpu = np.diff(np.sort(np.unique(pct)))
406/14: sum(dpu)
406/15: sum(dpu>1)
406/16: sum(dpu(dpu>1))
406/17: sum(dpu[dpu>1])
406/18: sum(dpu[dpu>1]) + 399
406/19: 1782 - sum(dpu[dpu>1])
406/20: plt.plot(dpu,'.')
406/21: plt.show()
406/22: plt.plot(pct,'.')
406/23: plt.show()
407/1: import kmall
407/2: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
407/3: pct = K.check_ping_count()
408/1: import kmall
408/2: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
408/3: pct = K.check_ping_count()
409/1: import kmall
409/2: import kmall
409/3: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
409/4: pct = K.check_ping_count()
409/5: a = [1,2,3,5,7]
409/6: da = diff(a)
409/7: da = np.diff(a)
409/8: import numpy as np
409/9: da = np.diff(a)
409/10: sum(da[da>1])
409/11: da[da>1]
409/12: sum((da[da>1]-1))
409/13: a = [1,2,3,5,7,10]
409/14: da = np.diff(a)
409/15: da
409/16: sum((da[da>1]-1))
410/1: import numpy as np
410/2: import kmall
410/3: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
410/4: pct = K.check_ping_count()
411/1: import kmall
411/2: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
411/3: pct = K.check_ping_count()
412/1: import kmall
412/2: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
412/3: pct = K.check_ping_count()
412/4: print('something %d' % [1,2,3])
412/5: print([1,2,3])
412/6: ":".join([1,2,3])
412/7: ":".join(str([1,2,3]))
412/8: ":".join(str(x) for x in [1,2,3])
413/1: import kmall
413/2: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
413/3: pct = K.check_ping_count()
414/1: import kmall
414/2: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
414/3: pct = K.check_ping_count()
415/1: import kmall
415/2: K = kmall.kmall("/Volumes/SCHMIDT/NA113/NA113_20190809_NikuA_ASV/0006_20190809_025035_ASVBEN.kmall")
415/3: pct = K.check_ping_count()
415/4: import matplotlib.pyplot as plt
415/5: plt.plot(pct,'.')
415/6: plt.title('K.filename')
415/7: plt.show()
415/8: plt.plot(pct,'.')
415/9: plt.title(K.filename)
415/10: plt.show()
415/11: plt.plot(pct,'.')
415/12: import os
415/13: os.path.basename(K.filename)
415/14: plt.title(os.path.basename(K.filename))
415/15: plt.ylabel('Ping Counter (pingCnt)')
415/16: plt.show()
416/1: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args=' -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/2: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args=' -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/3: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args=' -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/4: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/5: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/6: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/7: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/8: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/9: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/10: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/11: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/12: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/13: a = [1,2,3]
416/14: b = [4,5,6]
416/15: a+b
416/16: a.extend(b)
416/17: c = a.extend(b)
416/18: c
416/19: print(a)
416/20: a = [1,2,3;4,5,6]
416/21: a = [1,2,3; 4,5,6]
416/22: a = [[1,2,3],[4,5,6]]
416/23: a
416/24: b = [[2,3,4],[5,6,7]]
416/25: a.extend(b)
416/26: a
416/27: b = np.array(a)
416/28: b
416/29: runfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
416/30: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
417/1: import tabulate
418/1: pwd
418/2: cd gitsrc/vgrid/
418/3: ls
418/4: import vgrid
419/1: pwd
419/2: ls
419/3: import vgrid
419/4: G = vgrid.vgrid()
419/5: G = vgrid.vgrid(1.0,1.0,1)
419/6: import importlib
419/7: importlib.reload(vgrid)
419/8: G = vgrid.vgrid(1.0,1.0,1)
420/1: import vgrid
420/2: G = vgrid.vgrid(1.0,1.0,1)
421/1: import vgrid
421/2: G = vgrid.vgrid(1.0,1.0,1)
422/1: import vgrid
422/2: G = vgrid.vgrid(1.0,1.0,1)
423/1: import vgrid
423/2: G = vgrid.vgrid(1.0,1.0,1)
424/1: import vgrid
424/2: G = vgrid.vgrid(1.0,1.0,1)
425/1: import vgrid
425/2: G = vgrid.vgrid(1.0,1.0,1)
426/1: import vgrid
426/2: G = vgrid.vgrid(1.0,1.0,1)
426/3: G.add([0,1,0,1],[0,0,1,1],[0,1,1,2],1)
427/1: import vgrid
427/2: G = vgrid.vgrid(1.0,1.0,1)
427/3: G.add([0,1,0,1],[0,0,1,1],[0,1,1,2],1)
427/4: sum([1,3,4])
427/5: w = [1 ,2,3]
427/6:
Nzeroeight = 0
Nzeroeight +=1 for ww in w if ww==0
427/7:
Nzeroeight = 0
(Nzeroeight +=1) for ww in w if ww==0
427/8: import numpy as np
427/9: np.sum([1,3,4])
428/1: import vgrid
428/2: G = vgrid.vgrid(1.0,1.0,1)
428/3: G.add([0,1,0,1],[0,0,1,1],[0,1,1,2],1)
429/1: import vgrid
429/2: G = vgrid.vgrid(1.0,1.0,1)
429/3: G.add([0,1,0,1],[0,0,1,1],[0,1,1,2],1)
430/1: import vgrid
430/2: G = vgrid.vgrid(1.0,1.0,1)
430/3: G.add([0,1,0,1],[0,0,1,1],[0,1,1,2],1)
431/1: import vgrid
431/2: G = vgrid.vgrid(1.0,1.0,1)
431/3: G.add([0,1,0,1],[0,0,1,1],[0,1,1,2],1)
431/4: G.add([0,1,0,1],[0,0,1,1],[0,1,1,2],[1 1 1 1])
431/5: G.add([0,1,0,1],[0,0,1,1],[0,1,1,2],[1,1,1,1])
431/6: import numpy as np
431/7: np.version
431/8: np.version.version
432/1: import numpy as np
432/2: np.version.version
432/3: import vgrid
432/4: G = vgrid.vgrid(1.0,1.0,1)
432/5: G.add([0,1,0,1],[0,0,1,1],[0,1,1,2],[1,1,1,1])
432/6: w = [1, 2,3]
432/7: np.size(w)
432/8: w.size
432/9: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
432/10: np.min(w)
433/1: import vgrid
433/2: G = vgrid.vgrid(1.0,1.0,1)
433/3: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
433/4: import numpy as np
433/5: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
434/1: import numpy as np
434/2: import vgrid
434/3: G = vgrid.vgrid(1.0,1.0,1)
434/4: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
434/5: np.flatnonzero?
435/1: import numpy as np
435/2: import vgrid
435/3: G = vgrid.vgrid(1.0,1.0,1)
435/4: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
436/1: import numpy as np
436/2: import vgrid
436/3: G = vgrid.vgrid(1.0,1.0,1)
436/4: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
437/1: import numpy as np
437/2: import vgrid
437/3: G = vgrid.vgrid(1.0,1.0,1)
437/4: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
438/1: import numpy as np
438/2: import vgrid
438/3: G = vgrid.vgrid(1.0,1.0,1)
438/4: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
438/5: np.append?
438/6: np.nansum([np.nan,3])
439/1: import numpy as np
439/2: import vgrid
439/3: G = vgrid.vgrid(1.0,1.0,1)
439/4: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
440/1: import numpy as np
440/2: import vgrid
440/3: G = vgrid.vgrid(1.0,1.0,1)
440/4: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
441/1: import numpy as np
441/2: import vgrid
441/3: G = vgrid.vgrid(1.0,1.0,1)
441/4: G.add(np.array([0,1,0,1]),np.array([0,0,1,1]),np.array([0,1,1,2]),np.array([1,1,1,1]))
442/1: pwd
442/2: cd gitsrc/kmall/
442/3: ls
442/4: ./kmall.py -h
442/5: run kmall.py
442/6: run kmall.py -h
442/7: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/8: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/9: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/10: ls
442/11: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/12: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/13: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/14: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/15: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/16: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/17: import pandas as pd
442/18: D = pd.Dataframe([[1,2],[2 3]])
442/19: D = pd.Dataframe([[1,2],[2, 3]])
442/20: D = pd.DataFrame([[1,2],[2, 3]])
442/21: print(D)
442/22: D.columns=['A','B']
442/23: print(D)
442/24: D.set_value?
442/25: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/26: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/27: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/28: print("%*-s","1.234")
442/29: print("%-s","1.234")
442/30: print("%-s" % "1.234")
442/31: print("%-s\t%-s" % ["1.234","3.4556"])
442/32: print("%-s\t%-s" % ("1.234","3.4556"))
442/33: import terminaltables
442/34: import termtables
442/35: import prettytables
442/36: import PrettyTables
442/37: print("%-f\t%-f" % (1.234,3.4533356))
442/38: print("%*-f\t%*-f" % (1.234,3.4533356))
442/39: print("%-*f\t%-*f" % (1.234,3.4533356))
442/40: print("%-f%-f" % (1.234,3.4533356))
442/41: print("%-f   %-f" % (1.234,3.4533356))
442/42: print("%-f   %3-f" % (1.234,3.4533356))
442/43: print("%-f   %-3f" % (1.234,3.4533356))
442/44: print("%-f   %-3.2f" % (1.234,3.4533356))
442/45: print("%-f   %-3.4f" % (1.234,3.4533356))
442/46: print("%-f   %3.4f" % (1.234,3.4533356))
442/47: print("%-12f   %-12f" % (1.234,3.4533356))
442/48: print("%-15f   %-15f" % (1.234,3.4533356))
442/49: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/50: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/51: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/52: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
442/53: run kmall.py -f 0007_20190513_154724_ASVBEN.kmall -V
445/1:
%mabplotlib inline
import numpy as np
from filterpy.kalman import UnscentedKalmanFilter
from filterpy.common import Q_discrete_white_noise
from filterpy.kalman import unscented_transform, MerweScaledSigmaPoints
import matplotlib.pyplot as plt
445/2:
%matplotlib inline
import numpy as np
from filterpy.kalman import UnscentedKalmanFilter
from filterpy.common import Q_discrete_white_noise
from filterpy.kalman import unscented_transform, MerweScaledSigmaPoints
import matplotlib.pyplot as plt
446/1: import vgrid_v1p0
446/2: G = vgrid_v1p0.vgrid()
446/3: import numpy as np
446/4: xx = np.random.rand((100,100))
446/5: xx = np.random.rand?
446/6: xx = np.random.rand(100,100)
446/7: y = np.random.rand(100,100)
446/8: yy = y
446/9: zz = xx + yy
446/10: import matplotlib.pyplot as plt
446/11: plt.plot(xx,yy,zz,'.')
446/12: G.add(xx,yy,zz,1)
446/13: plt.image(G.xx,G.yy,G.zz())
446/14: plt.imagesc(G.xx,G.yy,G.zz())
446/15: plt.imshow(G.xx,G.yy,G.zz())
446/16: plt.imshow(G.zz())
446/17: xx = np.random.random?
446/18: xx = np.random.random((1000,1))*100
446/19: plt.plot(xx,'.')
446/20: plt.plot(xx,'.')
446/21: yy = np.random.random((1000,1))*100
446/22: zz = np.exp( 1/np.sqrt(xx**2 + yy**2))
446/23: plt.scatter(xx,yy,zz)
446/24: plt.scatter(xx,yy,zz,zz)
446/25: plt.scatter?
446/26: plt.scatter(xx,yy,zz,c=zz)
446/27: zz = np.exp( 1/np.sqrt((xx-50)**2 + (yy-50)**2))
446/28: plt.scatter(xx,yy,zz,s=zz,c=zz)
446/29: plt.scatter(xx,yy,zz,c=zz)
446/30: G = vgrid_v1p0.vgrid()
446/31: G.add(xx,yy,zz,1)
446/32: plt.imshow(G.zz())
446/33: xx.size
446/34: xx = np.random.random((10000,1))*100
446/35: yy = np.random.random((10000,1))*100
446/36: zz = np.exp( 50/np.sqrt((xx-50)**2 + (yy-50)**2))
446/37: plt.scatter(xx,yy,zz,c=zz)
447/1: cd gitsrc/vgrid/
447/2: import vgrid_v1p0
447/3: import numpy as np
447/4: import matplotlib.pyplot as plt
447/5: G = vgrid_v1p0.vgrid()
447/6: xx = np.random.random((10000,1))*100
447/7: yy = np.random.random((10000,1))*100
447/8: zz = np.exp( 50.0/np.sqrt((xx-50)**2 + (yy-50)**2))
447/9: plt.plot3(xx,yy,zz,'.')
447/10: plt.plot3D(xx,yy,zz,'.')
447/11: plt.plot(xx,yy,zz,'.')
447/12: plt.plot(xx,yy,zz,'.')
447/13: zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
447/14: plt.scatter(xx,yy,zz,c=zz)
447/15: G.add(xx,yy,zz,1)
447/16: plt.imshow(G.zz())
447/17: ls
447/18: !less vgrid.py
449/1: run('./vgrid_v1p0.py')
449/2: run('vgrid_v1p0.py')
449/3: run('vgrid_v1p0')
449/4: run ./vgrid_v1p0.py
449/5: vi vgrid_v1p0.py
448/1: import line_profiler as LineProfiler
448/2: lp = LineProfiler()
448/3: lp = LineProfiler.LineProfiler()
448/4: lp.print_stats?
448/5: lp.get_stats?
448/6: import numpya as np
448/7: import numpy as np
448/8: np.nanvar?
448/9: ls
448/10: !cd /Users/vschmidt/gitsrc/vgrid
448/11: ls
448/12: cd gitsrc/vgrid
448/13: ls
448/14: import vgrid_v1p0 as vgrid
448/15: G = vgrid.vgrid()
448/16: import numpy as np
448/17: xx = np.random.random((10000,1))*100
448/18: yy = np.random.random((10000,1))*100
448/19: zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
448/20: G.add(xx,yy,zz,1)
448/21: np.power?
448/22: import importlib
448/23: importlib.reload(vgrid_v1p0.py)
448/24: importlib.reload('vgrid_v1p0.py')
448/25: importlib.reload(vgrid)
448/26: G = vgrid.vgrid()
448/27: G.add(xx,yy,zz,1)
448/28: importlib.reload(vgrid)
448/29: G = vgrid.vgrid()
448/30: G.add(xx,yy,zz,1)
448/31: importlib.reload(vgrid)
448/32: G = vgrid.vgrid()
448/33: G.add(xx,yy,zz,1)
448/34: importlib.reload(vgrid)
448/35: G = vgrid.vgrid()
448/36: G.add(xx,yy,zz,1)
448/37: importlib.reload(vgrid)
448/38: G = vgrid.vgrid()
448/39: G.add(xx,yy,zz,1)
448/40: importlib.reload(vgrid)
448/41: G = vgrid.vgrid()
448/42: G.add(xx,yy,zz,1)
448/43: importlib.reload(vgrid)
448/44: G = vgrid.vgrid()
448/45: G.add(xx,yy,zz,1)
448/46: importlib.reload(vgrid)
448/47: G = vgrid.vgrid()
448/48: G.add(xx,yy,zz,1)
448/49: importlib.reload(vgrid)
448/50: G = vgrid.vgrid()
448/51: G.add(xx,yy,zz,1)
448/52: importlib.reload(vgrid)
448/53: G = vgrid.vgrid()
448/54: G.add(xx,yy,zz,1)
448/55: importlib.reload(vgrid)
448/56: G = vgrid.vgrid()
448/57: G.add(xx,yy,zz,1)
448/58: importlib.reload(vgrid)
448/59: G = vgrid.vgrid()
448/60: G.add(xx,yy,zz,1)
448/61: importlib.reload(vgrid)
448/62: G = vgrid.vgrid()
448/63: G.add(xx,yy,zz,1)
448/64: importlib.reload(vgrid)
448/65: G = vgrid.vgrid()
448/66: G.add(xx,yy,zz,1)
448/67: importlib.reload(vgrid)
448/68: G = vgrid.vgrid()
448/69: G.add(xx,yy,zz,1)
448/70: importlib.reload(vgrid)
448/71: G = vgrid.vgrid()
448/72: G.add(xx,yy,zz,1)
448/73: importlib.reload(vgrid)
448/74: G = vgrid.vgrid()
448/75: G.add(xx,yy,zz,1)
448/76: importlib.reload(vgrid)
448/77: G = vgrid.vgrid()
448/78: G.add(xx,yy,zz,1)
448/79: importlib.reload(vgrid)
448/80: G = vgrid.vgrid()
448/81: G.add(xx,yy,zz,1)
448/82: importlib.reload(vgrid)
448/83: G = vgrid.vgrid()
448/84: G.add(xx,yy,zz,1)
448/85: importlib.reload(vgrid)
448/86: G = vgrid.vgrid()
448/87: G.add(xx,yy,zz,1)
448/88: var = G.var()
448/89: var = G.varw()
448/90: import matplotlib.pyplot as plt
448/91: plt.pcolor(var)
448/92: plt.colorbar()
448/93: plt.pcolor(G.nn)
448/94: importlib.reload(vgrid)
448/95: plt.pcolor(G.nn)
448/96: importlib.reload(vgrid)
448/97: G = vgrid.vgrid()
448/98: G.add(xx,yy,zz,1)
448/99: pcolor(G.varw())
448/100: plt.pcolor(G.varw())
448/101: ax = plt.axes(projection='3d')
448/102: from mpl_toolkits import mplot3d
448/103: ax = plt.axes(projection='3d')
448/104: ax.plot_surface(G.xx,G.yy,G.zz(),edgecolor=None)
448/105: plt.show()
448/106: ax.plot_surface(G.zz(),edgecolor=None)
448/107: ax.plot_surface?
448/108: X,Y = np.meshgrid(G.xx,G.yy)
448/109: ax.plot_surface(X,Y,G.zz(),edgecolor=None)
448/110: plt.show()
448/111: ax.plot_surface(X,Y,G.zz(),edgecolor=None)
448/112: ax.plot_surface(X,Y,G.zz(),edgecolor=None,cmap='viridis')
448/113: plt.show()
448/114: ax.show()
448/115: fig = figure()
448/116: fig = plt.figure()
448/117: ax = plt.axes(projection='3d')
448/118: ax.plot_surface(X,Y,G.zz(),edgecolor=None,cmap='viridis')
448/119: plt.pcolor(G.zz())
448/120: plt.colorbar()
448/121: 101*101
448/122: zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
448/123: import scipy.spatial as spatial
448/124: tree = spatial.KDTree(zip(xx.ravel(),yy.ravel()))
448/125: xx.shape
448/126: xx.ravel().shape
448/127: tree = spatial.KDTree(zip(xx,yy))
448/128: tree = spatial.KDTree?
450/1: import scipy.spatial as spatial
450/2: import scipy
450/3: tree = spatial.KDTree?
450/4: import vgrid
450/5: ~ls
450/6: ls
450/7: ipython
450/8: import scipy.spatial as spatial
450/9: tree = spatial.KDTree(zip(xx,yy))
450/10: xx = np.random.random((10000,1))*100
450/11: import numpy as np
450/12: xx = np.random.random((10000,1))*100
450/13: yy = np.random.random((10000,1))*100
450/14: tree = spatial.KDTree(zip(xx,yy))
450/15: a = zip(xx,yy)
450/16: a[0]
450/17: tree = spatial.KDTree([zip(xx,yy)])
450/18:
tree = spatial.KDTree(a)
)
450/19: tree = spatial.KDTree(a)
450/20: a.shape
450/21: a = zip(xx.ravel(),yy.ravel())
450/22: tree = spatial.KDTree(a)
450/23: np.shape(a)
450/24: whos
450/25: a = list(zip(xx.ravel(),yy.ravel()))
450/26: np.shape(a)
450/27: tree = spatial.KDTree(a)
450/28: x,y = np.mgrid?
450/29: x,y = np.mgrid(0:100,0:100)
450/30: x = range(100)
450/31: y = range(100)
450/32: print(x)
450/33: import numpy as np
450/34: np.range(100)
450/35: x = np.array(range(100))
450/36: y = np.array(range(100))
450/37: print(x)
450/38: r = tree.query_ball_point(zip(x.ravel(),y.ravel()), 5, p=2)
450/39: r = tree.query_ball_point([x.ravel(),y.ravel()], 5, p=2)
450/40: points = zip(x,ravel(),y.ravel())
450/41: wohs
450/42: whos
450/43: r = tree.query_ball_point([x,y], 5, p=2)
450/44: r = tree.query_ball_point([x;y], 5, p=2)
450/45: r = tree.query_ball_point([x,y], 5, p=2)
450/46: r = tree.query_ball_point([x.ravel(),y.ravel()], 5, p=2)
450/47: whos
450/48: b = zip(x,ravel(),y.ravel())
450/49: b = zip(x.ravel(),y.ravel())
450/50: r = tree.query_ball_point(b, 5, p=2)
450/51: b
450/52: b = [x,:,y]
450/53: delete b
450/54: remove b
450/55: b = []
450/56: b(:,0] = x.ravel()
450/57: x.flatten()
450/58: x.ravel()
450/59: c = hstack(x,y)
450/60: c = np.hstack(x,y)
450/61: c = np.hstack((x,y))
450/62: c
450/63: c = np.vstack((x,y))
450/64: c
450/65: c'
450/66: c.T
450/67: whos
450/68: x
450/69: xxx,yyy = np.meshgrid(x,y)
450/70: xxx
450/71: c = np.vstack((x,y)).T
450/72: c
450/73: c = np.vstack((xxx,yyy)).T
450/74: c
450/75: r = tree.query_ball_point(c, 5, p=2)
450/76: c = np.vstack((xxx.ravel(),yyy.ravel())).T
450/77: c
450/78: r = tree.query_ball_point(c, 5, p=2)
450/79: r[0]
450/80: r.shape
450/81: r[0]
450/82: r[1]
450/83: import matplotlib.pyplot as plt
450/84: plt.scatter(xx,yy,'.')
450/85: wohs
450/86: whos
450/87: plt.plot(xx,yy,'.')
450/88: plt.plot(xx[r[0]],yy[r[0]],'.r')
450/89: plt.plot(xx[r[1]],yy[r[1]],'.y')
450/90: plt.plot(xx[r[2]],yy[r[2]],'.k')
450/91: plt.plot(xx[r[50]],yy[r[50]],'.r')
450/92: history
450/93:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())),1,p=2)
    zz = [for idx in indexes do np.nanmean(z[idx])]
450/94:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())),1,p=2)
    zz = [np.nanmean(z[idx]) for idx in indexes]
    return zz
450/95: whos
450/96: zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
450/97: zz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/98: history
450/99:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,1,p=2)
    zz = [np.nanmean(z[idx]) for idx in indexes]
    return zz
450/100: zz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/101: zz.shape()
450/102: zz
450/103:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,1,p=2)
    zz = np.array(np.nanmean(z[idx]) for idx in indexes).reshape(xx.shape)
    return zz
450/104: zz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/105:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,1,p=2)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xx.shape)
    return zz
450/106: zz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/107:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,1,p=2)
    zz = [np.nanmean(z[idx]) for idx in indexes].reshape(xx.shape)
    return zz
450/108: zz = kdtreego(xx[0:1000],yy[0:1000],zz[0:1000],xxx,yyy,1.0)
450/109:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,1,p=2)
    zz = [np.nanmean(z[idx]) for idx in indexes]
    return zz
450/110: zz = kdtreego(xx[0:1000],yy[0:1000],zz[0:1000],xxx,yyy,1.0)
450/111:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())),1,p=2)
    zz = [np.nanmean(z[idx]) for idx in indexes]
    return zz
450/112: zz = kdtreego(xx[0:1000],yy[0:1000],zz[0:1000],xxx,yyy,1.0)
450/113:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,r=r,p=2)
    zz = [np.nanmean(z[idx]) for idx in indexes]
    return zz
450/114: zz = kdtreego(xx[0:1000],yy[0:1000],zz[0:1000],xxx,yyy,1.0)
450/115: zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
450/116: zzz = kdtreego(xx[0:1000],yy[0:1000],zz[0:1000],xxx,yyy,1.0)
450/117: zzz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/118: plt.plot3D(xxx,yyy,zzz,'.')
450/119: zzz.shape
450/120: size(zzz)
450/121:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,r=r,p=2)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xx.shape())
    return zz
450/122: zzz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/123:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())))
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,r=r,p=2)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xx.shape)
    return zz
450/124: zzz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/125: whos
450/126: pyplot.scatter(xxx,yyy,zzz,zzz)
450/127: plt.scatter(xxx,yyy,zzz,zzz)
450/128: import vgrid
450/129: pwd
450/130: cd gitsrc/vgrid
450/131: import vgrid
450/132: import vgrid
450/133: G = vgrid.vgrid()
450/134: G.add(xxx,yyy,zzz)
450/135: G.add(xxx,yyy,zzz,1)
450/136: G = vgrid.vgrid()
450/137: G.add(x,y,z)
450/138: G.add(xx,yy,zz)
450/139: G.add(xx,yy,zz,w)
450/140: G.add(xx,yy,zz,1)
450/141:
def dovgrid(xx,yy,zz,xxx,yyy,r):
    G = vgrid.vgrid(cs=1,cinf=1.0)
    G.add(xx,yy,zz,1)
    return G.zz()
450/142: whos
450/143: vgz = dovgrid(xx,yy,zz,xxx,yyy,1.0)
450/144: vgz.shape
450/145: zzz.shape
450/146:
def kdtreego(x,y,z,xx,yy,r):
    tree = spatial.KDTree(list(zip(xx.ravel(),yy.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,r=r,p=2)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xx.shape)
    return zz
450/147: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/148: xxx = np.arange(min(x),max(x)+1,1)
450/149: yyy = np.arange(min(y),max(y)+1,1)
450/150: xxx.shape
450/151: vgz = dovgrid(xx,yy,zz,xxx,yyy,1.0)
450/152: vgz.shape
450/153: sum(sum(vgz-zz))
450/154: sum(sum(vgz-zzz))
450/155: sum(sum(vgz-kdz))
450/156: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/157: xxx
450/158: yyy
450/159:
def kdtreego(x,y,z,xx,yy,r):
    xxx,yyy = np.meshgrid(xx,yy)
    tree = spatial.KDTree(list(zip(xxx.ravel(),yyy.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,r=r,p=2)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xx.shape)
    return zz
450/160: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/161: kdz.shape
450/162: xxx.shape
450/163: yyy.shape
450/164: a,b = np.meshgrid(xxx,yyy)
450/165: a.shape
450/166: b.shape
450/167:
def kdtreego(x,y,z,xx,yy,r):
    xxx,yyy = np.meshgrid(xx,yy)
    print(xxx.shape)
    tree = spatial.KDTree(list(zip(xxx.ravel(),yyy.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,r=r,p=2)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xx.shape)
    return zz
450/168: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/169: kdz.shape
450/170: x.shape
450/171: xx.shape
450/172: yy.shape
450/173: zz.shape
450/174:
def kdtreego(x,y,z,xx,yy,r):
    xxx,yyy = np.meshgrid(xx,yy)
    print(xxx.shape)
    tree = spatial.KDTree(list(zip(xxx.ravel(),yyy.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,r=r,p=2)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xx.shape)
    return zz
450/175: kdz = []
450/176: whos
450/177: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/178: kdz
450/179: xx.shape
450/180: yy.shape
450/181: zz.shape
450/182: xxx.shape
450/183:
def kdtreego(x,y,z,xx,yy,r):
    xxx,yyy = np.meshgrid(xx,yy)
    print(xxx.shape)
    tree = spatial.KDTree(list(zip(xxx.ravel(),yyy.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xx.ravel(),yy.ravel())).T,r=r,p=2)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape)
    return zz
450/184: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/185:
def kdtreego(x,y,z,xx,yy,r):
    xxx,yyy = np.meshgrid(xx,yy)
    print(xxx.shape)
    tree = spatial.KDTree(list(zip(xxx.ravel(),yyy.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape)
    return zz
450/186: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/187:
def kdtreego(x,y,z,xx,yy,r):
    xxx,yyy = np.meshgrid(xx,yy)
    tree = spatial.KDTree(list(zip(xxx.ravel(),yyy.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape)
    return zz
450/188: import timeit
450/189: kdz.shape
450/190: vgz.shape
450/191: vgz = dovgrid(xx,yy,zz,xxx,yyy,1.0)
450/192: import importlib
450/193: importlib.reload(vgrid)
450/194: vgz = dovgrid(xx,yy,zz,xxx,yyy,1.0)
450/195: xxx.shape
450/196: xxx
450/197: xxx = np.arange(min(xx),max(xx)+1,1)
450/198: yyy = np.arange(min(yy),max(yy)+1,1)
450/199: xxx.shape
450/200: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/201:
def kdtreego(x,y,z,xx,yy,r):
    xxx,yyy = np.meshgrid(xx,yy)
    tree = spatial.KDTree(list(zip(xxx.ravel(),yyy.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2)
    print(idx) for idx in indexes if np.any(idx > x.ravel().size)
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape)
    return zz
450/202:
def kdtreego(x,y,z,xx,yy,r):
    xxx,yyy = np.meshgrid(xx,yy)
    tree = spatial.KDTree(list(zip(xxx.ravel(),yyy.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2)
    [print(idx) for idx in indexes if np.any(idx > x.ravel().size)]
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape)
    return zz
450/203: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/204:
def kdtreego(x,y,z,xx,yy,r):
    xxx,yyy = np.meshgrid(xx,yy)
    tree = spatial.KDTree(list(zip(xxx.ravel(),yyy.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2)
    [print(idx) for idx in indexes if np.any(np.array(idx) > x.ravel().size)]
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape)
    return zz
450/205: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/206: whos
450/207:
def kdtreego(x,y,z,xx,yy,r):
    xxx,yyy = np.meshgrid(xx,yy)
    tree = spatial.KDTree(list(zip(x.ravel(),y.ravel())),leafsize=1e7)
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2)
    [print(idx) for idx in indexes if np.any(np.array(idx) > x.ravel().size)]
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape)
    return zz
450/208: kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/209: kdz.shape
450/210: vgz-kdz
450/211: sum(vgz==kdz)
450/212: sum(vgz!=kdz)
450/213: importlib.reload(vgrid)
450/214: vgz = dovgrid(xx,yy,zz,xxx,yyy,1.0)
450/215: sum(vgz!=kdz)
450/216: plt.scatter(xxx,yyy,vgz,vgz)
450/217: whos
450/218: plt.scatter(xxx,yyy,vgz,vgz)
450/219: whos
450/220: xxx.shape
450/221: vgz.shape
450/222: xp,yp = meshgrid(xxx,yyy)
450/223: xp,yp = np.meshgrid(xxx,yyy)
450/224: plt.scatter(xp,yp,vgz,vgz)
450/225: figure
450/226: plt.figure()
450/227: plt.scatter(xp,yp,vgz,kdz)
450/228: plt.figure
450/229: plt.figure()
450/230: plt.scatter(xp,yp,vgz,kdz-vgz)
450/231: colorbar
450/232: plt.colorbar
450/233: plt.colorbar()
450/234: from mpl_toolkits import mplot3d
450/235: plt.plot(kdz-vgz,'.')
450/236: plt.figure()
450/237: plt.plot(kdz-vgz,'.')
450/238: sum(np.abs(kdz-vgz) < 1e-10)
450/239: sum(np.abs(kdz-vgz) > 1e-10)
450/240: timeit?
450/241: timeit(kdtreego(xx,yy,zz,xxx,yyy,1.0))
450/242: %timeit kdz = kdtreego(xx,yy,zz,xxx,yyy,1.0)
450/243: %timeit vgz = dovgrid(xx,yy,zz,xxx,yyy,1.0)
451/1:
import numpy as np
import vgrid
import scipy.spatial
451/2: %ls
451/3: %lsmagic
451/4:
import numpy as np
import vgrid
import scipy.spatial
%matplotlib notebook
import matplotlib.pyplot as plt
450/244: history
451/5:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,c=zz)
451/6:
import numpy as np
import vgrid
import scipy.spatial
%matplotlib notebook
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
451/7:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,c=zz)
451/8:
import numpy as np
import vgrid
import scipy.spatial
%matplotlib notebook
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
451/9:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,c=cm.viridis)
451/10:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,cmap=cm.viridis)
451/11:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,cmap=cm.viridis)
plt.show()
451/12:
import numpy as np
import vgrid
import scipy.spatial
%matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
451/13:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt((xx-50)**2 + (yy-50)**2)/50.0)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,cmap=cm.viridis)
plt.show()
451/14:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( ((xx-50)**2 + (yy-50))**2)/50.0)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,cmap=cm.viridis)
plt.show()
451/15:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( ((xx-50)**2 + (yy-50)**2)/50.0)
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,cmap=cm.viridis)
plt.show()
451/16:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( ((xx-50)**2 + (yy-50)**2)/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,cmap=cm.viridis)
plt.show()
451/17:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( ((xx-50)**2 + (yy-50)**2)/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,cmap=cm.viridis)
plt.show()
np.max(zz)
451/18:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt(((xx-50)**2 + (yy-50)**2)/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,cmap=cm.viridis)
plt.show()
np.max(zz)
451/19:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt(((xx-50)**2 + (yy-50)**2))/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,cmap=cm.viridis)
plt.show()
np.max(zz)
451/20:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt(((xx-50)**2 + (yy-50)**2))/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,zz,cmap=cm.viridis)
plt.show()
np.max(zz)
451/21:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt(((xx-50)**2 + (yy-50)**2))/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,c=zz,cmap=cm.viridis)
plt.show()
np.max(zz)
451/22:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt(((xx-50)**2 + (yy-50)**2))/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,zz,cmap=cm.viridis)
plt.show()
np.max(zz)
451/23:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt(((xx-50)**2 + (yy-50)**2))/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,zz,cmap=cm.viridis)
plt.show()
450/245: whos
451/24:
def kdtreego(x,y,z,r): 
    xxx = np.arange(min(x),max(x)+1,1) 
    yyy = np.arange(min(y),max(y)+1,1) 
    xxx,yyy = np.meshgrid(xx,yy) 
    tree = spatial.KDTree(list(zip(x.ravel(),y.ravel())),leafsize=1e7) 
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2) 
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape) 
    return zz 

def dovgrid(xx,yy,zz,r):  
    G = vgrid.vgrid(cs=1,cinf=1.0)  
    G.add(xx,yy,zz,1)  
    return G.zz()
451/25:
# Test to ensure we get the same results:
kd_z = kdtreego(xx,yy,zz,1.0)
vg_z = dovgrid(xx,yy,zz,1.0)

np.sum(np.abs(kd_z - vg_z).ravel() > 1e-10)
451/26:
import numpy as np
import vgrid
import scipy.spatial as spatial
%matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
451/27:
def kdtreego(x,y,z,r): 
    xxx = np.arange(min(x),max(x)+1,1) 
    yyy = np.arange(min(y),max(y)+1,1) 
    xxx,yyy = np.meshgrid(xx,yy) 
    tree = spatial.KDTree(list(zip(x.ravel(),y.ravel())),leafsize=1e7) 
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2) 
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape) 
    return zz 

def dovgrid(xx,yy,zz,r):  
    G = vgrid.vgrid(cs=1,cinf=1.0)  
    G.add(xx,yy,zz,1)  
    return G.zz()
451/28:
# Test to ensure we get the same results:
kd_z = kdtreego(xx,yy,zz,1.0)
vg_z = dovgrid(xx,yy,zz,1.0)

np.sum(np.abs(kd_z - vg_z).ravel() > 1e-10)
452/1:
import numpy as np
import vgrid
import scipy.spatial as spatial
%matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
452/2:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt(((xx-50)**2 + (yy-50)**2))/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,zz,cmap=cm.viridis)
plt.show()
452/3:
def kdtreego(x,y,z,r): 
    xxx = np.arange(min(x),max(x)+1,1) 
    yyy = np.arange(min(y),max(y)+1,1) 
    xxx,yyy = np.meshgrid(xx,yy) 
    tree = spatial.KDTree(list(zip(x.ravel(),y.ravel())),leafsize=1e7) 
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2) 
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape) 
    return zz 

def dovgrid(xx,yy,zz,r):  
    G = vgrid.vgrid(cs=1,cinf=1.0)  
    G.add(xx,yy,zz,1)  
    return G.zz()
452/4:
# Test to ensure we get the same results:
kd_z = kdtreego(xx,yy,zz,1.0)
vg_z = dovgrid(xx,yy,zz,1.0)

np.sum(np.abs(kd_z - vg_z).ravel() > 1e-10)
454/1:
import numpy as np
import vgrid
import scipy.spatial as spatial
%matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
454/2:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt(((xx-50)**2 + (yy-50)**2))/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,zz,cmap=cm.viridis)
plt.show()
455/1: whos
454/3: whos
454/4:
def kdtreego(x,y,z,r): 
    xxx = np.arange(min(x),max(x)+1,1) 
    yyy = np.arange(min(y),max(y)+1,1) 
    xxx,yyy = np.meshgrid(xx,yy) 
    tree = spatial.KDTree(list(zip(x.ravel(),y.ravel())),leafsize=1e7) 
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2) 
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape) 
    return zz 

def dovgrid(xx,yy,zz,r):  
    G = vgrid.vgrid(cs=1,cinf=1.0)  
    G.add(xx,yy,zz,1)  
    return G.zz()
454/5: test = kdtreego(x[:10],y[:10],z[:10],1)
454/6: test = kdtreego(xz[:10],yy[:10],zz[:10],1)
454/7: test = kdtreego(xx[:10],yy[:10],zz[:10],1)
456/1:
import numpy as np
import vgrid
import scipy.spatial as spatial
%matplotlib inline
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
456/2:
xx = np.random.random((10000,1))*100 
yy = np.random.random((10000,1))*100  
zz = np.exp( np.sqrt(((xx-50)**2 + (yy-50)**2))/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,zz,cmap=cm.viridis)
plt.show()
456/3: x = xx
456/4: y = yy
456/5: z = zz
456/6: xxx = np.arange(min(x),max(x)+1,1)
456/7: yyy = np.arange(min(y),max(y)+1,1)
456/8: whos
456/9: print(xxx)
456/10: tree = spatial.KDTree(list(zip(x.ravel(),y.ravel())),leafsize=1e7)
456/11:
def kdtreego(x,y,z,r): 
    # Create the grid nodes.
    xx = np.arange(min(x),max(x)+1,1) 
    yy = np.arange(min(y),max(y)+1,1) 
    xxx,yyy = np.meshgrid(xx,yy)
    # Create the KDTree and the grid.
    tree = spatial.KDTree(list(zip(x.ravel(),y.ravel())),leafsize=1e7) 
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2) 
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape) 
    return zz 

def dovgrid(xx,yy,zz,r):  
    G = vgrid.vgrid(cs=1,cinf=1.0)  
    G.add(xx,yy,zz,1)  
    return G.zz()
456/12:
# Test to ensure we get the same results:
kd_z = kdtreego(xx,yy,zz,1.0)
vg_z = dovgrid(xx,yy,zz,1.0)

np.sum(np.abs(kd_z - vg_z).ravel() > 1e-10)
456/13:
# Test processing time.
%timeit kd_z = kdtreego(xx,yy,zz,1.0)
%timeit vg_z = dovgrid(xx,yy,zz,1.0)
456/14:
def kdtreego(x,y,z,r): 
    # Create the grid nodes.
    xx = np.arange(min(x),max(x)+1,1) 
    yy = np.arange(min(y),max(y)+1,1) 
    xxx,yyy = np.meshgrid(xx,yy)
    # Create the KDTree and the grid.
    tree = spatial.KDTree(list(zip(x.ravel(),y.ravel())),leafsize=10) 
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2) 
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape) 
    return zz 

def dovgrid(xx,yy,zz,r):  
    G = vgrid.vgrid(cs=1,cinf=1.0)  
    G.add(xx,yy,zz,1)  
    return G.zz()
456/15:
# Test to ensure we get the same results:
kd_z = kdtreego(xx,yy,zz,1.0)
vg_z = dovgrid(xx,yy,zz,1.0)

np.sum(np.abs(kd_z - vg_z).ravel() > 1e-10)
456/16:
# Test processing time.
%timeit kd_z = kdtreego(xx,yy,zz,1.0)
%timeit vg_z = dovgrid(xx,yy,zz,1.0)
456/17:
def kdtreego(x,y,z,r): 
    # Create the grid nodes.
    xx = np.arange(min(x),max(x)+1,1) 
    yy = np.arange(min(y),max(y)+1,1) 
    xxx,yyy = np.meshgrid(xx,yy)
    # Create the KDTree and the grid.
    tree = spatial.KDTree(list(zip(x.ravel(),y.ravel())),leafsize=1e7) 
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2) 
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape) 
    return zz 

def dovgrid(xx,yy,zz,r):  
    G = vgrid.vgrid(cs=1,cinf=1.0)  
    G.add(xx,yy,zz,1)  
    return G.zz()
456/18:
def kdtreego_defaultleaf(x,y,z,r): 
    # Create the grid nodes.
    xx = np.arange(min(x),max(x)+1,1) 
    yy = np.arange(min(y),max(y)+1,1) 
    xxx,yyy = np.meshgrid(xx,yy)
    # Create the KDTree and the grid.
    tree = spatial.KDTree(list(zip(x.ravel(),y.ravel()))) 
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2) 
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape) 
    return zz 

%timeit kd_z = kdtreego_default_leaf(xx,yy,zz,1.0)
%timeit vg_z = dovgrid(xx,yy,zz,1.0)
456/19:
def kdtreego_defaultleaf(x,y,z,r): 
    # Create the grid nodes.
    xx = np.arange(min(x),max(x)+1,1) 
    yy = np.arange(min(y),max(y)+1,1) 
    xxx,yyy = np.meshgrid(xx,yy)
    # Create the KDTree and the grid.
    tree = spatial.KDTree(list(zip(x.ravel(),y.ravel()))) 
    indexes = tree.query_ball_point(np.vstack((xxx.ravel(),yyy.ravel())).T,r=r,p=2) 
    zz = np.array([np.nanmean(z[idx]) for idx in indexes]).reshape(xxx.shape) 
    return zz 

%timeit kd_z = kdtreego_defaultleaf(xx,yy,zz,1.0)
%timeit vg_z = dovgrid(xx,yy,zz,1.0)
456/20: xtest = np.concatenate((x,x))
456/21: whos xtest
456/22: whos
456/23: xtest = np.concatenate((x,x,x,x,x,x,x,x,x,x))
456/24: xtest.shape
456/25: xtest = []
456/26:
# Just 100 points
print ("100 points:")
%timeit kd_z = kdtreego(xx[:100],yy[:100],zz[:100],1.0)
%timeit vg_z = dovgrid(xx[:100],yy[:100],zz[:100],1.0)
# 1000 points
print("1000 points")
%timeit kd_z = kdtreego(xx[:1000],yy[:1000],zz[:1000],1.0)
%timeit vg_z = dovgrid(xx[:1000],yy[:1000],zz[:1000],1.0)
# 1e5 points
print("100,000 points")
x1e5 = np.concatinate((xx,xx,xx,xx,xx,xx,xx,xx,xx,xx))
y1e5 = np.concatinate((yy,yy,yy,yy,yy,yy,yy,yy,yy,yy))
z1e5 = np.concatinate((zz,zz,zz,zz,zz,zz,zz,zz,zz,zz))
%timeit kd_z = kdtreego(x1e5,y1e5,z1e5,1.0)
%timeit vg_z = dovgrid(x1e5,y1e5,z1e5,1.0)
456/27:
# Just 100 points
print ("100 points:")
%timeit kd_z = kdtreego(xx[:100],yy[:100],zz[:100],1.0)
%timeit vg_z = dovgrid(xx[:100],yy[:100],zz[:100],1.0)
# 1000 points
print("1000 points:")
%timeit kd_z = kdtreego(xx[:1000],yy[:1000],zz[:1000],1.0)
%timeit vg_z = dovgrid(xx[:1000],yy[:1000],zz[:1000],1.0)
# 1e5 points
print("100,000 points")
x1e5 = np.concatenate((xx,xx,xx,xx,xx,xx,xx,xx,xx,xx))
y1e5 = np.concatenate((yy,yy,yy,yy,yy,yy,yy,yy,yy,yy))
z1e5 = np.concatenate((zz,zz,zz,zz,zz,zz,zz,zz,zz,zz))
%timeit kd_z = kdtreego(x1e5,y1e5,z1e5,1.0)
%timeit vg_z = dovgrid(x1e5,y1e5,z1e5,1.0)
456/28: np.arange(100)
456/29: np.arange(100,.1)
456/30: np.range(0,100,.1)
456/31: np.arange(0,100,.1)
456/32:
xx = np.arange(0,100,.01)
xx = xx + np.random.random(xx.shape())
456/33:
xx = np.arange(0,100,.01)
xx = xx + np.random.random(xx.shape
456/34:
xx = np.arange(0,100,.01)
xx = xx + np.random.random(xx.shape)
456/35: plt.plot(xx,'.')
456/36:
xx = np.arange(0,100,.01)
xx = xx + np.random.random(xx.shape)*7
456/37: plt.plot(xx,'.')
456/38:
xx = np.arange(0,100,.01)
xx = xx + np.random.random(xx.shape)*7
yy = np.arange(0,100,.01)
yy = yy + np.random.random(xx.shape)*7
zz = np.exp( np.sqrt(((xx-50)**2 + (yy-50)**2))/50.0)
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xx,yy,zz,zz,cmap=cm.viridis)
plt.show()
456/39: xx.shape
456/40:
%timeit kd_z = kdtreego(xx,yy,zz,1.0)
%timeit vg_z = dovgrid(xx,yy,zz,1.0)
458/1:
import kmall
import numpy
import bz2
458/2: K = kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
458/3: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
458/4: K.index()
458/5: K.index_file()
458/6: K.Index
458/7:
import kmall
import numpy
import bz2
%matplotlib notebook
import matplotlib.pyplot as plt
458/8:
figure(figsize=(9,8))
plt.plot(np.diff(K.Index.ByteOffset),'.')
458/9:
plt.figure(figsize=(9,8))
plt.plot(np.diff(K.Index.ByteOffset),'.')
458/10:
import kmall
import numpy as np
import bz2
%matplotlib notebook
import matplotlib.pyplot as plt
458/11:
plt.figure(figsize=(9,8))
plt.plot(np.diff(K.Index.ByteOffset),'.')
458/12:
plt.figure(figsize=(9,8))
plt.plot(np.diff(K.Index.ByteOffset),'.')
plt.show()
458/13:
import kmall
import numpy as np
import bz2
%matplotlib inline
import matplotlib.pyplot as plt
458/14:
plt.figure(figsize=(9,8))
plt.plot(np.diff(K.Index.ByteOffset),'.')
plt.show()
458/15: K.Index
458/16:  msg_type_group = self.Index.groupby("MessageType")
458/17:  msg_type_group = K.Index.groupby("MessageType")
458/18: msg_type_group
458/19: print(msg_type_group)
458/20: print(msg_type_group.ByteOffset)
458/21: msg_type_group["MessageType"]
458/22: msg_type_group["MessageType"].count()
458/23: msg_type_group["MessageSize"]
458/24: msg_type_group["MessageSize"].sum()
459/1: import struct
459/2: struct.unpack?
459/3: import kmall
459/4: pwd
459/5: cd gitsrc/kmall
459/6: import kmall
459/7: struct.Struct("2Hf6BH11f2h2BHL3f2Hf2H6f4B2df")
459/8: s = struct.Struct("2Hf6BH11f2h2BHL3f2Hf2H6f4B2df")
459/9: s.size()
459/10: s.size
459/11: import kmall
459/12: import kmall
459/13: import kmall
459/14: import kmall
459/15: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/16: K.index_file()
459/17: K.Index()
459/18: K.Index
459/19: MRZOffsets = [x for x,y in zip(K.msgoffset,K.msgtype) if y == "b'#MRZ'"]
459/20: MRZOffsets[0]
459/21: FID = open(K.filename,'rb')
459/22: FID.seek(MRZOffsets[0],0)
459/23: header = K.read_EMdgmHeader_def(FID)
459/24: header
459/25: partdef = K.read_EMdgmMpartition_def(FID)
459/26: partdef
459/27: body = K.read_EMdgmMbody_def(FID)
459/28: body
459/29: pinginfo = K.read_EMdgrMRZ_pinginfo(FID)
459/30: import importlib
459/31: importlib.reload(kmall)
459/32: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/33: pinginfo = K.read_EMdgrMRZ_pinginfo(FID)
459/34: pinginfo
459/35: FID.seek(MRZOffsets[0],0)
459/36: header = K.read_EMdgmHeader_def(FID)
459/37: header
459/38: partdef = K.read_EMdgmMpartition_def(FID)
459/39: partdef
459/40: body = K.read_EMdgmMbody_def(FID)
459/41: body
459/42: pinginfo = K.read_EMdgrMRZ_pinginfo(FID)
459/43: pinginfo
459/44: importlib.reload(kmall)
459/45: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/46: FID.seek(MRZOffsets[0],0)
459/47: header = K.read_EMdgmHeader_def(FID)
459/48: partdef = K.read_EMdgmMpartition_def(FID)
459/49: body = K.read_EMdgmMbody_def(FID)
459/50: pinginfo
459/51: pinginfo = []
459/52: importlib.reload(kmall)
459/53: importlib.reload(kmall)
459/54: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/55: FID.seek(MRZOffsets[0],0)
459/56: header = K.read_EMdgmHeader_def(FID)
459/57: partdef = K.read_EMdgmMpartition_def(FID)
459/58: body = K.read_EMdgmMbody_def(FID)
459/59: pinginfo = K.read_EMdgrMRZ_pinginfo(FID)
459/60: pinginfo
459/61: importlib.reload(kmall)
459/62: txsect = K.read_EMdgmMRZ_txSectorInfo(FID,3)
459/63: importlib.reload(kmall)
459/64: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/65: txsect = K.read_EMdgmMRZ_txSectorInfo(FID,3)
459/66: struct.Struct("4B7f2BH").size
459/67: fseek(FID,-36,1)
459/68: FID.fseek(FID,-36,1)
459/69: FID.seek(FID,-36,1)
459/70: FID.seek(-36,1)
459/71: txsect = K.read_EMdgmMRZ_txSectorInfo(FID,3)
459/72: txsect
459/73: txsect = K.read_EMdgmMRZ_txSectorInfo(FID,3)
459/74: txsect
459/75: txsect = K.read_EMdgmMRZ_txSectorInfo(FID,3)
459/76: txsect
459/77: importlib.reload(kmall)
459/78: importlib.reload(kmall)
459/79: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/80: rxinfo = K.read_EMdgmMRZ_rxInfo(FID)
459/81: rxinfo
459/82: runcell(0, '/Users/vschmidt/gitsrc/kmall/kmall.py')
459/83: importlib.reload(kmall)
459/84: importlib.reload(kmall)
459/85: ls
459/86: importlib.reload(kmall)
459/87: importlib.reload(kmall)
459/88: ls
459/89: pwd
459/90: ls
459/91: import kmall
459/92: importlib.reload(kmall)
459/93: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/94: s = K.read_EMdgmMRZ_sounding(FID)
459/95: s
459/96: pinginfo
459/97: header
459/98: FID.seek(MRZOffsets[0],0)
459/99: importlib.reload(kmall)
459/100: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/101: dg = K.read_EMdgmMRZ(FID)
459/102: importlib.reload(kmall)
459/103: FID.seek(MRZOffsets[0],0)
459/104: dg = K.read_EMdgmMRZ(FID)
459/105: importlib.reload(kmall)
459/106: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/107: FID.seek(MRZOffsets[0],0)
459/108: dg = K.read_EMdgmMRZ(FID)
459/109: dg
459/110: whos
459/111: dg["soundings"]
459/112: import pandas as pd
459/113: DG = pd.DataFrame(dg)
459/114: whos dg
459/115: whos
459/116: import pandas as pd
459/117: importlib.reload(kmall)
459/118: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/119: FID.seek(MRZOffsets[0],0)
459/120: dg = K.read_EMdgmMRZ(FID)
459/121: importlib.reload(kmall)
459/122: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/123: FID.seek(MRZOffsets[0],0)
459/124: dg = K.read_EMdgmMRZ(FID)
459/125: importlib.reload(kmall)
459/126: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/127: FID.seek(MRZOffsets[0],0)
459/128: dg = K.read_EMdgmMRZ(FID)
459/129: dg["soundings"]
459/130: dg["Slsample_desidB]
459/131: dg["Slsample_desidB"]
459/132: import matplotlib.pyplot as plt
459/133: plt.plot(dg["Slsample_desidB"],'.')
459/134: plt.show()
459/135: plt.plot(20*np.log10(dg["Slsample_desidB"]),'.')
459/136: FID.tell()
459/137: K.Index
459/138: K.index_file()
459/139: K.Index
459/140: a = dg["soundings"]
459/141: whos
459/142: a["x_reRefPoint_m"]
459/143: plt.plot(dg["soundings"]["x_reRefPoint_m"],'.')
459/144: plt.plot(dg["soundings"]["x_reRefPoint_m"],dg["soundings"]["y_reRefPoint_m"],'.')
459/145: plt.plot(dg["soundings"]["y_reRefPoint_m"],dg["soundings"]["x_reRefPoint_m"],'.')
459/146: ax = fig.add_subplot(111, projection='3d')
459/147: fig = plt.figure()
459/148: ax = fig.add_subplot(111, projection='3d')
459/149: ax = fig.add_subplot(111, projection='3D')
459/150: ax = fig.add_subplot(111, projection='3d')
459/151: from mpl_toolkits import Axes3D
459/152: from mpl_toolkits.mplot3d import Axes3D
459/153: ax = fig.add_subplot(111, projection='3d')
459/154: ax.plot(dg["soundings"]["y_reRefPoint_m"],dg["soundings"]["x_reRefPoint_m"],-dg["soundings"]["z_reRefPoint_m"],'.')
459/155: ax.plot(dg["soundings"]["y_reRefPoint_m"],dg["soundings"]["x_reRefPoint_m"],-np.array(dg["soundings"]["z_reRefPoint_m"]),'.')
459/156: plt.show()
459/157: plt.figure()
459/158: ax = fig.add_subplot(111, projection='3d')
459/159: ax.plot(dg["soundings"]["y_reRefPoint_m"],dg["soundings"]["x_reRefPoint_m"],-np.array(dg["soundings"]["z_reRefPoint_m"]),'.')
459/160: ax.plot(dg["soundings"]["y_reRefPoint_m"],dg["soundings"]["x_reRefPoint_m"],-np.array(dg["soundings"]["z_reRefPoint_m"]))
459/161: fig = plt.figure()
459/162: ax = fig.add_subplot(111, projection='3d')
459/163: Axes3D.plot(dg["soundings"]["y_reRefPoint_m"],dg["soundings"]["x_reRefPoint_m"],-np.array(dg["soundings"]["z_reRefPoint_m"]))
459/164: Axes3D.plot(np.array(dg["soundings"]["y_reRefPoint_m"]),np.array(dg["soundings"]["x_reRefPoint_m"]),-np.array(dg["soundings"]["z_reRefPoint_m"]))
459/165: plot(np.array(dg["soundings"]["y_reRefPoint_m"]),np.array(dg["soundings"]["x_reRefPoint_m"]),-np.array(dg["soundings"]["z_reRefPoint_m"]))
459/166: ax.plot(np.array(dg["soundings"]["y_reRefPoint_m"]),np.array(dg["soundings"]["x_reRefPoint_m"]),-np.array(dg["soundings"]["z_reRefPoint_m"]))
459/167: plt.plot(np.array(dg["soundings"]["y_reRefPoint_m"]),-np.array(dg["soundings"]["z_reRefPoint_m"]))
459/168: dg.keys()
459/169: dg["header"].shape
459/170: dg["header"]
459/171: dg.keys()
459/172: dg["txSectorinfo"]
459/173: dg["txSectorinfo"].shape
459/174: dg["txSectorinfo"].size
459/175: len(dg["txSectorinfo"])
459/176:
for k in dg.keys():
    len(dg[k])
459/177:
for k in dg.keys():
    print(len(dg[k]))
459/178: import matplotlib.pyplot as plt
459/179: importlib.reload(kmall)
459/180: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/181: FID.seek(MRZOffsets[0],0)
459/182: dg = K.read_EMdgmMRZ(FID)
459/183: debugfile('/Users/vschmidt/gitsrc/kmall/kmall.py', args='-V  -f 0007_20190513_154724_ASVBEN.kmall', wdir='/Users/vschmidt/gitsrc/kmall')
459/184: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/185: pwd
459/186: importlib.reload(kmall)
459/187: pwd
459/188: import kmall
459/189: K = kmall.kmall(filename="data/0007_20190513_154724_ASVBEN.kmall")
459/190: FID.seek(MRZOffsets[0],0)
459/191: dg = K.read_EMdgmMRZ(FID)
459/192: dg
459/193: dg.keys()
459/194:
for k in dg.keys():
    print(dg[k].keys())
459/195:
for k in dg.keys():
    if dg[k] is not None:
        print(dg[k].keys())
    else:
        print("Nothing in %s" % k)
459/196:
for k in dg.keys():
    if dg[k] is not None:
        if isinstance(dg[k],dict):
            print(dg[k].keys())
        else:
            print(len(dg[k]))
    else:
        print("Nothing in %s" % k)
459/197:
for k in dg.keys():
    if dg[k] is not None:
        if isinstance(dg[k],dict):
            print(dg[k].keys())
        else:
            print("### Not a Dictionary ### %d" %len(dg[k]))
    else:
        print("Nothing in %s" % k)
459/198: import pandas as pd
459/199: DG = pd.DataFrame(dg)
460/1: import xarray as xa
461/1: import xarray as xr
461/2: import numpy as np
461/3: x = np.random.rand((1000,1000))
461/4: x = np.random.rand(1000,1000)
461/5: x = np.random.rand((1000,1000)) * 100
461/6: x = np.random.rand(1000,1000) * 100
461/7: X = xr.DataArray(x)
461/8: x
461/9: x = 100 + np.random.rand(1000,1000) * 5
461/10: X = xr.DataArray(x)
461/11: X
461/12: X.dtype
461/13: X = np.round(X*1000,0)
461/14: X
461/15: X.dtype
461/16: X.dtype = 'int32'
461/17: X2 = X.astype('category')
461/18: X2 = X.astype?
461/19: X2 = X.astype?
461/20: X2 = X.astype("category")
461/21: X2 = X.astype(int32)
461/22: X2 = X.astype(int)
461/23: whos
461/24: X2.info
461/25: X2[0].memory_usage()
461/26: X2[0]
461/27: X2.memory_usage()
461/28: X2.memory_usage
461/29: import sys
461/30: sys.getsizeof(X)
461/31: sys.getsizeof(X2)
461/32: import inspect
461/33: import sys
461/34:
def get_size(obj, seen=None):
    """Recursively finds size of objects in bytes"""
    size = sys.getsizeof(obj)
    if seen is None:
        seen = set()
    obj_id = id(obj)
    if obj_id in seen:
        return 0
    # Important mark as seen *before* entering recursion to gracefully handle
    # self-referential objects
    seen.add(obj_id)
    if hasattr(obj, '__dict__'):
        for cls in obj.__class__.__mro__:
            if '__dict__' in cls.__dict__:
                d = cls.__dict__['__dict__']
                if inspect.isgetsetdescriptor(d) or inspect.ismemberdescriptor(d):
                    size += get_size(obj.__dict__, seen)
                break
    if isinstance(obj, dict):
        size += sum((get_size(v, seen) for v in obj.values()))
        size += sum((get_size(k, seen) for k in obj.keys()))
    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):
        size += sum((get_size(i, seen) for i in obj))
        
    if hasattr(obj, '__slots__'): # can have __slots__ with __dict__
        size += sum(get_size(getattr(obj, s), seen) for s in obj.__slots__ if hasattr(obj, s))
        
    return size
461/35: gt_size(X)
461/36: whos?
461/37: gett_size(X)
461/38: get_size(X)
461/39: import resource
461/40: resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
461/41: X[0].nbytes
461/42: X2[0].nbytes
461/43: X
461/44: X.dtype
461/45: X2.dtype
461/46: X2 = X.astype(short)
461/47: X2 = X.astype('short')
461/48: X2[0].nbytes
461/49: import pickle
461/50: import cPickle
461/51: a = pickle.dumps(X)
461/52: a.nbytes
461/53: len(a)
461/54: b = pickle.dumps(X2)
461/55: len(b)
461/56: x.bytes
461/57: x.nbytes
461/58: import matplotlib.pyplot as plt
461/59: plt.plot(x,'.')
461/60: plt.plot(x.ravel(),'.')
461/61: x2 = x-np.mean(x)
461/62: mx = np.mean(x)
461/63: plt.plot(x2,'.')
461/64: plt.plot(x.ravel(),'.')
461/65: plt.plot(x.ravel(),'.')
461/66: plt.plot(x2.ravel(),'.')
461/67: p = np.polyfit(np.range(len(x)),x,2)
461/68: p = np.polyfit(np.arange(len(x)),x,2)
461/69: p
461/70: p = np.polyfit(np.arange(len(x.ravel())),x.ravel(),2)
461/71: p
461/72: p = np.polyfit(np.arange(len(x.ravel())),x.ravel(),1)
461/73: p
461/74: p,res = np.polyfit(np.arange(len(x.ravel())),x.ravel(),1)
461/75: res
461/76: p
461/77: p,res = np.polyfit(np.arange(len(x.ravel())),x.ravel(),1,full=True)
461/78: p,resid,rank,sv,rcond  = np.polyfit(np.arange(len(x.ravel())),x.ravel(),1,full=True)
461/79: resid
461/80: p = np.polyfit(np.arange(len(x.ravel())),x.ravel(),1)
461/81: xp = p(x.ravel())
461/82: pp = np.poly1d(p)
461/83: res = x-pp(xx)
461/84: res = x-pp(x)
461/85: res.nbytes
461/86: plt.hist(res.ravel(),100)
461/87: plt.plot(plt.hist(res.ravel(),100))
461/88: plt.bar(plt.hist(res.ravel(),100))
461/89: plt.hist(res.ravel(),bins=100)
461/90: plt.show()
461/91: plt.hist(res.ravel(),bins=100)
461/92: res
461/93: RES = np.round(res*1000,3)
461/94: plt.hist(RES.ravel(),bins=100)
461/95: import bz2
461/96: whos
461/97: az = bz2.compress(a)
461/98: len(az)
461/99: len(a)-len(az)
461/100: (len(a)-len(az))/len(a)*100
461/101: bz = bz2.compress(b)
461/102: (len(b)-len(bz))/len(b)*100
461/103: (len(a)-len(bz))/len(a)*100
461/104: len(a)
461/105: len(bz)
461/106: len(a)-len(bz)
461/107: len(B)
461/108: len(b)
461/109: len(a)
461/110: (len(a)-len(bz))/len(a)*100
461/111: x = np.arange(10000) * np.rand(10000,1)*5
461/112: x = np.arange(10000) * np.random.rand(10000,1)*5
461/113: plt.plot(x,'.')
462/1: import xarray as xr
462/2: import numpy as np
462/3: x = np.arange(10000)
462/4: x.shape
462/5: x = np.arange(10000) + np.random.random(10000,1)
462/6: x = np.arange(10000) + np.random.rand(10000,1)
462/7: import matplotlib.pyplot as plt
462/8: plt.plot(x,'.')
   1: np.random.rand(10).shape
   2: import numpy as np
   3: import xarray as xr
   4: np.random.rand(10).shape
   5: x = np.arange(10000) + np.random.rand(10000)
   6: x.shape
   7: import matplotlib.pyplot as plt
   8: plt.plot(x,'.')
   9: x = np.arange(10000)
  10: y = x * np.max(x)/10 + np.random.rand(10000)
  11: plt.plot(x,y,'.')
  12: y = x * 10/np.max(x) + np.random.rand(10000)
  13: plt.plot(x,y,'.')
  14: import bz2
  15: a = np.zeros(1e3)
  16: a = np.zeros((1e3,1))
  17: a = np.zeros((1000,1))
  18: az = bz2.compress(a)
  19: import pickle
  20: len(pickle.dumps(a))
  21: len(pickle.dumps(az))
  22: P = np.polyfit(x,y,1)
  23: PP = np.poly1d(P)
  24: res_int3 = np.round((y-PP(x))*1000,3)
  25: res_int3 = np.round((y-PP(x))*1000,3)
  26: len(res_int3)
  27: len(np.unique(res_int3))
  28: res3_int3_short = res_int3.astype(short)
  29: res3_int3_short = res_int3.astype("short")
  30: res3_int3_short_bz = bz2.compress(res3_int3_short)
  31: len(res3_int3_short_bz)
  32: len(pickle.dumps(res3_int3_short_bz))
  33: len(pickle.dumps(y))
  34: len(pickle.dumps(res3_int3_short))
  35: np.sort?
  36: len(pickle.dumps(bz2.compress(res_int3_short)))
  37: len(pickle.dumps(bz2.compress(res3_int3_short)))
  38: len(pickle.dumps(bz2.compress(np.sort(res3_int3_short))))
  39: index = np.argsort(res3_int3_short)
  40: len(pickle.dumps(bz2.compress([index,res3_int3_short[index]])))
  41: len(pickle.dumps(bz2.compress(pickle.dumps([index,res3_int3_short[index]]))))
  42: len(pickle.dumps(bz2.compress(pickle.dumps(res3_int3_short[index]))))
  43: index
  44: index_int = index.astype(ushort)
  45: index_int = index.astype("ushort")
  46: len(pickle.dumps(bz2.compress(pickle.dumps([index_int,res3_int3_short[index]]))))
  47: index_int.nbytes
  48: index.nbytes
  49: plt.plot(index_int,'.')
  50: len(bz2.compress(pickle.dumps([index_int,res3_int3_short[index]])))
  51: len(bz2.compress(pickle.dumps([index,res3_int3_short[index]])))
  52: x.nbytes
  53: len(bz2.compress(pickle.dumps(res3_int3_short)))
  54: len(bz2.compress(pickle.dumps((np.round(y,3)*1000).astype("short"))))
  55: 13433/17077
  56: P = np.polyfit(x,y,2)
  57: PP = np.poly1d(P)
  58: len(bz2.compress(pickle.dumps((np.round(y-PP(x),3)*1000).astype("short"))))
  59: P = np.polyfit(x,y,4)
  60: PP = np.poly1d(P)
  61: len(bz2.compress(pickle.dumps((np.round(y-PP(x),3)*1000).astype("short"))))
  62: P = np.polyfit(x,y,10)
  63: PP = np.poly1d(P)
  64: len(bz2.compress(pickle.dumps((np.round(y-PP(x),3)*1000).astype("short"))))
  65: P = np.polyfit(x,y,1)
  66: PP = np.poly1d(P)
  67: len(bz2.compress(pickle.dumps((np.round(y-PP(x),3)*1000).astype("short"))))
  68: len(bz2.compress(pickle.dumps((np.round(np.diff(y),3)*1000).astype("short"))))
  69: len(bz2.compress(pickle.dumps((np.round(np.diff(y-PP(x)),3)*1000).astype("short"))))
  70: y = [x[:5000] * 10/np.max(x) + np.random.rand(5000),x[5000:]*10/np.max() + np.random.rand(5000)].ravel()
  71: y = [x[:5000] * 10/np.max(x) + np.random.rand(5000),x[5000:]*10/np.max(x) + np.random.rand(5000)].ravel()
  72: y = np.array([x[:5000] * 10/np.max(x) + np.random.rand(5000),x[5000:]*10/np.max(x) + np.random.rand(5000)]).ravel()
  73: y.shape
  74: y = np.array([x[:5000] * 10/np.max(x) + np.random.rand(5000),x[5000:]*10/np.max(x) + 30 + np.random.rand(5000)]).ravel()
  75: plt.plot(x,y,'.')
  76: yrand = y(np.random.randint(y.shape))
  77: yrand = y[np.random.randint(y.shape)]
  78: plt.plot(x,yrand,'.')
  79: yrand.shape
  80: np.random.randint(y.shape).shape
  81: y.shape
  82: np.random.randint?
  83: yrand = y[np.random.randint(1,10000,size=y.shape)]
  84: yrand.shape
  85: plt.plot(x,yrand,'.')
  86: plt.close()
  87: len(bz2.compress(pickle.dumps((np.round(yrand,3)*1000).astype("short"))))
  88: len(bz2.compress(pickle.dumps((np.round(rand,3)*1000).astype("short"))))
  89: len(bz2.compress(pickle.dumps((np.round(y,3)*1000).astype("short"))))
  90: history
  91: %history -g -f compressiontestinghistory.txt
