{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The KMALL Data Reader\n",
    "This KMALL data reader is incomplete, but a good start. The following will guide one through what's currently possible. At the end is a section on commandline capability of `kmall.py` - be sure to check that out. Finally there's also a list of obvious things that are yet to be completed or might be in place, but warrant rethinking. \n",
    "\n",
    "## Installing the package\n",
    "There are a few ways to install the package, as there is a standard `setup.py` file. But one of the easiest follows, which will make the package available with a simple import statement, and the `kmall` commandline utility available to your command prompt. Execute the following in this kmall repository directory. \n",
    "\n",
    "`pip install -e .`\n",
    "\n",
    "The `-e` means we want to install the package in *editable* mode, meaning that if we edit any of the files in the package we do not have to reinstall the package for them to come into effect. We do have to reload the package or restart the python Kernel and reload it. \n",
    "\n",
    "\n",
    "## The kmall Python Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import KMALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each kmall object is associated with a datafile. So when creating an object, pass the filename to be associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = KMALL.kmall('data/0007_20190513_154724_ASVBEN.kmall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file can be indexed with the following. This happens automatically when reading the file for other purposes, but sometimes you want the index itself, so you can call it directly as shown here. The index itself is a pandas DataFrame, and we can look at first several rows of the index to get an idea of what's inside. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ByteOffset  MessageSize MessageType\n",
      "Time                                             \n",
      "1.557762e+09           0         1054     b'#IIP'\n",
      "1.557762e+09        1054         1332     b'#IOP'\n",
      "1.557762e+09        2386          292     b'#SVP'\n",
      "1.557762e+09        2678           68     b'#SVT'\n",
      "1.557762e+09        2746           68     b'#SVT'\n",
      "1.557762e+09        2814           68     b'#SVT'\n",
      "1.557762e+09        2882           68     b'#SVT'\n",
      "1.557762e+09        2950           68     b'#SVT'\n",
      "1.557762e+09        3018           68     b'#SVT'\n",
      "1.557762e+09        3086           68     b'#SVT'\n",
      "1.557762e+09        3154           68     b'#SVT'\n",
      "1.557762e+09        3222           68     b'#SVT'\n",
      "1.557762e+09        3290        13368     b'#SKM'\n",
      "1.557762e+09       16658           68     b'#SVT'\n",
      "1.557762e+09       16726           68     b'#SVT'\n",
      "1.557762e+09       16794           68     b'#SVT'\n",
      "1.557762e+09       16862          156     b'#SPO'\n",
      "1.557762e+09       17018        69036     b'#MRZ'\n",
      "1.557762e+09       86054        68996     b'#MRZ'\n",
      "1.557762e+09      155050        68938     b'#MRZ'\n"
     ]
    }
   ],
   "source": [
    "K.index_file()\n",
    "print(K.Index.iloc[0:20,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to have a summary of the types of packets in a file. This can be done with the `report_packet_types()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Count     Size:  Min Size  Max Size\n",
      "MessageType                                     \n",
      "b'#CPO'         87     13572       156       156\n",
      "b'#IIP'          1      1054      1054      1054\n",
      "b'#IOP'          1      1332      1332      1332\n",
      "b'#MRZ'        472  32556126     68688     69120\n",
      "b'#SCL'         87      6612        76        76\n",
      "b'#SKM'         86   1159680     13368     13632\n",
      "b'#SPO'         87     13572       156       156\n",
      "b'#SVP'          1       292       292       292\n",
      "b'#SVT'       2181    148308        68        68\n"
     ]
    }
   ],
   "source": [
    "K.report_packet_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Kongsberg system installation suffer from networking problems (or hardware malfunctions of the CPU), they sometimes loose data packets.  While there is indication in SIS 4/5 if incoming data to the PPU (navigation, attitude, velocity) has gaps, there is often not any indication that the sonar records coming out of the PPU have gaps. If the extent of the problem is great enough, there will be a \"Failure to report depths.\" error, but if not, the system will silently log data with the occasional missing record. \n",
    "\n",
    "In an effort to try to detect this in logged data files a routine has been written, `check_ping_count()`, which compares the ping indices (these values increase with each ping cycle, but repeat for each swath within a ping cycle), indices of expected receive fans and tne number of received *MRZ* records (there should be 1 per receive fan), and reports anything missing. \n",
    "\n",
    "In the future, the check will also audit the navigation and attitude data (which are stored in the same record when supplied by a POS/MV Group record via Ethernet) and report gaps in the record when they exist. This is done currently in if the module is run as a script on a file (more about that later), but not yet implemented as a class method.\n",
    "\n",
    "Here's an example, where the results are both printed out by default and returned as a tuple for internal use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   File  NpingsTotal  Pings Missed  MissingMRZRecords\n",
      " data/0007_20190513_154724_ASVBEN.kmall          238             2                  0\n"
     ]
    }
   ],
   "source": [
    "result = K.check_ping_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, there should be 238 pings based on the difference in first and last ping indices, but two pings were missed in the middle.  However all the MRZ records associated with each existing ping record were found. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future there will be utilty functions to make this process easier, for now one must extract desired data manually. Not all records can be read yet, but reading of complete MRZ records is supported. First lets filter the index for MRZ records: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ByteOffset</th>\n",
       "      <th>MessageSize</th>\n",
       "      <th>MessageType</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.557762e+09</th>\n",
       "      <td>17018</td>\n",
       "      <td>69036</td>\n",
       "      <td>b'#MRZ'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.557762e+09</th>\n",
       "      <td>86054</td>\n",
       "      <td>68996</td>\n",
       "      <td>b'#MRZ'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.557762e+09</th>\n",
       "      <td>155050</td>\n",
       "      <td>68938</td>\n",
       "      <td>b'#MRZ'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.557762e+09</th>\n",
       "      <td>223988</td>\n",
       "      <td>69006</td>\n",
       "      <td>b'#MRZ'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.557762e+09</th>\n",
       "      <td>294110</td>\n",
       "      <td>69044</td>\n",
       "      <td>b'#MRZ'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ByteOffset  MessageSize MessageType\n",
       "Time                                             \n",
       "1.557762e+09       17018        69036     b'#MRZ'\n",
       "1.557762e+09       86054        68996     b'#MRZ'\n",
       "1.557762e+09      155050        68938     b'#MRZ'\n",
       "1.557762e+09      223988        69006     b'#MRZ'\n",
       "1.557762e+09      294110        69044     b'#MRZ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iMRZ = K.Index[\"MessageType\"] == \"b'#MRZ'\"\n",
    "MRZIndex = K.Index[iMRZ]\n",
    "MRZIndex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can open the file, seek to the first record location and read the record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRZ Records:  header,partition,cmnPart,pingInfo,txSectorInfo,rxInfo,extraDetClassInfo,sounding,SIsample_desidB\n",
      "Soundings Record Fields: soundingIndex,\n",
      "\ttxSectorNumb,\n",
      "\tdetectionType,\n",
      "\tdetectionMethod,\n",
      "\trejectionInfo1,\n",
      "\trejectionInfo2,\n",
      "\tpostProcessingInfo,\n",
      "\tdetectionClass,\n",
      "\tdetectionConfidenceLevel,\n",
      "\tpadding,\n",
      "\trangeFactor,\n",
      "\tqualityFactor,\n",
      "\tdetectionUncertaintyVer_m,\n",
      "\tdetectionUncertaintyHor_m,\n",
      "\tdetectionWindowLength_sec,\n",
      "\techoLength_sec,\n",
      "\tWCBeamNumb,\n",
      "\tWCrange_samples,\n",
      "\tWCNomBeamAngleAcross_deg,\n",
      "\tmeanAbsCoeff_dbPerkm,\n",
      "\treflectivity1_dB,\n",
      "\treflectivity2_dB,\n",
      "\treceiverSensitivityApplied_dB,\n",
      "\tsourceLevelApplied_dB,\n",
      "\tBScalibration_dB,\n",
      "\tTVG_dB,\n",
      "\tbeamAngleReRx_deg,\n",
      "\tbeamAngleCorrection_deg,\n",
      "\ttwoWayTravelTime_sec,\n",
      "\ttwoWayTravelTimeCorrection_sec,\n",
      "\tdeltaLatitude_deg,\n",
      "\tdeltaLongitude_deg,\n",
      "\tz_reRefPoint_m,\n",
      "\ty_reRefPoint_m,\n",
      "\tx_reRefPoint_m,\n",
      "\tbeamIncAngleAdj_deg,\n",
      "\trealTimeCleanInfo,\n",
      "\tSIstartRange_samples,\n",
      "\tSIcentreSample,\n",
      "\tSInumSamples\n"
     ]
    }
   ],
   "source": [
    "K.OpenFiletoRead()\n",
    "K.FID.seek(MRZIndex[\"ByteOffset\"].iloc[0],0)\n",
    "dg = K.read_EMdgmMRZ()\n",
    "print(\"MRZ Records:  \" + \",\".join( dg.keys()))\n",
    "print(\"Soundings Record Fields: \" + \",\\n\\t\".join(dg[\"sounding\"].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a debugging method `print_datagram()` for printing the fields of a record. It is very verbose, but can be helpful to dump everything to sort out a problem. Here's an example on the MRZ header, which is not so large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "numBytesDgm:\t\t\t69036\n",
      "\n",
      "dgmType:\t\t\tb'#MRZ'\n",
      "\n",
      "dgmVersion:\t\t\t0\n",
      "\n",
      "systemID:\t\t\t40\n",
      "\n",
      "echoSounderID:\t\t\t2040\n",
      "\n",
      "dgtime:\t\t\t1557762443.1261249\n",
      "\n",
      "dgdatetime:\t\t\t2019-05-13 15:47:23.126125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "K.print_datagram(dg[\"header\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The kmall.py Commandline Utility\n",
    "In addition to being able to parse kmall data files, kmall.py has a lot of functionality build right in when called on the command line. Here are some examples: \n",
    "\n",
    "(Note that access to the bash shell from this python notebook requires pre-pending each line with `!`. This should be omitted when calling directly from the command line. Also note that kmall.py will be installed in your default python scripts directory.)\n",
    "\n",
    "First we can see what is possible by asking for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: kmall.py [-h] [-f KMALL_FILENAME] [-d KMALL_DIRECTORY] [-V] [-z]\r\n",
      "                [-l COMPRESSIONLEVEL] [-Z] [-v]\r\n",
      "\r\n",
      "A python script (and class) for parsing Kongsberg KMALL data files.\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help           show this help message and exit\r\n",
      "  -f KMALL_FILENAME    The path and filename to parse.\r\n",
      "  -d KMALL_DIRECTORY   A directory containing kmall data files to parse.\r\n",
      "  -V                   Perform series of checks to verify the kmall file.\r\n",
      "  -z                   Create a compressed (somewhat lossy) version of the\r\n",
      "                       file. See -l\r\n",
      "  -l COMPRESSIONLEVEL  Set the compression level (Default: 0). 0: Somewhat\r\n",
      "                       lossy compression of soundings and imagery\r\n",
      "                       data.(Default) 1: Somewhat lossy compression of\r\n",
      "                       soundings with imagery omitted.\r\n",
      "  -Z                   Decompress a file compressed with this library. Files\r\n",
      "                       must end in .Lz, where L is an integer indicating the\r\n",
      "                       compression level (set by -l when compresssing)\r\n",
      "  -v                   Increasingly verbose output (e.g. -v -vv -vvv),for\r\n",
      "                       debugging use -vvv\r\n"
     ]
    }
   ],
   "source": [
    "!./KMALL/kmall.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Verification\n",
    "Suppose I want to verify that no ping records are missing from a data file and there are no gaps in the navigation. I can check it with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: data/0007_20190513_154724_ASVBEN.kmall\n",
      "             Count     Size:  Min Size  Max Size\n",
      "MessageType                                     \n",
      "b'#CPO'         87     13572       156       156\n",
      "b'#IIP'          1      1054      1054      1054\n",
      "b'#IOP'          1      1332      1332      1332\n",
      "b'#MRZ'        472  32556126     68688     69120\n",
      "b'#SCL'         87      6612        76        76\n",
      "b'#SKM'         86   1159680     13368     13632\n",
      "b'#SPO'         87     13572       156       156\n",
      "b'#SVP'          1       292       292       292\n",
      "b'#SVT'       2181    148308        68        68\n",
      "                                   File  NpingsTotal  Pings Missed  MissingMRZRecords\n",
      " data/0007_20190513_154724_ASVBEN.kmall          238             2                  0\n",
      "Packet statistics:\n",
      "                                     File  Npings  NpingsMissing  NMissingMRZ  NavMinTimeGap  NavMaxTimeGap  NavMeanTimeGap  NavMeanFreq  NavNGaps>1s\n",
      "0  data/0007_20190513_154724_ASVBEN.kmall     238              2            0            0.0       0.010001        0.009997   100.034501            0\n"
     ]
    }
   ],
   "source": [
    "!./KMALL/kmall.py -f data/0007_20190513_154724_ASVBEN.kmall -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above the number of packets of each type are reported, along with how many bytes that packet type takes up in the file. It is sometimes useful to see the minimum and maximum size for a given packet type when troubleshooting, so these are reported too. \n",
    "\n",
    "Next the file is checked for missing pings records and this is assessed from the ping counter index. But a single ping can consist for multiple \"MRZ\" records. Two are reported for each swath in dual-swath mode, and the file format is agile such that is is possible to report them for individual transmit sectors. Every MRZ record reports an index indicating which \"receive fan\" this data holds, and the total number of receive fans (e.g. MRZ records) to expect. These numbers are used to look for missing MRZ records and these are also reported. \n",
    "\n",
    "Finally, the attitude data is extracted from the file (this may or may not include position information, for example, when the system logs Group 102/103 messages from a POS/MV over Ethernet), and the difference in successive time-stamps is calculated. Statistis of these differences is reported.\n",
    "\n",
    "### Compression \n",
    "**This is an exerimental feature.**\n",
    "\n",
    "Another useful tool in the `kmall.py` utilty belt is file compression. The kmall data format is rather inefficiently encoded and a few routines exist to reorganize and compress the data. The goal of these routines is to provide a significantly smaller file for more efficient transmission over a telemetry link. \n",
    "\n",
    "To accomplish this, new datagram format types are defined. Currently two methods are used, and the resulting datagrams have 3-letter identifiers \"#CZ0\" and \"#CZ1\".  These are non-standard, unapproved by Kongsberg, and an application not capabile of ignoring datagrams it doesn't understand will likely crash when trying to read them. Thus it is recommended that these formats be used in a temporary way for file transport, then decompressed and the compressed versions deleted to ensure compressed version are never accidentally archived.  \n",
    "THESE ROUTINES ARE LOSSY, meaning that a decompressed file is not identical to the original. However, the portions of the file not retained largely result from converting floating point values into integers and an effort has been made to do so in a way that will not loose data of any significance. Reasonable people can disagree about this (Do we need position to mm's or beam reflectivity to 0.000001?), and there may be errors (or bugs) in the methods resulting from testing only on shallow water systems. Thus the exerimental nature. \n",
    "\n",
    "Compression levels 0 and 1 are defined (hence CZ0 and CZ1 above). Level 0 reorganizes the sounding and imagery data, re-encodes it and compresses it before writing it to disk. Level 1 does the same but omits the imagery data altogether, because sometimes getting a start on the bathy processing is enough. Obviously Level 1 is not really compression and is very lossy. \n",
    "\n",
    "Note: There is more work to be done here and an additional file size reduction can be had by running a standard compression tool on the resulting file. \n",
    "\n",
    "Here's how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxr-xr-x  1 vschmidt  1129769604    32M Mar 17  2020 \u001b[31mcompressiondata/0007_20190513_154724_ASVBEN.kmall\u001b[m\u001b[m\n",
      "-rwxr-xr-x  1 vschmidt  1129769604    20M Oct 11 17:54 \u001b[31mcompressiondata/0007_20190513_154724_ASVBEN.kmall.test.bz2\u001b[m\u001b[m\n",
      "\n",
      "Processing: compressiondata/0007_20190513_154724_ASVBEN.kmall\n",
      "Compressing soundings and imagery.\n",
      "-rw-r--r--  1 vschmidt  1129769604    14M Mar 17  2020 compressiondata/0007_20190513_154724_ASVBEN.kmall.0z\n",
      "\n",
      "Processing: compressiondata/0007_20190513_154724_ASVBEN.kmall\n",
      "Compressing soundings, omitting imagery.\n",
      "-rw-r--r--  1 vschmidt  1129769604   7.6M Mar 17  2020 compressiondata/0007_20190513_154724_ASVBEN.kmall.1z\n",
      "-rw-r--r--  1 vschmidt  1129769604    13M Mar 17  2020 compressiondata/0007_20190513_154724_ASVBEN.kmall.0z.bz2\n",
      "-rw-r--r--  1 vschmidt  1129769604   7.0M Mar 17  2020 compressiondata/0007_20190513_154724_ASVBEN.kmall.1z.bz2\n",
      "\n",
      "Processing: compressiondata/0007_20190513_154724_ASVBEN.kmall.0z\n",
      "Decompressing soundings and imagery.(Level: 0)\n",
      "-rw-r--r--  1 vschmidt  1129769604    32M Mar 17  2020 compressiondata/0007_20190513_154724_ASVBEN_01.kmall\n",
      "\n",
      "Processing: compressiondata/0007_20190513_154724_ASVBEN.kmall.1z\n",
      "Decompessing soundings, imagery was omitted in this format. (Level: 1)\n",
      "-rw-r--r--  1 vschmidt  1129769604    23M Mar 17  2020 compressiondata/0007_20190513_154724_ASVBEN_02.kmall\n"
     ]
    }
   ],
   "source": [
    "# Standard bzip2 compression on a test file...\n",
    "!ls -lh compressiondata/0007_20190513_154724_ASVBEN.kmall\n",
    "!cp compressiondata/0007_20190513_154724_ASVBEN.kmall compressiondata/0007_20190513_154724_ASVBEN.kmall.test\n",
    "!bzip2 -f compressiondata/0007_20190513_154724_ASVBEN.kmall.test\n",
    "!ls -lh compressiondata/0007_20190513_154724_ASVBEN.kmall.test.bz2\n",
    "\n",
    "# kmall compresssion on the same file. \n",
    "!./KMALL/kmall.py -f compressiondata/0007_20190513_154724_ASVBEN.kmall -z -l0\n",
    "!ls -lh compressiondata/0007_20190513_154724_ASVBEN.kmall.0z\n",
    "!./KMALL/kmall.py -f compressiondata/0007_20190513_154724_ASVBEN.kmall -z -l1\n",
    "!ls -lh compressiondata/0007_20190513_154724_ASVBEN.kmall.1z\n",
    "\n",
    "# Now bzip2 that.\n",
    "!bzip2 compressiondata/0007_20190513_154724_ASVBEN.kmall.0z\n",
    "!bzip2 compressiondata/0007_20190513_154724_ASVBEN.kmall.1z\n",
    "!ls -lh compressiondata/0007_20190513_154724_ASVBEN.kmall.0z.bz2\n",
    "!ls -lh compressiondata/0007_20190513_154724_ASVBEN.kmall.1z.bz2\n",
    "\n",
    "# Now decompress those files to see the difference in file size.\n",
    "# Note that kmall.py is careful not to clobber the original file.\n",
    "!bunzip2 compressiondata/0007_20190513_154724_ASVBEN.kmall.0z.bz2\n",
    "!bunzip2 compressiondata/0007_20190513_154724_ASVBEN.kmall.1z.bz2\n",
    "!./KMALL/kmall.py -f compressiondata/0007_20190513_154724_ASVBEN.kmall.0z -Z\n",
    "!ls -lh compressiondata/0007_20190513_154724_ASVBEN_01.kmall\n",
    "\n",
    "\n",
    "!./KMALL/kmall.py -f compressiondata/0007_20190513_154724_ASVBEN.kmall.1z -Z\n",
    "!ls -lh compressiondata/0007_20190513_154724_ASVBEN_02.kmall\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example we start with a 32 MB file. Native bzip2 compression alone produces a 20 MB file.\n",
    "\n",
    "`kmall.py` compression at Level 0 produces a 14 MB file, and bzip2 compression of that gives a 13 MB file.\n",
    "\n",
    "`kmall.py` compression at Level 1 (omitting imagery) produces a 7.6 MB file, and bzip2 compression of that gives a 7.0 MB file. \n",
    "\n",
    "\n",
    "On this file, the Level 0 method reduces the file size to about 40% of the original, and the Level 1 method reduces it to about 20% of the orginal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next:\n",
    "Here's a list of improvements that need to be made:\n",
    "\n",
    "1. The installation parameters datagram can be read, but the text string cannot yet be parsed. (done)\n",
    "2. The runtime parameters datagram can be read, but the text string cannot yet be parsed. (done)\n",
    "3. The file Index is indexed by time in Unix format. These could/should be converted to human readable times.\n",
    "4. In file index message type is not a simple \"MRZ\" but rather the text \"b'#MRZ'\". This could be simplified.\n",
    "5. There is not yet a read_next_datagram() method, which can be useful to walk through a file. (although the index helps) (done)\n",
    "6. There is not yet a utilty function that can extract all the sounding data in x,y,z re vessel and x,y,z in geographic coordinates and meters for a) the ping and b) all pings between two indices and c) the whole file. \n",
    "7. The packets related to BIS error reports, reply, and short reply cannot yet be read / interpreted. \n",
    "8. The water column datagram, #MWC, cannot yet be read. (DONE)\n",
    "9. A \"compression\" method could drop the high rate navigation datagrams, (assuming there is no need for it)\n",
    "10. Lots of improvements in efficiency. \n",
    "11. Kongsberg has incremented the versions of their datagrams in a way that is not backward compatible and this code does not yet handle multiple versions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
